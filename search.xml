<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python standard library binascii]]></title>
    <url>%2F2020%2F02%2F24%2Fpython-standard-library-binascii%2F</url>
    <content type="text"><![CDATA[python 标准库 binascii the love of father is like a mountain 父爱如山 binascii 模块包含很多在二进制和二进制表示的各种ASCII码之间转换的方法。 通常情况不会直接使用这些函数，而是使用像 uu ， base64 ，或 binhex 这样的封装模块。 为了执行效率高，binascii 模块含有许多用 C 写的低级函数，这些底层函数被一些高级模块所使用。 a2b_* 函数接受只含有 ASCII 码的Unicode 字符串。其他函数只接受 字节类对象 （例如 bytes，bytearray 和其他支持缓冲区协议的对象）。 函数 binascii.a2b_uu(string) 将单行 uu 编码数据转换成二进制数据并返回。uu 编码每行的数据通常包含45 个（二进制）字节，最后一行除外。每行数据后面可能跟有空格。 binascii.b2a_uu(data, **, backtick=False*) 将二进制数据转换为 ASCII 编码字符，返回值是转换后的行数据，包括换行符。 data 的长度最多为45。如果 backtick 为ture，则零由 &#39;‘` 而不是空格表示。在 3.7 版更改: 增加 backtick 形参。 binascii.a2b_base64(string) 将 base64 数据块转换成二进制并以二进制数据形式返回。一次可以传递多行数据。 binascii.b2a_base64(data, **, newline=True*) 将二进制数据转换为一行用 base64 编码的ASCII字符串。返回值是转换后的行数据，如果 newline 为true，则返回值包括换行符。该函数的输出符合：rfc：3548。在 3.6 版更改: 增加 newline 形参。 binascii.a2b_qp(data, header=False) 将一个引号可打印的数据块转换成二进制数据并返回。一次可以转换多行。如果可选参数 header 存在且为true，则数据中的下划线将被解码成空格。 binascii.b2a_qp(data, quotetabs=False, istext=True, header=False) 将二进制数据转换为一行或多行带引号可打印编码的ASCII字符串。返回值是转换后的行数据。如果可选参数 quotetabs 存在且为真值，则对所有制表符和空格进行编码。如果可选参数 istext 存在且为真值，则不对新行进行编码，但将对尾随空格进行编码。如果可选参数 header 存在且为true，则空格将被编码为下划线 RFC 1522。如果可选参数 header 存在且为假值，则也会对换行符进行编码;不进行换行转换编码可能会破坏二进制数据流。 binascii.a2b_hqx(string) 将 binhex4 格式的 ASCII 数据不进行 RLE 解压缩直接转换为二进制数据。该字符串应包含完整数量的二进制字节，或者（在binhex4 数据最后部分）剩余位为零。 binascii.rledecode_hqx(data) 根据 binhex4 标准对数据执行 RLE 解压缩。该算法在一个字节的数据后使用 0x90 作为重复指示符，然后计数。计数 0 指定字节值 0x90 。该例程返回解压缩的数据，输入数据以孤立的重复指示符结束的情况下，将引发 Incomplete 异常。在 3.2 版更改: 仅接受 bytestring 或 bytearray 对象作为输入。 binascii.rlecode_hqx(data) 在 data 上执行 binhex4 游程编码压缩并返回结果。 binascii.b2a_hqx(data) 执行 hexbin4 类型二进制到 ASCII 码的转换并返回结果字符串。输入数据应经过 RLE 编码，且数据长度可被3整除（除了最后一个片段）。 binascii.crc_hqx(data, value) 以 value 作为初始 CRC 计算 data 的16位 CRC 值，返回其结果。这里使用 CRC-CCITT 生成多项式 x16 + x12 + x5 + 1 ，通常表示为0x1021。该 CRC 被用于 binhex4 格式。 binascii.crc32(data[, value]) 计算 CRC-32 ，从 value 的初始 CRC 开始计算 data 的32位校验和。默认初始 CRC 为零。该算法与 ZIP 文件校验和一致。由于该算法被设计用作校验和算法，因此不适合用作通用散列算法。使用方法如下： 12345print(binascii.crc32(b"hello world"))# Or, in two pieces:crc = binascii.crc32(b"hello")crc = binascii.crc32(b" world", crc)print('crc32 = &#123;:#010x&#125;'.format(crc)) 在 3.0 版更改: 校验结果始终是无符号类型的。要在所有Python版本和平台上生成相同的数值，请使用 crc32(data) &amp; 0xffffffff 。 binascii.b2a_hex(data[, sep[, bytes_per_sep=1]]) binascii.hexlify(data[, sep[, bytes_per_sep=1]]) 返回二进制数据 data 的十六进制表示形式。 data 的每个字节都被转换为相应的2位十六进制表示形式。因此返回的字节对象的长度是 data 的两倍。 使用：bytes.hex() 方法也可以方便地实现相似的功能（但仅返回文本字符串）。 如果指定了 sep，它必须为单字符 str 或 bytes 对象。 它将被插入每个 bytes_per_sep 输入字节之后。 分隔符位置默认从输出的右端开始计数，如果你希望从左端开始计数，请提供一个负的 bytes_per_sep 值。 123456789&gt;&gt;&gt; import binascii&gt;&gt;&gt; binascii.b2a_hex(b'\xb9\x01\xef')b'b901ef'&gt;&gt;&gt; binascii.hexlify(b'\xb9\x01\xef', '-')b'b9-01-ef'&gt;&gt;&gt; binascii.b2a_hex(b'\xb9\x01\xef', b'_', 2)b'b9_01ef'&gt;&gt;&gt; binascii.b2a_hex(b'\xb9\x01\xef', b' ', -2)b'b901 ef' 在 3.8 版更改: 添加了 sep 和 bytes_per_sep 形参。 binascii.a2b_hex(hexstr) binascii.unhexlify(hexstr) 返回由十六进制字符串 hexstr 表示的二进制数据。此函数功能与 b2a_hex() 相反。 hexstr 必须包含偶数个十六进制数字（可以是大写或小写），否则会引发 Error 异常。 使用：bytes.fromhex() 类方法也实现相似的功能（仅接受文本字符串参数，不限制其中的空白字符）。 exception binascii.Error 通常是因为编程错误引发的异常。 exception binascii.Incomplete 数据不完整引发的异常。通常不是编程错误导致的，可以通过读取更多的数据并再次尝试来处理该异常。 参见: 模块 base64 支持在16，32，64，85进制中进行符合 RFC 协议的 base64 样式编码。 模块 binhex 支持在 Macintosh 上使用的 binhex 格式。 模块 uu 支持在 Unix 上使用的 UU 编码。 模块 quopri 支持在 MIME 版本电子邮件中使用引号可打印编码。 实例例子112345678910111213141516171819202122 # 导入binascii模块import binascii a = b'BE27E8FFFF010203'# 先把b'BE27E8FFFF010203'转换成二进制数据然后在用十六进制表示b = binascii.b2a_hex(a)# 打印出：b'42453237453846464646303130323033'，例如B对应ascii码42，E对应ascii码45print(b) # 与b2a_hex相反，打印出：b'BE27E8FFFF010203'print(binascii.a2b_hex(b)) # 这个功能和b2a_hex()一样# 打印出：b'42453237453846464646303130323033'，例如B对应ascii码42，E对应ascii码45c = binascii.hexlify(a)print(c) # 这个功能和a2b_hex()一样，打印出：b'BE27E8FFFF010203'print(binascii.unhexlify(c)) 例子21234567891011121314151617181920212223242526272829303132#coding:utf-8import binasciia = 'hello world'#先把a转换成二进制数据然后在用十六进制表示b = binascii.b2a_hex(a)c = binascii.hexlify(a)#和a2b_hex()功能是一样的,但是推荐用这个函数,具体不清楚= =print '&#123;0:10s&#125;'.format('b2a_hex'),for i in range(0,len(b),2): print b[i:i+2],print#到这是不是发现了,利用b2a_hex()返回的字符串长度为原串的两倍,因为转换为十六进制,一个字节用两个字节表示了print '&#123;0:10s&#125;'.format('hexlify'),for i in range(0,len(c),2): print c[i:i+2], printprint '&#123;0:10s&#125;'.format('ord'),for i in a: print hex(ord(i))[2:],#手动转换为二进制十六进制print#与b2a_hex相反print binascii.a2b_hex(b)print binascii.unhexlify(c)'''result:b2a_hex 68 65 6c 6c 6f 20 77 6f 72 6c 64hexlify 68 65 6c 6c 6f 20 77 6f 72 6c 64ord 68 65 6c 6c 6f 20 77 6f 72 6c 64hello worldhello world''' 最后1234import datetimed1 = datetime.datetime(2019,4,7)d2 = datetime.datetime(2020,2,24)print(d2-d1) 父亲离开我已经过去了323天。 今天整理云盘,发现了父亲的照片。 心里很难受。 父亲平时少言寡语。不太喜欢和我们交流。 最后一次和父亲聊天,是19年3月底,医院住院的时候。 他说:鑫儿,昨天大夫查房和说我了,我是个定时炸弹,随时都会爆发。栓塞已经不是主要问题了。指了指心。这里是大问题。这个3到5分钟就过去了。父亲顿了顿,继续说：存着都在你妈那里，我要是万一哪天过去了,就找你妈要,你和你姐都有份,你姐身体不好,孩子还上大学,你就多让点你姐,你还年轻,以后还有机会赚钱。 我调侃道：您这是要交代后事啊? 父亲说,对啊，现在说了,我就了心思了。能活一天算一天。 我不知道该说些什么。只能扶着父亲在医院走廊里继续走啊，走啊。 想起我小时候拉着父亲的手过马路的情形。和这时候差不多。父亲的腿因为栓塞，没有劲,需要拄着拐杖才能慢慢挪动脚步。 谁能想到这次谈话,竟是永别。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python standard library gc]]></title>
    <url>%2F2020%2F02%2F23%2Fpython_standard_library_gc%2F</url>
    <content type="text"><![CDATA[python 标准库 gc 离开的时候,才会记得你。 此模块提供可选的垃圾回收器的接口，提供的功能包括：关闭收集器、调整收集频率、设置调试选项。它同时提供对回收器找到但是无法释放的不可达对象的访问。由于 Python 使用了带有引用计数的回收器，如果你确定你的程序不会产生循环引用，你可以关闭回收器。可以通过调用 gc.disable() 关闭自动垃圾回收。若要调试一个存在内存泄漏的程序，调用 gc.set_debug(gc.DEBUG_LEAK) ；需要注意的是，它包含 gc.DEBUG_SAVEALL ，使得被垃圾回收的对象会被存放在 gc.garbage 中以待检查。 函数gc 模块提供下列函数： gc.enable() 启用自动垃圾回收 gc.disable() 停用自动垃圾回收 gc.isenabled() 如果启用了自动回收则返回 True。 gc.collect(generation=2) 若被调用时不包含参数，则启动完全的垃圾回收。可选的参数 generation 可以是一个整数，指明需要回收哪一代（从 0 到 2 ）的垃圾。当参数 generation 无效时，会引发 ValueError 异常。返回发现的不可达对象的数目。每当运行完整收集或最高代 (2) 收集时，为多个内置类型所维护的空闲列表会被清空。 由于特定类型特别是 float 的实现，在某些空闲列表中并非所有项都会被释放。 gc.set_debug(flags) 设置垃圾回收器的调试标识位。调试信息会被写入 sys.stderr 。此文档末尾列出了各个标志位及其含义；可以使用位操作对多个标志位进行设置以控制调试器。 gc.get_debug() 返回当前调试标识位。 gc.get_objects(generation=None) 返回一个收集器所跟踪的所有对象的列表，所返回的列表除外。 如果 generation 不为 None，则只返回收集器所跟踪的属于该生成的对象。在 3.8 版更改: 新的 generation 形参。 gc.get_stats() 返回一个包含三个字典对象的列表，每个字典分别包含对应代的从解释器开始运行的垃圾回收统计数据。字典的键的数目在将来可能发生改变，目前每个字典包含以下内容：collections 是该代被回收的次数；collected 是该代中被回收的对象总数；uncollectable 是在这一代中被发现无法收集的对象总数 （因此被移动到 garbage 列表中）。3.4 新版功能. gc.set_threshold(threshold0[, threshold1[, threshold2]]) 设置垃圾回收阈值（收集频率）。 将 threshold0 设为零会禁用回收。垃圾回收器把所有对象分类为三代，取决于对象幸存于多少次垃圾回收。新创建的对象会被放在最年轻代（第 0 代）。如果一个对象幸存于一次垃圾回收，则该对象会被放入下一代。第 2 代是最老的一代，因此这一代的对象幸存于垃圾回收后，仍会留在第 2 代。为了判定何时需要进行垃圾回收，垃圾回收器会跟踪上一次回收后，分配和释放的对象的数目。当分配对象的数量减去释放对象的数量大于阈值 threshold0 时，回收器开始进行垃圾回收。起初只有第 0 代会被检查。当上一次第 1 代被检查后，第 0 代被检查的次数多于阈值 threshold1 时，第 1 代也会被检查。相似的， threshold2 设置了触发第 2 代被垃圾回收的第 1 代被垃圾回收的次数。 gc.get_count() 将当前回收计数以形为 (count0, count1, count2) 的元组返回。 gc.get_threshold() 将当前回收阈值以形为 (threshold0, threshold1, threshold2) 的元组返回。 gc.get_referrers(*objs) 返回直接引用任意一个 ojbs 的对象列表。这个函数只定位支持垃圾回收的容器；引用了其它对象但不支持垃圾回收的扩展类型不会被找到。需要注意的是，已经解除对 objs 引用的对象，但仍存在于循环引用中未被回收时，仍然会被作为引用者出现在返回的列表当中。若要获取当前正在引用 objs 的对象，需要调用 collect() 然后再调用 get_referrers() 。在使用 get_referrers() 返回的对象时必须要小心，因为其中一些对象可能仍在构造中因此处于暂时的无效状态。不要把 get_referrers() 用于调试以外的其它目的。 gc.get_referents(*objs) 返回被任意一个参数中的对象直接引用的对象的列表。返回的被引用对象是被参数中的对象的C语言级别方法（若存在） tp_traverse 访问到的对象，可能不是所有的实际直接可达对象。只有支持垃圾回收的对象支持 tp_traverse 方法，并且此方法只会在需要访问涉及循环引用的对象时使用。因此，可以有以下例子：一个整数对其中一个参数是直接可达的，这个整数有可能出现或不出现在返回的结果列表当中。 gc.is_tracked(obj) 当对象正在被垃圾回收器监控时返回 True ，否则返回 False 。一般来说，原子类的实例不会被监控，而非原子类（如容器、用户自定义的对象）会被监控。然而，会有一些特定类型的优化以便减少垃圾回收器在简单实例（如只含有原子性的键和值的字典）上的消耗。 123456789101112&gt;&gt;&gt; gc.is_tracked(0)False&gt;&gt;&gt; gc.is_tracked("a")False&gt;&gt;&gt; gc.is_tracked([])True&gt;&gt;&gt; gc.is_tracked(&#123;&#125;)False&gt;&gt;&gt; gc.is_tracked(&#123;"a": 1&#125;)False&gt;&gt;&gt; gc.is_tracked(&#123;"a": []&#125;)True gc.freeze() 冻结 gc 所跟踪的所有对象 —— 将它们移至永久代并忽略所有未来的集合。 这可以在 POSIX fork() 调用之前使用以便令对写入复制保持友好或加速收集。 并且在 POSIX fork() 调用之前的收集也可以释放页面以供未来分配，这也可能导致写入时复制，因此建议在主进程中禁用 gc 并在 fork 之前冻结，而在子进程中启用 gc。3.7 新版功能. gc.unfreeze() 解冻永久代中的对象，并将它们放回到年老代中。3.7 新版功能. gc.get_freeze_count() 返回永久代中的对象数量。3.7 新版功能. 提供以下变量仅供只读访问（你可以修改但不应该重绑定它们）： gc.garbage 一个回收器发现不可达而又无法被释放的对象（不可回收对象）列表。 从 Python 3.4 开始，该列表在大多数时候都应该是空的，除非使用了含有非 NULL tp_del 空位的 C 扩展类型的实例。如果设置了 DEBUG_SAVEALL ，则所有不可访问对象将被添加至该列表而不会被释放。在 3.2 版更改: 当 interpreter shutdown 即解释器关闭时，若此列表非空，会产生 ResourceWarning ，即资源警告，在默认情况下此警告不会被提醒。如果设置了 DEBUG_UNCOLLECTABLE ，所有无法被回收的对象会被打印。在 3.4 版更改: 根据 PEP 442 ，带有 __del__() 方法的对象最终不再会进入 gc.garbage 。 gc.callbacks 在垃圾回收器开始前和完成后会被调用的一系列回调函数。这些回调函数在被调用时使用两个参数： phase 和 info 。phase 可为以下两值之一：”start”: 垃圾回收即将开始。”stop”: 垃圾回收已结束。info is a dict providing more information for the callback. The following keys are currently defined:”generation”（代） ：正在被回收的最久远的一代。”collected”（已回收的 ）: 当phase 为 “stop” 时，被成功回收的对象的数目。”uncollectable”（不可回收的）: 当 phase 为 “stop” 时，不能被回收并被放入 garbage 的对象的数目。应用程序可以把他们自己的回调函数加入此列表。主要的使用场景有：统计垃圾回收的数据，如：不同代的回收频率、回收所花费的时间。使应用程序可以识别和清理他们自己的在 garbage 中的不可回收类型的对象。3.3 新版功能. 常量以下常量被用于 set_debug() ： gc.DEBUG_STATS 在回收完成后打印统计信息。当回收频率设置较高时，这些信息会比较有用。 gc.DEBUG_COLLECTABLE 当发现可回收对象时打印信息。 gc.DEBUG_UNCOLLECTABLE 打印找到的不可回收对象的信息（指不能被回收器回收的不可达对象）。这些对象会被添加到 garbage 列表中。在 3.2 版更改: 当 interpreter shutdown 时，即解释器关闭时，若 garbage 列表中存在对象，这些对象也会被打印输出。 gc.DEBUG_SAVEALL 设置后，所有回收器找到的不可达对象会被添加进 garbage 而不是直接被释放。这在调试一个内存泄漏的程序时会很有用。 gc.DEBUG_LEAK 调试内存泄漏的程序时，使回收器打印信息的调试标识位。（等价于 DEBUG_COLLECTABLE | DEBUG_UNCOLLECTABLE | DEBUG_SAVEALL ）。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library Built-in Exception]]></title>
    <url>%2F2020%2F02%2F22%2Fpython-standard-library-Built-in-Exception%2F</url>
    <content type="text"><![CDATA[python 标准库 内置异常 每日一词: worthn 价值；意义；价值（十元、40 英镑等）的东西 adj 有…价值；值…钱；（指行动）值得；值得（费周折） web 值得的；有……的价值；值…的 短语: for all sb/it is worth 竭尽全力；拼命 for what its worth 非正式 （所说的只是个人意见）无论管不管用，不论好坏 (the game is) not worth the candle 得不偿失 not worth the paper its written/printed on 尤指 (法律上 )毫无价值 worth your/its salt 称职；胜任 worth sbs while 对…有好处（或用处） 在 Python 中，所有异常必须为一个派生自 BaseException 的类的实例。 在带有提及一个特定类的 except 子句的 try 语句中，该子句也会处理任何派生自该类的异常类（但不处理 它 所派生出的异常类）。 通过子类化创建的两个不相关异常类永远是不等效的，既使它们具有相同的名称。 下面列出的内置异常可通过解释器或内置函数来生成。除非另有说明，它们都会具有一个提示导致错误详细原因的“关联值”。 这可以是一个字符串或由多个信息项（例如一个错误码和一个解释错误的字符串）组成的元组。 关联值通常会作为参数被传递给异常类的构造器。 用户代码可以引发内置异常。 这可被用于测试异常处理程序或报告错误条件，“就像” 在解释器引发了相同异常的情况时一样；但是请注意，没有任何机制能防止用户代码引发不适当的错误。 内置异常类可以被子类化以定义新的异常；鼓励程序员从 Exception 类或它的某个子类而不是从 BaseException 来派生新的异常。 关于定义异常的更多信息可以在 Python 教程的 用户自定义异常 部分查看。 当在 except 或 finally 子句中引发（或重新引发）异常时，__context__ 会被自动设为所捕获的最后一个异常；如果新的异常未被处理，则最终显示的回溯信息将包括原始的异常和最后的异常。 当引发一个新的异常（而不是简单地使用 raise 来重新引发当前在处理的异常）时，隐式的异常上下文可以通过使用带有 raise 的 from 来补充一个显式的原因: 1raise new_exc from original_exc 跟在 from 之后的表达式必须为一个异常或 None。 它将在所引发的异常上被设置为 __cause__。 设置 __cause__ 还会隐式地将 __suppress_context__ 属性设为 True，这样使用 raise new_exc from None 可以有效地将旧异常替换为新异常来显示其目的 (例如将 KeyError 转换为 AttributeError)，同时让旧异常在 __context__ 中保持可用状态以便在调试时进行内省。 除了异常本身的回溯以外，默认的回溯还会显示这些串连的异常。 __cause__ 中的显式串连异常如果存在将总是显示。 __context__ 中的隐式串连异常仅在 __cause__ 为 None 并且 __suppress_context__ 为假值时显示。 不论在哪种情况下，异常本身总会在任何串连异常之后显示，以便回溯的最后一行总是显示所引发的最后一个异常。 基类下列异常主要被用作其他异常的基类。 exception BaseException 所有内置异常的基类。 它不应该被用户自定义类直接继承 (这种情况请使用 Exception)。 如果在此类的实例上调用 str()，则会返回实例的参数表示，或者当没有参数时返回空字符串。 args 传给异常构造器的参数元组。 某些内置异常 (例如 OSError) 接受特定数量的参数并赋予此元组中的元素特殊的含义，而其他异常通常只接受一个给出错误信息的单独字符串。 with_traceback(tb) 此方法将 tb 设为异常的新回溯信息并返回该异常对象。 它通常以如下的形式在异常处理程序中使用: 12345try: ...except SomeException: tb = sys.exc_info()[2] raise OtherException(...).with_traceback(tb) exception Exception 所有内置的非系统退出类异常都派生自此类。 所有用户自定义异常也应当派生自此类。 exception ArithmeticError 此基类用于派生针对各种算术类错误而引发的内置异常: OverflowError, ZeroDivisionError, FloatingPointError。 exception BufferError 当与 缓冲区 相关的操作无法执行时将被引发。 exception LookupError 此基类用于派生当映射或序列所使用的键或索引无效时引发的异常: IndexError, KeyError。 这可以通过 codecs.lookup() 来直接引发。 具体异常以下异常属于经常被引发的异常。 exception AssertionError 当 assert 语句失败时将被引发。 exception AttributeError 当属性引用 (参见 属性引用) 或赋值失败时将被引发。 （当一个对象根本不支持属性引用或属性赋值时则将引发 TypeError。） exception EOFError 当 input() 函数未读取任何数据即达到文件结束条件 (EOF) 时将被引发。 （另外，io.IOBase.read() 和 io.IOBase.readline() 方法在遇到 EOF 则将返回一个空字符串。） exception FloatingPointError 目前未被使用。 exception GeneratorExit 当一个 generator 或 coroutine 被关闭时将被引发；参见 generator.close() 和 coroutine.close()。 它直接继承自 BaseException 而不是 Exception，因为从技术上来说它并不是一个错误。 exception ImportError 当 import 语句尝试加载模块遇到麻烦时将被引发。 并且当 from ... import 中的 “from list” 存在无法找到的名称时也会被引发。name 与 path 属性可通过对构造器使用仅关键字参数来设定。 设定后它们将分别表示被尝试导入的模块名称与触发异常的任意文件所在路径。在 3.3 版更改: 添加了 name 与 path 属性。 exception ModuleNotFoundError ImportError 的子类，当一个模块无法被定位时将由 import 引发。 当在 sys.modules 中找到 None 时也会被引发。 3.6 新版功能. exception IndexError 当序列抽取超出范围时将被引发。 （切片索引会被静默截短到允许的范围；如果指定索引不是整数则 TypeError 会被引发。） exception KeyError 当在现有键集合中找不到指定的映射（字典）键时将被引发。 exception KeyboardInterrupt 当用户按下中断键 (通常为 Control-C 或 Delete) 时将被引发。 在执行期间，会定期检测中断信号。 该异常继承自 BaseException 以确保不会被处理 Exception 的代码意外捕获，这样可以避免退出解释器。 exception MemoryError 当一个操作耗尽内存但情况仍可（通过删除一些对象）进行挽救时将被引发。 关联的值是一个字符串，指明是哪种（内部）操作耗尽了内存。 请注意由于底层的内存管理架构（C 的 malloc() 函数），解释器也许并不总是能够从这种情况下完全恢复；但它毕竟可以引发一个异常，这样就能打印出栈回溯信息，以便找出导致问题的失控程序。 exception NameError 当某个局部或全局名称未找到时将被引发。 此异常仅用于非限定名称。 关联的值是一条错误信息，其中包含未找到的名称。 exception NotImplementedError 此异常派生自 RuntimeError。 在用户自定义的基类中，抽象方法应当在其要求所派生类重载该方法，或是在其要求所开发的类提示具体实现尚待添加时引发此异常。 它不应当用来表示一个运算符或方法根本不能被支持 – 在此情况下应当让特定运算符 / 方法保持未定义，或者在子类中将其设为 None。 NotImplementedError 和 NotImplemented 不可互换，即使它们有相似的名称和用途。 请参阅 NotImplemented 了解有关何时使用它们的详细说明。 exception OSError([arg]) exception OSError(errno, strerror[, filename[, winerror[, filename2]]]) 此异常在一个系统函数返回系统相关的错误时将被引发，此类错误包括 I/O 操作失败例如 “文件未找到” 或 “磁盘已满” 等（不包括非法参数类型或其他偶然性错误）。 构造器的第二种形式可设置如下所述的相应属性。 如果未指定这些属性则默认为 None。 为了能向下兼容，如果传入了三个参数，则 args 属性将仅包含由前两个构造器参数组成的 2 元组。 构造器实际返回的往往是 OSError 的某个子类，如下文 OS exceptions 中所描述的。 具体的子类取决于最终的 errno 值。 此行为仅在直接或通过别名来构造 OSError 时发生，并且在子类化时不会被继承。 errno 来自于 C 变量 errno 的数字错误码。 winerror 在 Windows 下，此参数将给出原生的 Windows 错误码。 而 errno 属性将是该原生错误码在 POSIX 平台下的近似转换形式。在 Windows 下，如果 winerror 构造器参数是一个整数，则 errno 属性会根据 Windows 错误码来确定，而 errno 参数会被忽略。 在其他平台上，winerror 参数会被忽略，并且 winerror 属性将不存在。 strerror 操作系统所提供的相应错误信息。 它在 POSIX 平台中由 C 函数 perror() 来格式化，在 Windows 中则是由 FormatMessage()。 filename filename2 对于与文件系统路径有关 (例如 open() 或 os.unlink()) 的异常，filename 是传给函数的文件名。 对于涉及两个文件系统路径的函数 (例如 os.rename())，filename2 将是传给函数的第二个文件名。 在 3.3 版更改: EnvironmentError, IOError, WindowsError, socket.error, select.error 与 mmap.error 已被合并到 OSError，构造器可能返回其中一个子类。 在 3.4 版更改: filename 属性现在将是传给函数的原始文件名，而不是经过编码或基于文件系统编码进行解码之后的名称。 此外还添加了 filename2 构造器参数和属性。 exception OverflowError 当算术运算的结果大到无法表示时将被引发。 这对整数来说不可能发生（宁可引发 MemoryError 也不会放弃尝试）。 但是出于历史原因，有时也会在整数超出要求范围的情况下引发 OverflowError。 因为在 C 中缺少对浮点异常处理的标准化，大多数浮点运算都不会做检查。 exception RecursionError 此异常派生自 RuntimeError。 它会在解释器检测发现超过最大递归深度 (参见 sys.getrecursionlimit()) 时被引发。3.5 新版功能: 在此之前将只引发 RuntimeError。 exception ReferenceError 此异常将在使用 weakref.proxy() 函数所创建的弱引用来访问该引用的某个已被作为垃圾回收的属性时被引发。 有关弱引用的更多信息请参阅 weakref 模块。 exception RuntimeError 当检测到一个不归属于任何其他类别的错误时将被引发。 关联的值是一个指明究竟发生了什么问题的字符串。 exception StopIteration 由内置函数 next() 和 iterator 的 __next__() 方法所引发，用来表示该迭代器不能产生下一项。该异常对象只有一个属性 value，它在构造该异常时作为参数给出，默认值为 None。当一个 generator 或 coroutine 函数返回时，将引发一个新的 StopIteration 实例，函数返回的值将被用作异常构造器的 value 形参。如果某个生成器代码直接或间接地引发了 StopIteration，它会被转换为 RuntimeError (并将 StopIteration 保留为导致新异常的原因)。在 3.3 版更改: 添加了 value 属性及其被生成器函数用作返回值的功能。在 3.5 版更改: 引入了通过 from __future__ import generator_stop 来实现 RuntimeError 转换，参见 PEP 479。在 3.7 版更改: 默认对所有代码启用 PEP 479: 在生成器中引发的 StopIteration 错误将被转换为 RuntimeError。 exception StopAsyncIteration 必须由一个 asynchronous iterator 对象的 __anext__() 方法来引发以停止迭代操作。3.5 新版功能. exception SyntaxError 当解析器遇到语法错误时将被引发。 这可以发生在 import 语句，对内置函数 exec() 或 eval() 的调用，或者读取原始脚本或标准输入（也包括交互模式）的时候。该类的实例包含有属性 filename, lineno, offset 和 text 用于方便地访问相应的详细信息。 异常实例的 str() 仅返回消息文本。 exception IndentationError 与不正确的缩进相关的语法错误的基类。 这是 SyntaxError 的一个子类。 exception TabError 当缩进包含对制表符和空格符不一致的使用时将被引发。 这是 IndentationError 的一个子类。 exception SystemError 当解释器发现内部错误，但情况看起来尚未严重到要放弃所有希望时将被引发。 关联的值是一个指明发生了什么问题的字符串（表示为低层级的符号）。你应当将此问题报告给你所用 Python 解释器的作者或维护人员。 请确认报告 Python 解释器的版本号 (sys.version; 它也会在交互式 Python 会话开始时被打印出来)，具体的错误消息（异常所关联的值）以及可能触发该错误的程序源码。 exception SystemExit 此异常由 sys.exit() 函数引发。 它继承自 BaseException 而不是 Exception 以确保不会被处理 Exception 的代码意外捕获。 这允许此异常正确地向上传播并导致解释器退出。 如果它未被处理，则 Python 解释器就将退出；不会打印任何栈回溯信息。 构造器接受的可选参数与传递给 sys.exit() 的相同。 如果该值为一个整数，则它指明系统退出状态码（会传递给 C 的 exit() 函数）；如果该值为 None，则退出状态码为零；如果该值为其他类型（例如字符串），则会打印对象的值并将退出状态码设为一。对 sys.exit() 的调用会被转换为一个异常以便能执行清理处理程序 (try 语句的 finally 子句)，并且使得调试器可以执行一段脚本而不必冒失去控制的风险。 如果绝对确实地需要立即退出（例如在调用 os.fork() 之后的子进程中）则可使用 os._exit().code传给构造器的退出状态码或错误信息（默认为 None。） exception TypeError 当一个操作或函数被应用于类型不适当的对象时将被引发。 关联的值是一个字符串，给出有关类型不匹配的详情。此异常可以由用户代码引发，以表明尝试对某个对象进行的操作不受支持也不应当受支持。 如果某个对象应当支持给定的操作但尚未提供相应的实现，所要引发的适当异常应为 NotImplementedError。传入参数的类型错误 (例如在要求 int 时却传入了 list) 应当导致 TypeError，但传入参数的值错误 (例如传入要求范围之外的数值) 则应当导致 ValueError。 exception UnboundLocalError 当在函数或方法中对某个局部变量进行引用，但该变量并未绑定任何值时将被引发。 此异常是 NameError 的一个子类。 exception UnicodeError 当发生与 Unicode 相关的编码或解码错误时将被引发。 此异常是 ValueError 的一个子类。UnicodeError 具有一些描述编码或解码错误的属性。 例如 err.object[err.start:err.end] 会给出导致编解码器失败的特定无效输入。encoding引发错误的编码名称。reason描述特定编解码器错误的字符串。object编解码器试图要编码或解码的对象。startobject 中无效数据的开始位置索引。endobject 中无效数据的末尾位置索引（不含）。 exception UnicodeEncodeError 当在编码过程中发生与 Unicode 相关的错误时将被引发。 此异常是 UnicodeError 的一个子类。 exception UnicodeDecodeError 当在解码过程中发生与 Unicode 相关的错误时将被引发。 此异常是 UnicodeError 的一个子类。 exception UnicodeTranslateError 在转写过程中发生与 Unicode 相关的错误时将被引发。 此异常是 UnicodeError 的一个子类。 exception ValueError 当操作或函数接收到具有正确类型但值不适合的参数，并且情况不能用更精确的异常例如 IndexError 来描述时将被引发。 exception ZeroDivisionError 当除法或取余运算的第二个参数为零时将被引发。 关联的值是一个字符串，指明操作数和运算的类型。 下列异常被保留以与之前的版本相兼容；从 Python 3.3 开始，它们都是 OSError 的别名。 exception EnvironmentError exception IOError exception WindowsError 限在 Windows 中可用。 OS 异常下列异常均为 OSError 的子类，它们将根据系统错误代码被引发。 exception BlockingIOError 当一个操作会被某个设置为非阻塞操作的对象（例如套接字）所阻塞时将被引发。 对应于 errno EAGAIN, EALREADY, EWOULDBLOCK 和 EINPROGRESS。除了 OSError 已有的属性，BlockingIOError 还有一个额外属性：characters_written一个整数，表示在被阻塞前已写入到流的字符数。 当使用来自 io 模块的带缓冲 I/O 类时此属性可用。 exception ChildProcessError 当一个子进程上的操作失败时将被引发。 对应于 errno ECHILD。 exception ConnectionError 与连接相关问题的基类。其子类有 BrokenPipeError, ConnectionAbortedError, ConnectionRefusedError 和 ConnectionResetError。 exception BrokenPipeError ConnectionError 的子类，当试图写入另一端已被关闭的管道，或是试图写入已关闭写入的套接字时将被引发。 对应于 errno EPIPE 和 ESHUTDOWN。 exception ConnectionAbortedError ConnectionError 的子类，当连接尝试被对端中止时将被引发。 对应于 errno ECONNABORTED。 exception ConnectionRefusedError ConnectionError 的子类，当连接尝试被对端拒绝时将被引发。 对应于 errno ECONNREFUSED。 exception ConnectionResetError ConnectionError 的子类，当连接被对端重置时将被引发。 对应于 errno ECONNRESET。 exception FileExistsError 当试图创建一个已存在的文件或目录时将被引发。 对应于 errno EEXIST。 exception FileNotFoundError 当所请求的文件或目录不存在时将被引发。 对应于 errno ENOENT。 exception InterruptedError 当系统调用被输入信号中断时将被引发。 对应于 errno EINTR。在 3.5 版更改: 当系统调用被某个信号中断时，Python 现在会重试系统调用，除非该信号的处理程序引发了其它异常 (原理参见 PEP 475) 而不是引发 InterruptedError。 exception IsADirectoryError 当请求对一个目录执行文件操作 (例如 os.remove()) 将被引发。 对应于 errno EISDIR。 exception NotADirectoryError 当请求对一个非目录对象执行目录操作 (例如 os.listdir()) 时将被引发。 对应于 errno ENOTDIR。 exception PermissionError 当在没有足够操作权限的情况下试图执行某个操作时将被引发 —— 例如缺少文件系统权限。 对应于 errno EACCES 和 EPERM。 exception ProcessLookupError 当给定的进程不存在时将被引发。 对应于 errno ESRCH。 exception TimeoutError 当一个系统函数发生系统级超时的情况下将被引发。 对应于 errno ETIMEDOUT。 3.3 新版功能: 添加了以上所有 OSError 的子类。 参见：PEP 3151 - 重写 OS 和 IO 异常的层次结构 警告下列异常被用作警告类别；请参阅 警告类别 文档了解详情。 exception Warning 警告类别的基类。 exception UserWarning 用户代码所产生警告的基类。 exception DeprecationWarning 如果所发出的警告是针对其他 Python 开发者的，则以此作为与已弃用特性相关警告的基类。 exception PendingDeprecationWarning 对于已过时并预计在未来弃用，但目前尚未弃用的特性相关警告的基类。这个类很少被使用，因为针对未来可能的弃用发出警告的做法并不常见，而针对当前已有的弃用则推荐使用 DeprecationWarning。 exception SyntaxWarning 与模糊的语法相关的警告的基类。 exception RuntimeWarning 与模糊的运行时行为相关的警告的基类。 exception FutureWarning 如果所发出的警告是针对以 Python 所编写应用的最终用户的，则以此作为与已弃用特性相关警告的基类。 exception ImportWarning 与在模块导入中可能的错误相关的警告的基类。 exception UnicodeWarning 与 Unicode 相关的警告的基类。 exception BytesWarning 与 bytes 和 bytearray 相关的警告的基类。 exception ResourceWarning 与资源使用相关的警告的基类。 会被默认的警告过滤器忽略。3.2 新版功能. 异常层次结构内置异常的类层级结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StopAsyncIteration +-- ArithmeticError | +-- FloatingPointError | +-- OverflowError | +-- ZeroDivisionError +-- AssertionError +-- AttributeError +-- BufferError +-- EOFError +-- ImportError | +-- ModuleNotFoundError +-- LookupError | +-- IndexError | +-- KeyError +-- MemoryError +-- NameError | +-- UnboundLocalError +-- OSError | +-- BlockingIOError | +-- ChildProcessError | +-- ConnectionError | | +-- BrokenPipeError | | +-- ConnectionAbortedError | | +-- ConnectionRefusedError | | +-- ConnectionResetError | +-- FileExistsError | +-- FileNotFoundError | +-- InterruptedError | +-- IsADirectoryError | +-- NotADirectoryError | +-- PermissionError | +-- ProcessLookupError | +-- TimeoutError +-- ReferenceError +-- RuntimeError | +-- NotImplementedError | +-- RecursionError +-- SyntaxError | +-- IndentationError | +-- TabError +-- SystemError +-- TypeError +-- ValueError | +-- UnicodeError | +-- UnicodeDecodeError | +-- UnicodeEncodeError | +-- UnicodeTranslateError +-- Warning +-- DeprecationWarning +-- PendingDeprecationWarning +-- RuntimeWarning +-- SyntaxWarning +-- UserWarning +-- FutureWarning +-- ImportWarning +-- UnicodeWarning +-- BytesWarning +-- ResourceWarning]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>Exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library cmd]]></title>
    <url>%2F2020%2F02%2F21%2Fpython-standard-library-cmd%2F</url>
    <content type="text"><![CDATA[python 标准库 cmd模块 每日一词: collapse 近义词: crashbreakdowncrumblefall apart 例句: 我曾经神经崩溃过。那是一次痛苦的经历。I suffered a nervous breakdown. It was a traumatic experience 他能明显地看出我快要精神崩溃了。It was plain to him that I was having a nervous breakdown 源代码: Lib/cmd.py Cmd 类提供简单框架用于编写面向行的命令解释器。 这些通常对测试工具，管理工具和原型有用，这些工具随后将被包含在更复杂的接口中。 class cmd.Cmd(completekey=’tab’, stdin=None, stdout=None) 一个 Cmd 实例或子类实例是面向行的解释器框架结构。 实例化 Cmd 本身是没有充分理由的， 它作为自定义解释器类的超类是非常有用的为了继承 Cmd 的方法并且封装动作方法。可选参数 completekey 是完成键的 readline 名称；默认是 Tab 。如果 completekey 不是 None 并且 readline 是可用的， 命令完成会自动完成。可选参数 stdin 和 stdout 指定了Cmd实例或子类实例将用于输入和输出的输入和输出文件对象。如果没有指定，他们将默认为 sys.stdin 和 sys.stdout 。如果你想要使用一个给定的 stdin ，确保将实例的 use_rawinput 属性设置为 False ，否则 stdin 将被忽略 Cmd 对象Cmd 实例有下列方法： Cmd.cmdloop(intro=None) 反复发出提示，接受输入，从收到的输入中解析出一个初始前缀，并分派给操作方法，将其余的行作为参数传递给它们。可选参数是在第一个提示之前发布的横幅或介绍字符串（这将覆盖 intro 类属性）。如果 readline 继承模块被加载，输入将自动继承类似 bash的历史列表编辑（例如， Control-P 滚动回到最后一个命令， Control-N 转到下一个命令，以 Control-F 非破坏性的方式向右 Control-B 移动光标，破坏性地等）。输入的文件结束符被作为字符串传回 &#39;EOF&#39; 。解释器实例将会识别命令名称 foo 当且仅当它有方法 do_foo() 。有一个特殊情况，分派始于字符 &#39;?&#39; 的行到方法 do_help() 。另一种特殊情况，分派始于字符 &#39;!&#39; 的行到方法 do_shell() （如果定义了这个方法）这个方法将返回当 postcmd() 方法返回一个真值 。参数 stop 到 postcmd() 是命令对应的返回值 do_*() 的方法。如果激活了完成，全部命令将会自动完成，并且通过调用 complete_foo() 参数 text , line, begidx ,和 endidx 完成全部命令参数。 text 是我们试图匹配的字符串前缀，所有返回的匹配项必须以它为开头。 line 是删除了前导空格的当前的输入行， begidx 和 endidx 是前缀文本的开始和结束索引。，可以用于根据参数位置提供不同的完成。所有 Cmd 的子类继承一个预定义 do_help() 。 这个方法使用参数 &#39;bar&#39; 调用， 调用对应的方法 help_bar() ，如果不存在，打印 do_bar() 的文档字符串，如果可用。没有参数的情况下， do_help() 方法会列出所有可用的帮助主题 （即所有具有相应的 help_*() 方法或命令的 文档字符串），也会列举所有未被记录的命令。 Cmd.onecmd(str) 解释该参数，就好像它是为响应提示而键入的一样。 这可能会被覆盖，但通常不应该被覆盖; 请参阅： precmd() 和 postcmd() 方法，用于执行有用的挂钩。 返回值是一个标志，指示解释器对命令的解释是否应该停止。 如果命令 str 有一个 do_*() 方法，则返回该方法的返回值，否则返回 default() 方法的返回值。 Cmd.emptyline() 在响应提示输入空行时调用的方法。如果此方法未被覆盖，则重复输入的最后一个非空命令。 Cmd.default(line) 当命令前缀不能被识别的时候在输入行调用的方法。如果此方法未被覆盖，它将输出一个错误信息并返回。 Cmd.completedefault(text, line, begidx, endidx) 当没有特定于命令的 complete_*() 方法可用时，调用此方法完成输入行。默认情况下，它返回一个空列表。 Cmd.precmd(line) 钩方法在命令行 line 被解释之前执行，但是在输入提示被生成和发出后。这个方法是一个在 Cmd 中的存根；它的存在是为了被子类覆盖。返回值被用作 onecmd() 方法执行的命令； precmd() 的实现或许会重写命令或者简单的返回 line 不变。 Cmd.postcmd(stop, line) 钩方法只在命令调度完成后执行。这个方法是一个在 Cmd 中的存根；它的存在是为了子类被覆盖。 line 是被执行的命令行， stop 是一个表示在调用 postcmd() 之后是否终止执行的标志；这将作为 onecmd() 方法的返回值。这个方法的返回值被用作与 stop 相关联的内部标志的新值；返回 false 将导致解释继续。 Cmd.preloop() 钩方法当 cmdloop() 被调用时执行一次。方法是一个在 Cmd 中的存根；它的存在是为了被子类覆盖。 Cmd.postloop() 钩方法在 cmdloop() 即将返回时执行一次。这个方法是一个在 Cmd 中的存根；塔顶存在是为了被子类覆盖。 Instances of Cmd subclasses have some public instance variables: Cmd.prompt 发出提示以请求输入。 Cmd.identchars 接受命令前缀的字符串。 Cmd.lastcmd 看到最后一个非空命令前缀。 Cmd.cmdqueue 排队的输入行列表。当需要新的输入时，在 cmdloop() 中检查 cmdqueue 列表；如果它不是空的，它的元素将被按顺序处理，就像在提示符处输入一样。 Cmd.intro 要作为简介或横幅发出的字符串。 可以通过给 cmdloop() 方法一个参数来覆盖它。 Cmd.doc_header 如果帮助输出具有记录命令的段落，则发出头文件。 Cmd.misc_header 如果帮助输出其他帮助主题的部分（即与 do_*() 方法没有关联的 help_*() 方法），则发出头文件。 Cmd.undoc_header 如果帮助输出未被记录命令的部分（即与 help_*() 方法没有关联的 do_*() 方法），则发出头文件。 Cmd.ruler 用于在帮助信息标题的下方绘制分隔符的字符，如果为空，则不绘制标尺线。 这个字符默认是 &#39;=&#39; 。 Cmd.use_rawinput 这是一个标志，默认为 true 。如果为 true ，, cmdloop() 使用 input() 先是提示并且阅读下一个命令；如果为 false ， sys.stdout.write() 和 sys.stdin.readline() 被使用。（这意味着解释器将会自动支持类似于 Emacs的行编辑和命令历史记录按键操作，通过导入 readline 在支持它的系统上。） Cmd 例子这部分提供了一个简单的例子来介绍如何使用一部分在 turtle 模块中的命令构建一个 shell 。 基础的 turtle 命令比如 forward() 被添加进一个 Cmd 子类，方法名为 do_forward() 。参数被转换成数字并且分发至 turtle 模组中。 docstring 是 shell 提供的帮助实用程序。 例子也包含使用 precmd() 方法实现基础的记录和回放的功能，这个方法负责将输入转换为小写并且将命令写入文件。 do_playback() 方法读取文件并添加记录命令至 cmdqueue 用于即时回放: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import cmd, sysfrom turtle import *class TurtleShell(cmd.Cmd): intro = 'Welcome to the turtle shell. Type help or ? to list commands.\n' prompt = '(turtle) ' file = None # ----- basic turtle commands ----- def do_forward(self, arg): 'Move the turtle forward by the specified distance: FORWARD 10' forward(*parse(arg)) def do_right(self, arg): 'Turn turtle right by given number of degrees: RIGHT 20' right(*parse(arg)) def do_left(self, arg): 'Turn turtle left by given number of degrees: LEFT 90' left(*parse(arg)) def do_goto(self, arg): 'Move turtle to an absolute position with changing orientation. GOTO 100 200' goto(*parse(arg)) def do_home(self, arg): 'Return turtle to the home position: HOME' home() def do_circle(self, arg): 'Draw circle with given radius an options extent and steps: CIRCLE 50' circle(*parse(arg)) def do_position(self, arg): 'Print the current turtle position: POSITION' print('Current position is %d %d\n' % position()) def do_heading(self, arg): 'Print the current turtle heading in degrees: HEADING' print('Current heading is %d\n' % (heading(),)) def do_color(self, arg): 'Set the color: COLOR BLUE' color(arg.lower()) def do_undo(self, arg): 'Undo (repeatedly) the last turtle action(s): UNDO' def do_reset(self, arg): 'Clear the screen and return turtle to center: RESET' reset() def do_bye(self, arg): 'Stop recording, close the turtle window, and exit: BYE' print('Thank you for using Turtle') self.close() bye() return True # ----- record and playback ----- def do_record(self, arg): 'Save future commands to filename: RECORD rose.cmd' self.file = open(arg, 'w') def do_playback(self, arg): 'Playback commands from a file: PLAYBACK rose.cmd' self.close() with open(arg) as f: self.cmdqueue.extend(f.read().splitlines()) def precmd(self, line): line = line.lower() if self.file and 'playback' not in line: print(line, file=self.file) return line def close(self): if self.file: self.file.close() self.file = Nonedef parse(arg): 'Convert a series of zero or more numbers to an argument tuple' return tuple(map(int, arg.split()))if __name__ == '__main__': TurtleShell().cmdloop() 这是一个示例会话，其中 turtle shell 显示帮助功能，使用空行重复命令，以及简单的记录和回放功能： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Welcome to the turtle shell. Type help or ? to list commands.(turtle) ?Documented commands (type help &lt;topic&gt;):========================================bye color goto home playback record rightcircle forward heading left position reset undo(turtle) help forwardMove the turtle forward by the specified distance: FORWARD 10(turtle) record spiral.cmd(turtle) positionCurrent position is 0 0(turtle) headingCurrent heading is 0(turtle) reset(turtle) circle 20(turtle) right 30(turtle) circle 40(turtle) right 30(turtle) circle 60(turtle) right 30(turtle) circle 80(turtle) right 30(turtle) circle 100(turtle) right 30(turtle) circle 120(turtle) right 30(turtle) circle 120(turtle) headingCurrent heading is 180(turtle) forward 100(turtle)(turtle) right 90(turtle) forward 100(turtle)(turtle) right 90(turtle) forward 400(turtle) right 90(turtle) forward 500(turtle) right 90(turtle) forward 400(turtle) right 90(turtle) forward 300(turtle) playback spiral.cmdCurrent position is 0 0Current heading is 0Current heading is 180(turtle) byeThank you for using Turtle]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library os]]></title>
    <url>%2F2020%2F02%2F20%2Fpython-standard-library-os%2F</url>
    <content type="text"><![CDATA[python 标准库 os 每日一词： bustle v.[I] 1.闹哄哄地忙乱；匆忙；奔忙 2.充满 v.[T] 催促；使忙碌 n. 忙乱；喧扰 短语： hustle and bustle 熙熙攘攘 bustle in and out bustle about sth 近义词: run out of one’s feet on the flyon the humpon the jump 源代码： Lib/os.py 本模块提供了一种使用与操作系统相关的功能的便捷式途径。 如果你只是想读写一个文件，请参阅 open()，如果你想操作文件路径，请参阅 os.path 模块，如果你想读取通过命令行给出的所有文件中的所有行，请参阅 fileinput 模块。 为了创建临时文件和目录，请参阅 tempfile 模块，对于高级文件和目录处理，请参阅 shutil 模块。 关于这些函数的可用性的说明： Python中所有依赖于操作系统的内置模块的设计都是这样，只要不同的操作系统某一相同的功能可用，它就使用相同的接口。例如，函数 os.stat(path) 以相同的格式返回关于 path 的状态信息（该格式源于 POSIX 接口）。 特定于某一操作系统的扩展通过操作 os 模块也是可用的，但是使用它们当然是对可移植性的一种威胁。 所有接受路径或文件名的函数都同时支持字节串和字符串对象，并在返回路径或文件名时使用相应类型的对象作为结果。 在 VxWorks 系统上，os.fork, os.execv 和 os.spawnp 不被支持。 如果使用无效或无法访问的文件名与路径，或者其他类型正确但操作系统不接受的参数，此模块的所有函数都抛出 OSError （或者它的子类）。 exception os.error 内建的 OSError 异常的一个别名。 os.name 导入的依赖特定操作系统的模块的名称。以下名称目前已注册: &#39;posix&#39;, &#39;nt&#39;, &#39;java&#39;. sys.platform 有更详细的描述. os.uname() 只给出系统提供的版本信息。 platform 模块对系统的标识有更详细的检查。 文件名，命令行参数，以及环境变量。在 Python 中，使用字符串类型表示文件名、命令行参数和环境变量。 在某些系统上，在将这些字符串传递给操作系统之前，必须将这些字符串解码为字节。 Python 使用文件系统编码来执行此转换（请参阅 sys.getfilesystemencoding() ）。 在 3.1 版更改: 在某些系统上，使用文件系统编码进行转换可能会失败。 在这种情况下，Python 会使用 代理转义编码错误处理器，这意味着在解码时，不可解码的字节被 Unicode 字符 U+DCxx 替换，并且这些字节在编码时再次转换为原始字节。 文件系统编码必须保证成功解码小于 128 的所有字节。如果文件系统编码无法提供此保证， API 函数可能会引发 UnicodeErrors 。 进程参数这些函数和数据项提供了操作当前进程和用户的信息。 os.ctermid() 返回与进程控制终端对应的文件名。可用性: Unix。 os.environ 一个表示字符串环境的 mapping 对象。 例如，environ[&#39;HOME&#39;] 是你的主目录（在某些平台上）的路径名，相当于 C 中的 getenv(&quot;HOME&quot;)。这个映射是在第一次导入 os 模块时捕获的，通常作为 Python 启动时处理 site.py 的一部分。除了通过直接修改 os.environ 之外，在此之后对环境所做的更改不会反映在 os.environ 中。如果平台支持 putenv() 函数，这个映射除了可以用于查询环境外还能用于修改环境。 当这个映射被修改时，putenv() 将被自动调用。在Unix系统上，键和值会使用 sys.getfilesystemencoding() 和 &#39;surrogateescape&#39; 的错误处理。如果你想使用其他的编码，使用 environb。注解 直接调用 putenv() 并不会影响 os.environ，所以推荐直接修改 os.environ。注解 在某些平台上，包括 FreeBSD 和 Mac OS X，设置 environ 可能导致内存泄露。参阅 putenv() 的系统文档。如果平台没有提供 putenv(), 为了使启动的子进程使用修改后的环境，一份修改后的映射会被传给合适的进程创建函数。如果平台支持 unsetenv() 函数，你可以通过删除映射中元素的方式来删除对应的环境变量。当一个元素被从 os.environ 删除时，以及 pop() 或 clear() 被调用时， unsetenv() 会被自动调用。 os.environb 字节版本的 environ: 一个以字节串表示环境的 mapping 对象。 environ 和 environb 是同步的（修改 environb 会更新 environ，反之亦然）。只有在 supports_bytes_environ 为 True 的时候 environb 才是可用的。3.2 新版功能. os.chdir(path) os.fchdir(fd) os.getcwd() 以上函数请参阅 文件和目录 。 os.fsencode(filename) 编码 路径类 文件名 为文件系统接受的形式，使用 &#39;surrogateescape&#39; 代理转义编码错误处理器，在Windows系统上会使用 &#39;strict&#39; ；返回 bytes 字节类型不变。fsdecode() 是此函数的逆向函数。3.2 新版功能.**在 3.6 版更改: 增加对实现了 os.PathLike 接口的对象的支持。 os.fsdecode(filename) 从文件系统编码方式解码为 路径类 文件名，使用 &#39;surrogateescape&#39; 代理转义编码错误处理器，在Windows系统上会使用 &#39;strict&#39; ；返回 str 字符串不变。fsencode() 是此函数的逆向函数。3.2 新版功能.**在 3.6 版更改: 增加对实现了 os.PathLike 接口的对象的支持。 os.fspath(path) 返回路径的文件系统表示。如果传入的是 str 或 bytes 类型的字符串，将原样返回。否则 __fspath__() 将被调用，如果得到的是一个 str 或 bytes 类型的对象，那就返回这个值。其他所有情况则会抛出 TypeError 异常。3.6 新版功能. class os.PathLike 某些对象用于表示文件系统中的路径（如 pathlib.PurePath 对象），本类是这些对象的 抽象基类。3.6 新版功能.**abstractmethod __fspath__()返回当前对象的文件系统表示。这个方法只应该返回一个 str 字符串或 bytes 字节串，请优先选择 str 字符串。 os.getenv(key, default=None) 如果存在，返回环境变量 key 的值，否则返回 default。 key ， default 和返回值均为 str 字符串类型。在Unix系统上，键和值会使用 sys.getfilesystemencoding() 和’surrogateescape’ 错误处理进行解码。如果你想使用其他的编码，使用 os.getenvb()。可用性: 大部分的Unix系统，Windows。 os.getenvb(key, default=None) 如果存在环境变量 key 那么返回其值，否则返回 default。 key ， default 和返回值均为bytes字节串类型。getenvb() 仅在 supports_bytes_environ 为 True 时可用。可用性: 大部分的Unix系统。3.2 新版功能. os.get_exec_path(env=None) 返回将用于搜索可执行文件的目录列表，与在外壳程序中启动一个进程时相似。指定的 env 应为用于搜索 PATH 的环境变量字典。默认情况下，当 env 为 None 时，将会使用 environ 。3.2 新版功能. os.getegid() 返回当前进程的有效组ID。对应当前进程执行文件的 “set id” 位。可用性: Unix。 os.geteuid() 返回当前进程的有效用户ID。可用性: Unix。 os.getgid() 返回当前进程的实际组ID。可用性: Unix。 os.getgrouplist(user, group) 返回该用户所在的组 ID 列表。可能 group 参数没有在返回的列表中，实际上用户应该也是属于该 group。group 参数一般可以从储存账户信息的密码记录文件中找到。可用性: Unix。3.3 新版功能. os.getgroups() 返回当前进程对应的组ID列表可用性: Unix。 注解：在Mac OS X系统中，getgroups() 会和其他 Unix 平台有些不同。如果 Python 解释器是在 10.5 或更早版本中部署，getgroups() 返回当前用户进程相关的有效组ID列表。 该列表长度由于系统预设的接口限制，最长为 16。 而且在适当的权限下，返回结果还会因 getgroups() 而发生变化；如果 Python 解释器是在 10.5 以上版本中部署，getgroups() 返回进程所属有效用户 ID 所对应的用户的组 ID 列表，组用户列表可能因为进程的生存周期而发生变动，而且也不会因为 setgroups() 的调用而发生，返回的组用户列表长度也没有长度 16 的限制。在部署中，Python 解释器用到的变量 MACOSX_DEPLOYMENT_TARGET 可以用 sysconfig.get_config_var()。 os.getlogin() 返回通过控制终端进程进行登录的用户名。在多数情况下，使用 getpass.getuser() 会更有效，因为后者会通过检查环境变量 LOGNAME 或 USERNAME 来查找用户，再由 pwd.getpwuid(os.getuid())[0] 来获取当前用户 ID 的登录名。可用性: Unix, Windows。 os.getpgid(pid) 根据进程id pid 返回进程的组 ID 列表。如果 pid 为 0，则返回当前进程的进程组 ID 列表可用性: Unix。 os.getpgrp() 返回当时进程组的ID可用性: Unix。 os.getpid() 返回当前进程ID os.getppid() 返回父进程ID。当父进程已经结束，在Unix中返回的ID是初始进程(1)中的一个，在Windows中仍然是同一个进程ID，该进程ID有可能已经被进行进程所占用。可用性: Unix, Windows。在 3.2 版更改: 添加WIndows的支持。 os.getpriority(which, who) 获取程序调度优先级。which 参数值可以是 PRIO_PROCESS，PRIO_PGRP，或 PRIO_USER 中的一个，who 是相对于 which (PRIO_PROCESS 的进程标识符，PRIO_PGRP 的进程组标识符和 PRIO_USER 的用户ID)。当 who 为 0 时（分别）表示调用的进程，调用进程的进程组或调用进程所属的真实用户 ID。可用性: Unix。3.3 新版功能. os.PRIO_PROCESS os.PRIO_PGRP os.PRIO_USER 函数 getpriority() 和 setpriority() 的参数。可用性: Unix。3.3 新版功能. os.getresuid() 返回一个由 (ruid, euid, suid) 所组成的元组，分别表示当前进程的真实用户ID，有效用户ID和甲暂存用户ID。可用性: Unix。3.2 新版功能. os.getresgid() 返回一个由 (rgid, egid, sgid) 所组成的元组，分别表示当前进程的真实组ID，有效组ID和暂存组ID。可用性: Unix。3.2 新版功能. os.getuid() 返回当前进程的真实用户ID。可用性: Unix。 os.initgroups(username, gid) 调用系统 initgroups()，使用指定用户所在的所有值来初始化组访问列表，包括指定的组ID。可用性: Unix。3.2 新版功能. os.putenv(key, value) 将名为 key 的环境变量值设置为 value。该变量名修改会影响由 os.system()， popen() ，fork() 和 execv() 发起的子进程。可用性: 大部分的Unix系统，Windows。注解 在一些平台，包括 FreeBSD 和 Mac OS X，设置 environ 可能导致内存泄露。详情参考 putenv 相关系统文档。当系统支持 putenv() 时，os.environ 中的参数赋值会自动转换为对 putenv() 的调用。不过 putenv() 的调用不会更新 os.environ，因此最好使用 os.environ 对变量赋值。引发一个 审计事件 os.putenv，附带参数 key, value。 os.setegid(egid) 设置当前进程的有效组ID。可用性: Unix。 os.seteuid(euid) 设置当前进程的有效用户ID。可用性: Unix。 os.setgid(gid) 设置当前进程的组ID。可用性: Unix。 os.setgroups(groups) 将 group 参数值设置为与当进程相关联的附加组ID列表。group 参数必须为一个序列，每个元素应为每个组的数字ID。该操作通常只适用于超级用户。可用性: Unix。注解 在 Mac OS X 中，groups 的长度不能超过系统定义的最大有效组 ID 个数，一般为 16。 如果它没有返回与调用 setgroups() 所设置的相同的组列表，请参阅 getgroups() 的文档。 os.setpgrp() 根据已实现的版本（如果有）来调用系统 setpgrp() 或 setpgrp(0, 0) 。相关说明，请参考 Unix 手册。可用性: Unix。 os.setpgid(pid, pgrp) 使用系统调用 setpgid()，将 pid 对应进程的组ID设置为 pgrp。相关说明，请参考 Unix 手册。可用性: Unix。 os.setpriority(which, who, priority) 设置程序调度优先级。 which 的值为 PRIO_PROCESS, PRIO_PGRP 或 PRIO_USER 之一，而 who 会相对于 which (PRIO_PROCESS 的进程标识符, PRIO_PGRP 的进程组标识符和 PRIO_USER 的用户 ID) 被解析。 who 值为零 (分别) 表示调用进程，调用进程的进程组或调用进程的真实用户 ID。 priority 是范围在 -20 至 19 的值。 默认优先级为 0；较小的优先级数值会更优先被调度。可用性: Unix。3.3 新版功能. os.setregid(rgid, egid) 设置当前进程的真实和有效组ID。可用性: Unix。 os.setresgid(rgid, egid, sgid) 设置当前进程的真实，有效和暂存组ID。可用性: Unix。3.2 新版功能. os.setresuid(ruid, euid, suid) 设置当前进程的真实，有效和暂存用户ID。可用性: Unix。3.2 新版功能. os.setreuid(ruid, euid) 设置当前进程的真实和有效用户ID。可用性: Unix。 os.getsid(pid) 调用系统调用 getsid()。相关说明，请参考 Unix 手册。可用性: Unix。 os.setsid() 使用系统调用 getsid()。相关说明，请参考 Unix 手册。可用性: Unix。 os.setuid(uid) 设置当前进程的用户ID。可用性: Unix。 os.strerror(code) 根据 code 中的错误码返回错误消息。 在某些平台上当给出未知错误码时 strerror() 将返回 NULL 并会引发 ValueError。 os.supports_bytes_environ 如果操作系统上原生环境类型是字节型则为 True (例如在 Windows 上为 False)。3.2 新版功能. os.umask(mask) 设定当前数值掩码并返回之前的掩码。 os.uname() 返回当前操作系统的识别信息。返回值是一个有5个属性的对象：sysname - 操作系统名nodename - 机器在网络上的名称（需要先设定）release - 操作系统发行信息version - 操作系统版本信息machine - 硬件标识符为了向后兼容，该对象也是可迭代的，像是一个按照 sysname，nodename，release，version，和 machine 顺序组成的元组。有些系统会将 nodename 截短为 8 个字符或截短至前缀部分；获取主机名的一个更好方式是 socket.gethostname() 或甚至可以用 socket.gethostbyaddr(socket.gethostname())。可用性: 较新的 Unix 版本。在 3.3 版更改: 返回结果的类型由元组变成一个类似元组的对象，同时具有命名的属性。 os.unsetenv(key) 取消设置（删除）名为 key 的环境变量。变量名的改变会影响由 os.system()，popen()，fork() 和 execv() 触发的子进程。当系统支持 unsetenv() ，删除在 os.environ 中的变量会自动转换为对 unsetenv() 的调用。但是 unsetenv() 不能更新 os.environ，因此最好直接删除 os.environ 中的变量。引发一个 审计事件 os.unsetenv，附带参数 key。可用性: 大部分的Unix系统。 创建文件对象这些函数创建新的 file objects 。（参见 open() 以获取打开文件描述符的相关信息。） os.fdopen(fd, args, kwargs*) 返回打开文件描述符 fd 对应文件的对象。类似内建 open() 函数，二者接受同样的参数。不同之处在于 fdopen() 第一个参数应该为整数。 文件描述符操作这些函数对文件描述符所引用的 I/O 流进行操作。 文件描述符是一些小的整数，对应于当前进程所打开的文件。例如，标准输入的文件描述符通常是0，标准输出是1，标准错误是2。之后被进程打开的文件的文件描述符会被依次指定为3，4，5等。“文件描述符”这个词有点误导性，在 Unix 平台中套接字和管道也被文件描述符所引用。 当需要时，可以用 fileno() 可以获得 file object 所对应的文件描述符。需要注意的是，直接使用文件描述符会绕过文件对象的方法，会忽略如数据内部缓冲等情况。 os.close(fd) 关闭文件描述符 fd。注解 该功能适用于低级 I/O 操作，必须用于 os.open() 或 pipe() 返回的文件描述符。若要关闭由内建函数 open()、popen() 或 fdopen() 返回的 “文件对象”，则应使用其相应的 close() 方法。 os.closerange(fd_low, fd_high) 关闭从 fd_low （包括）到 fd_high （排除）间的文件描述符，并忽略错误。类似（但快于）: 12345for fd in range(fd_low, fd_high): try: os.close(fd) except OSError: pass os.copy_file_range(src, dst, count, offset_src=None, offset_dst=None) 从文件描述符 src 复制 count 字节，从偏移量 offset_src 开始读取，到文件描述符 dst，从偏移量 offset_dst 开始写入。如果 offset_src 为 None，则 src 将从当前位置开始读取；offset_dst 同理。src 和 dst 指向的文件必须处于相同的文件系统，否则将会抛出一个 errno 被设为 errno.EXDEV 的 OSError 。此复制的完成没有额外的从内核到用户空间再回到内核的数据转移花费。另外，一些文件系统可能实现额外的优化。完成复制就如同打开两个二进制文件一样。返回值是复制的字节的数目。这可能低于需求的数目。Availability: Linux kernel &gt;= 4.5 或 glibc &gt;= 2.27。3.8 新版功能. os.device_encoding(fd) 如果连接到终端，则返回一个与 fd 关联的设备描述字符，否则返回 None。 os.dup(fd) 返回一个文件描述符 fd 的副本。该文件描述符的副本是 不可继承的。在 Windows 中，当复制一个标准流（0: stdin, 1: stdout, 2: stderr）时，新的文件描述符是 可继承的。在 3.4 版更改: 新的文件描述符现在是不可继承的。 os.dup2(fd, fd2, inheritable=True) 把文件描述符 fd 复制为 fd2，必要时先关闭后者。返回 fd2。新的文件描述符默认是 可继承的，除非在 inheritable 为 False 时，是不可继承的。在 3.4 版更改: 添加可选参数 inheritable。在 3.7 版更改: 成功时返回 fd2，以过去的版本中，总是返回 None。 os.fchmod(fd, mode) 将 fd 指定文件的权限状态修改为 mode。可以参考 chmod() 中列出 mode 的可用值。从Python 3.3开始，这相当于 os.chmod(fd, mode)。引发一个 审计事件 os.chmod，附带参数 path、mode、dir_fd。可用性: Unix。 os.fchown(fd, uid, gid) 分别将 fd 指定文件的所有者和组 ID 修改为 uid 和 gid 的值。若不想变更其中的某个 ID，可将相应值设为 -1。参考 chown()。从 Python 3.3 开始，这相当于 os.chown(fd, uid, gid)。引发一个 审计事件 os.chown，附带参数 path、uid、gid、dir_fd。可用性: Unix。 os.fdatasync(fd) 强制将文件描述符 fd 指定文件写入磁盘。不强制更新元数据。可用性: Unix。 该功能在 MacOS 中不可用。 os.fpathconf(fd, name) 返回与打开的文件有关的系统配置信息。name 指定要查找的配置名称，它可以是字符串，是一个系统已定义的名称，这些名称定义在不同标准（POSIX.1，Unix 95，Unix 98 等）中。一些平台还定义了额外的其他名称。当前操作系统已定义的名称在 pathconf_names 字典中给出。对于未包含在该映射中的配置名称，也可以传递一个整数作为 name。如果 name 是一个字符串且不是已定义的名称，将抛出 ValueError 异常。如果当前系统不支持 name 指定的配置名称，即使该名称存在于 pathconf_names，也会抛出 OSError 异常，错误码为 errno.EINVAL。从 Python 3.3 起，此功能等价于 os.pathconf(fd, name)。可用性: Unix。 os.fstat(fd) 获取文件描述符 fd 的状态. 返回一个 stat_result 对象。从 Python 3.3 起，此功能等价于 os.stat(fd)。 参见： stat() 函数。 os.fstatvfs(fd) 返回文件系统的信息，该文件系统是文件描述符 fd 指向的文件所在的文件系统，与 statvfs() 一样。从 Python 3.3 开始，它等效于 os.statvfs(fd)。可用性: Unix。 os.fsync(fd) 强制将文件描述符 fd 指向的文件写入磁盘。在 Unix，这将调用原生 fsync() 函数；在 Windows，则是 MS _commit() 函数。如果要写入的是缓冲区内的 Python 文件对象 f，请先执行 f.flush()，然后执行 os.fsync(f.fileno())，以确保与 f 关联的所有内部缓冲区都写入磁盘。可用性: Unix, Windows。 os.ftruncate(fd, length) 截断文件描述符 fd 指向的文件，以使其最大为 length 字节。从 Python 3.3 开始，它等效于 os.truncate(fd, length)。引发一个 审计事件 os.truncate，附带参数 fd, length。可用性: Unix, Windows。在 3.5 版更改: 添加了 Windows 支持 os.get_blocking(fd) 获取文件描述符的阻塞模式：如果设置了 O_NONBLOCK 标志位，返回 False，如果该标志位被清除，返回 True。参见 set_blocking() 和 socket.socket.setblocking()。可用性: Unix。3.5 新版功能. os.isatty(fd) 如果文件描述符 fd 打开且已连接至 tty 设备（或类 tty 设备），返回 True，否则返回 False。 os.lockf(fd, cmd, len) 在打开的文件描述符上，使用、测试或删除 POSIX 锁。fd 是一个打开的文件描述符。cmd 指定要进行的操作，它们是 F_LOCK、F_TLOCK、F_ULOCK 或 F_TEST 中的一个。len 指定哪部分文件需要锁定。引发一个 审计事件 os.lockf，附带参数 fd、cmd、len。可用性: Unix。3.3 新版功能. os.F_LOCK os.F_TLOCK os.F_ULOCK os.F_TEST 标志位，用于指定 lockf() 进行哪一种操作。可用性: Unix。3.3 新版功能. os.lseek(fd, pos, how) 将文件描述符 fd 的当前位置设置为 pos，位置的计算方式 how 如下：设置为 SEEK_SET 或 0 表示从文件开头计算，设置为 SEEK_CUR 或 1 表示从文件当前位置计算，设置为 SEEK_END 或 2 表示文件末尾计算。返回新指针位置，这个位置是从文件开头计算的，单位是字节。 os.SEEK_SET os.SEEK_CUR os.SEEK_END lseek() 函数的参数，它们的值分别为 0、1 和 2。3.3 新版功能: 某些操作系统可能支持其他值，例如 os.SEEK_HOLE 或 os.SEEK_DATA。 os.open(path, flags, mode=0o777, **, dir_fd=None*) 打开文件 path，根据 flags 设置各种标志位，并根据 mode 设置其权限状态。当计算 mode 时，会首先根据当前 umask 值将部分权限去除。本方法返回新文件的描述符。新的文件描述符是 不可继承 的。有关 flag 和 mode 取值的说明，请参见 C 运行时文档。标志位常量（如 O_RDONLY 和 O_WRONLY）在 os 模块中定义。特别地，在 Windows 上需要添加 O_BINARY 才能以二进制模式打开文件。本函数带有 dir_fd 参数，支持 基于目录描述符的相对路径。引发一个 审计事件 open，附带参数 path、mode、flags。在 3.4 版更改: 新的文件描述符现在是不可继承的。 注解：本函数适用于底层的 I/O。常规用途请使用内置函数 open()，该函数的 read() 和 write() 方法（及其他方法）会返回 文件对象。要将文件描述符包装在文件对象中，请使用 fdopen()。 3.3 新版功能: dir_fd 参数。 在 3.5 版更改: 如果系统调用被中断，但信号处理程序没有触发异常，此函数现在会重试系统调用，而不是触发 InterruptedError 异常 (原因详见 PEP 475)。 在 3.6 版更改: 接受一个 类路径对象。 常量以下常量是 open() 函数 flags 参数的选项。可以用按位或运算符 | 将它们组合使用。部分常量并非在所有平台上都可用。有关其可用性和用法的说明，请参阅 open(2)) 手册（Unix 上）或 MSDN （Windows 上）。 os.O_RDONLY os.O_WRONLY os.O_RDWR os.O_APPEND os.O_CREAT os.O_EXCL os.O_TRUNC 上述常量在 Unix 和 Windows 上均可用。 os.O_DSYNC os.O_RSYNC os.O_SYNC os.O_NDELAY os.O_NONBLOCK os.O_NOCTTY os.O_CLOEXEC 这个常数仅在 Unix 系统中可用。在 3.3 版更改: 增加 O_CLOEXEC 常量。 os.O_BINARY os.O_NOINHERIT os.O_SHORT_LIVED os.O_TEMPORARY os.O_RANDOM os.O_SEQUENTIAL os.O_TEXT 这个常数仅在 Windows 系统中可用。 os.O_ASYNC os.O_DIRECT os.O_DIRECTORY os.O_NOFOLLOW os.O_NOATIME os.O_PATH os.O_TMPFILE os.O_SHLOCK os.O_EXLOCK 上述常量是扩展常量，如果 C 库未定义它们，则不存在。在 3.4 版更改: 在支持的系统上增加 O_PATH。增加 O_TMPFILE，仅在 Linux Kernel 3.11 或更高版本可用。 os.openpty() 打开一对新的伪终端，返回一对文件描述符 （主，从），分别为 pty 和 tty。新的文件描述符是 不可继承 的。对于（稍微）轻量一些的方法，请使用 pty 模块。可用性: 某些 Unix。在 3.4 版更改: 新的文件描述符不再可继承。 os.pipe() 创建一个管道，返回一对分别用于读取和写入的文件描述符 (r, w)。新的文件描述符是 不可继承 的。可用性: Unix, Windows。在 3.4 版更改: 新的文件描述符不再可继承。 os.pipe2(flags) 创建带有 flags 标志位的管道。可通过对以下一个或多个值进行“或”运算来构造这些 flags：O_NONBLOCK、O_CLOEXEC。返回一对分别用于读取和写入的文件描述符 (r, w)。可用性: 某些 Unix。3.3 新版功能. os.posix_fallocate(fd, offset, len) 确保为 fd 指向的文件分配了足够的磁盘空间，该空间从偏移量 offset 开始，到 len 字节为止。可用性: Unix。3.3 新版功能. os.posix_fadvise(fd, offset, len, advice) 声明即将以特定模式访问数据，使内核可以提前进行优化。数据范围是从 fd 所指向文件的 offset 开始，持续 len 个字节。advice 的取值是如下之一：POSIX_FADV_NORMAL, POSIX_FADV_SEQUENTIAL, POSIX_FADV_RANDOM, POSIX_FADV_NOREUSE, POSIX_FADV_WILLNEED 或 POSIX_FADV_DONTNEED。可用性: Unix。3.3 新版功能. os.POSIX_FADV_NORMAL os.POSIX_FADV_SEQUENTIAL os.POSIX_FADV_RANDOM os.POSIX_FADV_NOREUSE os.POSIX_FADV_WILLNEED os.POSIX_FADV_DONTNEED 用于 posix_fadvise() 的 advice 参数的标志位，指定可能使用的访问模式。可用性: Unix。3.3 新版功能. os.pread(fd, n, offset) 从文件描述符 fd 所指向文件的偏移位置 offset 开始，读取至多 n 个字节，而保持文件偏移量不变。返回所读取字节的字节串 (bytestring)。如果到达了 fd 指向的文件末尾，则返回空字节对象。可用性: Unix。3.3 新版功能. os.preadv(fd, buffers, offset, flags=0) 从文件描述符 fd 所指向文件的偏移位置 offset 开始，将数据读取至可变 字节类对象 缓冲区 buffers 中，保持文件偏移量不变。将数据依次存放到每个缓冲区中，填满一个后继续存放到序列中的下一个缓冲区，来保存其余数据。flags 参数可以由零个或多个标志位进行按位或运算来得到：RWF_HIPRIRWF_NOWAIT返回实际读取的字节总数，该总数可以小于所有对象的总容量。操作系统可能对允许使用的缓冲区数量有限制（使用 sysconf() 获取 &#39;SC_IOV_MAX&#39; 值）。本方法结合了 os.readv() 和 os.pread() 的功能。可用性：Linux 2.6.30 或更高版本，FreeBSD 6.0 或更高版本，OpenBSD 2.7 或更高版本。使用标志位需要 Linux 4.6 或更高版本。3.7 新版功能. os.RWF_NOWAIT 不要等待无法立即获得的数据。如果指定了此标志，那么当需要从后备存储器中读取数据，或等待文件锁时，系统调用将立即返回。如果成功读取数据，则返回读取的字节数。如果未读取到数据，则返回 -1，并将错误码 errno 置为 errno.EAGAIN。可用性：Linux 4.14 或更高版本。3.7 新版功能. os.RWF_HIPRI 高优先级读/写。允许基于块的文件系统对设备进行轮询，这样可以降低延迟，但可能会占用更多资源。目前在 Linux 上，此功能仅在使用 O_DIRECT 标志打开的文件描述符上可用。可用性：Linux 4.6 或更高版本。3.7 新版功能. os.pwrite(fd, str, offset) 将 str 中的字节串 (bytestring) 写入文件描述符 fd 的偏移位置 offset 处，保持文件偏移量不变。返回实际写入的字节数。可用性: Unix。3.3 新版功能. os.pwritev(fd, buffers, offset, flags=0) 将缓冲区 buffers 的内容写入文件描述符 fd 的偏移位置 offset 处，保持文件偏移量不变。缓冲区 buffers 必须是由 字节类对象 组成的序列。缓冲区以数组顺序处理。先写入第一个缓冲区的全部内容，再写入第二个缓冲区，照此继续。flags 参数可以由零个或多个标志位进行按位或运算来得到：RWF_DSYNCRWF_SYNC返回实际写入的字节总数。操作系统可能对允许使用的缓冲区数量有限制（使用 sysconf() 获取 &#39;SC_IOV_MAX&#39; 值）。本方法结合了 os.writev() 和 os.pwrite() 的功能。可用性：Linux 2.6.30 或更高版本，FreeBSD 6.0 或更高版本，OpenBSD 2.7 或更高版本。使用标志位需要 Linux 4.7 或更高版本。3.7 新版功能. os.RWF_DSYNC 提供立即写入功能，等效于 O_DSYNC open(2) 标志。该标志仅作用于系统调用写入的数据。可用性：Linux 4.7 或更高版本。3.7 新版功能. os.RWF_SYNC 提供立即写入功能，等效于 O_SYNC open(2) 标志。该标志仅作用于系统调用写入的数据。可用性：Linux 4.7 或更高版本。3.7 新版功能. os.read(fd, n) 从文件描述符 fd 中读取至多 n 个字节。返回所读取字节的字节串 (bytestring)。如果到达了 fd 指向的文件末尾，则返回空字节对象。 该功能适用于低级 I/O 操作，必须用于 os.open() 或 pipe() 返回的文件描述符。若要读取由内建函数 open()、popen()、fdopen() 或 sys.stdin 返回的 “文件对象”，则应使用其相应的 read() 或 readline() 方法。 在 3.5 版更改: 如果系统调用被中断，但信号处理程序没有触发异常，此函数现在会重试系统调用，而不是触发 InterruptedError 异常 (原因详见 PEP 475)。 os.sendfile(out, in, offset, count) os.sendfile(out, in, offset, count, [headers, ][trailers, ]flags=0) 将文件描述符 in 中的 count 字节复制到文件描述符 out 的偏移位置 offset 处。返回复制的字节数，如果到达 EOF，返回 0。 定义了 sendfile() 的所有平台均支持第一种函数用法。 在 Linux 上，将 offset 设置为 None，则从 in 的当前位置开始读取，并更新 in 的位置。 第二种函数用法可以在 Mac OS X 和 FreeBSD 上使用，其中，headers 和 trailers 是任意的缓冲区序列，它们分别在写入 in 的数据前、后被写入。返回值与第一种用法相同。 在 Mac OS X 和 FreeBSD 上，将 count 设为 0 表示持续复制直到 in 的结尾。 所有平台都支持将套接字作为 out 文件描述符，有些平台也支持其他类型（如常规文件或管道）。 跨平台应用程序不应使用 headers、trailers 和 flags 参数。 可用性: Unix。 注解：有关 sendfile() 的高级封装，参见 socket.socket.sendfile()。 os.set_blocking(fd, blocking) 设置指定文件描述符的阻塞模式：如果 blocking 为 False，则为该描述符设置 O_NONBLOCK 标志位，反之则清除该标志位。参见 get_blocking() 和 socket.socket.setblocking()。可用性: Unix。3.5 新版功能. os.SF_NODISKIO os.SF_MNOWAIT os.SF_SYNC sendfile() 函数的参数（假设当前实现支持这些参数）。可用性: Unix。3.3 新版功能. os.readv(fd, buffers) 从文件描述符 fd 将数据读取至多个可变的 字节类对象 缓冲区 buffers 中。将数据依次存放到每个缓冲区中，填满一个后继续存放到序列中的下一个缓冲区，来保存其余数据。返回实际读取的字节总数，该总数可以小于所有对象的总容量。操作系统可能对允许使用的缓冲区数量有限制（使用 sysconf() 获取 &#39;SC_IOV_MAX&#39; 值）。可用性: Unix。3.3 新版功能. os.tcgetpgrp(fd) 返回与 fd 指定的终端相关联的进程组（fd 是由 os.open() 返回的已打开的文件描述符）。可用性: Unix。 os.tcsetpgrp(fd, pg) 设置与 fd 指定的终端相关联的进程组为 pg\（fd 是由 os.open() 返回的已打开的文件描述符）。可用性: Unix。 os.ttyname(fd) 返回一个字符串，该字符串表示与文件描述符 fd 关联的终端。如果 fd 没有与终端关联，则抛出异常。可用性: Unix。 os.write(fd, str) 将 str 中的字节串 (bytestring) 写入文件描述符 fd。返回实际写入的字节数。 该功能适用于低级 I/O 操作，必须用于 os.open() 或 pipe() 返回的文件描述符。若要写入由内建函数 open()、popen()、fdopen()、sys.stdout 或 sys.stderr 返回的 “文件对象”，则应使用其相应的 write() 方法。 在 3.5 版更改: 如果系统调用被中断，但信号处理程序没有触发异常，此函数现在会重试系统调用，而不是触发 InterruptedError 异常 (原因详见 PEP 475)。 os.writev(fd, buffers) 将缓冲区 buffers 的内容写入文件描述符 fd。缓冲区 buffers 必须是由 字节类对象 组成的序列。缓冲区以数组顺序处理。先写入第一个缓冲区的全部内容，再写入第二个缓冲区，照此继续。 返回实际写入的字节总数。 操作系统可能对允许使用的缓冲区数量有限制（使用 sysconf() 获取 &#39;SC_IOV_MAX&#39; 值）。 可用性: Unix。 3.3 新版功能. 查询终端的尺寸3.3 新版功能. os.get_terminal_size(fd=STDOUT_FILENO) 返回终端窗口的尺寸，格式为 (columns, lines)，它是类型为 terminal_size 的元组。可选参数 fd （默认为 STDOUT_FILENO 或标准输出）指定应查询的文件描述符。如果文件描述符未连接到终端，则抛出 OSError 异常。shutil.get_terminal_size() 是供常规使用的高阶函数，os.get_terminal_size 是其底层的实现。可用性: Unix, Windows。 class os.terminal_size 元组的子类，存储终端窗口尺寸 (columns, lines)。columns终端窗口的宽度，单位为字符。lines终端窗口的高度，单位为字符。 文件描述符的继承3.4 新版功能. 每个文件描述符都有一个 “inheritable”（可继承）标志位，该标志位控制了文件描述符是否可以由子进程继承。从 Python 3.4 开始，由 Python 创建的文件描述符默认是不可继承的。 在 UNIX 上，执行新程序时，不可继承的文件描述符在子进程中是关闭的，其他文件描述符将被继承。 在 Windows 上，不可继承的句柄和文件描述符在子进程中是关闭的，但标准流（文件描述符 0、1 和 2 即标准输入、标准输出和标准错误）是始终继承的。如果使用 spawn* 函数，所有可继承的句柄和文件描述符都将被继承。如果使用 subprocess 模块，将关闭除标准流以外的所有文件描述符，并且仅当 close_fds 参数为 False 时才继承可继承的句柄。 os.get_inheritable(fd) 获取指定文件描述符的“可继承”标志位（为布尔值）。 os.set_inheritable(fd, inheritable) 设置指定文件描述符的“可继承”标志位。 os.get_handle_inheritable(handle) 获取指定句柄的“可继承”标志位（为布尔值）。可用性: Windows。 os.set_handle_inheritable(handle, inheritable) 设置指定句柄的“可继承”标志位。可用性: Windows。 文件和目录在某些 Unix 平台上，许多函数支持以下一项或多项功能： 指定文件描述符为参数： 通常在 os 模块中提供给函数的 path 参数必须是表示文件路径的字符串，但是，某些函数现在可以接受其 path 参数为打开文件描述符，该函数将对描述符指向的文件进行操作。（对于 POSIX 系统，Python 将调用以 f 开头的函数变体（如调用 fchdir 而不是 chdir）。） 可以用 os.supports_fd 检查某个函数在你的平台上是否支持将 path 参数指定为文件描述符。如果不支持，使用该功能将抛出 NotImplementedError 异常。 如果该函数还支持 dir_fd 或 follow_symlinks 参数，那么用文件描述符作为 path 后就不能再指定上述参数了。 基于目录描述符的相对路径： 如果 dir_fd 不是 None，它就应该是一个指向目录的文件描述符，这时待操作的 path 应该是相对路径，相对路径是相对于前述目录的。如果 path 是绝对路径，则 dir_fd 将被忽略。（对于 POSIX 系统，Python 将调用该函数的变体，变体以 at 结尾，可能以 f 开头（如调用 faccessat 而不是 access）。 可以用 os.supports_dir_fd 检查某个函数在你的平台上是否支持 dir_fd。如果不支持，使用该功能将抛出 NotImplementedError 异常。 不跟踪符号链接： 如果 follow_symlinks 为 False，并且待操作路径的最后一个元素是符号链接，则该函数将在符号链接本身而不是链接所指向的文件上操作。（对于 POSIX 系统，Python 将调用该函数的 l... 变体。） 可以用 os.supports_follow_symlinks 检查某个函数在你的平台上是否支持 follow_symlinks。如果不支持，使用该功能将抛出 NotImplementedError 异常。 os.access(path, mode, **, dir_fd=None, effective_ids=False, follow_symlinks=True*) 使用 实际用户ID/用户组ID 测试对 path 的访问。请注意，大多数测试操作将使用 有效用户ID/用户组ID，因此可以在 suid/sgid 环境中运用此例程，来测试调用用户是否具有对 path 的指定访问权限。mode 为 F_OK 时用于测试 path 是否存在，也可以对 R_OK、W_OK 和 X_OK 中的一个或多个进行“或”运算来测试指定权限。允许访问则返回 True，否则返回 False。更多信息请参见 Unix 手册页 access(2))。本函数支持指定 基于目录描述符的相对路径 和 不跟踪符号链接。如果 effective_ids 为 True，access() 将使用 有效用户ID/用户组ID 而非 实际用户ID/用户组ID 进行访问检查。您的平台可能不支持 effective_ids，您可以使用 os.supports_effective_ids 检查它是否可用。如果不可用，使用它时会抛出 NotImplementedError 异常。 注解：使用 access() 来检查用户是否具有某项权限（如打开文件的权限），然后再使用 open() 打开文件，这样做存在一个安全漏洞，因为用户可能会在检查和打开文件之间的时间里做其他操作。推荐使用 EAFP 技术。如: 12345&gt; if os.access("myfile", os.R_OK):&gt; with open("myfile") as fp:&gt; return fp.read()&gt; return "some default data"&gt; ​ 最好写成: 12345678&gt; try:&gt; fp = open("myfile")&gt; except PermissionError:&gt; return "some default data"&gt; else:&gt; with fp:&gt; return fp.read()&gt; 即使 access() 指示 I/O 操作会成功，但实际操作仍可能失败，尤其是对网络文件系统的操作，其权限语义可能超出常规的 POSIX 权限位模型。 os.F_OK os.R_OK os.W_OK os.X_OK 作为 access() 的 mode 参数的可选值，分别测试 path 的存在性、可读性、可写性和可执行性。 os.chdir(path) 将当前工作目录更改为 path。本函数支持 指定文件描述符为参数。其中，描述符必须指向打开的目录，不能是打开的文件。本函数可以抛出 OSError 及其子类的异常，如 FileNotFoundError、PermissionError 和 NotADirectoryError 异常。引发一个 审计事件 os.chdir，附带参数 path。3.3 新版功能: 在某些平台上新增支持将 path 参数指定为文件描述符。在 3.6 版更改: 接受一个 类路径对象。 os.chflags(path, flags, **, follow_symlinks=True*) 将 path 的 flags 设置为其他由数字表示的 flags。flags 可以用以下值按位或组合起来（以下值在 stat 模块中定义）：stat.UF_NODUMPstat.UF_IMMUTABLEstat.UF_APPENDstat.UF_OPAQUEstat.UF_NOUNLINKstat.UF_COMPRESSEDstat.UF_HIDDENstat.SF_ARCHIVEDstat.SF_IMMUTABLEstat.SF_APPENDstat.SF_NOUNLINKstat.SF_SNAPSHOT本函数支持 不跟踪符号链接。引发一个 审计事件 os.chflags，附带参数 path、flags。可用性: Unix。3.3 新版功能: follow_symlinks 参数。在 3.6 版更改: 接受一个 类路径对象。 os.chmod(path, mode, **, dir_fd=None, follow_symlinks=True*) 将 path 的 mode 更改为其他由数字表示的 mode。mode 可以用以下值之一，也可以将它们按位或组合起来（以下值在 stat 模块中定义）： stat.S_ISUID stat.S_ISGID stat.S_ENFMT stat.S_ISVTX stat.S_IREAD stat.S_IWRITE stat.S_IEXEC stat.S_IRWXU stat.S_IRUSR stat.S_IWUSR stat.S_IXUSR stat.S_IRWXG stat.S_IRGRP stat.S_IWGRP stat.S_IXGRP stat.S_IRWXO stat.S_IROTH stat.S_IWOTH stat.S_IXOTH 本函数支持 指定文件描述符、指定基于目录描述符的相对路径 和 不跟踪符号链接。 尽管 Windows 支持 chmod()，但只能用它设置文件的只读标志（stat.S_IWRITE 和 stat.S_IREAD 常量或对应的整数值）。所有其他标志位都会被忽略。 引发一个 审计事件 os.chmod，附带参数 path、mode、dir_fd。 3.3 新版功能: 添加了指定 path 为文件描述符的支持，以及 dir_fd 和 follow_symlinks 参数。 在 3.6 版更改: 接受一个 类路径对象。 os.chown(path, uid, gid, **, dir_fd=None, follow_symlinks=True*) 将 path 的用户和组 ID 分别修改为数字形式的 uid 和 gid。若要使其中某个 ID 保持不变，请将其置为 -1。本函数支持 指定文件描述符、指定基于目录描述符的相对路径 和 不跟踪符号链接。参见更高阶的函数 shutil.chown()，除了数字 ID 之外，它也接受名称。引发一个 审计事件 os.chown，附带参数 path、uid、gid、dir_fd。可用性: Unix。3.3 新版功能: 添加了指定 path 为文件描述符的支持，以及 dir_fd 和 follow_symlinks 参数。在 3.6 版更改: 支持 类路径对象。 os.chroot(path) 将当前进程的根目录更改为 path。可用性: Unix。在 3.6 版更改: 接受一个 类路径对象。 os.fchdir(fd) 将当前工作目录更改为文件描述符 fd 指向的目录。fd 必须指向打开的目录而非文件。从 Python 3.3 开始，它等效于 os.chdir(fd)。引发一个 审计事件 os.chdir，附带参数 path。可用性: Unix。 os.getcwd() 返回表示当前工作目录的字符串。 os.getcwdb() 返回表示当前工作目录的字节串 (bytestring)。在 3.8 版更改: 在 Windows 上，本函数现在会使用 UTF-8 编码格式而不是 ANSI 代码页：请参看 PEP 529 了解具体原因。 该函数在 Windows 上不再被弃用。 os.lchflags(path, flags) 将 path 的 flags 设置为其他由数字表示的 flags，与 chflags() 类似，但不跟踪符号链接。从 Python 3.3 开始，它等效于 os.chflags(path, flags, follow_symlinks=False)。引发一个 审计事件 os.chflags，附带参数 path、flags。可用性: Unix。在 3.6 版更改: 接受一个 类路径对象。 os.lchmod(path, mode) 将 path 的权限状态修改为 mode。如果 path 是符号链接，则影响符号链接本身而非链接目标。可以参考 chmod() 中列出 mode 的可用值。从 Python 3.3 开始，它等效于 os.chmod(path, mode, follow_symlinks=False)。引发一个 审计事件 os.chmod，附带参数 path、mode、dir_fd。可用性: Unix。在 3.6 版更改: 接受一个 类路径对象。 os.lchown(path, uid, gid) 将 path 的用户和组 ID 分别修改为数字形式的 uid 和 gid，本函数不跟踪符号链接。从 Python 3.3 开始，它等效于 os.chown(path, uid, gid, follow_symlinks=False)。引发一个 审计事件 os.chown，附带参数 path、uid、gid、dir_fd。可用性: Unix。在 3.6 版更改: 接受一个 类路径对象。 os.link(src, dst, **, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True*) 创建一个指向 src 的硬链接，名为 dst。本函数支持将 src_dir_fd 和 dst_dir_fd 中的一个或两个指定为 基于目录描述符的相对路径，支持 不跟踪符号链接。引发一个 审计事件 os.link 附带参数 src、dst、src_dir_fd、dst_dir_fd。可用性: Unix, Windows。在 3.2 版更改: 添加了对 Windows 的支持。3.3 新版功能: 添加 src_dir_fd、dst_dir_fd 和 follow_symlinks 参数。在 3.6 版更改: 接受一个 类路径对象 作为 src 和 dst。 os.listdir(path=’.’) 返回一个列表，该列表包含了 path 中所有文件与目录的名称。该列表按任意顺序排列，并且不包含特殊条目 &#39;.&#39; 和 &#39;..&#39;，即使它们确实在目录中存在。path 可以是 类路径对象。如果 path 是（直接传入或通过 PathLike 接口间接传入） bytes 类型，则返回的文件名也将是 bytes 类型，其他情况下是 str 类型。本函数也支持 指定文件描述符为参数，其中描述符必须指向目录。引发一个 审计事件 os.listdir，附带参数 path。 要将 str 类型的文件名编码为 bytes，请使用 fsencode()。 scandir() 函数返回目录内文件名的同时，也返回文件属性信息，它在某些具体情况下能提供更好的性能。 在 3.2 版更改: path 变为可选参数。 3.3 新版功能: 新增支持将 path 参数指定为打开的文件描述符。 在 3.6 版更改: 接受一个 类路径对象。 os.lstat(path, **, dir_fd=None*) 在给定路径上执行本函数，其操作相当于 lstat() 系统调用，类似于 stat() 但不跟踪符号链接。返回值是 stat_result 对象。 在不支持符号链接的平台上，本函数是 stat() 的别名。 从 Python 3.3 起，此功能等价于 os.stat(path, dir_fd=dir_fd, follow_symlinks=False)。 本函数支持 基于目录描述符的相对路径。 在 3.2 版更改: 添加对 Windows 6.0 (Vista) 符号链接的支持。 在 3.3 版更改: 添加了 dir_fd 参数。 在 3.6 版更改: 接受一个 类路径对象 作为 src 和 dst。 在 3.8 版更改: 目前在 Windows 上，遇到表示另一个路径的重解析点（即名称代理，包括符号链接和目录结点），本函数将打开它。其他种类的重解析点由 stat() 交由操作系统解析。 os.mkdir(path, mode=0o777, **, dir_fd=None*) 创建一个名为 path 的目录，应用以数字表示的权限模式 mode。如果目录已存在，则抛出 FileExistsError 异常。某些系统会忽略 mode。如果没有忽略它，那么将首先从它中减去当前的 umask 值。如果除最后 9 位（即 mode 八进制的最后 3 位）之外，还设置了其他位，则其他位的含义取决于各个平台。在某些平台上，它们会被忽略，应显式调用 chmod() 进行设置。本函数支持 基于目录描述符的相对路径。如果需要创建临时目录，请参阅 tempfile 模块中的 tempfile.mkdtemp() 函数。引发一个 审计事件 os.mkdir，附带参数 path、mode、dir_fd。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.makedirs(name, mode=0o777, exist_ok=False) 递归目录创建函数。与 mkdir() 类似，但会自动创建到达最后一级目录所需要的中间目录。mode 参数会传递给 mkdir()，用来创建最后一级目录，对于该参数的解释，请参阅 mkdir() 中的描述。要设置某些新建的父目录的权限，可以在调用 makedirs() 之前设置 umask。现有父目录的权限不会更改。如果 exist_ok 为 False (默认值)，则如果目标目录已存在将引发 FileExistsError。 如果要创建的路径元素包含 pardir (如 UNIX 系统中的 “..”) makedirs() 将无法明确目标。 本函数能正确处理 UNC 路径。 引发一个 审计事件 os.mkdir，附带参数 path、mode、dir_fd。 3.2 新版功能: exist_ok 参数。 在 3.4.1 版更改: 在 Python 3.4.1 以前，如果 exist_ok 为 True，且目录已存在，且 mode 与现有目录的权限不匹配，makedirs() 仍会抛出错误。由于无法安全地实现此行为，因此在 Python 3.4.1 中将该行为删除。请参阅 bpo-21082。 在 3.6 版更改: 接受一个 类路径对象。 在 3.7 版更改: mode 参数不再影响新创建的中间目录的权限。 os.mkfifo(path, mode=0o666, **, dir_fd=None*) 创建一个名为 path 的 FIFO（命名管道，一种先进先出队列），具有以数字表示的权限状态 mode。将从 mode 中首先减去当前的 umask 值。本函数支持 基于目录描述符的相对路径。FIFO 是可以像常规文件一样访问的管道。FIFO 如果没有被删除（如使用 os.unlink()），会一直存在。通常，FIFO 用作“客户端”和“服务器”进程之间的汇合点：服务器打开 FIFO 进行读取，而客户端打开 FIFO 进行写入。请注意，mkfifo() 不会打开 FIFO — 它只是创建汇合点。可用性: Unix。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.mknod(path, mode=0o600, device=0, **, dir_fd=None*) 创建一个名为 path 的文件系统节点（文件，设备专用文件或命名管道）。mode 指定权限和节点类型，方法是将权限与下列节点类型 stat.S_IFREG、stat.S_IFCHR、stat.S_IFBLK 和 stat.S_IFIFO 之一（按位或）组合（这些常量可以在 stat 模块中找到）。对于 stat.S_IFCHR 和 stat.S_IFBLK，device 参数指定了新创建的设备专用文件（可能会用到 os.makedev()），否则该参数将被忽略。本函数支持 基于目录描述符的相对路径。可用性: Unix。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.major(device) 提取主设备号，提取自原始设备号（通常是 stat 中的 st_dev 或 st_rdev 字段）。 os.minor(device) 提取次设备号，提取自原始设备号（通常是 stat 中的 st_dev 或 st_rdev 字段）。 os.makedev(major, minor) 将主设备号和次设备号组合成原始设备号。 os.pathconf(path, name) 返回所给名称的文件有关的系统配置信息。name 指定要查找的配置名称，它可以是字符串，是一个系统已定义的名称，这些名称定义在不同标准（POSIX.1，Unix 95，Unix 98 等）中。一些平台还定义了额外的其他名称。当前操作系统已定义的名称在 pathconf_names 字典中给出。对于未包含在该映射中的配置名称，也可以传递一个整数作为 name。如果 name 是一个字符串且不是已定义的名称，将抛出 ValueError 异常。如果当前系统不支持 name 指定的配置名称，即使该名称存在于 pathconf_names，也会抛出 OSError 异常，错误码为 errno.EINVAL。本函数支持 指定文件描述符为参数。可用性: Unix。在 3.6 版更改: 接受一个 类路径对象。 os.pathconf_names 字典，表示映射关系，为 pathconf() 和 fpathconf() 可接受名称与操作系统为这些名称定义的整数值之间的映射。这可用于判断系统已定义了哪些名称。可用性: Unix。 os.readlink(path, **, dir_fd=None*) 返回一个字符串，为符号链接指向的实际路径。其结果可以是绝对或相对路径。如果是相对路径，则可用 os.path.join(os.path.dirname(path), result) 转换为绝对路径。如果 path 是字符串对象（直接传入或通过 PathLike 接口间接传入），则结果也将是字符串对象，且此类调用可能会引发 UnicodeDecodeError。如果 path 是字节对象（直接传入或间接传入），则结果将会是字节对象。本函数支持 基于目录描述符的相对路径。当尝试解析的路径可能含有链接时，请改用 realpath() 以正确处理递归和平台差异。可用性: Unix, Windows。在 3.2 版更改: 添加对 Windows 6.0 (Vista) 符号链接的支持。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 在 Unix 上可以接受一个 类路径对象。在 3.8 版更改: 在 Windows 上接受 类路径对象 和字节对象。在 3.8 版更改: 增加了对目录链接的支持，且返回值改为了“替换路径”的形式（通常带有 \\?\ 前缀），而不是先前那样返回可选的 “print name” 字段。 os.remove(path, **, dir_fd=None*) 移除（删除）文件 path。如果 path 是目录，则抛出 IsADirectoryError 异常。请使用 rmdir() 删除目录。本函数支持 基于目录描述符的相对路径。在 Windows 上，尝试删除正在使用的文件会抛出异常。而在 Unix 上，虽然该文件的条目会被删除，但分配给文件的存储空间仍然不可用，直到原始文件不再使用为止。本函数在语义上与 unlink() 相同。引发一个 审计事件 os.remove，附带参数 path、dir_fd。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.removedirs(name) 递归删除目录。工作方式类似于 rmdir()，不同之处在于，如果成功删除了末尾一级目录，removedirs() 会尝试依次删除 path 中提到的每个父目录，直到抛出错误为止（但该错误会被忽略，因为这通常表示父目录不是空目录）。例如，os.removedirs(&#39;foo/bar/baz&#39;) 将首先删除目录 &#39;foo/bar/baz&#39;，然后如果 &#39;foo/bar&#39; 和 &#39;foo&#39; 为空，则继续删除它们。如果无法成功删除末尾一级目录，则抛出 OSError 异常。引发一个 审计事件 os.remove，附带参数 path、dir_fd。在 3.6 版更改: 接受一个 类路径对象。 os.rename(src, dst, **, src_dir_fd=None, dst_dir_fd=None*) 将文件或目录 src 重命名为 dst。如果 dst 已存在，则下列情况下将会操作失败，并抛出 OSError 的子类：在 Windows 上，如果 dst 已存在，则抛出 FileExistsError 异常。在 Unix 上，如果 src 是文件而 dst 是目录，将抛出 IsADirectoryError 异常，反之则抛出 NotADirectoryError 异常。如果两者都是目录且 dst 为空，则 dst 将被静默替换。如果 dst 是非空目录，则抛出 OSError 异常。如果两者都是文件，则在用户具有权限的情况下，将对 dst 进行静默替换。如果 src 和 dst 在不同的文件系统上，则本操作在某些 Unix 分支上可能会失败。如果成功，重命名操作将是一个原子操作（这是 POSIX 的要求）。本函数支持将 src_dir_fd 和 dst_dir_fd 中的一个或两个指定为 基于目录描述符的相对路径。如果需要在不同平台上都能替换目标，请使用 replace()。引发一个 审计事件 os.rename 附带参数 src、dst、src_dir_fd、dst_dir_fd。3.3 新版功能: src_dir_fd 和 dst_dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象 作为 src 和 dst。 os.renames(old, new) 递归重命名目录或文件。工作方式类似 rename()，除了会首先创建新路径所需的中间目录。重命名后，将调用 removedirs() 删除旧路径中不需要的目录。注解 如果用户没有权限删除末级的目录或文件，则本函数可能会无法建立新的目录结构。引发一个 审计事件 os.rename 附带参数 src、dst、src_dir_fd、dst_dir_fd。在 3.6 版更改: 接受一个 类路径对象 作为 old 和 new。 os.replace(src, dst, **, src_dir_fd=None, dst_dir_fd=None*) 将文件或目录 src 重命名为 dst。如果 dst 是目录，将抛出 OSError 异常。如果 dst 已存在且为文件，则在用户具有权限的情况下，将对其进行静默替换。如果 src 和 dst 在不同的文件系统上，本操作可能会失败。如果成功，重命名操作将是一个原子操作（这是 POSIX 的要求）。本函数支持将 src_dir_fd 和 dst_dir_fd 中的一个或两个指定为 基于目录描述符的相对路径。引发一个 审计事件 os.rename 附带参数 src、dst、src_dir_fd、dst_dir_fd。3.3 新版功能.**在 3.6 版更改: 接受一个 类路径对象 作为 src 和 dst。 os.rmdir(path, **, dir_fd=None*) 移除（删除）目录 path。如果目录不存在或不为空，则会分别抛出 FileNotFoundError 或 OSError 异常。要删除整个目录树，可以使用 shutil.rmtree()。本函数支持 基于目录描述符的相对路径。引发一个 审计事件 os.rmdir，附带参数 path、dir_fd。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.scandir(path=’.’) 返回一个迭代出 os.DirEntry 对象的迭代器，这些对象对应于 path 目录中的条目。条目的生成顺序是任意的，特殊条目 &#39;.&#39; 和 &#39;..&#39; 不包括在内。如果需要文件类型或文件属性信息，使用 scandir() 代替 listdir() 可以大大提高这部分代码的性能，因为如果操作系统在扫描目录时返回的是 os.DirEntry 对象，则该对象包含了这些信息。所有 os.DirEntry 的方法都可能执行一次系统调用，但是 is_dir() 和 is_file() 通常只在有符号链接时才执行一次系统调用。os.DirEntry.stat() 在 Unix 上始终需要一次系统调用，而在 Windows 上只在有符号链接时才需要。path 可以是 类路径对象。如果 path 是（直接传入或通过 PathLike 接口间接传入的） bytes 类型，那么每个 os.DirEntry 的 name 和 path 属性将是 bytes 类型，其他情况下是 str 类型。本函数也支持 指定文件描述符为参数，其中描述符必须指向目录。引发一个 审计事件 os.scandir，附带参数 path。scandir() 迭代器支持 上下文管理 协议，并具有以下方法：scandir.close()关闭迭代器并释放占用的资源。当迭代器迭代完毕，或垃圾回收，或迭代过程出错时，将自动调用本方法。但仍建议显式调用它或使用 with 语句。 3.6 新版功能. 下面的例子演示了 scandir() 的简单用法，用来显示给定 path 中所有不以 &#39;.&#39; 开头的文件（不包括目录）。entry.is_file() 通常不会增加一次额外的系统调用: 1234with os.scandir(path) as it: for entry in it: if not entry.name.startswith('.') and entry.is_file(): print(entry.name) 在基于 Unix 的系统上，scandir() 使用系统的 opendir() 和 readdir() 函数。在 Windows 上，它使用 Win32 FindFirstFileW.aspx) 和 FindNextFileW.aspx) 函数。 .5 新版功能. 3.6 新版功能: 添加了对 上下文管理 协议和 close() 方法的支持。如果 scandir() 迭代器没有迭代完毕且没有显式关闭，其析构函数将发出 ResourceWarning 警告。 本函数接受一个 类路径对象。 在 3.7 版更改: 在 Unix 上新增支持 指定文件描述符为参数。 class os.DirEntry 由 scandir() 生成的对象，用于显示目录内某个条目的文件路径和其他文件属性。 scandir() 将在不进行额外系统调用的情况下，提供尽可能多的此类信息。每次进行 stat() 或 lstat() 系统调用时，os.DirEntry 对象会将结果缓存下来。 os.DirEntry 实例不适合存储在长期存在的数据结构中，如果你知道文件元数据已更改，或者自调用 scandir() 以来已经经过了很长时间，请调用 os.stat(entry.path) 来获取最新信息。 因为 os.DirEntry 方法可以进行系统调用，所以它也可能抛出 OSError 异常。如需精确定位错误，可以逐个调用 os.DirEntry 中的方法来捕获 OSError，并适当处理。 为了能直接用作 类路径对象，os.DirEntry 实现了 PathLike 接口。 os.DirEntry 实例所包含的属性和方法如下： name 本条目的基本文件名，是根据 scandir() 的 path 参数得出的相对路径。如果 scandir() 的 path 参数是 bytes 类型，则 name 属性也是 bytes 类型，否则为 str。使用 fsdecode() 解码 byte 类型的文件名。 path 本条目的完整路径：等效于 os.path.join(scandir_path, entry.name)，其中 scandir_path 就是 scandir() 的 path 参数。仅当 scandir() 的 path 参数为绝对路径时，本路径才是绝对路径。如果 scandir() 的 path 参数是 文件描述符，则 path 属性与上述 name 属性相同。如果 scandir() 的 path 参数是 bytes 类型，则 path 属性也是 bytes 类型，否则为 str。使用 fsdecode() 解码 byte 类型的文件名。 inode() 返回本条目的索引节点号 (inode number)。这一结果是缓存在 os.DirEntry 对象中的，请调用 os.stat(entry.path, follow_symlinks=False).st_ino 来获取最新信息。一开始没有缓存时，在 Windows 上需要一次系统调用，但在 Unix 上不需要。 is_dir(**, follow_symlinks=True*) 如果本条目是目录，或是指向目录的符号链接，则返回 True。如果本条目是文件，或指向任何其他类型的文件，或该目录不再存在，则返回 False。如果 follow_symlinks 是 False，那么仅当本条目为目录时返回 True （不跟踪符号链接），如果本条目是任何类型的文件，或该文件不再存在，则返回 False。这一结果是缓存在 os.DirEntry 对象中的，且 follow_symlinks 为 True 和 False 时的缓存是分开的。请调用 os.stat() 和 stat.S_ISDIR() 来获取最新信息。一开始没有缓存时，大多数情况下不需要系统调用。特别是对于非符号链接，Windows 和 Unix 都不需要系统调用，除非某些 Unix 文件系统（如网络文件系统）返回了 dirent.d_type == DT_UNKNOWN。如果本条目是符号链接，则需要一次系统调用来跟踪它（除非 follow_symlinks 为 False）。本方法可能抛出 OSError 异常，如 PermissionError 异常，但 FileNotFoundError 异常会被内部捕获且不会抛出。 is_file(**, follow_symlinks=True*) 如果本条目是文件，或是指向文件的符号链接，则返回 True。如果本条目是目录，或指向目录，或指向其他非文件条目，或该文件不再存在，则返回 False。如果 follow_symlinks 是 False，那么仅当本条目为文件时返回 True （不跟踪符号链接），如果本条目是目录或其他非文件条目，或该文件不再存在，则返回 False。这一结果是缓存在 os.DirEntry 对象中的。缓存、系统调用、异常抛出都与 is_dir() 一致。 is_symlink() 如果本条目是符号链接（即使是断开的链接），返回 True。如果是目录或任何类型的文件，或本条目不再存在，返回 False。这一结果是缓存在 os.DirEntry 对象中的，请调用 os.path.islink() 来获取最新信息。一开始没有缓存时，大多数情况下不需要系统调用。其实 Windows 和 Unix 都不需要系统调用，除非某些 Unix 文件系统（如网络文件系统）返回了 dirent.d_type == DT_UNKNOWN。本方法可能抛出 OSError 异常，如 PermissionError 异常，但 FileNotFoundError 异常会被内部捕获且不会抛出。 stat(**, follow_symlinks=True*) 返回本条目对应的 stat_result 对象。本方法默认会跟踪符号链接，要获取符号链接本身的 stat，请添加 follow_symlinks=False 参数。在 Unix 上，本方法需要一次系统调用。在 Windows 上，仅在 follow_symlinks 为 True 且该条目是一个重解析点（如符号链接或目录结点）时，才需要一次系统调用。在 Windows 上，stat_result 的 st_ino、st_dev 和 st_nlink 属性总是为零。请调用 os.stat() 以获得这些属性。这一结果是缓存在 os.DirEntry 对象中的，且 follow_symlinks 为 True 和 False 时的缓存是分开的。请调用 os.stat() 来获取最新信息。 注意，os.DirEntry 和 pathlib.Path 的几个属性和方法之间存在很好的对应关系。具体来说是 name 属性，以及 is_dir()、is_file()、is_symlink() 和 stat() 方法，在两个类中具有相同的含义。 3.5 新版功能. 在 3.6 版更改: 添加了对 PathLike 接口的支持。在 Windows 上添加了对 bytes 类型路径的支持。 os.stat(path, **, dir_fd=None, follow_symlinks=True*) 获取文件或文件描述符的状态。在所给路径上执行等效于 stat() 系统调用的操作。path 可以是字符串类型，或（直接传入或通过 PathLike 接口间接传入的） bytes 类型，或打开的文件描述符。返回一个 stat_result 对象。 本函数默认会跟踪符号链接，要获取符号链接本身的 stat，请添加 follow_symlinks=False 参数，或使用 lstat()。 本函数支持 指定文件描述符为参数 和 不跟踪符号链接。 在 Windows 上，传入 follow_symlinks=False 将禁用所有名称代理重解析点，其中包括符号链接和目录结点。其他类型的重解析点将直接打开，比如不像链接的或系统无法跟踪的重解析点。当多个链接形成一个链时，本方法可能会返回原始链接的 stat，无法完整遍历到非链接的对象。在这种情况下，要获取最终路径的 stat，请使用 os.path.realpath() 函数尽可能地解析路径，并在解析结果上调用 lstat()。这不适用于空链接或交接点，否则会抛出异常。 示例: 12345678&gt;&gt;&gt; import os&gt;&gt;&gt; statinfo = os.stat('somefile.txt')&gt;&gt;&gt; statinfoos.stat_result(st_mode=33188, st_ino=7876932, st_dev=234881026,st_nlink=1, st_uid=501, st_gid=501, st_size=264, st_atime=1297230295,st_mtime=1297230027, st_ctime=1297230027)&gt;&gt;&gt; statinfo.st_size264 fstat() 和 lstat() 函数。 3.3 新版功能: 增加 dir_fd 和 follow_symlinks 参数，可指定文件描述符代替路径。 在 3.6 版更改: 接受一个 类路径对象。 在 3.8 版更改: 在 Windows 上，本方法将跟踪系统能解析的所有重解析点，并且传入 follow_symlinks=False 会停止跟踪所有名称代理重解析点。现在，如果操作系统遇到无法跟踪的重解析点，stat 将返回原始路径的信息，就像已指定 follow_symlinks=False 一样，而不会抛出异常。 class os.stat_result 本对象的属性大致对应于 stat 结构体成员，主要作为 os.stat()、os.fstat() 和 os.lstat() 的返回值。 属性： st_mode 文件模式：包括文件类型和文件模式位（即权限位）。 st_ino 与平台有关，但如果不为零，则根据 st_dev 值唯一地标识文件。通常：在 Unix 上该值表示索引节点号 (inode number)。在 Windows 上该值表示 文件索引号 。 st_dev 该文件所在设备的标识符。 st_nlink 硬链接的数量。 st_uid 文件所有者的用户 ID。 st_gid 文件所有者的用户组 ID。 st_size 文件大小（以字节为单位），文件可以是常规文件或符号链接。符号链接的大小是它包含的路径的长度，不包括末尾的空字节。 时间戳： st_atime 最近的访问时间，以秒为单位。 st_mtime 最近的修改时间，以秒为单位。 st_ctime 取决于平台：在 Unix 上表示最近的元数据更改时间，在 Windows 上表示创建时间，以秒为单位。 st_atime_ns 最近的访问时间，以纳秒表示，为整数。 st_mtime_ns 最近的修改时间，以纳秒表示，为整数。 st_ctime_ns 取决于平台：在 Unix 上表示最近的元数据更改时间，在 Windows 上表示创建时间，以纳秒表示，为整数。 st_atime](https://docs.python.org/zh-cn/3.8/library/os.html#os.stat_result.st_atime)、[`st_mtime`](https://docs.python.org/zh-cn/3.8/library/os.html#os.stat_result.st_mtime) 和 st_ctime 属性的确切含义和分辨率取决于操作系统和文件系统。例如，在使用 FAT 或 FAT32 文件系统的 Windows 上，st_mtime 有 2 秒的分辨率，而 st_atime 仅有 1 天的分辨率。详细信息请参阅操作系统文档。 类似地，尽管 st_atime_ns、st_mtime_ns 和 st_ctime_ns 始终以纳秒表示，但许多系统并不提供纳秒精度。在确实提供纳秒精度的系统上，用于存储 st_atime、st_mtime 和 st_ctime 的浮点对象无法保留所有精度，因此不够精确。如果需要确切的时间戳，则应始终使用 st_atime_ns、st_mtime_ns 和 st_ctime_ns。 在某些 Unix 系统上（如 Linux 上），以下属性可能也可用： st_blocks 为文件分配的字节块数，每块 512 字节。文件是稀疏文件时，它可能小于 st_size/512。 st_blksize “首选的” 块大小，用于提高文件系统 I/O 效率。写入文件时块大小太小可能会导致读取-修改-重写效率低下。 st_rdev 设备类型（如果是 inode 设备）。 st_flags 用户定义的文件标志位。 在其他 Unix 系统上（如 FreeBSD 上），以下属性可能可用（但仅当 root 使用它们时才被填充）： st_gen 文件生成号。 st_birthtime 文件创建时间。 在 Solaris 及其衍生版本上，以下属性可能也可用： st_fstype 文件所在文件系统的类型的唯一标识，为字符串。 在 Mac OS 系统上，以下属性可能也可用： st_rsize 文件的实际大小。 st_creator 文件的创建者。 st_type 文件类型。 在 Windows 系统上，以下属性也可用： st_file_attributes Windows 文件属性：dwFileAttributes，由 GetFileInformationByHandle() 返回的 BY_HANDLE_FILE_INFORMATION 结构体的成员之一。请参阅 stat 模块中的 FILE_ATTRIBUTE_* 常量。 st_reparse_tag 当 st_file_attributes 存在 FILE_ATTRIBUTE_REPARSE_POINT 集合时，本字段包含重解析点类型标记。请参阅 stat 模块中的 IO_REPARSE_TAG_* 常量。 标准模块 stat 中定义了函数和常量，这些函数和常量可用于从 stat 结构体中提取信息。（在 Windows 上，某些项填充的是虚值。） 为了向后兼容，一个 stat_result 实例还可以作为至少包含 10 个整数的元组访问，以提供 stat 结构中最重要（和可移植）的成员，整数顺序为 st_mode, st_ino, st_dev, st_nlink, st_uid, st_gid, st_size, st_atime, st_mtime, st_ctime。某些实现可能在末尾还有更多项。为了与旧版 Python 兼容，以元组形式访问 stat_result 始终返回整数。 3.3 新版功能: 添加了 st_atime_ns、st_mtime_ns 和 st_ctime_ns 成员。 3.5 新版功能: 在 Windows 上添加了 st_file_attributes 成员。 在 3.5 版更改: 在 Windows 上，如果可用，会返回文件索引作为 st_ino 的值。 3.7 新版功能: 在 Solaris 及其衍生版本上添加了 st_fstype 成员。 3.8 新版功能: 在 Windows 上添加了 st_reparse_tag 成员。 在 3.8 版更改: 在 Windows 上，st_mode 成员现在可以根据需要将特殊文件标识为 S_IFCHR、S_IFIFO 或 S_IFBLK。 os.statvfs(path) 在所给的路径上执行 statvfs() 系统调用。返回值是一个对象，其属性描述了所给路径上的文件系统，并且与 statvfs 结构体的成员相对应，即：f_bsize, f_frsize, f_blocks, f_bfree, f_bavail, f_files, f_ffree, f_favail, f_flag, f_namemax, f_fsid。 为 f_flag 属性位定义了两个模块级常量：如果存在 ST_RDONLY 位，则文件系统以只读挂载；如果存在 ST_NOSUID 位，则文件系统禁用或不支持 setuid/setgid 位。 为基于 GNU/glibc 的系统还定义了额外的模块级常量。它们是 ST_NODEV （禁止访问设备专用文件），ST_NOEXEC （禁止执行程序），ST_SYNCHRONOUS （写入后立即同步），ST_MANDLOCK （允许文件系统上的强制锁定），ST_WRITE （写入文件/目录/符号链接），ST_APPEND （仅追加文件），ST_IMMUTABLE （不可变文件），ST_NOATIME （不更新访问时间），ST_NODIRATIME （不更新目录访问时间），ST_RELATIME （相对于 mtime/ctime 更新访问时间）。 本函数支持 指定文件描述符为参数。 可用性: Unix。 在 3.2 版更改: 添加了 ST_RDONLY 和 ST_NOSUID 常量。 3.3 新版功能: 新增支持将 path 参数指定为打开的文件描述符。 在 3.4 版更改: 添加了 ST_NODEV、ST_NOEXEC、ST_SYNCHRONOUS、ST_MANDLOCK、ST_WRITE、ST_APPEND、ST_IMMUTABLE、ST_NOATIME、ST_NODIRATIME 和 ST_RELATIME 常量。 在 3.6 版更改: 接受一个 类路径对象。 3.7 新版功能: 添加了 f_fsid。 1os.supports_dir_fd 一个 set 对象，指示 os 模块中的哪些函数接受一个打开的文件描述符作为 dir_fd 参数。不同平台提供的功能不同，且 Python 用于实现 dir_fd 参数的底层函数并非在 Python 支持的所有平台上都可用。考虑到一致性，支持 dir_fd 的函数始终允许指定描述符，但如果在底层不支持时调用了该函数，则会抛出异常。（在所有平台上始终支持将 dir_fd 指定为 None。） 要检查某个函数是否接受打开的文件描述符作为 dir_fd 参数，请在 supports_dir_fd 前使用 in 运算符。例如，如果 os.stat() 在当前平台上接受打开的文件描述符作为 dir_fd 参数，则此表达式的计算结果为 True: 1os.stat in os.supports_dir_fd 目前 dir_fd 参数仅在 Unix 平台上有效，在 Windows 上均无效。 3.3 新版功能. 1os.supports_effective_ids 一个 set 对象，指示 os.access() 是否允许在当前平台上将其 effective_ids 参数指定为 True。（所有平台都支持将 effective_ids 指定为 False。）如果当前平台支持，则集合将包含 os.access()，否则集合为空。 如果当前平台上的 os.access() 支持 effective_ids=True，则此表达式的计算结果为 True: 1os.access in os.supports_effective_ids 目前仅 Unix 平台支持 effective_ids，Windows 不支持。 3.3 新版功能. 1os.supports_fd 一个 set 对象，指示在当前平台上 os 模块中的哪些函数接受一个打开的文件描述符作为 path 参数。不同平台提供的功能不同，且 Python 所使用到的底层函数（用于实现接受描述符作为 path）并非在 Python 支持的所有平台上都可用。 要判断某个函数是否接受打开的文件描述符作为 path 参数，请在 supports_fd 前使用 in 运算符。例如，如果 os.chdir() 在当前平台上接受打开的文件描述符作为 path 参数，则此表达式的计算结果为 True: 1os.chdir in os.supports_fd 3.3 新版功能. 1os.supports_follow_symlinks 一个 set 对象，指示在当前平台上 os 模块中的哪些函数的 follow_symlinks 参数可指定为 False。不同平台提供的功能不同，且 Python 用于实现 follow_symlinks 的底层函数并非在 Python 支持的所有平台上都可用。考虑到一致性，支持 follow_symlinks 的函数始终允许将其指定为 False，但如果在底层不支持时调用了该函数，则会抛出异常。（在所有平台上始终支持将 follow_symlinks 指定为 True。） 要检查某个函数的 follow_symlinks 参数是否可以指定为 False，请在 supports_follow_symlinks 前使用 in 运算符。例如，如果在当前平台上调用 os.stat() 时可以指定 follow_symlinks=False，则此表达式的计算结果为 True: 1os.stat in os.supports_follow_symlinks 3.3 新版功能. os.symlink(src, dst, target_is_directory=False, **, dir_fd=None*) 创建一个指向 src 的符号链接，名为 dst。 在 Windows 上，符号链接可以表示文件或目录两种类型，并且不会动态改变类型。如果目标存在，则新建链接的类型将与目标一致。否则，如果 target_is_directory 为 True，则符号链接将创建为目录链接，为 False （默认）将创建为文件链接。在非 Windows 平台上，target_is_directory 被忽略。 本函数支持 基于目录描述符的相对路径 在 Windows 10 或更高版本上，如果启用了开发人员模式，非特权帐户可以创建符号链接。如果开发人员模式不可用/未启用，则需要 SeCreateSymbolicLinkPrivilege 权限，或者该进程必须以管理员身份运行。 当本函数由非特权账户调用时，抛出 OSError 异常。 引发一个 审计事件 os.symlink，附带参数 src、dst、dir_fd。 可用性: Unix, Windows。 在 3.2 版更改: 添加对 Windows 6.0 (Vista) 符号链接的支持。 3.3 新版功能: 添加了 dir_fd 参数，现在在非 Windows 平台上允许 target_is_directory 参数。 在 3.6 版更改: 接受一个 类路径对象 作为 src 和 dst。 在 3.8 版更改: 针对启用了开发人员模式的 Windows，添加了非特权账户创建符号链接的支持。 os.sync() 强制将所有内容写入磁盘。可用性: Unix。3.3 新版功能. os.truncate(path, length) 截断 path 对应的文件，以使其最大为 length 字节。本函数支持 指定文件描述符为参数。引发一个 审计事件 os.truncate，附带参数 path, length。可用性: Unix, Windows。3.3 新版功能.**在 3.5 版更改: 添加了 Windows 支持在 3.6 版更改: 接受一个 类路径对象。 os.unlink(path, **, dir_fd=None*) 移除（删除）文件 path。该函数在语义上与 remove() 相同，unlink 是其传统的 Unix 名称。请参阅 remove() 的文档以获取更多信息。引发一个 审计事件 os.remove，附带参数 path、dir_fd。3.3 新版功能: dir_fd 参数。在 3.6 版更改: 接受一个 类路径对象。 os.utime(path, times=None, **, [ns, ]dir_fd=None, follow_symlinks=True*) 设置文件 path 的访问时间和修改时间。utime() 有 times 和 ns 两个可选参数，它们指定了设置给 path 的时间，用法如下： 如果指定 ns，它必须是一个 (atime_ns, mtime_ns) 形式的二元组，其中每个成员都是一个表示纳秒的整数。 如果 times 不为 None，则它必须是 (atime, mtime) 形式的二元组，其中每个成员都是一个表示秒的 int 或 float。 如果 times 为 None 且未指定 ns，则相当于指定 ns=(atime_ns, mtime_ns)，其中两个时间均为当前时间。 同时为 times 和 ns 指定元组会出错。 注意，根据操作系统记录访问时间和修改时间的分辨率，后续的 stat() 调用可能不会返回此处设置的确切时间。请参阅 stat()。保留精确时间的最佳方法是使用 os.stat() 结果对象中的 st_atime_ns 和 st_mtime_ns 字段，并将 ns 参数设置为 utime。 本函数支持 指定文件描述符、指定基于目录描述符的相对路径 和 不跟踪符号链接。 引发一个 审计事件 os.utime，附带参数 path、times、ns、dir_fd。 3.3 新版功能: 新增支持将 path 参数指定为打开的文件描述符，以及支持 dir_fd、follow_symlinks 和 ns 参数。 在 3.6 版更改: 接受一个 类路径对象。 os.walk(top, topdown=True, onerror=None, followlinks=False) 生成目录树中的文件名，方式是按上-&gt;下或下-&gt;上顺序浏览目录树。对于以 top 为根的目录树中的每个目录（包括 top 本身），它都会生成一个三元组 (dirpath, dirnames, filenames)。 dirpath 是一个字符串，表示目录的路径。dirnames 是一个列表，内含 dirpath 中子目录的名称（不包括 &#39;.&#39; 和 &#39;..&#39; ）。filenames 也是列表，内含 dirpath 中文件（非目录）的名称。注意，列表中的名称不包含路径部分。要获取 dirpath 中文件或目录的完整路径（从 top 起始），请执行 os.path.join(dirpath, name)。 如果可选参数 topdown 为 True 或未指定，则在所有子目录的三元组之前生成父目录的三元组（目录是自上而下生成的）。如果 topdown 为 False，则在所有子目录的三元组生成之后再生成父目录的三元组（目录是自下而上生成的）。无论 topdown 为何值，在生成目录及其子目录的元组之前，都将检索全部子目录列表。 当 topdown 为 True 时，调用者可以就地修改 dirnames 列表（也许用到了 del 或切片），而 walk() 将仅仅递归到仍保留在 dirnames 中的子目录内。这可用于减少搜索、加入特定的访问顺序，甚至可在继续 walk() 之前告知 walk() 由调用者新建或重命名的目录的信息。当 topdown 为 False 时，修改 dirnames 对 walk 的行为没有影响，因为在自下而上模式中，dirnames 中的目录是在 dirpath 本身之前生成的。 默认将忽略 scandir() 调用中的错误。如果指定了可选参数 onerror，它应该是一个函数。出错时它会被调用，参数是一个 OSError 实例。它可以报告错误然后继续遍历，或者抛出异常然后中止遍历。注意，可以从异常对象的 filename 属性中获取出错的文件名。 walk() 默认不会递归进指向目录的符号链接。可以在支持符号链接的系统上将 followlinks 设置为 True，以访问符号链接指向的目录。 注意，如果链接指向自身的父目录，则将 followlinks 设置为 True 可能导致无限递归。walk() 不会记录它已经访问过的目录。 如果传入的是相对路径，请不要在恢复 walk() 之间更改当前工作目录。walk() 不会更改当前目录，并假定其调用者也不会更改当前目录。 下面的示例遍历起始目录内所有子目录，打印每个目录内的文件占用的字节数，CVS 子目录不会被遍历: 12345678import osfrom os.path import join, getsizefor root, dirs, files in os.walk('python/Lib/email'): print(root, "consumes", end=" ") print(sum(getsize(join(root, name)) for name in files), end=" ") print("bytes in", len(files), "non-directory files") if 'CVS' in dirs: dirs.remove('CVS') # don't visit CVS directories 在下一个示例（shutil.rmtree() 的简单实现）中，必须使树自下而上遍历，因为 rmdir() 只允许在目录为空时删除目录: 12345678910# Delete everything reachable from the directory named in "top",# assuming there are no symbolic links.# CAUTION: This is dangerous! For example, if top == '/', it# could delete all your disk files.import osfor root, dirs, files in os.walk(top, topdown=False): for name in files: os.remove(os.path.join(root, name)) for name in dirs: os.rmdir(os.path.join(root, name)) 在 3.5 版更改: 现在，本函数调用的是 os.scandir() 而不是 os.listdir()，从而减少了调用 os.stat() 的次数而变得更快。 在 3.6 版更改: 接受一个 类路径对象。 os.fwalk(top=’.’, topdown=True, onerror=None, **, follow_symlinks=False, dir_fd=None*) 本方法的行为与 walk() 完全一样，除了它产生的是 4 元组 (dirpath, dirnames, filenames, dirfd)，并且它支持 dir_fd。 dirpath、dirnames 和 filenames 与 walk() 输出的相同，dirfd 是指向目录 dirpath 的文件描述符。 本函数始终支持 基于目录描述符的相对路径 和 不跟踪符号链接。但是请注意，与其他函数不同，fwalk() 的 follow_symlinks 的默认值为 False。 由于 fwalk() 会生成文件描述符，而它们仅在下一个迭代步骤前有效，因此如果要将描述符保留更久，则应复制它们（比如使用 dup()）。 下面的示例遍历起始目录内所有子目录，打印每个目录内的文件占用的字节数，CVS 子目录不会被遍历: 12345678import osfor root, dirs, files, rootfd in os.fwalk('python/Lib/email'): print(root, "consumes", end="") print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]), end="") print("bytes in", len(files), "non-directory files") if 'CVS' in dirs: dirs.remove('CVS') # don't visit CVS directories 在下一个示例中，必须使树自下而上遍历，因为 rmdir() 只允许在目录为空时删除目录: 12345678910# Delete everything reachable from the directory named in "top",# assuming there are no symbolic links.# CAUTION: This is dangerous! For example, if top == '/', it# could delete all your disk files.import osfor root, dirs, files, rootfd in os.fwalk(top, topdown=False): for name in files: os.unlink(name, dir_fd=rootfd) for name in dirs: os.rmdir(name, dir_fd=rootfd) 可用性: Unix。 3.3 新版功能. 在 3.6 版更改: 接受一个 类路径对象。 在 3.7 版更改: 添加了对 bytes 类型路径的支持。 os.memfd_create(name[, flags=os.MFD_CLOEXEC]) 创建一个匿名文件，返回指向该文件的文件描述符。flags 必须是系统上可用的 os.MFD_* 常量之一（或将它们按位“或”组合起来）。新文件描述符默认是 不可继承的。 name 提供的名称会被用作文件名，并且 /proc/self/fd/ 目录中相应符号链接的目标将显示为该名称。显示的名称始终以 memfd: 为前缀，并且仅用于调试目的。名称不会影响文件描述符的行为，因此多个文件可以有相同的名称，不会有副作用。 可用性：Linux 3.17 或更高版本，且装有 glibc 2.27 或更高版本。 3.8 新版功能. os.MFD_CLOEXEC os.MFD_ALLOW_SEALING os.MFD_HUGETLB os.MFD_HUGE_SHIFT os.MFD_HUGE_MASK os.MFD_HUGE_64KB os.MFD_HUGE_512KB os.MFD_HUGE_1MB os.MFD_HUGE_2MB os.MFD_HUGE_8MB os.MFD_HUGE_16MB os.MFD_HUGE_32MB os.MFD_HUGE_256MB os.MFD_HUGE_512MB os.MFD_HUGE_1GB os.MFD_HUGE_2GB os.MFD_HUGE_16GB 以上标志位可以传递给 memfd_create()。可用性：Linux 3.17 或更高版本，且装有 glibc 2.27 或更高版本。MFD_HUGE* 标志仅在 Linux 4.14 及以上可用。 3.8 新版功能. Linux 扩展属性3.3 新版功能. 这些函数仅在 Linux 上可用。 os.getxattr(path, attribute, **, follow_symlinks=True*) 返回 path 的扩展文件系统属性 attribute 的值。attribute 可以是 bytes 或 str （直接传入或通过 PathLike 接口间接传入）。如果是 str，则使用文件系统编码来编码字符串。本函数支持 指定文件描述符为参数 和 不跟踪符号链接。引发一个 审计事件 os.getxattr，附带参数 path、attribute。在 3.6 版更改: 接受一个 类路径对象 作为 path 和 attribute。 os.listxattr(path=None, **, follow_symlinks=True*) 返回一个列表，包含 path 的所有扩展文件系统属性。列表中的属性都表示为字符串，它们是根据文件系统编码解码出来的。如果 path 为 None，则 listxattr() 将检查当前目录。本函数支持 指定文件描述符为参数 和 不跟踪符号链接。引发一个 审计事件 os.listxattr，附带参数 path。在 3.6 版更改: 接受一个 类路径对象。 os.removexattr(path, attribute, **, follow_symlinks=True*) 从 path 中删除扩展文件系统属性 attribute。attribute 应该是 bytes 或 str （直接传入或通过 PathLike 接口间接传入）。如果是 str，则使用文件系统编码来编码字符串。本函数支持 指定文件描述符为参数 和 不跟踪符号链接。引发一个 审计事件 os.removexattr，附带参数 path、attribute。在 3.6 版更改: 接受一个 类路径对象 作为 path 和 attribute。 os.setxattr(path, attribute, value, flags=0, **, follow_symlinks=True*) 将 path 的扩展文件系统属性 attribute 设置为 value。attribute 必须是没有空字符的 bytes 或 str （直接传入或通过 PathLike 接口间接传入）。如果是 str，则应使用文件系统编码进行编码。flags 可以是 XATTR_REPLACE 或 XATTR_CREATE。如果指定 XATTR_REPLACE 而该属性不存在，则抛出 EEXISTS 异常。如果指定 XATTR_CREATE 而该属性已经存在，则不会创建该属性，抛出 ENODATA 异常。本函数支持 指定文件描述符为参数 和 不跟踪符号链接。 Linux kernel 2.6.39 以下版本的一个 bug 导致在某些文件系统上，flags 参数会被忽略。 引发一个 审计事件 os.setxattr，附带参数 path、attribute、value、flags。 在 3.6 版更改: 接受一个 类路径对象 作为 path 和 attribute。 os.XATTR_SIZE_MAX 一条扩展属性的值的最大大小。在当前的 Linux 上是 64 KiB。 os.XATTR_CREATE 这是 setxattr() 的 flags 参数的可取值，它表示该操作必须创建一个属性。 os.XATTR_REPLACE 这是 setxattr() 的 flags 参数的可取值，它表示该操作必须替换现有属性。 进程管理下列函数可用于创建和管理进程。 所有 exec* 函数都接受一个参数列表，用来给新程序加载到它的进程中。在所有情况下，传递给新程序的第一个参数是程序本身的名称，而不是用户在命令行上输入的参数。对于 C 程序员来说，这就是传递给 main() 函数的 argv[0]。例如，os.execv(&#39;/bin/echo&#39;, [&#39;foo&#39;, &#39;bar&#39;]) 只会在标准输出上打印 bar，而 foo 会被忽略。 os.abort() 发送 SIGABRT 信号到当前进程。在 Unix 上，默认行为是生成一个核心转储。在 Windows 上，该进程立即返回退出代码 3。请注意，使用 signal.signal() 可以为 SIGABRT 注册 Python 信号处理程序，而调用本函数将不会调用按前述方法注册的程序。 os.add_dll_directory(path) 将路径添加到 DLL 搜索路径。当需要解析扩展模块的依赖时（扩展模块本身通过 sys.path 解析），会使用该搜索路径，ctypes 也会使用该搜索路径。要移除目录，可以在返回的对象上调用 close()，也可以在 with 语句内使用本方法。参阅 Microsoft 文档 获取如何加载 DLL 的信息。引发一个 审计事件 os.add_dll_directory，附带参数 path。可用性: Windows。3.8 新版功能: 早期版本的 CPython 解析 DLL 时用的是当前进程的默认行为。这会导致不一致，比如不是每次都会去搜索 PATH 和当前工作目录，且系统函数（如 AddDllDirectory ）失效。在 3.8 中，DLL 的两种主要加载方式现在可以显式覆盖进程的行为，以确保一致性。请参阅 移植说明 了解如何更新你的库。 os.execl(path, arg0, arg1, …) os.execle(path, arg0, arg1, …, env) os.execlp(file, arg0, arg1, …) os.execlpe(file, arg0, arg1, …, env) os.execv(path, args) os.execve(path, args, env) os.execvp(file, args) os.execvpe(file, args, env) 这些函数都将执行一个新程序，以替换当前进程。它们没有返回值。在 Unix 上，新程序会加载到当前进程中，且进程号与调用者相同。过程中的错误会被报告为 OSError 异常。 当前进程会被立即替换。打开的文件对象和描述符都不会刷新，因此如果这些文件上可能缓冲了数据，则应在调用 exec* 函数之前使用 sys.stdout.flush() 或 os.fsync() 刷新它们。 exec* 函数的 “l” 和 “v” 变体不同在于命令行参数的传递方式。如果在编码时固定了参数数量，则 “l” 变体可能是最方便的，各参数作为 execl*() 函数的附加参数传入即可。当参数数量可变时，”v” 变体更方便，参数以列表或元组的形式作为 args 参数传递。在这两种情况下，子进程的第一个参数都应该是即将运行的命令名称，但这不是强制性的。 结尾包含 “p” 的变体（execlp()、execlpe()、execvp() 和 execvpe() ）将使用 PATH 环境变量来查找程序 file。当环境被替换时（使用下一段讨论的 exec*e 变体之一），PATH 变量将来自于新环境。其他变体 execl()、execle()、execv() 和 execve() 不使用 PATH 变量来查找程序，因此 path 必须包含正确的绝对或相对路径。 对于 execle()、execlpe()、execve() 和 execvpe() （都以 “e” 结尾），env 参数是一个映射，用于定义新进程的环境变量（代替当前进程的环境变量）。而函数 execl()、execlp()、execv() 和 execvp() 会将当前进程的环境变量过继给新进程。 某些平台上的 execve() 可以将 path 指定为打开的文件描述符。当前平台可能不支持此功能，可以使用 os.supports_fd 检查它是否支持。如果不可用，则使用它会抛出 NotImplementedError 异常。 引发一个 审计事件 os.exec，附带参数 path、args、env。 可用性: Unix, Windows。 3.3 新版功能: 新增支持将 execve() 的 path 参数指定为打开的文件描述符。 在 3.6 版更改: 接受一个 类路径对象。 os._exit(n) 以状态码 n 退出进程，不会调用清理处理程序，不会刷新 stdio，等等。 退出的标准方法是使用 sys.exit(n)。而 _exit() 通常只应在 fork() 出的子进程中使用。 以下是已定义的退出代码，可以用于 _exit()，尽管它们不是必需的。这些退出代码通常用于 Python 编写的系统程序，例如邮件服务器的外部命令传递程序。 其中部分退出代码在部分 Unix 平台上可能不可用，因为平台间存在差异。如果底层平台定义了这些常量，那上层也会定义。 os.EX_OK 退出代码，表示未发生任何错误。可用性: Unix。 os.EX_USAGE 退出代码，表示命令使用不正确，如给出的参数数量有误。可用性: Unix。 os.EX_DATAERR 退出代码，表示输入数据不正确。可用性: Unix。 os.EX_NOINPUT 退出代码，表示某个输入文件不存在或不可读。可用性: Unix。 os.EX_NOUSER 退出代码，表示指定的用户不存在。可用性: Unix。 os.EX_NOHOST 退出代码，表示指定的主机不存在。可用性: Unix。 os.EX_UNAVAILABLE 退出代码，表示所需的服务不可用。可用性: Unix。 os.EX_SOFTWARE 退出代码，表示检测到内部软件错误。可用性: Unix。 os.EX_OSERR 退出代码，表示检测到操作系统错误，例如无法 fork 或创建管道。可用性: Unix。 os.EX_OSFILE 退出代码，表示某些系统文件不存在、无法打开或发生其他错误。可用性: Unix。 os.EX_CANTCREAT 退出代码，表示无法创建用户指定的输出文件。可用性: Unix。 os.EX_IOERR 退出代码，表示对某些文件进行读写时发生错误。可用性: Unix。 os.EX_TEMPFAIL 退出代码，表示发生了暂时性故障。它可能并非意味着真正的错误，例如在可重试的情况下无法建立网络连接。可用性: Unix。 os.EX_PROTOCOL 退出代码，表示协议交换是非法的、无效的或无法解读的。可用性: Unix。 os.EX_NOPERM 退出代码，表示没有足够的权限执行该操作（但不适用于文件系统问题）。可用性: Unix。 os.EX_CONFIG 退出代码，表示发生某种配置错误。可用性: Unix。 os.EX_NOTFOUND 退出代码，表示的内容类似于“找不到条目”。可用性: Unix。 os.fork() Fork 出一个子进程。在子进程中返回 0，在父进程中返回子进程的进程号。如果发生错误，则抛出 OSError 异常。注意，当从线程中使用 fork() 时，某些平台（包括 FreeBSD &lt;= 6.3 和 Cygwin）存在已知问题。引发一个 审计事件 os.fork，没有附带参数。在 3.8 版更改: 不再支持在子解释器中调用 fork() （将抛出 RuntimeError 异常） 有关 SSL 模块与 fork() 结合的应用，请参阅 ssl。 可用性: Unix os.forkpty() Fork 出一个子进程，使用新的伪终端作为子进程的控制终端。返回一对 (pid, fd)，其中 pid 在子进程中为 0，这是父进程中新子进程的进程号，而 fd 是伪终端主设备的文件描述符。对于更便于移植的方法，请使用 pty 模块。如果发生错误，则抛出 OSError 异常。引发一个 审计事件 os.forkpty，没有附带参数。在 3.8 版更改: 不再支持在子解释器中调用 forkpty() （将抛出 RuntimeError 异常）。可用性: 某些 Unix。 os.kill(pid, sig) 将信号 sig 发送至进程 pid。特定平台上可用的信号常量定义在 signal 模块中。Windows： signal.CTRL_C_EVENT 和 signal.CTRL_BREAK_EVENT 信号是特殊信号，只能发送给共享同一个控制台窗口的控制台进程，如某些子进程。sig 取任何其他值将导致该进程被 TerminateProcess API 无条件终止，且退出代码为 sig。Windows 版本的 kill() 还需要传入待结束进程的句柄。另请参阅 signal.pthread_kill()。引发一个 审计事件 os.kill，附带参数 pid、sig。3.2 新版功能: Windows 支持。 os.killpg(pgid, sig) 将信号 sig 发送给进程组 pgid。引发一个 审计事件 os.killpg，附带参数 pgid、sig。可用性: Unix。 os.nice(increment) 将进程的优先级（nice 值）增加 increment，返回新的 nice 值。可用性: Unix。 os.plock(op) 将程序段锁定到内存中。op 的值（定义在 中）决定了哪些段被锁定。可用性: Unix。 os.popen(cmd, mode=’r’, buffering=-1) 打开一个管道，它通往 / 接受自命令 cmd。返回值是连接到管道的文件对象，根据 mode 是 &#39;r&#39; （默认）还是 &#39;w&#39; 决定该对象可以读取还是写入。buffering 参数与内置函数 open() 相应的参数含义相同。返回的文件对象只能读写文本字符串，不能是字节类型。 如果子进程成功退出，则 close 方法返回 None。如果发生错误，则返回子进程的返回码。在 POSIX 系统上，如果返回码为正，则它就是进程返回值左移一个字节后的值。如果返回码为负，则进程是被信号终止的，返回码取反后就是该信号。（例如，如果子进程被终止，则返回值可能是 - signal.SIGKILL。）在 Windows 系统上，返回值包含子进程的返回码（有符号整数）。 本方法是使用 subprocess.Popen 实现的，如需更强大的方法来管理和沟通子进程，请参阅该类的文档。 os.posix_spawn(path, argv, env, **, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None*) 包装 posix_spawn() C 库 API，使其可以从 Python 调用。 大多数用户应使用 subprocess.run() 代替 posix_spawn()。 仅位置参数 (Positional-only arguments) path、args 和 env 与 execve() 中的类似。 path 参数是可执行文件的路径，path 中应该包含目录。使用 posix_spawnp() 可直接传入可执行文件名称，不带有目录。 file_actions 参数可以是由元组组成的序列，序列描述了对子进程中指定文件描述符采取的操作，这些操作会在 C 库实现的 fork() 和 exec() 步骤间完成。每个元组的第一个元素必须是下面列出的三个类型指示符之一，用于描述元组剩余的元素： os.POSIX_SPAWN_OPEN (os.POSIX_SPAWN_OPEN, fd, path, flags, mode)执行 os.dup2(os.open(path, flags, mode), fd)。 os.POSIX_SPAWN_CLOSE (os.POSIX_SPAWN_CLOSE, fd)执行 os.close(fd)。 os.POSIX_SPAWN_DUP2 (os.POSIX_SPAWN_DUP2, fd, new_fd)执行 os.dup2(fd, new_fd)。 这些元组对应于 C 库 posix_spawn_file_actions_addopen()， posix_spawn_file_actions_addclose() 和 posix_spawn_file_actions_adddup2() API 调用，它们为调用 posix_spawn() 自身做准备。 setpgroup 参数将子进程的进程组设置为指定值。如果指定值为 0，则子进程的进程组 ID 将与其进程 ID 相同。如果未设置 setpgroup 值，则子进程将继承父进程的进程组 ID。本参数对应于 C 库 POSIX_SPAWN_SETPGROUP 标志。 如果 resetids 参数为 True，则会将子进程的有效用户 ID 和有效组 ID 重置为父进程的实际用户 ID 和实际组 ID。如果该参数为 False，则子进程保留父进程的有效用户 ID 和有效组 ID。无论哪种情况，若在可执行文件上启用了 “设置用户 ID” 和 “设置组 ID” 权限位，它们将覆盖有效用户 ID 和有效组 ID 的设置。本参数对应于 C 库 POSIX_SPAWN_RESETIDS 标志。 如果 setsid 参数为 True，它将为 posix_spawn 新建一个会话 ID。setsid 需要 POSIX_SPAWN_SETSID 或 POSIX_SPAWN_SETSID_NP 标志，否则会抛出 NotImplementedError 异常。 setsigmask 参数将信号掩码设置为指定的信号集合。如果未使用该参数，则子进程将继承父进程的信号掩码。本参数对应于 C 库 POSIX_SPAWN_SETSIGMASK 标志。 sigdef 参数将集合中所有信号的操作全部重置为默认。本参数对应于 C 库 POSIX_SPAWN_SETSIGDEF 标志。 scheduler 参数必须是一个元组，其中包含调度器策略（可选）以及携带了调度器参数的 sched_param 实例。在调度器策略所在位置为 None 表示未提供该值。本参数是 C 库 POSIX_SPAWN_SETSCHEDPARAM 和 POSIX_SPAWN_SETSCHEDULER 标志的组合。 引发一个 审计事件 os.posix_spawn，附带参数 path、argv、env。 3.8 新版功能. 可用性: Unix。 os.posix_spawnp(path, argv, env, **, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None*) 包装 posix_spawnp() C 库 API，使其可以从 Python 调用。 与 posix_spawn() 相似，但是系统会在 PATH 环境变量指定的目录列表中搜索可执行文件 executable （与 execvp(3) 相同）。 引发一个 审计事件 os.posix_spawn，附带参数 path、argv、env。 3.8 新版功能. 可用性: 请参阅 posix_spawn() 文档。 os.register_at_fork(**, before=None, after_in_parent=None, after_in_child=None*) 注册可调用对象，在使用 os.fork() 或类似的进程克隆 API 派生新的子进程时，这些对象会运行。参数是可选的，且为仅关键字 (Keyword-only) 参数。每个参数指定一个不同的调用点。 before 是一个函数，在 fork 子进程前调用。 after_in_parent 是一个函数，在 fork 子进程后从父进程调用。 after_in_child 是一个函数，从子进程中调用。 只有希望控制权回到 Python 解释器时，才进行这些调用。典型的 子进程 启动时不会触发它们，因为子进程不会重新进入解释器。 在注册的函数中，用于 fork 前运行的函数将按与注册相反的顺序调用。用于 fork 后（从父进程或子进程）运行的函数按注册顺序调用。 注意，第三方 C 代码的 fork() 调用可能不会调用这些函数，除非它显式调用了 PyOS_BeforeFork()、PyOS_AfterFork_Parent() 和 PyOS_AfterFork_Child()。 函数注册后无法注销。 可用性: Unix。 3.7 新版功能. os.spawnl(mode, path, …) os.spawnle(mode, path, …, env) os.spawnlp(mode, file, …) os.spawnlpe(mode, file, …, env) os.spawnv(mode, path, args) os.spawnve(mode, path, args, env) os.spawnvp(mode, file, args) os.spawnvpe(mode, file, args, env)¶ 在新进程中执行程序 path。 （注意，subprocess 模块提供了更强大的工具来生成新进程并跟踪执行结果，使用该模块比使用这些函数更好。尤其应当检查 Replacing Older Functions with the subprocess Module 部分。） mode 为 P_NOWAIT 时，本函数返回新进程的进程号。mode 为 P_WAIT 时，如果进程正常退出，返回退出代码，如果被终止，返回 -signal，其中 signal 是终止进程的信号。在 Windows 上，进程号实际上是进程句柄，因此可以与 waitpid() 函数一起使用。 注意在 VxWorks 上，新进程被终止时，本函数不会返回 -signal，而是会抛出 OSError 异常。 spawn* 函数的 “l” 和 “v” 变体不同在于命令行参数的传递方式。如果在编码时固定了参数数量，则 “l” 变体可能是最方便的，各参数作为 spawnl*() 函数的附加参数传入即可。当参数数量可变时，”v” 变体更方便，参数以列表或元组的形式作为 args 参数传递。在这两种情况下，子进程的第一个参数都必须是即将运行的命令名称。 结尾包含第二个 “p” 的变体（spawnlp()、spawnlpe()、spawnvp() 和 spawnvpe()）将使用 PATH 环境变量来查找程序 file。当环境被替换时（使用下一段讨论的 spawn*e 变体之一），PATH 变量将来自于新环境。其他变体 spawnl()、spawnle()、spawnv() 和 spawnve() 不使用 PATH 变量来查找程序，因此 path 必须包含正确的绝对或相对路径。 对于 spawnle()、spawnlpe()、spawnve() 和 spawnvpe() （都以 “e” 结尾），env 参数是一个映射，用于定义新进程的环境变量（代替当前进程的环境变量）。而函数 spawnl()、spawnlp()、spawnv() 和 spawnvp() 会将当前进程的环境变量过继给新进程。注意，env 字典中的键和值必须是字符串。无效的键或值将导致函数出错，返回值为 127。 例如，以下对 spawnlp() 和 spawnvpe() 的调用是等效的: 12345import os os.spawnlp(os.P_WAIT, 'cp', 'cp', 'index.html', '/dev/null') L = ['cp', 'index.html', '/dev/null']os.spawnvpe(os.P_WAIT, 'cp', L, os.environ) 引发一个 审计事件 os.spawn，附带参数 mode、path、args、env。 可用性: Unix, Windows。spawnlp()、spawnlpe()、spawnvp() 和 spawnvpe() 在 Windows 上不可用。spawnle() 和 spawnve() 在 Windows 上不是线程安全的，建议使用 subprocess 模块替代。 在 3.6 版更改: 接受一个 类路径对象。 os.P_NOWAIT os.P_NOWAITO spawn* 系列函数的 mode 参数的可取值。如果给出这些值中的任何一个，则 spawn*() 函数将在创建新进程后立即返回，且返回值为进程号。可用性: Unix, Windows。 os.P_WAIT spawn* 系列函数的 mode 参数的可取值。如果将 mode 指定为该值，则 spawn*() 函数将在新进程运行完毕后返回，运行成功则返回进程的退出代码，被信号终止则返回 -signal。可用性: Unix, Windows。 os.P_DETACH os.P_OVERLAY spawn* 系列函数的 mode 参数的可取值。它们比上面列出的值可移植性差。P_DETACH 与 P_NOWAIT 相似，但是新进程会与父进程的控制台脱离。使用 P_OVERLAY 则会替换当前进程，spawn* 函数将不会返回。可用性: Windows。 os.startfile(path[, operation]) 使用已关联的应用程序打开文件。当 operation 未指定或指定为 &#39;open&#39; 时，这类似于在 Windows 资源管理器中双击文件，或在交互式命令行中将文件名作为 start 命令的参数：通过扩展名相关联的应用程序（如果有）打开文件。当指定另一个 operation 时，它必须是一个“命令动词” (“command verb”)，该词指定对文件执行的操作。Microsoft 文档中的常用动词有 &#39;print&#39; 和 &#39;edit&#39; （用于文件），以及 &#39;explore&#39; 和 &#39;find&#39; （用于目录）。关联的应用程序启动后 startfile() 就会立即返回。本函数没有等待应用程序关闭的选项，也没有办法检索应用程序的退出状态。path 参数是基于当前目录的相对路径。如果要使用绝对路径，请确保第一个字符不是斜杠 (&#39;/&#39;)，是斜杠的话底层的 Win32 ShellExecute() 函数将失效。使用 os.path.normpath() 函数确保路径已针对 Win32 正确编码。为了减少解释器的启动开销，直到第一次调用本函数后，才解析 Win32 ShellExecute() 函数。如果无法解析该函数，则抛出 NotImplementedError 异常。引发一个 审计事件 os.startfile，附带参数 path、operation。可用性: Windows。 os.system(command) 在子 shell 中执行命令（字符串）。这是调用标准 C 函数 system() 来实现的，因此限制条件与该函数相同。对 sys.stdin 等的更改不会反映在执行命令的环境中。command 产生的任何输出将被发送到解释器标准输出流。在 Unix 上，返回值是进程的退出状态，编码格式与为 wait() 指定的格式相同。注意，POSIX 没有指定 C 函数 system() 返回值的含义，因此 Python 函数的返回值与系统有关。在 Windows 上，返回值是运行 command 后系统 Shell 返回的值。该 Shell 由 Windows 环境变量 COMSPEC: 给出：通常是 cmd.exe，它会返回命令的退出状态。在使用非原生 Shell 的系统上，请查阅 Shell 的文档。subprocess 模块提供了更强大的工具来生成新进程并跟踪执行结果，使用该模块比使用本函数更好。参阅 subprocess 文档中的 Replacing Older Functions with the subprocess Module 部分以获取有用的帮助。引发一个 审计事件 os.system，附带参数 command。可用性: Unix, Windows。 os.times() 返回当前的全局进程时间。返回值是一个有 5 个属性的对象：user - 用户时间system - 系统时间children_user - 所有子进程的用户时间children_system - 所有子进程的系统时间elapsed - 从过去的固定时间点起，经过的真实时间为了向后兼容，该对象的行为也类似于五元组，按照 user，system，children_user，children_system 和 elapsed 顺序组成。在 Unix 上请参阅 times(2)) 和 times(3)) 手册页，在 Windows 上请参阅 the GetProcessTimes MSDN 。在 Windows 上，只有 user 和 system 是已知的，其他属性均为零。可用性: Unix, Windows。在 3.3 版更改: 返回结果的类型由元组变成一个类似元组的对象，同时具有命名的属性。 os.wait() 等待子进程执行完毕，返回一个元组，包含其 pid 和退出状态指示：一个 16 位数字，其低字节是终止该进程的信号编号，高字节是退出状态码（信号编号为零的情况下），如果生成了核心文件，则低字节的高位会置位。可用性: Unix。 os.waitid(idtype, id, options) 等待一个或多个子进程执行完毕。idtype 可以是 P_PID、P_PGID 或 P_ALL。id 指定要等待的 pid。options 是由 WEXITED、WSTOPPED 或 WCONTINUED 中的一个或多个进行或运算构造的，且额外可以与 WNOHANG 或 WNOWAIT 进行或运算。返回值是一个对象，对应着 siginfo_t 结构体中的数据，即： si_pid, si_uid, si_signo, si_status, si_code 或 None （如果指定了 WNOHANG 且没有子进程处于等待状态）。可用性: Unix。3.3 新版功能. os.P_PID os.P_PGID os.P_ALL waitid() 的 idtype 参数的可取值。它们影响 id 的解释方式。可用性: Unix。3.3 新版功能. os.WEXITED os.WSTOPPED os.WNOWAIT 用于 waitid() 的 options 参数的标志位，指定要等待的子进程信号。可用性: Unix。3.3 新版功能. os.CLD_EXITED os.CLD_DUMPED os.CLD_TRAPPED os.CLD_CONTINUED waitid() 返回的结果中，si_code 的可取值。可用性: Unix。3.3 新版功能. os.waitpid(pid, options) 本函数的细节在 Unix 和 Windows 上有不同之处。 在 Unix 上：等待进程号为 pid 的子进程执行完毕，返回一个元组，内含其进程 ID 和退出状态指示（编码与 wait() 相同）。调用的语义受整数 options 的影响，常规操作下该值应为 0。 如果 pid 大于 0，则 waitpid() 会获取该指定进程的状态信息。如果 pid 为 0，则获取当前进程所在进程组中的所有子进程的状态。如果 pid 为 -1，则获取当前进程的子进程状态。如果 pid 小于 -1，则获取进程组 -pid （ pid 的绝对值）中所有进程的状态。 当系统调用返回 -1 时，将抛出带有错误码的 OSError 异常。 在 Windows 上：等待句柄为 pid 的进程执行完毕，返回一个元组，内含 pid 以及左移 8 位后的退出状态码（移位简化了跨平台使用本函数）。小于或等于 0 的 pid 在 Windows 上没有特殊含义，且会抛出异常。整数值 options 无效。pid 可以指向任何 ID 已知的进程，不一定是子进程。调用 spawn* 函数时传入 P_NOWAIT 将返回合适的进程句柄。 在 3.5 版更改: 如果系统调用被中断，但信号处理程序没有触发异常，此函数现在会重试系统调用，而不是触发 InterruptedError 异常 (原因详见 PEP 475)。 os.wait3(options) 与 waitpid() 相似，差别在于没有进程 ID 参数，且返回一个 3 元组，其中包括子进程 ID，退出状态指示和资源使用信息。关于资源使用信息的详情，请参考 resource.getrusage()。option 参数与传入 waitpid() 和 wait4() 的相同。可用性: Unix。 os.wait4(pid, options) 与 waitpid() 相似，差别在本方法返回一个 3 元组，其中包括子进程 ID，退出状态指示和资源使用信息。关于资源使用信息的详情，请参考 resource.getrusage()。wait4() 的参数与 waitpid() 的参数相同。可用性: Unix。 os.WNOHANG 用于 waitpid() 的选项，如果没有立即可用的子进程状态，则立即返回。在这种情况下，函数返回 (0, 0)。可用性: Unix。 os.WCONTINUED 被任务控制 (job control) 停止的子进程，如果上次报告状态后已恢复运行，则此选项将报告这些子进程。可用性: 部分 Unix 系统。 os.WUNTRACED 已停止的子进程，如果自停止以来尚未报告其当前状态，则此选项将报告这些子进程。可用性: Unix。 下列函数采用进程状态码作为参数，状态码由 system()、wait() 或 waitpid() 返回。它们可用于确定进程上发生的操作。 os.WCOREDUMP(status) 如果为该进程生成了核心转储，返回 True，否则返回 False。可用性: Unix。 os.WIFCONTINUED(status) 如果进程被任务控制 (job control) 停止后，又重新继续运行，返回 True，否则返回 False。可用性: Unix。 os.WIFSTOPPED(status) 如果进程已停止，返回 True，否则返回 False。可用性: Unix。 os.WIFSIGNALED(status) 如果进程由于信号而退出，返回 True，否则返回 False。可用性: Unix。 os.WIFEXITED(status) 如果进程使用 exit(2)) 系统调用退出，返回 True，否则返回 False。可用性: Unix。 os.WEXITSTATUS(status) 如果 WIFEXITED(status) 为值，则将整数形参返回给 exit(2)) 系统调用。 否则，返回值将没有任何意义。可用性: Unix。 os.WSTOPSIG(status) 返回导致进程停止的信号。可用性: Unix。 os.WTERMSIG(status) 返回导致进程退出的信号。可用性: Unix。 调度器接口这些函数控制操作系统如何为进程分配 CPU 时间。 它们仅在某些 Unix 平台上可用。 更多细节信息请查阅你所用 Unix 的指南页面。 3.3 新版功能. 以下调度策略如果被操作系统支持就会对外公开。 os.SCHED_OTHER 默认调度策略。 os.SCHED_BATCH 用于 CPU 密集型进程的调度策略，它会尽量为计算机中的其余任务保留交互性。 os.SCHED_IDLE 用于极低优先级的后台任务的调度策略。 os.SCHED_SPORADIC 用于偶发型服务程序的调度策略。 os.SCHED_FIFO 先进先出的调度策略。 os.SCHED_RR 循环式的调度策略。 os.SCHED_RESET_ON_FORK 此旗标可与任何其他调度策略进行 OR 运算。 当带有此旗标的进程设置分叉时，其子进程的调度策略和优先级会被重置为默认值。 class os.sched_param(sched_priority) 这个类表示在 sched_setparam(), sched_setscheduler() 和 sched_getparam() 中使用的可修改调度形参。 它属于不可变对象。目前它只有一个可能的形参：sched_priority一个调度策略的调度优先级。 os.sched_get_priority_min(policy) 获取 policy 的最小优先级数值。 policy 是以上调度策略常量之一。 os.sched_get_priority_max(policy) 获取 policy 的最高优先级数值。 policy 是以上调度策略常量之一。 os.sched_setscheduler(pid, policy, param) 设置 PID 为 pid 的进程的调度策略。pid 为 0 指的是调用本方法的进程。policy 是以上调度策略常量之一。param 是一个 sched_param 实例。 os.sched_getscheduler(pid) 返回 PID 为 pid 的进程的调度策略。pid 为 0 指的是调用本方法的进程。返回的结果是以上调度策略常量之一。 os.sched_setparam(pid, param) 设置 PID 为 pid 的进程的某个调度参数。pid 为 0 指的是调用本方法的进程。param 是一个 sched_param 实例。 os.sched_getparam(pid) 返回 PID 为 pid 的进程的调度参数为一个 sched_param 实例。pid 为 0 指的是调用本方法的进程。 os.sched_rr_get_interval(pid) 返回 PID 为 pid 的进程在时间片轮转调度下的时间片长度（单位为秒）。pid 为 0 指的是调用本方法的进程。 os.sched_yield() 自愿放弃 CPU。 os.sched_setaffinity(pid, mask) 将 PID 为 pid 的进程（为零则为当前进程）限制到一组 CPU 上。mask 是整数的可迭代对象，表示应将进程限制在其中的一组 CPU。 os.sched_getaffinity(pid) 返回 PID 为 pid 的进程（为零则为当前进程）被限制到的那一组 CPU。 其他系统信息 os.confstr(name) 返回字符串格式的系统配置信息。name 指定要查找的配置名称，它可以是字符串，是一个系统已定义的名称，这些名称定义在不同标准（POSIX，Unix 95，Unix 98 等）中。一些平台还定义了额外的其他名称。当前操作系统已定义的名称在 confstr_names 字典的键中给出。对于未包含在该映射中的配置名称，也可以传递一个整数作为 name。 如果 name 指定的配置值未定义，返回 None。 如果 name 是一个字符串且不是已定义的名称，将抛出 ValueError 异常。如果当前系统不支持 name 指定的配置名称，即使该名称存在于 confstr_names，也会抛出 OSError 异常，错误码为 errno.EINVAL。 可用性: Unix。 s.confstr_names 字典，表示映射关系，为 confstr() 可接受名称与操作系统为这些名称定义的整数值之间的映射。这可用于判断系统已定义了哪些名称。可用性: Unix。 os.cpu_count() 返回系统的 CPU 数量。不确定则返回 None。该数量不同于当前进程可以使用的CPU数量。可用的CPU数量可以由 len(os.sched_getaffinity(0)) 方法获得。3.4 新版功能. os.getloadavg() 返回系统运行队列中最近 1、5 和 15 分钟内的平均进程数。无法获得平均负载则抛出 OSError 异常。可用性: Unix。 os.sysconf(name) 返回整数格式的系统配置信息。如果 name 指定的配置值未定义，返回 -1。对 confstr() 的 name 参数的注释在此处也适用。当前已知的配置名称在 sysconf_names 字典中提供。可用性: Unix。 os.sysconf_names 字典，表示映射关系，为 sysconf() 可接受名称与操作系统为这些名称定义的整数值之间的映射。这可用于判断系统已定义了哪些名称。可用性: Unix。 以下数据值用于支持对路径本身的操作。所有平台都有定义。 对路径的高级操作在 os.path 模块中定义。 os.curdir 操作系统用来表示当前目录的常量字符串。在 Windows 和 POSIX 上是 &#39;.&#39;。在 os.path 中也可用。 os.pardir 操作系统用来表示父目录的常量字符串。在 Windows 和 POSIX 上是 &#39;..&#39;。在 os.path 中也可用。 os.defpath 在环境变量没有 &#39;PATH&#39; 键的情况下，exec*p* and spawn*p* 使用的默认搜索路径。在 os.path 中也可用。 os.linesep 当前平台用于分隔（或终止）行的字符串。它可以是单个字符，如 POSIX 上是 &#39;\n&#39;，也可以是多个字符，如 Windows 上是 &#39;\r\n&#39;。在写入以文本模式（默认模式）打开的文件时，请不要使用 os.linesep 作为行终止符，请在所有平台上都使用一个 &#39;\n&#39; 代替。 os.devnull 空设备的文件路径。如 POSIX 上为 &#39;/dev/null&#39;，Windows 上为 &#39;nul&#39;。在 os.path 中也可用。 os.RTLD_LAZY os.RTLD_NOW os.RTLD_GLOBAL os.RTLD_LOCAL os.RTLD_NODELETE os.RTLD_NOLOAD os.RTLD_DEEPBIND setdlopenflags() 和 getdlopenflags() 函数所使用的标志。请参阅 Unix 手册页 dlopen(3)) 获取不同标志的含义。3.3 新版功能. 随机数 os.getrandom(size, flags=0) 获得最多为 size 的随机字节。本函数返回的字节数可能少于请求的字节数。 这些字节可用于为用户空间的随机数生成器提供种子，或用于加密目的。 getrandom() 依赖于从设备驱动程序和其他环境噪声源收集的熵。不必要地读取大量数据将对使用 /dev/random 和 /dev/urandom 设备的其他用户产生负面影响。 flags 参数是一个位掩码，可以是零个或多个下列值以或运算组合： os.GRND_RANDOM 和 GRND_NONBLOCK。 另请参阅 Linux getrandom() 手册页 。 可用性：Linux 3.17 或更高版本。 3.6 新版功能. os.urandom(size) 返回大小为 size 的字符串，它是适合加密使用的随机字节。本函数从系统指定的随机源获取随机字节。对于加密应用程序，返回的数据应有足够的不可预测性，尽管其确切的品质取决于操作系统的实现。在 Linux 上，如果 getrandom() 系统调用可用，它将以阻塞模式使用：阻塞直到系统的 urandom 熵池初始化完毕（内核收集了 128 位熵）。原理请参阅 PEP 524。在 Linux 上，getrandom() 可以以非阻塞模式（使用 GRND_NONBLOCK 标志）获取随机字节，或者轮询直到系统的 urandom 熵池初始化完毕。在类 Unix 系统上，随机字节是从 /dev/urandom 设备读取的。如果 /dev/urandom 设备不可用或不可读，则抛出 NotImplementedError 异常。在 Windows 上将使用 CryptGenRandom()。参见 secrets 模块提供了更高级的功能。所在平台会提供随机数生成器，有关其易于使用的接口，请参阅 random.SystemRandom。在 3.6.0 版更改: 在 Linux 上，getrandom() 现在以阻塞模式使用，以提高安全性。在 3.5.2 版更改: 在 Linux 上，如果 getrandom() 系统调用阻塞（urandom 熵池尚未初始化完毕），则退回一步读取 /dev/urandom。在 3.5 版更改: 在 Linux 3.17 和更高版本上，现在使用 getrandom() 系统调用（如果可用）。在 OpenBSD 5.6 和更高版本上，现在使用 getentropy() C 函数。这些函数避免了使用内部文件描述符。 os.GRND_NONBLOCK 默认情况下，从 /dev/random 读取时，如果没有可用的随机字节，则 getrandom() 会阻塞；从 /dev/urandom 读取时，如果熵池尚未初始化，则会阻塞。如果设置了 GRND_NONBLOCK 标志，则这些情况下 getrandom() 不会阻塞，而是立即抛出 BlockingIOError 异常。3.6 新版功能. os.GRND_RANDOM 如果设置了此标志位，那么将从 /dev/random 池而不是 /dev/urandom 池中提取随机字节。 3.6 新版功能.]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library shutil]]></title>
    <url>%2F2020%2F02%2F19%2Fpython-standard-library-shutil%2F</url>
    <content type="text"><![CDATA[python 标准库 shutil 高阶文件操作 收集了一些网上找到的学习python的资源,分享给大家。 源码源代码： Lib/shutil.py shutil 模块提供了一系列对文件和文件集合的高阶操作。 特别是提供了一些支持文件拷贝和删除的函数。 对于单个文件的操作，请参阅 os 模块。 警告：即便是高阶文件拷贝函数 (shutil.copy(), shutil.copy2()) 也无法拷贝所有的文件元数据。 在 POSIX 平台上，这意味着将丢失文件所有者和组以及 ACL 数据。 在 Mac OS 上，资源钩子和其他元数据不被使用。 这意味着将丢失这些资源并且文件类型和创建者代码将不正确。 在 Windows 上，将不会拷贝文件所有者、ACL 和替代数据流。 目录和文件操作 shutil.copyfileobj(fsrc, fdst[, length]) 将文件类对象 fsrc 的内容拷贝到文件类对象 fdst。 整数值 length 如果给出则为缓冲区大小。 特别地， length 为负值表示拷贝数据时不对源数据进行分块循环处理；默认情况下会分块读取数据以避免不受控制的内存消耗。 请注意如果 fsrc 对象的当前文件位置不为 0，则只有从当前文件位置到文件末尾的内容会被拷贝。 shutil.copyfile(src, dst, **, follow_symlinks=True*) 将名为 src 的文件的内容（不包括元数据）拷贝到名为 dst 的文件并以尽可能高效的方式返回 dst。 src 和 dst 均为路径类对象或以字符串形式给出的路径名。dst 必须是完整的目标文件名；对于接受目标目录路径的拷贝请参见 copy()。 如果 src 和 dst 指定了同一个文件，则将引发 SameFileError。目标位置必须是可写的；否则将引发 OSError 异常。 如果 dst 已经存在，它将被替换。 特殊文件如字符或块设备以及管道无法用此函数来拷贝。如果 follow_symlinks 为假值且 src 为符号链接，则将创建一个新的符号链接而不是拷贝 src 所指向的文件。引发一个 审计事件 shutil.copyfile 附带参数 src, dst。在 3.3 版更改: 曾经是引发 IOError 而不是 OSError。 增加了 follow_symlinks 参数。 现在是返回 dst。在 3.4 版更改: 引发 SameFileError 而不是 Error。 由于前者是后者的子类，此改变是向后兼容的。在 3.8 版更改: 可能会在内部使用平台专属的快速拷贝系统调用以更高效地拷贝文件。 参见 依赖于具体平台的高效拷贝操作 一节。 exception shutil.SameFileError 此异常会在 copyfile() 中的源和目标为同一文件时被引发。3.4 新版功能. shutil.copymode(src, dst, **, follow_symlinks=True*) 从 src 拷贝权限位到 dst。 文件的内容、所有者和分组将不受影响。 src 和 dst 均为路径类对象或字符串形式的路径名。 如果 follow_symlinks 为假值，并且 src 和 dst 均为符号链接，copymode() 将尝试修改 dst 本身的模式（而非它所指向的文件）。 此功能并不是在所有平台上均可用；请参阅 copystat() 了解详情。 如果 copymode() 无法修改本机平台上的符号链接，而它被要求这样做，它将不做任何操作即返回。引发一个 审计事件 shutil.copymode 附带参数 src, dst。在 3.3 版更改: 加入 follow_symlinks 参数。 shutil.copystat(src, dst, **, follow_symlinks=True*) 从 src 拷贝权限位、最近访问时间、最近修改时间以及旗标到 dst。 在 Linux上，copystat() 还会在可能的情况下拷贝“扩展属性”。 文件的内容、所有者和分组将不受影响。 src 和 dst 均为路径类对象或字符串形式的路径名。如果 follow_symlinks 为假值，并且 src 和 dst 均指向符号链接，copystat() 将作用于符号链接本身而非该符号链接所指向的文件 — 从 src 符号链接读取信息，并将信息写入 dst 符号链接。 注解: 并非所有平台者提供检查和修改符号链接的功能。 Python 本身可以告诉你哪些功能是在本机上可用的。 如果 os.chmod in os.supports_follow_symlinks 为 True，则 copystat() 可以修改符号链接的权限位。 如果 os.utime in os.supports_follow_symlinks 为 True，则 copystat() 可以修改符号链接的最近访问和修改时间。 如果 os.chflags in os.supports_follow_symlinks 为 True，则 copystat() 可以修改符号链接的旗标。 (os.chflags 不是在所有平台上均可用。) 在此功能部分或全部不可用的平台上，当被要求修改一个符号链接时，copystat() 将尽量拷贝所有内容。 copystat() 一定不会返回失败信息。 更多信息请参阅 os.supports_follow_symlinks。 引发一个 审计事件 shutil.copystat 附带参数 src, dst。 在 3.3 版更改: 添加了 follow_symlinks 参数并且支持 Linux 扩展属性。 shutil.copy(src, dst, **, follow_symlinks=True*) 将文件 src 拷贝到文件或目录 dst。 src 和 dst 应为字符串。 如果 dst 指定了一个目录，文件将使用 src 中的基准文件名拷贝到 dst。 返回新创建文件的路径。如果 follow_symlinks 为假值且 src 为符号链接，则 dst 也将被创建为符号链接。 如果 follow_symlinks 为真值且 src 为符号链接，dst 将成为 src 所指向的文件的一个副本。copy() 会拷贝文件数据和文件的权限模式 (参见 os.chmod())。 其他元数据，例如文件的创建和修改时间不会被保留。 要保留所有原有的元数据，请改用 copy2() 。引发一个 审计事件 shutil.copyfile 附带参数 src, dst。引发一个 审计事件 shutil.copymode 附带参数 src, dst。在 3.3 版更改: 添加了 follow_symlinks 参数。 现在会返回新创建文件的路径。在 3.8 版更改: 可能会在内部使用平台专属的快速拷贝系统调用以更高效地拷贝文件。 参见 依赖于具体平台的高效拷贝操作 一节。 shutil.copy2(src, dst, **, follow_symlinks=True*) 类似于 copy()，区别在于 copy2() 还会尝试保留文件的元数据。当 follow_symlinks 为假值且 src 为符号链接时，copy2() 会尝试将来自 src 符号链接的所有元数据拷贝到新创建的 dst 符号链接。 但是，此功能不是在所有平台上均可用。 在此功能部分或全部不可用的平台上，copy2() 将尽量保留所有元数据；copy2() 一定不会由于无法保留文件元数据而引发异常。copy2() 会使用 copystat() 来拷贝文件元数据。 请参阅 copystat() 了解有关修改符号链接元数据的平台支持的更多信息。引发一个 审计事件 shutil.copyfile 附带参数 src, dst。引发一个 审计事件 shutil.copystat 附带参数 src, dst。在 3.3 版更改: 添加了 follow_symlinks 参数，还会尝试拷贝扩展文件系统属性（目前仅限 Linux）。 现在会返回新创建文件的路径。在 3.8 版更改: 可能会在内部使用平台专属的快速拷贝系统调用以更高效地拷贝文件。 参见 依赖于具体平台的高效拷贝操作 一节。 shutil.ignore_patterns(*patterns) 这个工厂函数会创建一个函数，它可被用作 copytree() 的 ignore 可调用对象参数，以忽略那些匹配所提供的 glob 风格的 patterns 之一的文件和目录。 参见以下示例。 shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False, dirs_exist_ok=False) 将以 src 为根起点的整个目录树拷贝到名为 dst 的目录并返回目标目录。 dirs_exist_ok 指明是否要在 dst 或任何丢失的父目录已存在的情况下引发异常。目录的权限和时间会通过 copystat() 来拷贝，单个文件则会使用 copy2() 来拷贝。如果 symlinks 为真值，源目录树中的符号链接会在新目录树中表示为符号链接，并且原链接的元数据在平台允许的情况下也会被拷贝；如果为假值或省略，则会将被链接文件的内容和元数据拷贝到新目录树。当 symlinks 为假值时，如果符号链接所指向的文件不存在，则会在拷贝进程的末尾将一个异常添加到 Error 异常中的错误列表。 如果你希望屏蔽此异常那就将可选的 ignore_dangling_symlinks 旗标设为真值。 请注意此选项在不支持 os.symlink() 的平台上将不起作用。如果给出了 ignore，它必须是一个可调用对象，该对象将接受 copytree() 所访问的目录以及 os.listdir() 所返回的目录内容列表作为其参数。 由于 copytree() 是递归地被调用的，ignore 可调用对象对于每个被拷贝目录都将被调用一次。 该可调用对象必须返回一个相对于当前目录的目录和文件名序列（即其第二个参数的子集）；随后这些名称将在拷贝进程中被忽略。 ignore_patterns() 可被用于创建这种基于 glob 风格模式来忽略特定名称的可调用对象。如果发生了（一个或多个）异常，将引发一个附带原因列表的 Error。如果给出了 copy_function，它必须是一个将被用来拷贝每个文件的可调用对象。 它在被调用时会将源路径和目标路径作为参数传入。 默认情况下，copy2() 将被使用，但任何支持同样签名（与 copy() 一致）都可以使用。引发一个 审计事件 shutil.copytree 附带参数 src, dst。在 3.3 版更改: 当 symlinks 为假值时拷贝元数据。 现在会返回 dst。在 3.2 版更改: 添加了 copy_function 参数以允许提供定制的拷贝函数。 添加了 ignore_dangling_symlinks 参数以便在 symlinks 为假值时屏蔽符号链接错误。在 3.8 版更改: 可能会在内部使用平台专属的快速拷贝系统调用以更高效地拷贝文件。 参见 依赖于具体平台的高效拷贝操作 一节。3.8 新版功能: dirs_exist_ok 形参。 shutil.rmtree(path, ignore_errors=False, onerror=None) 删除一个完整的目录树；path 必须指向一个目录（但不能是一个目录的符号链接）。 如果 ignore_errors 为真值，删除失败导致的错误将被忽略；如果为假值或是省略，此类错误将通过调用由 onerror 所指定的处理程序来处理，或者如果此参数被省略则将引发一个异常。 注解: 在支持必要的基于 fd 的函数的平台上，默认会使用 rmtree() 的可防御符号链接攻击的版本。 在其他平台上，rmtree() 较易遭受符号链接攻击：给定适当的时间和环境，攻击者可以操纵文件系统中的符号链接来删除他们在其他情况下无法访问的文件。 应用程序可以使用 rmtree.avoids_symlink_attacks 函数属性来确定此类情况具体是哪一些。 shutil.move(src, dst, copy_function=copy2) 递归地将一个文件或目录 (src) 移至另一位置 (dst) 并返回目标位置。如果目标是已存在的目录，则 src 会被移至该目录下。 如果目标已存在但不是目录，它可能会被覆盖，具体取决于 os.rename() 的语义。如果目标是在当前文件系统中，则会使用 os.rename()。 在其他情况下，src 将被拷贝至 dst，使用的函数为 copy_function，然后目标会被移除。 对于符号链接，则将在 dst 之下或以其本身为名称创建一个指向 src 目标的新符号链接，并且 src 将被移除。如果给出了 copy_function，则它必须为接受两个参数 src 和 dst 的可调用对象，并会在 os.rename() 无法使用时被用来将 src 拷贝到 dest。 如果源位置是一个目录，则会调用 copytree()，并向它传入 copy_function()。 默认的 copy_function 是 copy2()。 使用 copy() 作为 copy_function 允许在无法附带拷贝元数据时让移动操作成功执行，但其代价是不拷贝任何元数据。引发一个 审计事件 shutil.move 附带参数 src, dst。在 3.3 版更改: 为异类文件系统添加了显式的符号链接处理，以便使它适应 GNU 的 mv 的行为。 现在会返回 dst。在 3.5 版更改: 增加了 copy_function 关键字参数。在 3.8 版更改: 可能会在内部使用平台专属的快速拷贝系统调用以更高效地拷贝文件。 参见 依赖于具体平台的高效拷贝操作 一节。 shutil.disk_usage(path) 返回给定路径的磁盘使用统计数据，形式为一个 named tuple，其中包含 total, used 和 free 属性，分别表示总计、已使用和未使用空间的字节数。 path 可以是一个文件或是一个目录。3.3 新版功能.**在 3.8 版更改: 在 Windows 上，path 现在可以是一个文件或目录。可用性: Unix, Windows。 shutil.chown(path, user=None, group=None) 修改给定 path 的所有者 user 和/或 group。user 可以是一个系统用户名或 uid；group 同样如此。 要求至少有一个参数。另请参阅下层的函数 os.chown()。引发一个 审计事件 shutil.chown 附带参数 path, user, group。Availability: Unix.3.3 新版功能. shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None) 返回当给定的 cmd 被调用时将要运行的可执行文件的路径。 如果没有 cmd 会被调用则返回 None。mode 是一个传递给 os.access() 的权限掩码，在默认情况下将确定文件是否存在并且为可执行文件。当未指定 path 时，将会使用 os.environ() 的结果，返回 “PATH” 的值或回退为 os.defpath。在 Windows 上当前目录总是会被添加为 path 的第一项，无论你是否使用默认值或提供你自己的路径，这是命令行终端在查找可执行文件时所采用的行为方式。 此外，当在 path 中查找 cmd 时，还会检查 PATHEXT 环境变量。 例如，如果你调用 shutil.which(&quot;python&quot;)，which() 将搜索 PATHEXT 来确定它要在 path 目录中查找 python.exe。 例如，在 Windows 上:&gt;&gt;&gt;&gt;&gt;&gt; shutil.which(&quot;python&quot;) &#39;C:\\Python33\\python.EXE&#39;3.3 新版功能.**在 3.8 版更改: 现在可以接受 bytes 类型。 如果 cmd 的类型为 bytes，结果的类型也将为 bytes。 exception shutil.Error 此异常会收集在多文件操作期间所引发的异常。 对于 copytree()，此异常参数将是一个由三元组 (srcname, dstname, exception) 构成的列表。 依赖于具体平台的高效拷贝操作从 Python 3.8 开始，所有涉及文件拷贝的函数 (copyfile(), copy(), copy2(), copytree(), 以及 move()) 将会使用平台专属的 “fast-copy” 系统调用以便更高效地拷贝文件 (参见 bpo-33671)。 “fast-copy” 意味着拷贝操作将发生于内核之中，避免像在 “outfd.write(infd.read())“ 中那样使用用户空间的缓冲区。 在 macOS 上将会使用 fcopyfile 来拷贝文件内容（不含元数据）。 在 Linux 上将会使用 os.sendfile()。 在 Windows 上 shutil.copyfile() 将会使用更大的默认缓冲区（1 MiB 而非 64 KiB）并且会使用基于 memoryview() 的 shutil.copyfileobj() 变种形式。 如果快速拷贝操作失败并且没有数据被写入目标文件，则 shutil 将在内部静默地回退到使用效率较低的 copyfileobj() 函数。 在 3.8 版更改. copytree 示例这个示例就是上面所描述的 copytree() 函数的实现，其中省略了文档字符串。 它还展示了此模块所提供的许多其他函数。 123456789101112131415161718192021222324252627282930def copytree(src, dst, symlinks=False): names = os.listdir(src) os.makedirs(dst) errors = [] for name in names: srcname = os.path.join(src, name) dstname = os.path.join(dst, name) try: if symlinks and os.path.islink(srcname): linkto = os.readlink(srcname) os.symlink(linkto, dstname) elif os.path.isdir(srcname): copytree(srcname, dstname, symlinks) else: copy2(srcname, dstname) # XXX What about devices, sockets etc.? except OSError as why: errors.append((srcname, dstname, str(why))) # catch the Error from the recursive copytree so that we can # continue with other files except Error as err: errors.extend(err.args[0]) try: copystat(src, dst) except OSError as why: # can't copy file access times on Windows if why.winerror is None: errors.extend((src, dst, str(why))) if errors: raise Error(errors) 另一个使用 ignore_patterns() 辅助函数的例子: 123from shutil import copytree, ignore_patternscopytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*')) 这将会拷贝除 .pyc 文件和以 tmp 打头的文件或目录以外的所有条目. 另一个使用 ignore 参数来添加记录调用的例子: 12345678from shutil import copytreeimport loggingdef _logpath(path, names): logging.info('Working in %s', path) return [] # nothing will be ignoredcopytree(source, destination, ignore=_logpath) rmtree 示例这个例子演示了如何在 Windows 上删除一个目录树，其中部分文件设置了只读属性位。 它会使用 onerror 回调函数来清除只读属性位并再次尝试删除。 任何后续的失败都将被传播。 123456789import os, statimport shutildef remove_readonly(func, path, _): "Clear the readonly bit and reattempt the removal" os.chmod(path, stat.S_IWRITE) func(path)shutil.rmtree(directory, onerror=remove_readonly) 归档操作3.2 新版功能. 在 3.5 版更改: 添加了对 xztar 格式的支持。 本模块也提供了用于创建和读取压缩和归档文件的高层级工具。 它们依赖于 zipfile 和 tarfile 模块。 shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]]) 创建一个归档文件（例如 zip 或 tar）并返回其名称。base_name 是要创建的文件名称，包括路径，去除任何特定格式的扩展名。 format 是归档格式：为 “zip” (如果 zlib 模块可用), “tar”, “gztar” (如果 zlib 模块可用), “bztar” (如果 bz2 模块可用) 或 “xztar” (如果 lzma 模块可用) 中的一个。root_dir 是一个目录，它将作为归档文件的根目录；例如，我们通常会在创建归档文件之前用 chdir 命令切换到 root_dir。base_dir 是我们要执行归档的起始目录；也就是说 base_dir 将成为归档文件中所有文件和目录共有的路径前缀。root_dir 和 base_dir 默认均为当前目录。如果 dry_run 为真值，则不会创建归档文件，但将要被执行的操作会被记录到 logger。owner 和 group 将在创建 tar 归档文件时被使用。 默认会使用当前的所有者和分组。logger 必须是一个兼容 PEP 282 的对象，通常为 logging.Logger 的实例。verbose 参数已不再使用并进入弃用状态。引发一个 审计事件 shutil.make_archive 并附带参数 base_name, format, root_dir, base_dir。在 3.8 版更改: 现在对于通过 format=&quot;tar&quot; 创建的归档文件将使用新式的 pax (POSIX.1-2001) 格式而非旧式的 GNU 格式。 shutil.get_archive_formats() 返回支持的归档格式列表。 所返回序列中的每个元素为一个元组 (name, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（如果 zlib 模块可用）。tar: 未压缩的 tar 文件。 对于新归档文件将使用 POSIX.1-2001 pax 格式。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_archive_format() 注册新的格式或为任何现有格式提供你自己的归档器。 shutil.register_archive_format(name, function[, extra_args[, description]]) 为 name 格式注册一个归档器。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接收要创建文件的 base_name，再加上要归档内容的 base_dir (其默认值为 os.curdir)。 更多参数会被作为关键字参数传入: owner, group, dry_run 和 logger (与向 make_archive() 传入的参数一致)。如果给出了 extra_args，则其应为一个 (name, value) 对的序列，将在归档器可调用对象被使用时作为附加的关键字参数。description 由 get_archive_formats() 使用，它将返回归档器的列表。 默认值为一个空字符串。 shutil.unregister_archive_format(name) 从支持的格式中移除归档格式 name。 shutil.unpack_archive(filename[, extract_dir[, format]]) 解包一个归档文件。 filename 是归档文件的完整路径。extract_dir 是归档文件解包的目标目录名称。 如果未提供，则将使用当前工作目录。format 是归档格式：应为 “zip”, “tar”, “gztar”, “bztar” 或 “xztar” 之一。 或者任何通过 register_unpack_format() 注册的其他格式。 如果未提供，unpack_archive() 将使用归档文件的扩展名来检查是否注册了对应于该扩展名的解包器。 在未找到任何解包器的情况下，将引发 ValueError。引发一个 审计事件 shutil.unpack_archive 附带参数 filename, extract_dir, format。在 3.7 版更改: 接受一个 path-like object 作为 filename 和 extract_dir。 shutil.register_unpack_format(name, extensions, function[, extra_args[, description]]) 注册一个解包格式。 name 为格式名称而 extensions 为对应于该格式的扩展名列表，例如 Zip 文件的扩展名为 .zip。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接受归档文件的路径，加上该归档文件要被解包的目标目录。如果提供了 extra_args，则其应为一个 (name, value) 元组的序列，将被作为关键字参数传递给该可调用对象。可以提供 description 来描述该格式，它将被 get_unpack_formats() 返回。 shutil.unregister_unpack_format(name) 撤销注册一个解包格式。 name 为格式的名称。 shutil.get_unpack_formats() 返回所有已注册的解包格式列表。 所返回序列中的每个元素为一个元组 (name, extensions, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（只有在相应模块可用时才能解包压缩文件）。tar: 未压缩的 tar 文件。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_unpack_format() 注册新的格式或为任何现有格式提供你自己的解包器。 3.2 新版功能. 在 3.5 版更改: 添加了对 xztar 格式的支持。 本模块也提供了用于创建和读取压缩和归档文件的高层级工具。 它们依赖于 zipfile 和 tarfile 模块。 shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]]) 创建一个归档文件（例如 zip 或 tar）并返回其名称。base_name 是要创建的文件名称，包括路径，去除任何特定格式的扩展名。 format 是归档格式：为 “zip” (如果 zlib 模块可用), “tar”, “gztar” (如果 zlib 模块可用), “bztar” (如果 bz2 模块可用) 或 “xztar” (如果 lzma 模块可用) 中的一个。root_dir 是一个目录，它将作为归档文件的根目录；例如，我们通常会在创建归档文件之前用 chdir 命令切换到 root_dir。base_dir 是我们要执行归档的起始目录；也就是说 base_dir 将成为归档文件中所有文件和目录共有的路径前缀。root_dir 和 base_dir 默认均为当前目录。如果 dry_run 为真值，则不会创建归档文件，但将要被执行的操作会被记录到 logger。owner 和 group 将在创建 tar 归档文件时被使用。 默认会使用当前的所有者和分组。logger 必须是一个兼容 PEP 282 的对象，通常为 logging.Logger 的实例。verbose 参数已不再使用并进入弃用状态。引发一个 审计事件 shutil.make_archive 并附带参数 base_name, format, root_dir, base_dir。在 3.8 版更改: 现在对于通过 format=&quot;tar&quot; 创建的归档文件将使用新式的 pax (POSIX.1-2001) 格式而非旧式的 GNU 格式。 shutil.get_archive_formats() 返回支持的归档格式列表。 所返回序列中的每个元素为一个元组 (name, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（如果 zlib 模块可用）。tar: 未压缩的 tar 文件。 对于新归档文件将使用 POSIX.1-2001 pax 格式。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_archive_format() 注册新的格式或为任何现有格式提供你自己的归档器。 shutil.register_archive_format(name, function[, extra_args[, description]]) 为 name 格式注册一个归档器。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接收要创建文件的 base_name，再加上要归档内容的 base_dir (其默认值为 os.curdir)。 更多参数会被作为关键字参数传入: owner, group, dry_run 和 logger (与向 make_archive() 传入的参数一致)。如果给出了 extra_args，则其应为一个 (name, value) 对的序列，将在归档器可调用对象被使用时作为附加的关键字参数。description 由 get_archive_formats() 使用，它将返回归档器的列表。 默认值为一个空字符串。 shutil.unregister_archive_format(name) 从支持的格式中移除归档格式 name。 shutil.unpack_archive(filename[, extract_dir[, format]]) 解包一个归档文件。 filename 是归档文件的完整路径。extract_dir 是归档文件解包的目标目录名称。 如果未提供，则将使用当前工作目录。format 是归档格式：应为 “zip”, “tar”, “gztar”, “bztar” 或 “xztar” 之一。 或者任何通过 register_unpack_format() 注册的其他格式。 如果未提供，unpack_archive() 将使用归档文件的扩展名来检查是否注册了对应于该扩展名的解包器。 在未找到任何解包器的情况下，将引发 ValueError。引发一个 审计事件 shutil.unpack_archive 附带参数 filename, extract_dir, format。在 3.7 版更改: 接受一个 path-like object 作为 filename 和 extract_dir。 shutil.register_unpack_format(name, extensions, function[, extra_args[, description]]) 注册一个解包格式。 name 为格式名称而 extensions 为对应于该格式的扩展名列表，例如 Zip 文件的扩展名为 .zip。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接受归档文件的路径，加上该归档文件要被解包的目标目录。如果提供了 extra_args，则其应为一个 (name, value) 元组的序列，将被作为关键字参数传递给该可调用对象。可以提供 description 来描述该格式，它将被 get_unpack_formats() 返回。 shutil.unregister_unpack_format(name) 撤销注册一个解包格式。 name 为格式的名称。 shutil.get_unpack_formats() 返回所有已注册的解包格式列表。 所返回序列中的每个元素为一个元组 (name, extensions, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（只有在相应模块可用时才能解包压缩文件）。tar: 未压缩的 tar 文件。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_unpack_format() 注册新的格式或为任何现有格式提供你自己的解包器。 3.2 新版功能. 在 3.5 版更改: 添加了对 xztar 格式的支持。 本模块也提供了用于创建和读取压缩和归档文件的高层级工具。 它们依赖于 zipfile 和 tarfile 模块。 shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]]) 创建一个归档文件（例如 zip 或 tar）并返回其名称。base_name 是要创建的文件名称，包括路径，去除任何特定格式的扩展名。 format 是归档格式：为 “zip” (如果 zlib 模块可用), “tar”, “gztar” (如果 zlib 模块可用), “bztar” (如果 bz2 模块可用) 或 “xztar” (如果 lzma 模块可用) 中的一个。root_dir 是一个目录，它将作为归档文件的根目录；例如，我们通常会在创建归档文件之前用 chdir 命令切换到 root_dir。base_dir 是我们要执行归档的起始目录；也就是说 base_dir 将成为归档文件中所有文件和目录共有的路径前缀。root_dir 和 base_dir 默认均为当前目录。如果 dry_run 为真值，则不会创建归档文件，但将要被执行的操作会被记录到 logger。owner 和 group 将在创建 tar 归档文件时被使用。 默认会使用当前的所有者和分组。logger 必须是一个兼容 PEP 282 的对象，通常为 logging.Logger 的实例。verbose 参数已不再使用并进入弃用状态。引发一个 审计事件 shutil.make_archive 并附带参数 base_name, format, root_dir, base_dir。在 3.8 版更改: 现在对于通过 format=&quot;tar&quot; 创建的归档文件将使用新式的 pax (POSIX.1-2001) 格式而非旧式的 GNU 格式。 shutil.get_archive_formats() 返回支持的归档格式列表。 所返回序列中的每个元素为一个元组 (name, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（如果 zlib 模块可用）。tar: 未压缩的 tar 文件。 对于新归档文件将使用 POSIX.1-2001 pax 格式。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_archive_format() 注册新的格式或为任何现有格式提供你自己的归档器。 shutil.register_archive_format(name, function[, extra_args[, description]]) 为 name 格式注册一个归档器。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接收要创建文件的 base_name，再加上要归档内容的 base_dir (其默认值为 os.curdir)。 更多参数会被作为关键字参数传入: owner, group, dry_run 和 logger (与向 make_archive() 传入的参数一致)。如果给出了 extra_args，则其应为一个 (name, value) 对的序列，将在归档器可调用对象被使用时作为附加的关键字参数。description 由 get_archive_formats() 使用，它将返回归档器的列表。 默认值为一个空字符串。 shutil.unregister_archive_format(name) 从支持的格式中移除归档格式 name。 shutil.unpack_archive(filename[, extract_dir[, format]]) 解包一个归档文件。 filename 是归档文件的完整路径。extract_dir 是归档文件解包的目标目录名称。 如果未提供，则将使用当前工作目录。format 是归档格式：应为 “zip”, “tar”, “gztar”, “bztar” 或 “xztar” 之一。 或者任何通过 register_unpack_format() 注册的其他格式。 如果未提供，unpack_archive() 将使用归档文件的扩展名来检查是否注册了对应于该扩展名的解包器。 在未找到任何解包器的情况下，将引发 ValueError。引发一个 审计事件 shutil.unpack_archive 附带参数 filename, extract_dir, format。在 3.7 版更改: 接受一个 path-like object 作为 filename 和 extract_dir。 shutil.register_unpack_format(name, extensions, function[, extra_args[, description]]) 注册一个解包格式。 name 为格式名称而 extensions 为对应于该格式的扩展名列表，例如 Zip 文件的扩展名为 .zip。function 是将被用来解包归档文件的可调用对象。 该可调用对象将接受归档文件的路径，加上该归档文件要被解包的目标目录。如果提供了 extra_args，则其应为一个 (name, value) 元组的序列，将被作为关键字参数传递给该可调用对象。可以提供 description 来描述该格式，它将被 get_unpack_formats() 返回。 shutil.unregister_unpack_format(name) 撤销注册一个解包格式。 name 为格式的名称。 shutil.get_unpack_formats() 返回所有已注册的解包格式列表。 所返回序列中的每个元素为一个元组 (name, extensions, description)。默认情况下 shutil 提供以下格式:zip: ZIP 文件（只有在相应模块可用时才能解包压缩文件）。tar: 未压缩的 tar 文件。gztar: gzip 压缩的 tar 文件（如果 zlib 模块可用）。bztar: bzip2 压缩的 tar 文件（如果 bz2 模块可用）。xztar: xz 压缩的 tar 文件（如果 lzma 模块可用）。你可以通过使用 register_unpack_format() 注册新的格式或为任何现有格式提供你自己的解包器。 归档程序示例在这个示例中，我们创建了一个 gzip 压缩的 tar 归档文件，其中包含用户的 .ssh 目录下的所有文件: 123456&gt;&gt;&gt; from shutil import make_archive&gt;&gt;&gt; import os&gt;&gt;&gt; archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))&gt;&gt;&gt; root_dir = os.path.expanduser(os.path.join('~', '.ssh'))&gt;&gt;&gt; make_archive(archive_name, 'gztar', root_dir)'/Users/tarek/myarchive.tar.gz' 结果归档文件中包含有: 123456789$ tar -tzvf /Users/tarek/myarchive.tar.gzdrwx------ tarek/staff 0 2010-02-01 16:23:40 ./-rw-r--r-- tarek/staff 609 2008-06-09 13:26:54 ./authorized_keys-rwxr-xr-x tarek/staff 65 2008-06-09 13:26:54 ./config-rwx------ tarek/staff 668 2008-06-09 13:26:54 ./id_dsa-rwxr-xr-x tarek/staff 609 2008-06-09 13:26:54 ./id_dsa.pub-rw------- tarek/staff 1675 2008-06-09 13:26:54 ./id_rsa-rw-r--r-- tarek/staff 397 2008-06-09 13:26:54 ./id_rsa.pub-rw-r--r-- tarek/staff 37192 2010-02-06 18:23:10 ./known_hosts 查询输出终端的尺寸 shutil.get_terminal_size(fallback=(columns, lines)) 获取终端窗口的尺寸。 对于两个维度中的每一个，会分别检查环境变量 COLUMNS 和 LINES。 如果定义了这些变量并且其值为正整数，则将使用这些值。 如果未定义 COLUMNS 或 LINES，这是通常的情况，则连接到 sys.__stdout__ 的终端将通过发起调用 os.get_terminal_size() 被查询。 如果由于系统不支持查询，或是由于我们未连接到某个终端而导致查询终端尺寸不成功，则会使用在 fallback 形参中给出的值。 fallback 默认为 (80, 24)，这是许多终端模拟器所使用的默认尺寸。 返回的值是一个 os.terminal_size 类型的具名元组。 另请参阅: The Single UNIX Specification, Version 2, Other Environment Variables. 3.3 新版功能. 小结123456789101112131415161718192021222324252627shutil主要API:1 shutil.copyfileobj(fsrc, fdst[, length=16*1024]) #copy文件内容到另一个文件，可以copy指定大小的内容 2 shutil.copyfile(src,dst) #copy文件内容，是不是感觉上面的文件复制很麻烦？还需要自己手动用open函数打开文件，在这里就不需要了，事实上，copyfile调用了copyfileobj 3 shutil.copymode(src,dst) #仅copy权限，不更改文件内容，组和用户。 4 shutil.copystat(src,dst) #复制所有的状态信息，包括权限，组，用户，时间等 5 shutil.copy(src,dst) #复制文件的内容以及权限，先copyfile后copymode 6 shutil.copy2(src,dst) #复制文件的内容以及文件的所有状态信息。先copyfile后copystat 7 shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2,ignore_dangling_symlinks=False) #递归的复制文件内容及状态信息 8 shutil.rmtree(path, ignore_errors=False, onerror=None) #递归地删除文件 9 shutil.move(src, dst) #递归的移动文件 10 make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,dry_run=0, owner=None, group=None, logger=None) #压缩打包 base_name： 压缩打包后的文件名或者路径名format： 压缩或者打包格式 "zip", "tar", "bztar"or "gztar"root_dir : 将哪个目录或者文件打包（也就是源文件）]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>shutil</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[using ffmpeg download yizhibo m3u8 type playback video]]></title>
    <url>%2F2020%2F02%2F18%2Fusing-ffmpeg-download-yizhibo-m3u8-type-playback-video%2F</url>
    <content type="text"><![CDATA[使用 ffmpe 下载一直播 回放视频 背景想下载一直播上的直播视频到本地,但是发现没有直接下载的途径,只能回放。 分析问题下播后,通过分享链接到qq,得到了在线观看回放的视频地址。F12 发现m3u8格式的链接地址。 复制该链接地址。 本地已经搭建了ffmpeg的环境 1234567891011121314151617PS &gt; ffmpegffmpeg version git-2019-11-20-d73f062 Copyright (c) 2000-2019 the FFmpeg developers built with gcc 9.2.1 (GCC) 20191010 configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy--enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt --enable-amf libavutil 56. 36.100 / 56. 36.100 libavcodec 58. 62.100 / 58. 62.100 libavformat 58. 35.100 / 58. 35.100 libavdevice 58. 9.101 / 58. 9.101 libavfilter 7. 66.100 / 7. 66.100 libswscale 5. 6.100 / 5. 6.100 libswresample 3. 6.100 / 3. 6.100 libpostproc 55. 6.100 / 55. 6.100Hyper fast Audio and Video encoderusage: ffmpeg [options] [[infile options] -i infile]... &#123;[outfile options] outfile&#125;...Use -h to get full help or, even better, run 'man ffmpeg' 解决方案接下来使用 ffmpeg 解析上面网址中含有 m3u8的链接 1ffmpeg -i "https://test.test/test.m3u8" -vcodec copy -acodec copy -absf aac_adtstoasc test.mp4 经过漫长的等待,终于解析成功。视频可以直接播放。]]></content>
      <categories>
        <category>ffmpeg</category>
      </categories>
      <tags>
        <tag>ffmpeg</tag>
        <tag>m3u8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library dbm]]></title>
    <url>%2F2020%2F02%2F17%2Fpython-standard-library-dbm%2F</url>
    <content type="text"><![CDATA[python 标准库 dbm 要使整个人生都过得舒适、愉快，这是不可能的，因为人类必须具备一种能应付逆境的态度。 ​ ——卢梭 源代码: Lib/dbm/init.py dbm 是一种泛用接口，针对各种 DBM 数据库 — 包括 dbm.gnu 或 dbm.ndbm。 如果未安装这些模块中的任何一种，则将使用 dbm.dumb 模块中慢速但简单的实现。 还有一个适用于 Oracle Berkeley DB 的 第三方接口。 exception dbm.error 一个元组，其中包含每个受支持的模块可引发的异常，另外还有一个名为 dbm.error 的特殊异常作为第一项 — 后者最在引发 dbm.error 时被使用。 dbm.whichdb(filename) 此函数会猜测各种简单数据库模块中的哪一个是可用的 — dbm.gnu, dbm.ndbm 还是 dbm.dumb — 应该被用来打开给定的文件。返回下列值中的一个：如果文件由于不可读或不存在而无法打开则返回 None；如果文件的格式无法猜测则返回空字符串 (&#39;&#39;)；或是包含所需模块名称的字符串，例如 &#39;dbm.ndbm&#39; 或 &#39;dbm.gnu&#39;。 dbm.open(file, flag=’r’, mode=0o666) 打开数据库文件 file 并返回一个相应的对象。如果数据库文件已存在，则使用 whichdb() 函数来确定其类型和要使用的适当模块；如果文件不存在，则会使用上述可导入模块中的第一个。可选的 flag 参数可以是：’’ | 值 | 意义 || —– | —————————————- || &#39;r&#39; | 以只读方式打开现有数据库（默认） || &#39;w&#39; | 以读写方式打开现有数据库 || &#39;c&#39; | 以读写方式打开数据库，如果不存在则创建它 || &#39;n&#39; | 始终创建一个新的空数据库，以读写方式打开 | open() 所返回的对象支持与字典相同的基本功能；可以存储、获取和删除键及其对应的值，并可使用 in 运算符和 keys() 方法，以及 get() 和 setdefault()。 在 3.2 版更改: 现在 get() 和 setdefault() 在所有数据库模块中均可用。 在 3.8 版更改: 从只读数据库中删除键将引发数据库模块专属的错误而不是 KeyError。 键和值总是被存储为字节串。 这意味着当使用字符串时它们会在被存储之前隐式地转换至默认编码格式。 这些对象也支持在 with 语句中使用，当语句结束时将自动关闭它们。 在 3.4 版更改: 向 open() 所返回的对象添加了上下文管理协议的原生支持。 以下示例记录了一些主机名和对应的标题，随后将数据库的内容打印出来。: 1234567891011121314151617181920212223import dbm# Open database, creating it if necessary.with dbm.open('cache', 'c') as db: # Record some values db[b'hello'] = b'there' db['www.python.org'] = 'Python Website' db['www.cnn.com'] = 'Cable News Network' # Note that the keys are considered bytes now. assert db[b'www.python.org'] == b'Python Website' # Notice how the value is now in bytes. assert db['www.cnn.com'] == b'Cable News Network' # Often-used methods of the dict interface work too. print(db.get('python.org', b'not present')) # Storing a non-string key or value will raise an exception (most # likely a TypeError). db['www.yahoo.com'] = 4# db is automatically closed when leaving the with statement. 参见:模块 shelve 存储非字符串数据的持久化模块。 以下部分描述了各个单独的子模块。 dbm.gnu — GNU 对 dbm 的重解析源代码: Lib/dbm/gnu.py 此模块与 dbm 模块很相似，但是改用 GNU 库 gdbm 来提供某些附加功能。 请注意由 dbm.gnu 与 dbm.ndbm 所创建的文件格式是不兼容的。 dbm.gnu 模块提供了对 GNU DBM 库的接口。 dbm.gnu.gdbm 对象的行为类似于映射（字典），区别在于其键和值总是会在存储之前被转换为字节串。 打印 gdbm 对象不会打印出键和值，并且 items() 和 values() 等方法也不受支持。 exception dbm.gnu.error 针对 dbm.gnu 专属错误例如 I/O 错误引发。 KeyError 的引发则针对一般映射错误例如指定了不正确的键。 dbm.gnu.open(filename[, flag[, mode]]) 打开一个 gdbm 数据库并返回 gdbm 对象。 filename 参数为数据库文件名称。 可选的 flag 参数可以是： | 值 | 意义 || —– | —————————————- || &#39;r&#39; | 以只读方式打开现有数据库（默认） || &#39;w&#39; | 以读写方式打开现有数据库 || &#39;c&#39; | 以读写方式打开数据库，如果不存在则创建它 || &#39;n&#39; | 始终创建一个新的空数据库，以读写方式打开 | 下列附加字符可被添加至旗标以控制数据库的打开方式： | 值 | 意义 || —– | ——————————————– || &#39;f&#39; | 以快速模式打开数据库。写入数据库将不会同步。 || &#39;s&#39; | 同步模式。这将导致数据库的更改立即写入文件。 || &#39;u&#39; | 不要锁定数据库。 | 不是所有旗标都可用于所有版本的 gdbm。 模块常量 open_flags 为包含受支持旗标字符的字符串。 如果指定了无效的旗标则会引发 error。 可选的 mode 参数是文件的 Unix 模式，仅在要创建数据库时才会被使用。 其默认值为八进制数 0o666。 除了与字典类似的方法，gdbm 对象还有以下方法： gdbm.firstkey() 使用此方法和 nextkey() 方法可以循环遍历数据库中的每个键。 遍历的顺序是按照 gdbm 的内部哈希值，而不会根据键的值排序。 此方法将返回起始键。 gdbm.nextkey(key) 在遍历中返回 key 之后的的下一个键。 以下代码将打印数据库 db 中的每个键，而不会在内存中创建一个包含所有键的列表:k = db.firstkey() while k != None: print(k) k = db.nextkey(k) gdbm.reorganize() 如果你进行了大量删除操作并且想要缩减 gdbm 文件所使用的空间，此例程将可重新组织数据库。 除非使用此重组功能否则 gdbm 对象不会缩减数据库文件大小；在其他情况下，被删除的文件空间将会保留并在添加新的 (键, 值) 对时被重用。 gdbm.sync() 当以快速模式打开数据库时，此方法会将任何未写入数据强制写入磁盘。 gdbm.close()¶ 关闭 gdbm 数据库。 dbm.ndbm — 基于 ndbm 的接口源代码: Lib/dbm/ndbm.py dbm.ndbm 模块提供了对 Unix “(n)dbm” 库的接口。 Dbm 对象的行为类似于映射（字典），区别在于其键和值总是被存储为字节串。 打印 dbm 对象不会打印出键和值，并且 items() 和 values() 等方法也不受支持。 此模块可与 “经典classic” ndbm 接口或 GNU GDBM 兼容接口一同使用。 在 Unix 上，configure 脚本将尝试定位适当的头文件来简化此模块的构建。 exception dbm.ndbm.error 针对 dbm.ndbm 专属错误例如 I/O 错误引发。 KeyError 的引发则针对一般映射错误例如指定了不正确的键。 dbm.ndbm.library 所使用的 ndbm 实现库的名称。 dbm.ndbm.open(filename[, flag[, mode]]) 打开一个 dbm 数据库并返回 ndbm 对象。 filename 参数为数据库文件名称（不带 .dir 或 .pag 扩展名）。可选的 flag 参数必须是下列值之一：值意义&#39;r&#39;以只读方式打开现有数据库（默认）&#39;w&#39;以读写方式打开现有数据库&#39;c&#39;以读写方式打开数据库，如果不存在则创建它&#39;n&#39;始终创建一个新的空数据库，以读写方式打开可选的 mode 参数是文件的 Unix 模式，仅在要创建数据库时才会被使用。 其默认值为八进制数 0o666 (并将被当前的 umask 所修改)。除了与字典类似的方法，ndbm 对象还有以下方法：ndbm.close()关闭 ndbm 数据库。 dbm.dumb — 便携式 DBM 实现源代码: Lib/dbm/dumb.py 注解:dbm.dumb 模块的目的是在更健壮的模块不可用时作为 dbm 模块的最终回退项。 dbm.dumb 不是为高速运行而编写的，也不像其他数据库模块一样被经常使用。 dbm.dumb 模块提供了一个完全以 Python 编写的持久化字典类接口。 不同于 dbm.gnu 等其他模块，它不需要外部库。 与其他持久化映射一样，它的键和值也总是被存储为字节串。 该模块定义以下内容： exception dbm.dumb.error 针对 dbm.dumb 专属错误例如 I/O 错误引发。 KeyError 的引发则针对一般映射例如指定了不正确的键。 dbm.dumb.open(filename[, flag[, mode]]) 打开一个 dumbdbm 数据库并返回 dumbdbm 对象。 filename 参数为数据库文件的主名称（不带任何特定扩展名）。 创建一个 dumbdbm 数据库时将创建多个带有 .dat 和 .dir 扩展名的文件。可选的 flag 参数可以是： | 值 | 意义 || —– | —————————————- || &#39;r&#39; | 以只读方式打开现有数据库（默认） || &#39;w&#39; | 以读写方式打开现有数据库 || &#39;c&#39; | 以读写方式打开数据库，如果不存在则创建它 || &#39;n&#39; | 始终创建一个新的空数据库，以读写方式打开 | 可选的 mode 参数是文件的 Unix 模式，仅在要创建数据库时才会被使用。 其默认值为八进制数 0o666 (并将 被当前的 umask 所修改)。 在 3.5 版更改: open() 在 flag 值为 &#39;n&#39; 时将总是创建一个新的数据库。 在 3.8 版更改: 附带 &#39;r&#39; 旗标打开的数据库现在将是只读的。 附带 &#39;r&#39; 和 &#39;w&#39; 旗标的打开操作不会再创建数据库。 除了 collections.abc.MutableMapping 类所提供的方法，dumbdbm 对象还提供了以下方法： dumbdbm.sync() 同步磁盘上的目录和数据文件。 此方法会由 Shelve.sync() 方法来调用。 dumbdbm.close() 关闭 dumbdbm 数据库。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>dbm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library marshal]]></title>
    <url>%2F2020%2F02%2F16%2Fpython-standard-library-marshal%2F</url>
    <content type="text"><![CDATA[marshal — 内部 Python 对象序列化 每日一词： 否极泰来( pi ji tai lai): 否，读如痞(pǐ)又作“否极终泰”、“否去泰来”。天地相交，因而安泰。天与地不相交，叫做否。在这种情况下，君子应该收敛自己的才华，以避免小人陷害；不可追求荣誉富贵，以避免小人嫉妒。闭塞到了极点，则转向通泰。人们将这些观点概括为否极泰来或否极终泰。原指事物发展到一定程度，就要转化到它的对立面。后常以此形容情况从坏变好。 【出典】： 《易·泰》：“天地交，泰。”《易·否》：“天地不交，否；君子以俭德辟难，不可荣以禄。”《易·杂卦》：“否泰反其类也。” 【例句】： 《吴越春秋·句践入臣外传》：“时过于期，否终则泰。” 唐·白居易《遣怀诗》：“乐往必悲生，泰来犹否极。” 唐·韦庄《湘中作》：“否去泰来终可待。” 【英文】 after a storm comes a calm 【反义词】 乐极生悲 after joy comes sadness 此模块包含一此能以二进制格式来读写 Python 值的函数。 这种格式是 Python 专属的，但是独立于特定的机器架构（即你可以在一台 PC 上写入某个 Python 值，将文件传到一台 Sun 上并在那里读取它）。 这种格式的细节有意不带文档说明；它可能在不同 Python 版本中发生改变（但这种情况极少发生）。 1 这不是一个通用的“持久化”模块。 对于通用的持久化以及通过 RPC 调用传递 Python 对象，请参阅 pickle 和 shelve 等模块。 marshal 模块主要是为了支持读写 .pyc 文件形式“伪编译”代码的 Python 模块。 因此，Python 维护者保留在必要时以不向下兼容的方式修改 marshal 格式的权利。 如果你要序列化和反序列化 Python 对象，请改用 pickle 模块 – 其执行效率相当，版本独立性有保证，并且 pickle 还支持比 marshal 更多样的对象类型。 警告marshal 模块对于错误或恶意构建的数据来说是不安全的。 永远不要 unmarshal 来自不受信任的或未经验证的来源的数据。 不是所有 Python 对象类型都受支持；一般来说，此模块只能写入和读取不依赖于特定 Python 调用的对象。 下列类型是受支持的：布尔值、整数、浮点数、复数、字符串、字节串、字节数组、元组、列表、集合、冻结集合、字典和代码对象，需要了解的一点是元组、列表、集合、冻结集合和字典只在其所包含的值也是这些值时才受支持。 单例对象 None, Ellipsis and StopIteration 也可以被 marshal 和 unmarshal。 对于 version 低于 3 的格式，递归列表、集合和字典无法被写入（见下文）。 有些函数可以读/写文件，还有些函数可以操作字节类对象。 这个模块定义了以下函数： marshal.dump(value, file[, version]) 向打开的文件写入值。 值必须为受支持的类型。 文件必须为可写的 binary file。如果值具有（或所包含的对象具有）不受支持的类型，则会引发 ValueError — 但是将向文件写入垃圾数据。 对象也将不能正确地通过 load() 重新读取。version 参数指明 dump 应当使用的数据格式（见下文）。 marshal.load(file) 从打开的文件读取一个值并返回。 如果读不到有效的值（例如由于数据为不同 Python 版本的不兼容 marshal 格式），则会引发 EOFError, ValueError 或 TypeError。 文件必须为可读的 binary file。注解 如果通过 dump() marshal 了一个包含不受支持类型的对象，load() 将为不可 marshal 的类型替换 None。 marshal.dumps(value[, version]) 返回将通过 dump(value, file) 被写入一个文件的字节串对象。 值必须属于受支持的类型。 如果值属于（或包含的对象属于）不受支持的类型则会引发 ValueError。version 参数指明 dumps 应当使用的数据类型（见下文）。 marshal.loads(bytes) 将 bytes-like object 转换为一个值。 如果找不到有效的值，则会引发 EOFError, ValueError 或 TypeError。 输入的额外字节串会被忽略。 此外，还定义了以下常量： marshal.version 指明模块所使用的格式。 第 0 版为历史格式，第 1 版为共享固化的字符串，第 2 版对浮点数使用二进制格式。 第 3 版添加了对于对象实例化和递归的支持。 目前使用的为第 4 版。 例子12345678910111213141516171819202122232425262728import marshaldata1 = ['abc',12,23,'jb51'] #几个测试数据data2 = &#123;1:'aaa',"b":'dad'&#125;data3 = (1,2,4) output_file = open("a.txt",'wb')#把这些数据序列化到文件中，注：文件必须以二进制模式打开marshal.dump(data1,output_file)marshal.dump(data2,output_file)marshal.dump(data3,output_file)output_file.close() input_file = open('a.txt','rb')#从文件中读取序列化的数据#data1 = []data1 = marshal.load(input_file)data2 = marshal.load(input_file)data3 = marshal.load(input_file)print data1#给同志们打印出结果看看print data2print data3 outstring = marshal.dumps(data1)#marshal.dumps()返回是一个字节串，该字节串用于写入文件open('out.txt','wb').write(outstring) file_data = open('out.txt','rb').read()real_data = marshal.loads(file_data)print(real_data)]]></content>
  </entry>
  <entry>
    <title><![CDATA[python standard library os.path]]></title>
    <url>%2F2020%2F02%2F15%2Fpython-standard-library-os-path%2F</url>
    <content type="text"><![CDATA[python 标准库 os.path 每日一词 retrograde [ˈrɛtrəɡreɪd] v directed or moving backwards. n retrograder 逆行者 倒行；不按正常方向行进。《孟子·滕文公下》：“当 尧 之时，水逆行，氾滥於中国。”《史记·孝景本纪》：“彗星出东北。秋， 衡山 雨雹，大者五寸，深者二尺。荧惑逆行，守北辰。”《后汉书·杨震传》：“ 丰 等闻，惶怖，会太史言星变逆行，遂共譖 震 。” 指逆流而行。 源码源代码： Lib/posixpath.py （用于 POSIX）和 Lib/ntpath.py （用于 Windows NT） 该模块在路径名上实现了一些有用的功能：如需读取或写入文件，请参见 open() ；有关访问文件系统的信息，请参见 os 模块。路径参数可以字符串或字节形式传递。我们鼓励应用程序将文件名表示为（Unicode）字符串。不幸的是，某些文件名在Unix上可能无法用字符串表示，因此在Unix上平台上需要支持任意文件名的应用程序，应使用字节对象来表示路径名。反之亦然，在Windows平台上仅使用字节对象，不能表示的所有文件名（以标准 mbcs 编码），因此Windows应用程序应使用字符串对象来访问所有文件。 与unix shell不同，Python不执行任何 自动 路径扩展。当应用程序需要类似shell的路径扩展时，可以显式调用诸如 expanduser() 和 expandvars() 之类的函数。 （另请参见 glob 模块。） 参见 pathlib 模块提供高级路径对象。 所有这些函数都仅接受字节或字符串对象作为其参数。如果返回路径或文件名，则结果是相同类型的对象。 由于不同的操作系统具有不同的路径名称约定，因此标准库中有此模块的几个版本。os.path 模块始终是适合 Python 运行的操作系统的路径模块，因此可用于本地路径。但是，如果操作的路径 总是 以一种不同的格式显示，那么也可以分别导入和使用各个模块。它们都具有相同的接口： posixpath 用于Unix 样式的路径 ntpath 用于 Windows 路径 在 3.8 版更改: exists()、lexists()、isdir()、isfile()、islink() 和 ismount() 现在遇到系统层面上不可表示的字符或字节的路径时，会返回 False，而不是抛出异常。 os.path.abspath(path) 返回路径 path 的绝对路径（标准化的）。在大多数平台上，这等同于用 normpath(join(os.getcwd(), path)) 的方式调用 normpath() 函数。在 3.6 版更改: 接受一个 类路径对象。 os.path.basename(path) 返回路径 path 的基本名称。这是将 path 传入函数 split() 之后，返回的一对值中的第二个元素。请注意，此函数的结果与Unix basename 程序不同。basename 在 &#39;/foo/bar/&#39; 上返回 &#39;bar&#39;，而 basename() 函数返回一个空字符串 (&#39;&#39;)。在 3.6 版更改: 接受一个 类路径对象。 os.path.commonpath(paths) 接受包含多个路径的序列 paths，返回 paths 的最长公共子路径。如果 paths 同时包含绝对路径和相对路径，或 paths 在不同的驱动器上，或 paths 为空，则抛出 ValueError 异常。与 commonprefix() 不同，本方法返回有效路径。可用性: Unix, Windows。3.5 新版功能.**在 3.6 版更改: 接受一个 类路径对象 序列。 os.path.commonprefix(list) 接受包含多个路径的 列表，返回所有路径的最长公共前缀（逐字符比较）。如果 列表 为空，则返回空字符串 (&#39;&#39;)。 此函数是逐字符比较，因此可能返回无效路径。要获取有效路径，参见 commonpath()。 12345&gt;&gt;&gt; os.path.commonprefix(['/usr/lib', '/usr/local/lib'])'/usr/l'&gt;&gt;&gt; os.path.commonpath(['/usr/lib', '/usr/local/lib'])'/usr' 在 3.6 版更改: 接受一个 类路径对象。 os.path.dirname(path) 返回路径 path 的目录名称。这是将 path 传入函数 split() 之后，返回的一对值中的第一个元素。在 3.6 版更改: 接受一个 类路径对象。 os.path.exists(path) 如果 path 指向一个已存在的路径或已打开的文件描述符，返回 True。对于失效的符号链接，返回 False。在某些平台上，如果使用 os.stat() 查询到目标文件没有执行权限，即使 path 确实存在，本函数也可能返回 False。在 3.3 版更改: path 现在可以是一个整数：如果该整数是一个已打开的文件描述符，返回 True，否则返回 False。 在 3.6 版更改: 接受一个 类路径对象。 os.path.lexists(path) 如果 path 指向一个已存在的路径，返回 True。对于失效的符号链接，也返回 True。在缺失 os.lstat() 的平台上等同于 exists()。 在 3.6 版更改: 接受一个 类路径对象。 os.path.expanduser(path) 在 Unix 和 Windows 上，将参数中开头部分的 ~ 或 ~user 替换为当前 用户 的家目录并返回。在 Unix 上，开头的 ~ 会被环境变量 HOME 代替，如果变量未设置，则通过内置模块 pwd 在 password 目录中查找当前用户的主目录。以 ~user 开头则直接在 password 目录中查找。在 Windows 上，如果设置了 USERPROFILE，就使用这个变量，否则会将 HOMEPATH 和 HOMEDRIVE 结合在一起使用。以 ~user 开头则将上述方法生成路径的最后一截目录替换成 user。如果展开路径失败，或者路径不是以波浪号开头，则路径将保持不变。在 3.6 版更改: 接受一个 类路径对象。 在 3.8 版更改: Windows 不再使用 HOME。 os.path.expandvars(path) 输入带有环境变量的路径作为参数，返回展开变量以后的路径。$name 或 ${name} 形式的子字符串被环境变量 name 的值替换。格式错误的变量名称和对不存在变量的引用保持不变。在 Windows 上，除了 $name 和 ${name} 外，还可以展开 %name%。 在 3.6 版更改: 接受一个 类路径对象。 os.path.getatime(path) 返回 path 的最后访问时间。返回值是一个浮点数，为纪元秒数（参见 time 模块）。如果该文件不存在或不可访问，则抛出 OSError 异常。 os.path.getmtime(path) 返回 path 的最后修改时间。返回值是一个浮点数，为纪元秒数（参见 time 模块）。如果该文件不存在或不可访问，则抛出 OSError 异常。 在 3.6 版更改: 接受一个 类路径对象。 os.path.getctime(path) 返回 path 在系统中的 ctime，在有些系统（比如 Unix）上，它是元数据的最后修改时间，其他系统（比如 Windows）上，它是 path 的创建时间。返回值是一个数，为纪元秒数（参见 time 模块）。如果该文件不存在或不可访问，则抛出 OSError 异常。 在 3.6 版更改: 接受一个 类路径对象。 os.path.getsize(path) 返回 path 的大小，以字节为单位。如果该文件不存在或不可访问，则抛出 OSError 异常。 在 3.6 版更改: 接受一个 类路径对象。 os.path.isabs(path) 如果 path 是一个绝对路径，则返回 True。在 Unix 上，它就是以斜杠开头，而在 Windows 上，它可以是去掉驱动器号后以斜杠（或反斜杠）开头。 在 3.6 版更改: 接受一个 类路径对象。 os.path.isfile(path) 如果 path 是 现有的 常规文件，则返回 True。本方法会跟踪符号链接，因此，对于同一路径，islink() 和 isfile() 都可能为 True。 在 3.6 版更改: 接受一个 类路径对象。 os.path.isdir(path) 如果 path 是 现有的 目录，则返回 True。本方法会跟踪符号链接，因此，对于同一路径，islink() 和 isdir() 都可能为 True。在 3.6 版更改: 接受一个 类路径对象。 os.path.islink(path) 如果 path 指向的 现有 目录条目是一个符号链接，则返回 True。如果 Python 运行时不支持符号链接，则总是返回 False。 在 3.6 版更改: 接受一个 类路径对象。 os.path.ismount(path) 如果路径 path 是 挂载点 （文件系统中挂载其他文件系统的点），则返回 True。在 POSIX 上，该函数检查 path 的父目录 *path*/.. 是否在与 path 不同的设备上，或者 *path*/.. 和 path 是否指向同一设备上的同一 inode（这一检测挂载点的方法适用于所有 Unix 和 POSIX 变体）。本方法不能可靠地检测同一文件系统上的绑定挂载 (bind mount)。在 Windows 上，盘符和共享 UNC 始终是挂载点，对于任何其他路径，将调用 GetVolumePathName 来查看它是否与输入的路径不同。3.4 新版功能: 支持在 Windows 上检测非根挂载点。在 3.6 版更改: 接受一个 类路径对象。 os.path.join(path, *paths) 合理地拼接一个或多个路径部分。返回值是 path 和 *paths 所有值的连接，每个非空部分后面都紧跟一个目录分隔符 (os.sep)，除了最后一部分。这意味着如果最后一部分为空，则结果将以分隔符结尾。如果参数中某个部分是绝对路径，则绝对路径前的路径都将被丢弃，并从绝对路径部分开始连接。在 Windows 上，遇到绝对路径部分（例如 r&#39;\foo&#39;）时，不会重置盘符。如果某部分路径包含盘符，则会丢弃所有先前的部分，并重置盘符。请注意，由于每个驱动器都有一个“当前目录”，所以 os.path.join(&quot;c:&quot;, &quot;foo&quot;) 表示驱动器 C: 上当前目录的相对路径 (c:foo)，而不是 c:\foo。 在 3.6 版更改: 接受一个 类路径对象 用于 path 和 paths 。 os.path.normcase(path) 规范路径的大小写。在 Windows 上，将路径中的所有字符都转换为小写，并将正斜杠转换为反斜杠。在其他操作系统上返回原路径。 在 3.6 版更改: 接受一个 类路径对象。 os.path.normpath(path) 通过折叠多余的分隔符和对上级目录的引用来标准化路径名，所以 A//B、A/B/、A/./B 和 A/foo/../B 都会转换成 A/B。这个字符串操作可能会改变带有符号链接的路径的含义。在 Windows 上，本方法将正斜杠转换为反斜杠。要规范大小写，请使用 normcase()。 在 3.6 版更改: 接受一个 类路径对象。 os.path.realpath(path) 返回指定文件的规范路径，消除路径中存在的任何符号链接（如果操作系统支持）。注解 当发生符号链接循环时，返回的路径将是该循环的某个组成部分，但不能保证是哪个部分。在 3.6 版更改: 接受一个 类路径对象。 在 3.8 版更改: 在 Windows 上现在可以正确解析符号链接和交接点 (junction point)。 os.path.relpath(path, start=os.curdir) 返回从当前目录或 start 目录（可选）到达 path 之间要经过的相对路径。这仅仅是对路径的计算，不会访问文件系统来确认 path 或 start 的存在性或属性。start 默认为 os.curdir。可用性: Unix, Windows。 在 3.6 版更改: 接受一个 类路径对象。 os.path.samefile(path1, path2) 如果两个路径都指向相同的文件或目录，则返回 True。这由设备号和 inode 号确定，在任一路径上调用 os.stat() 失败则抛出异常。可用性: Unix, Windows。在 3.2 版更改: 添加了 Windows 支持。在 3.4 版更改: Windows现在使用与其他所有平台相同的实现。 在 3.6 版更改: 接受一个 类路径对象。 os.path.sameopenfile(fp1, fp2) 如果文件描述符 fp1 和 fp2 指向相同文件，则返回 True。可用性: Unix, Windows。在 3.2 版更改: 添加了 Windows 支持。 在 3.6 版更改: 接受一个 类路径对象。 os.path.samestat(stat1, stat2) 如果 stat 元组 stat1 和 stat2 指向相同文件，则返回 True。这些 stat 元组可能是由 os.fstat()、os.lstat() 或 os.stat() 返回的。本函数实现了 samefile() 和 sameopenfile() 底层所使用的比较过程。可用性: Unix, Windows。在 3.4 版更改: 添加了 Windows 支持。 在 3.6 版更改: 接受一个 类路径对象。 os.path.split(path) 将路径 path 拆分为一对，即 (head, tail)，其中，tail 是路径的最后一部分，而 head 里是除最后部分外的所有内容。tail 部分不会包含斜杠，如果 path 以斜杠结尾，则 tail 将为空。如果 path 中没有斜杠，head 将为空。如果 path 为空，则 head 和 tail 均为空。head 末尾的斜杠会被去掉，除非它是根目录（即它仅包含一个或多个斜杠）。在所有情况下，join(head, tail) 指向的位置都与 path 相同（但字符串可能不同）。另请参见函数 dirname() 和 basename()。 在 3.6 版更改: 接受一个 类路径对象。 os.path.splitdrive(path) 将路径 path 拆分为一对，即 (drive, tail)，其中 drive 是挂载点或空字符串。在没有驱动器概念的系统上，drive 将始终为空字符串。在所有情况下，drive + tail 都与 path 相同。在 Windows 上，本方法将路径拆分为驱动器/UNC 根节点和相对路径。如果路径 path 包含盘符，则 drive 将包含冒号及冒号前面的所有内容。例如 splitdrive(&quot;c:/dir&quot;) 返回 (&quot;c:&quot;, &quot;/dir&quot;)。如果 path 是一个 UNC 路径，则 drive 将包含主机名和共享点，但不包括第四个分隔符。例如 splitdrive(&quot;//host/computer/dir&quot;) 返回 (&quot;//host/computer&quot;, &quot;/dir&quot;)。 在 3.6 版更改: 接受一个 类路径对象。 os.path.splitext(path) 将路径 path 拆分为一对，即 (root, ext)，使 root + ext == path，其中 ext 为空或以英文句点开头，且最多包含一个句点。路径前的句点将被忽略，例如 splitext(&#39;.cshrc&#39;) 返回 (&#39;.cshrc&#39;, &#39;&#39;)。 在 3.6 版更改: 接受一个 类路径对象。 os.path.supports_unicode_filenames 如果（在文件系统限制下）允许将任意 Unicode 字符串用作文件名，则为 True。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>os.path</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library linecache]]></title>
    <url>%2F2020%2F02%2F14%2Fpython-standard-library-linecache%2F</url>
    <content type="text"><![CDATA[情人节快乐，愿有情人终成眷属! 源代码: Lib/linecache.py linecache 模块允许从一个 Python 源文件中获取任意的行，并会尝试使用缓存进行内部优化，常应用于从单个文件读取多行的场合。 此模块被 traceback 模块用来提取源码行以便包含在格式化的回溯中。 tokenize.open() 函数被用于打开文件。 此函数使用 tokenize.detect_encoding() 来获取文件的编码格式；如果未指明编码格式，则默认编码为 UTF-8。 linecache 模块定义了下列函数： linecache.getline(filename, lineno, module_globals=None) 从名为 filename 的文件中获取 lineno 行，此函数绝不会引发异常 — 出现错误时它将返回 &#39;&#39; (所有找到的行都将包含换行符作为结束)。如果找不到名为 filename 的文件，此函数会先在 module_globals 中检查 PEP 302 __loader__。 如果存在这样的加载器并且它定义了 get_source 方法，则由该方法来确定源行 (如果 get_source() 返回 None，则该函数返回 &#39;&#39;)。 最后，如果 filename 是一个相对路径文件名，则它会在模块搜索路径 sys.path 中按条目的相对位置进行查找。 linecache.clearcache() 清空缓存。 如果你不再需要之前使用 getline() 从文件读取的行即可使用此函数。 linecache.checkcache(filename=None) 检查缓存有效性。 如果缓存中的文件在磁盘上发生了改变，而你需要更新后的版本即可使用此函数。 如果省略了 filename，它会检查缓存中的所有条目。 linecache.lazycache(filename, module_globals) 捕获有关某个非基于文件的模块的足够细节信息，以允许稍后再通过 getline() 来获取其中的行，即使当稍后调用时 module_globals 为 None。 这可以避免在实际需要读取行之前执行 I/O，也不必始终保持模块全局变量。3.5 新版功能. 示例: 123&gt;&gt;&gt; import linecache&gt;&gt;&gt; linecache.getline(linecache.__file__, 8)'import sys\n' 1234567import linecache## 获取指定前四条数据a = linecache.getlines('aa.txt')[0:3]print(a)## 获取第四条数据a = linecache.getline('aa.txt',4)print(a)]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>linecache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library tempfile]]></title>
    <url>%2F2020%2F02%2F13%2Fpython-standard-library-tempfile%2F</url>
    <content type="text"><![CDATA[python 标准库 tempfile 源代码： Lib/tempfile.py 该模块用于创建临时文件和目录，它可以跨平台使用。TemporaryFile、NamedTemporaryFile、TemporaryDirectory 和 SpooledTemporaryFile 是带有自动清理功能的高级接口，可用作上下文管理器。mkstemp() 和 mkdtemp() 是低级函数，使用完毕需手动清理。 所有由用户调用的函数和构造函数都带有参数，这些参数可以设置临时文件和临时目录的路径和名称。该模块生成的文件名包括一串随机字符，在公共的临时目录中，这些字符可以让创建文件更加安全。为了保持向后兼容性，参数的顺序有些奇怪。所以为了代码清晰，建议使用关键字参数。 这个模块定义了以下内容供用户调用： tempfile.TemporaryFile(mode=’w+b’, buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, **, errors=None*) 返回一个 file-like object （文件类对象）作为临时存储区域。创建该文件使用了与 mkstemp() 相同的安全规则。它将在关闭后立即销毁（包括垃圾回收机制关闭该对象时）。在 Unix 下，该文件在目录中的条目根本不创建，或者创建文件后立即就被删除了，其他平台不支持此功能。您的代码不应依赖使用此功能创建的临时文件名称，因为它在文件系统中的名称可能是可见的，也可能是不可见的。 生成的对象可以用作上下文管理器（参见 示例）。完成上下文或销毁临时文件对象后，临时文件将从文件系统中删除。 mode 参数默认值为 &#39;w+b&#39;，所以创建的文件不用关闭，就可以读取或写入。因为用的是二进制模式，所以无论存的是什么数据，它在所有平台上都表现一致。buffering、encoding、errors 和 newline 的含义与 open() 中的相同。 参数 dir、prefix 和 suffix 的含义和默认值都与它们在 mkstemp() 中的相同。 在 POSIX 平台上，它返回的对象是真实的文件对象。在其他平台上，它是一个文件类对象 (file-like object)，它的 file 属性是底层的真实文件对象。 如果可用，则使用 os.O_TMPFILE 标志（仅限于 Linux，需要 3.11 及更高版本的内核）。 引发一个 tempfile.mkstemp 审计事件，附带参数 fullpath。 在 3.5 版更改: 如果可用，现在用的是 os.O_TMPFILE 标志。 在 3.8 版更改: 添加了 errors 参数。 tempfile.NamedTemporaryFile(mode=’w+b’, buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, delete=True, **, errors=None*) 此函数执行的操作与 TemporaryFile() 完全相同，但确保了该临时文件在文件系统中具有可见的名称（在 Unix 上表现为目录条目不取消链接）。从返回的文件类对象的 name 属性中可以检索到文件名。在临时文件仍打开时，是否允许用文件名第二次打开文件，在各个平台上是不同的（在 Unix 上可以，但在 Windows NT 或更高版本上不行）。如果 delete 为 true（默认值），则文件会在关闭后立即被删除。该函数返回的对象始终是文件类对象 (file-like object)，它的 file 属性是底层的真实文件对象。文件类对象可以像普通文件一样在 with 语句中使用。 引发一个 tempfile.mkstemp 审计事件，附带参数 fullpath。 在 3.8 版更改: 添加了 errors 参数。 tempfile.SpooledTemporaryFile(max_size=0, mode=’w+b’, buffering=None, encoding=None, newline=None, suffix=None, prefix=None, dir=None, **, errors=None*) 此函数执行的操作与 TemporaryFile() 完全相同，但会将数据缓存在内存中，直到文件大小超过 max_size，或调用文件的 fileno() 方法为止，此时数据会被写入磁盘，并且写入操作与 TemporaryFile() 相同。 此函数生成的文件对象有一个额外的方法——rollover()，可以忽略文件大小，让文件立即写入磁盘。 返回的对象是文件类对象 (file-like object)，它的 _file 属性是 io.BytesIO 或 io.TextIOWrapper 对象（取决于指定的是二进制模式还是文本模式）或真实的文件对象（取决于是否已调用 rollover()）。文件类对象可以像普通文件一样在 with 语句中使用。 在 3.3 版更改: 现在，文件的 truncate 方法可接受一个 size 参数。 在 3.8 版更改: 添加了 errors 参数。 tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None) 此函数会安全地创建一个临时目录，且使用与 mkdtemp() 相同的规则。此函数返回的对象可用作上下文管理器（参见 示例）。完成上下文或销毁临时目录对象后，新创建的临时目录及其所有内容将从文件系统中删除。 可以从返回对象的 name 属性中找到临时目录的名称。当返回的对象用作上下文管理器时，这个 name 会作为 with 语句中 as 子句的目标（如果有 as 的话）。 可以调用 cleanup() 方法来手动清理目录。 引发一个 tempfile.mkdtemp 审计事件，附带参数 fullpath。 3.2 新版功能. tempfile.mkstemp(suffix=None, prefix=None, dir=None, text=False) 以最安全的方式创建一个临时文件。假设所在平台正确实现了 os.open() 的 os.O_EXCL 标志，则创建文件时不会有竞争的情况。该文件只能由创建者读写，如果所在平台用权限位来标记文件是否可执行，那么没有人有执行权。文件描述符不会过继给子进程。 与 TemporaryFile() 不同，mkstemp() 用户用完临时文件后需要自行将其删除。 如果 suffix 不是 None 则文件名将以该后缀结尾，是 None 则没有后缀。mkstemp() 不会在文件名和后缀之间加点，如果需要加一个点号，请将其放在 suffix 的开头。 如果 prefix 不是 None，则文件名将以该前缀开头，是 None 则使用默认前缀。默认前缀是 gettempprefix() 或 gettempprefixb() 函数的返回值（自动调用合适的函数）。 如果 dir 不为 None，则在指定的目录创建文件，是 None 则使用默认目录。默认目录是从一个列表中选择出来的，这个列表不同平台不一样，但是用户可以设置 TMPDIR、TEMP 或 TMP 环境变量来设置目录的位置。因此，不能保证生成的临时文件路径很规范，比如，通过 os.popen() 将路径传递给外部命令时仍需要加引号。 如果 suffix、prefix 和 dir 中的任何一个不是 None，就要保证它们是同一数据类型。如果它们是 bytes，则返回的名称的类型就是 bytes 而不是 str。如果确实要用默认参数，但又想要返回值是 bytes 类型，请传入 suffix=b&#39;&#39;。 如果指定了 text 参数，它表示的是以二进制模式（默认）还是文本模式打开文件。在某些平台上，两种模式没有区别。 mkstemp() 返回一个元组，元组中第一个元素是句柄，它是一个系统级句柄，指向一个打开的文件（等同于 os.open() 的返回值），第二元素是该文件的绝对路径。 引发一个 tempfile.mkstemp 审计事件，附带参数 fullpath。 在 3.5 版更改: 现在，suffix、prefix 和 dir 可以以 bytes 类型按顺序提供，以获得 bytes 类型的返回值。之前只允许使用 str。suffix 和 prefix 现在可以接受 None，并且默认为 None 以使用合适的默认值。 在 3.6 版更改: dir 参数现在可接受一个路径类对象 (path-like object)。 tempfile.mkdtemp(suffix=None, prefix=None, dir=None) 以最安全的方式创建一个临时目录，创建该目录时不会有竞争的情况。该目录只能由创建者读取、写入和搜索。 mkdtemp() 用户用完临时目录后需要自行将其删除。 prefix、suffix 和 dir 的含义与它们在 mkstemp() 中的相同。 mkdtemp() 返回新目录的绝对路径。 引发一个 tempfile.mkdtemp 审计事件，附带参数 fullpath。 在 3.5 版更改: 现在，suffix、prefix 和 dir 可以以 bytes 类型按顺序提供，以获得 bytes 类型的返回值。之前只允许使用 str。suffix 和 prefix 现在可以接受 None，并且默认为 None 以使用合适的默认值。 在 3.6 版更改: dir 参数现在可接受一个路径类对象 (path-like object)。 tempfile.gettempdir() 返回放置临时文件的目录的名称。这个方法的返回值就是本模块所有函数的 dir 参数的默认值。 Python 搜索标准目录列表，以找到调用者可以在其中创建文件的目录。这个列表是： TMPDIR 环境变量指向的目录。 TEMP 环境变量指向的目录。 TMP 环境变量指向的目录。 与平台相关的位置： 在 Windows 上，依次为 C:\TEMP、C:\TMP、\TEMP 和 \TMP。 在所有其他平台上，依次为 /tmp、/var/tmp 和 /usr/tmp。 不得已时，使用当前工作目录。 搜索的结果会缓存起来，参见下面 tempdir 的描述。 tempfile.gettempdirb() 与 gettempdir() 相同，但返回值为字节类型。3.5 新版功能. tempfile.gettempprefix() 返回用于创建临时文件的文件名前缀，它不包含目录部分。 tempfile.gettempprefixb() 与 gettempprefix() 相同，但返回值为字节类型。3.5 新版功能. 本模块使用一个全局变量来存储由 gettempdir() 返回的临时文件目录路径。可以直接给它赋值，这样可以覆盖自动选择的路径，但是不建议这样做。本模块中的所有函数都带有一个 dir 参数，该参数可用于指定目录，这是推荐的方法。 tempfile.tempdir 当设置为 None 以外的其他值时，此变量将决定本模块所有函数的 dir 参数的默认值。如果在调用除 gettempprefix() 外的上述任何函数时 tempdir 为 None (默认值) 则它会按照 gettempdir() 中所描述的算法来初始化。 示例以下是 tempfile 模块典型用法的一些示例: 1234567891011121314151617181920212223242526&gt;&gt;&gt; import tempfile# create a temporary file and write some data to it&gt;&gt;&gt; fp = tempfile.TemporaryFile()&gt;&gt;&gt; fp.write(b'Hello world!')# read data from file&gt;&gt;&gt; fp.seek(0)&gt;&gt;&gt; fp.read()b'Hello world!'# close the file, it will be removed&gt;&gt;&gt; fp.close()# create a temporary file using a context manager&gt;&gt;&gt; with tempfile.TemporaryFile() as fp:... fp.write(b'Hello world!')... fp.seek(0)... fp.read()b'Hello world!'&gt;&gt;&gt;# file is now closed and removed# create a temporary directory using the context manager&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdirname:... print('created temporary directory', tmpdirname)&gt;&gt;&gt;# directory and contents have been removed 已弃用的函数和变量创建临时文件有一种历史方法，首先使用 mktemp() 函数生成一个文件名，然后使用该文件名创建文件。不幸的是，这是不安全的，因为在调用 mktemp() 与随后尝试创建文件的进程之间的时间里，其他进程可能会使用该名称创建文件。解决方案是将两个步骤结合起来，立即创建文件。这个方案目前被 mkstemp() 和上述其他函数所采用。 tempfile.mktemp(suffix=’’, prefix=’tmp’, dir=None) 2.3 版后已移除: 使用 mkstemp() 来代替。返回一个绝对路径，这个路径指向的文件在调用本方法时不存在。prefix、suffix 和 dir 参数与 mkstemp() 中的同名参数类似，不同之处在于不支持字节类型的文件名，不支持 suffix=None 和 prefix=None。 使用此功能可能会在程序中引入安全漏洞。当你开始使用本方法返回的文件执行任何操作时，可能有人已经捷足先登了。mktemp() 的功能可以很轻松地用 NamedTemporaryFile() 代替，当然需要传递 delete=False 参数: 123456789&gt;&gt;&gt; f = NamedTemporaryFile(delete=False)&gt;&gt;&gt; f.name'/tmp/tmptjujjt'&gt;&gt;&gt; f.write(b"Hello World!\n")13&gt;&gt;&gt; f.close()&gt;&gt;&gt; os.unlink(f.name)&gt;&gt;&gt; os.path.exists(f.name)False]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>tempfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library coroutines]]></title>
    <url>%2F2020%2F02%2F12%2Fpython-standard-library-coroutines%2F</url>
    <content type="text"><![CDATA[python 标准库 coroutines 协程 协程 Coroutines declared with the async/await syntax is the preferred way of writing asyncio applications. For example, the following snippet of code (requires Python 3.7+) prints “hello”, waits 1 second, and then prints “world”: Coroutines 通过 async/await 语法声明是编写异步应用程序的首选方式。例如下面的语法片段(需要Python 3.7+),我们实现了等待一秒,打印’’world“的功能。 12345678910&gt;&gt;&gt; import asyncio&gt;&gt;&gt; async def main():... print('hello')... await asyncio.sleep(1)... print('world')&gt;&gt;&gt; asyncio.run(main())helloworld 注意：简单地调用一个协程并不会将其加入执行日程: 12&gt;&gt;&gt; main()&lt;coroutine object main at 0x1053bb7c8&gt; 要真正运行一个协程，asyncio 提供了三种主要机制: asyncio.run() 函数用来运行最高层级的入口点 “main()” 函数 (参见上面的示例。) 等待一个协程。以下代码段会在等待 1 秒后打印 “hello”，然后 再次 等待 2 秒后打印 “world”: 12345678910111213141516import asyncioimport timeasync def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): print(f"started at &#123;time.strftime('%X')&#125;") await say_after(1, 'hello') await say_after(2, 'world') print(f"finished at &#123;time.strftime('%X')&#125;")asyncio.run(main()) 预期的输出: 1234started at 17:13:52helloworldfinished at 17:13:55 asyncio.create_task() 函数用来并发运行作为 asyncio 任务 的多个协程。 让我们修改以上示例，并发 运行两个 say_after 协程: 123456789101112131415async def main(): task1 = asyncio.create_task( say_after(1, 'hello')) task2 = asyncio.create_task( say_after(2, 'world')) print(f"started at &#123;time.strftime('%X')&#125;") # Wait until both tasks are completed (should take # around 2 seconds.) await task1 await task2 print(f"finished at &#123;time.strftime('%X')&#125;") 注意，预期的输出显示代码段的运行时间比之前快了 1 秒: 1234started at 17:14:32helloworldfinished at 17:14:34 可等待对象如果一个对象可以在 await 语句中使用，那么它就是 可等待 对象。许多 asyncio API 都被设计为接受可等待对象。 可等待 对象有三种主要类型: 协程, 任务 和 Future. 协程 Python 协程属于 可等待 对象，因此可以在其他协程中被等待: 123456789101112131415import asyncioasync def nested(): return 42async def main(): # Nothing happens if we just call "nested()". # A coroutine object is created but not awaited, # so it *won't run at all*. nested() # Let's do it differently now and await it: print(await nested()) # will print "42".asyncio.run(main()) 重要 在本文档中 “协程” 可用来表示两个紧密关联的概念: 协程函数: 定义形式为 async def 的函数; 协程对象: 调用 协程函数 所返回的对象。 asyncio 也支持旧式的 基于生成器的 协程。 任务 任务 被用来设置日程以便 并发 执行协程。 当一个协程通过 asyncio.create_task() 等函数被打包为一个 任务，该协程将自动排入日程准备立即运行: 123456789101112131415import asyncioasync def nested(): return 42async def main(): # Schedule nested() to run soon concurrently # with "main()". task = asyncio.create_task(nested()) # "task" can now be used to cancel "nested()", or # can simply be awaited to wait until it is complete: await taskasyncio.run(main()) Future 对象 Future 是一种特殊的 低层级 可等待对象，表示一个异步操作的 最终结果。 当一个 Future 对象 被等待，这意味着协程将保持等待直到该 Future 对象在其他地方操作完毕。 在 asyncio 中需要 Future 对象以便允许通过 async/await 使用基于回调的代码。 通常情况下 没有必要 在应用层级的代码中创建 Future 对象。 Future 对象有时会由库和某些 asyncio API 暴露给用户，用作可等待对象: 12345678async def main(): await function_that_returns_a_future_object() # this is also valid: await asyncio.gather( function_that_returns_a_future_object(), some_python_coroutine() ) 一个很好的返回对象的低层级函数的示例是 loop.run_in_executor()。 运行 asyncio 程序 asyncio.run(coro, **, debug=False*) 执行 coroutine coro 并返回结果。 此函数运行传入的协程，负责管理 asyncio 事件循环并 完结异步生成器。 当有其他 asyncio 事件循环在同一线程中运行时，此函数不能被调用。 如果 debug 为 True，事件循环将以调试模式运行。 此函数总是会创建一个新的事件循环并在结束时关闭之。它应当被用作 asyncio 程序的主入口点，理想情况下应当只被调用一次。 示例: 12345async def main(): await asyncio.sleep(1) print('hello')asyncio.run(main()) 3.7 新版功能. asyncio.run()源代码请移步至 Lib/asyncio/runners.py. 创建任务 asyncio.create_task(coro, **, name=None*) 将 coro 协程 打包为一个 Task 排入日程准备执行。返回 Task 对象。 If name is not None, it is set as the name of the task using Task.set_name(). 该任务会在 get_running_loop() 返回的循环中执行，如果当前线程没有在运行的循环则会引发 RuntimeError。 此函数 在 Python 3.7 中被加入。在 Python 3.7 之前，可以改用低层级的 asyncio.ensure_future() 函数。 12345678910async def coro(): ...# In Python 3.7+task = asyncio.create_task(coro())...# This works in all Python versions but is less readabletask = asyncio.ensure_future(coro())... 3.7 新版功能. 在 3.8 版更改: Added the name parameter. 休眠 coroutine asyncio.sleep(delay, result=None, **, loop=None*) 阻塞 delay 指定的秒数。 如果指定了 result，则当协程完成时将其返回给调用者。 sleep() 总是会挂起当前任务，以允许其他任务运行。 Deprecated since version 3.8, will be removed in version 3.10: loop 形参。 以下协程示例运行 5 秒，每秒显示一次当前日期: 12345678910111213import asyncioimport datetimeasync def display_date(): loop = asyncio.get_running_loop() end_time = loop.time() + 5.0 while True: print(datetime.datetime.now()) if (loop.time() + 1.0) &gt;= end_time: break await asyncio.sleep(1)asyncio.run(display_date()) 并发运行任务 awaitable asyncio.gather(*aws, loop=None, return_exceptions=False) 并发 运行 aws 序列中的 可等待对象。 如果 aws 中的某个可等待对象为协程，它将自动作为一个任务加入日程。 如果所有可等待对象都成功完成，结果将是一个由所有返回值聚合而成的列表。结果值的顺序与 aws 中可等待对象的顺序一致。 如果 return_exceptions 为 False (默认)，所引发的首个异常会立即传播给等待 gather() 的任务。aws 序列中的其他可等待对象 不会被取消 并将继续运行。 如果 return_exceptions 为 True，异常会和成功的结果一样处理，并聚合至结果列表。 如果 gather() 被取消，所有被提交 (尚未完成) 的可等待对象也会 被取消。 如果 aws 序列中的任一 Task 或 Future 对象 被取消，它将被当作引发了 CancelledError 一样处理 – 在此情况下 gather() 调用 不会 被取消。这是为了防止一个已提交的 Task/Future 被取消导致其他 Tasks/Future 也被取消。 Deprecated since version 3.8, will be removed in version 3.10: loop 形参。 示例: 12345678910111213141516171819202122232425262728293031import asyncioasync def factorial(name, number): f = 1 for i in range(2, number + 1): print(f"Task &#123;name&#125;: Compute factorial(&#123;i&#125;)...") await asyncio.sleep(1) f *= i print(f"Task &#123;name&#125;: factorial(&#123;number&#125;) = &#123;f&#125;")async def main(): # Schedule three calls *concurrently*: await asyncio.gather( factorial("A", 2), factorial("B", 3), factorial("C", 4), )asyncio.run(main())# Expected output:## Task A: Compute factorial(2)...# Task B: Compute factorial(2)...# Task C: Compute factorial(2)...# Task A: factorial(2) = 2# Task B: Compute factorial(3)...# Task C: Compute factorial(3)...# Task B: factorial(3) = 6# Task C: Compute factorial(4)...# Task C: factorial(4) = 24 在 3.7 版更改: 如果 gather 本身被取消，则无论 return_exceptions 取值为何，消息都会被传播。 屏蔽取消操作 awaitable asyncio.shield(aw, **, loop=None*) 保护一个 可等待对象 防止其被 取消。 如果 aw 是一个协程，它将自动作为任务加入日程。 以下语句: 1res = await shield(something()) 相当于: 1res = await something() 不同之处 在于如果包含它的协程被取消，在 something() 中运行的任务不会被取消。从 something() 的角度看来，取消操作并没有发生。然而其调用者已被取消，因此 “await” 表达式仍然会引发 CancelledError。 如果通过其他方式取消 something() (例如在其内部操作) 则 shield() 也会取消。 如果希望完全忽略取消操作 (不推荐) 则 shield() 函数需要配合一个 try/except 代码段，如下所示: 1234try: res = await shield(something())except CancelledError: res = None 从 3.8版本加入，将于 3.10版本移除loop 形参。 超时 coroutine asyncio.wait_for(aw, timeout, **, loop=None*) 等待 aw 可等待对象 完成，指定 timeout 秒数后超时。 如果 aw 是一个协程，它将自动作为任务加入日程。 timeout 可以为 None，也可以为 float 或 int 型数值表示的等待秒数。如果 timeout 为 None，则等待直到完成。 如果发生超时，任务将取消并引发 asyncio.TimeoutError. 要避免任务 取消，可以加上 shield()。 函数将等待直到目标对象确实被取消，所以总等待时间可能超过 timeout 指定的秒数。 如果等待被取消，则 aw 指定的对象也会被取消。 Deprecated since version 3.8, will be removed in version 3.10: loop 形参。 示例: 1234567891011121314151617async def eternity(): # Sleep for one hour await asyncio.sleep(3600) print('yay!')async def main(): # Wait for at most 1 second try: await asyncio.wait_for(eternity(), timeout=1.0) except asyncio.TimeoutError: print('timeout!')asyncio.run(main())# Expected output:## timeout! 在 3.7 版更改: 当 aw 因超时被取消，wait_for 会等待 aw 被取消。之前版本则将立即引发 asyncio.TimeoutError。 简单等待 coroutine asyncio.wait(aws, **, loop=None, timeout=None, return_when=ALL_COMPLETED*) 并发运行 aws 指定的 可等待对象 并阻塞线程直到满足 return_when 指定的条件。 返回两个 Task/Future 集合: (done, pending)。 用法: 1done, pending = await asyncio.wait(aws) 如指定 timeout (float 或 int 类型) 则它将被用于控制返回之前等待的最长秒数。 请注意此函数不会引发 asyncio.TimeoutError。当超时发生时，未完成的 Future 或 Task 将在指定秒数后被返回。 return_when 指定此函数应在何时返回。它必须为以下常数之一: | 常数 | 描述 || :—————- | :———————————————————– || FIRST_COMPLETED | 函数将在任意可等待对象结束或取消时返回。 || FIRST_EXCEPTION | 函数将在任意可等待对象因引发异常而结束时返回。当没有引发任何异常时它就相当于 ALL_COMPLETED。 || ALL_COMPLETED | 函数将在所有可等待对象结束或取消时返回。 | 与 wait_for() 不同，wait() 在超时发生时不会取消可等待对象。 3.8 版后已移除: 如果 aws 中的某个可等待对象为协程，它将自动作为任务加入日程。直接向 wait() 传入协程对象已弃用，因为这会导致 令人迷惑的行为。 从 3.8版本加入，将于 3.10版本移除loop 形参。 注解 wait() 会自动将协程作为任务加入日程，以后将以 (done, pending) 集合形式返回显式创建的任务对象。因此以下代码并不会有预期的行为: 123456789&gt; async def foo():&gt; return 42&gt; &gt; coro = foo()&gt; done, pending = await asyncio.wait(&#123;coro&#125;)&gt; &gt; if coro in done:&gt; # This branch will never be run!&gt; 以上代码段的修正方法如下: 123456789&gt; async def foo():&gt; return 42&gt; &gt; task = asyncio.create_task(foo())&gt; done, pending = await asyncio.wait(&#123;task&#125;)&gt; &gt; if task in done:&gt; # Everything will work as expected now.&gt; ​ 3.8 版后已移除: 直接向 wait() 传入协程对象的方式已弃用。 asyncio.as_completed(aws, **, loop=None, timeout=None*) 并发地运行 aws 集合中的 可等待对象。返回一个 Future 对象的迭代器。返回的每个 Future 对象代表来自剩余可等待对象集合的最早结果。 如果在所有 Future 对象完成前发生超时则将引发 asyncio.TimeoutError。 Deprecated since version 3.8, will be removed in version 3.10: loop 形参。 示例: 123for f in as_completed(aws): earliest_result = await f # ... 来自其他线程的日程安排 asyncio.run_coroutine_threadsafe(coro, loop) 向指定事件循环提交一个协程。线程安全。 返回一个 concurrent.futures.Future 以等待来自其他 OS 线程的结果。 此函数应该从另一个 OS 线程中调用，而非事件循环运行所在线程。示例: 12345678# Create a coroutinecoro = asyncio.sleep(1, result=3)# Submit the coroutine to a given loopfuture = asyncio.run_coroutine_threadsafe(coro, loop)# Wait for the result with an optional timeout argumentassert future.result(timeout) == 3 如果在协程内产生了异常，将会通知返回的 Future 对象。它也可被用来取消事件循环中的任务: 123456789try: result = future.result(timeout)except asyncio.TimeoutError: print(&apos;The coroutine took too long, cancelling the task...&apos;) future.cancel()except Exception as exc: print(f&apos;The coroutine raised an exception: &#123;exc!r&#125;&apos;)else: print(f&apos;The coroutine returned: &#123;result!r&#125;&apos;) 查看 并发和多线程 章节的文档。 不同与其他 asyncio 函数，此函数要求显式地传入 loop 参数。 3.5.1 新版功能. 内省 asyncio.current_task(loop=None) 返回当前运行的 Task 实例，如果没有正在运行的任务则返回 None。如果 loop 为 None 则会使用 get_running_loop() 获取当前事件循环。3.7 新版功能. asyncio.all_tasks(loop=None) 返回事件循环所运行的未完成的 Task 对象的集合。如果 loop 为 None，则会使用 get_running_loop() 获取当前事件循环。3.7 新版功能. Task 对象 class asyncio.Task(coro, **, loop=None, name=None*) 一个与 Future 类似 的对象，可运行 Python 协程。非线程安全。 Task 对象被用来在事件循环中运行协程。如果一个协程在等待一个 Future 对象，Task 对象会挂起该协程的执行并等待该 Future 对象完成。当该 Future 对象 完成，被打包的协程将恢复执行。 事件循环使用协同日程调度: 一个事件循环每次运行一个 Task 对象。而一个 Task 对象会等待一个 Future 对象完成，该事件循环会运行其他 Task、回调或执行 IO 操作。 使用高层级的 asyncio.create_task() 函数来创建 Task 对象，也可用低层级的 loop.create_task() 或 ensure_future() 函数。不建议手动实例化 Task 对象。 要取消一个正在运行的 Task 对象可使用 cancel() 方法。调用此方法将使该 Task 对象抛出一个 CancelledError 异常给打包的协程。如果取消期间一个协程正在等待一个 Future 对象，该 Future 对象也将被取消。 cancelled() 可被用来检测 Task 对象是否被取消。如果打包的协程没有抑制 CancelledError 异常并且确实被取消，该方法将返回 True。 asyncio.Task 从 Future 继承了其除 Future.set_result() 和 Future.set_exception() 以外的所有 API。 Task 对象支持 contextvars 模块。当一个 Task 对象被创建，它将复制当前上下文，然后在复制的上下文中运行其协程。 在 3.7 版更改: 加入对 contextvars 模块的支持。 在 3.8 版更改: Added the name parameter. Deprecated since version 3.8, will be removed in version 3.10: loop 形参。 cancel() 请求取消 Task 对象。这将安排在下一轮事件循环中抛出一个 CancelledError 异常给被封包的协程。协程在之后有机会进行清理甚至使用 try … … except CancelledError … finally 代码块抑制异常来拒绝请求。不同于 Future.cancel()，Task.cancel() 不保证 Task 会被取消，虽然抑制完全取消并不常见，也很不鼓励这样做。以下示例演示了协程是如何侦听取消请求的: 123456789101112131415161718192021222324252627282930313233async def cancel_me(): print('cancel_me(): before sleep') try: # Wait for 1 hour await asyncio.sleep(3600) except asyncio.CancelledError: print('cancel_me(): cancel sleep') raise finally: print('cancel_me(): after sleep')async def main(): # Create a "cancel_me" Task task = asyncio.create_task(cancel_me()) # Wait for 1 second await asyncio.sleep(1) task.cancel() try: await task except asyncio.CancelledError: print("main(): cancel_me is cancelled now")asyncio.run(main())# Expected output:## cancel_me(): before sleep# cancel_me(): cancel sleep# cancel_me(): after sleep# main(): cancel_me is cancelled now cancelled() 如果 Task 对象 被取消 则返回 True。当使用 cancel() 发出取消请求时 Task 会被 取消，其封包的协程将传播被抛入的 CancelledError 异常。 done() 如果 Task 对象 已完成 则返回 True。当 Task 所封包的协程返回一个值、引发一个异常或 Task 本身被取消时，则会被认为 已完成。 result() 返回 Task 的结果。如果 Task 对象 已完成，其封包的协程的结果会被返回 (或者当协程引发异常时，该异常会被重新引发。)如果 Task 对象 被取消，此方法会引发一个 CancelledError 异常。如果 Task 对象的结果还不可用，此方法会引发一个 InvalidStateError 异常。 exception() 返回 Task 对象的异常。如果所封包的协程引发了一个异常，该异常将被返回。如果所封包的协程正常返回则该方法将返回 None。如果 Task 对象 被取消，此方法会引发一个 CancelledError 异常。如果 Task 对象尚未 完成，此方法将引发一个 InvalidStateError 异常。 add_done_callback(callback, **, context=None*) 添加一个回调，将在 Task 对象 完成 时被运行。此方法应该仅在低层级的基于回调的代码中使用。要了解更多细节请查看 Future.add_done_callback() 的文档。 remove_done_callback(callback) 从回调列表中移除 callback 指定的回调。此方法应该仅在低层级的基于回调的代码中使用。要了解更多细节请查看 Future.remove_done_callback() 的文档。 get_stack(**, limit=None*) 返回此 Task 对象的栈框架列表。如果所封包的协程未完成，这将返回其挂起所在的栈。如果协程已成功完成或被取消，这将返回一个空列表。如果协程被一个异常终止，这将返回回溯框架列表。框架总是从按从旧到新排序。每个被挂起的协程只返回一个栈框架。可选的 limit 参数指定返回框架的数量上限；默认返回所有框架。返回列表的顺序要看是返回一个栈还是一个回溯：栈返回最新的框架，回溯返回最旧的框架。(这与 traceback 模块的行为保持一致。) print_stack(**, limit=None, file=None*) 打印此 Task 对象的栈或回溯。此方法产生的输出类似于 traceback 模块通过 get_stack() 所获取的框架。limit 参数会直接传递给 get_stack()。file 参数是输出所写入的 I/O 流；默认情况下输出会写入 sys.stderr。 get_coro() 返回绑定到 Task.的协程对象。3.8 新版功能. get_name() 返回Task 名字。如果没有显式分配给Task一个名字,则默认的异步Task将分配给默认的生成的名字。3.8 新版功能. set_name(value) 设置Task名字。参数值可以是任意数据类型,都将被转换成字符串。默认的Task实现，可以通过在task对象中实现 repr()函数显式输出。3.8 新版功能. classmethod all_tasks(loop=None) 返回一个事件循环中所有任务的集合。默认情况下将返回当前事件循环中所有任务。如果 loop 为 None，则会使用 get_event_loop() 函数来获取当前事件循环。从3.7版本就被废弃,3.9版本将会被移除。尽量不要作为一个task方法来使用,建议使用 asyncio.all_tasks() 代替。 classmethod current_task(loop=None) 返回当前运行任务或 None。如果 loop 为 None，则会使用 get_event_loop() 函数来获取当前事件循环。 从3.7版本就被废弃,3.9版本将会被移除。尽量不要作为一个task方法来使用,建议使用 asyncio.current_task() 代替。 基于生成器的协程 对基于生成器的协程的支持 已弃用 并计划在 Python 3.10 中移除。 基于生成器的协程是 async/await 语法的前身。它们是使用 yield from 语句创建的 Python 生成器，可以等待 Future 和其他协程。 基于生成器的协程应该使用 @asyncio.coroutine 装饰，虽然这并非强制。 `@asyncio.coroutine` 用来标记基于生成器的协程的装饰器。此装饰器使得旧式的基于生成器的协程能与 async/await 代码相兼容: 此装饰器使得旧式的基于生成器的协程能与 async/await 代码相兼容: 123456@asyncio.coroutinedef old_style_coroutine(): yield from asyncio.sleep(1)async def main(): await old_style_coroutine() 此装饰器不应该被用于 async def 协程。 从3.8版本被废弃, 将于3.10版本移除:* 使用 async def 代替。 asyncio.iscoroutine(obj) 如果 obj 是一个 协程对象 则返回 True。此方法不同于 inspect.iscoroutine() 因为它对基于生成器的协程返回 True。 asyncio.iscoroutinefunction(func) 如果 func 是一个 协程函数 则返回 True。此方法不同于 inspect.iscoroutinefunction() 因为它对以 @coroutine 装饰的基于生成器的协程函数返回 True。 小结转自 python协程 作者：侠三十六 协程 首先要明确，线程和进程都是系统帮咱们开辟的，不管是thread还是process他内部都是调用的系统的API,而对于协程来说它和系统毫无关系; 协程不同于线程的是，线程是抢占式的调度，而协程是协同式的调度，也就是说，协程需要自己做调度。 他就和程序员有关系，对于线程和进程来说，调度是由CPU来决定调度的; 对于协程来说，程序员就是上帝，你想让谁执行到哪里他就执行到哪里; 协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时（保存状态，下次继续）。协程，则只使用一个线程，在一个线程中规定某个代码块执行顺序。 适用场景：其实在其他语言中，协程的其实是意义不大的多线程即可已解决I/O的问题，但是在python因为他有GIL（Global Interpreter Lock 全局解释器锁 ）在同一时间只有一个线程在工作，所以：如果一个线程里面I/O操作特别多，协程就比较适用; 协程，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程。 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此： 协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。 协程的好处： 无需线程上下文切换的开销 无需原子操作锁定及同步的开销 方便切换控制流，简化编程模型 高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。 缺点： 无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>coroutines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library weakref]]></title>
    <url>%2F2020%2F02%2F11%2Fpython-standard-library-weakref%2F</url>
    <content type="text"><![CDATA[python 标准库 weakref 弱引用 通过google Insights 优化,我把图片进行了压缩,明显速度提升了15%，接下来压缩css和js. 源码 源码： Lib/weakref.py weakref 模块允许Python程序员创建对象的 weak references 。 在下文中，术语 referent 表示由弱引用引用的对象。 对对象的弱引用不能保证对象存活：当对像的引用只剩弱引用时， garbage collection 可以销毁引用并将其内存重用于其他内容。但是，在实际销毁对象之前，即使没有强引用，弱引用也一直能返回该对象。 弱引用的主要用途是实现保存大对象的高速缓存或映射，但又并希望大对象仅仅因为它出现在高速缓存或映射中而保持存活。 例如，如果您有许多大型二进制图像对象，则可能希望将名称与每个对象关联起来。如果您使用Python字典将名称映射到图像，或将图像映射到名称，则图像对象将保持活动状态，因为它们在字典中显示为值或键。 weakref 模块提供的 WeakKeyDictionary 和 WeakValueDictionary 类可以替代Python字典，使用弱引用来构造映射，这些映射不会仅仅因为它们出现在映射对象中而使对象保持存活。例如，如果一个图像对象是 WeakValueDictionary 中的值，那么当对该图像对象的剩余引用是弱映射对象所持有的弱引用时，垃圾回收可以回收该对象并将其在弱映射对象中相应的条目删除。 WeakKeyDictionary 和 WeakValueDictionary 在它们的实现中使用弱引用，在弱引用上设置回调函数，当键或值被垃圾回收回收时通知弱字典。 WeakSet 实现了 set 接口，但像 WeakKeyDictionary 一样，只持有其元素的弱引用。` finalize 提供了注册一个对象被垃圾收集时要调用的清理函数的方式。这比在原始弱引用上设置回调函数更简单，因为模块会自动确保对象被回收前终结器一直保持存活。 这些弱容器类型之一或者 finalize 就是大多数程序所需要的 - 通常不需要直接创建自己的弱引用。weakref 模块暴露了低级机制，以便于高级用途。 并非所有对象都可以被弱引用；可以被弱引用的对象包括类实例，用 Python（而不是用 C）编写的函数，实例方法、集合、冻结集合，某些 文件对象，生成器，类型对象，套接字，数组，双端队列，正则表达式模式对象以及代码对象等。 在 3.2 版更改: 添加了对thread.lock，threading.Lock和代码对象的支持。 几个内建类型如 list 和 dict 不直接支持弱引用，但可以通过子类化添加支持: 1234class Dict(dict): passobj = Dict(red=1, green=2, blue=3) # this object is weak referenceable CPython implementation detail: 其他内置类型例如 tuple 和 int 不支持弱引用，即使通过子类化也不支持。 Extension types can easily be made to support weak references; see Weak Reference Support. class weakref.`ref`(object[, callback]) 返回对 对象 的弱引用。如果原始对象仍然存活，则可以通过调用引用对象来检索原始对象；如果引用的原始对象不再存在，则调用引用对象将得到 None 。如果提供了 回调 而且值不是 None ，并且返回的弱引用对象仍然存活，则在对象即将终结时将调用回调;弱引用对象将作为回调的唯一参数传递；指示物将不再可用。 许多弱引用也允许针对相同对象来构建。 为每个弱引用注册的回调将按从最近注册的回调到最早注册的回调的顺序被调用。 回调所引发的异常将记录于标准错误输出，但无法被传播；它们会按与对象的 __del__() 方法所引发的异常相同的方式被处理。 如果 object 可哈希，则弱引用也为 hashable。 即使在 object 被删除之后它们仍将保持其哈希值。 如果 hash() 在 object 被删除之后才首次被调用，则该调用将引发 TypeError。 弱引用支持相等检测，但不支持排序比较。 如果被引用对象仍然存在，两个引用具有与它们的被引用对象一致的相等关系（无论 callback 是否相同）。 如果删除了任一被引用对象，则仅在两个引用对象为同一对象时两者才相等。 这是一个可子类化的类型而非一个工厂函数。 callback 这个只读属性会返回当前关联到弱引用的回调。 如果回调不存在或弱引用的被引用对象已不存在，则此属性的值为 None。 weakref.`proxy`(object[, callback]) 返回 object 的一个使用弱引用的代理。 此函数支持在大多数上下文中使用代理，而不要求显式地对所使用的弱引用对象解除引用。 返回的对象类型将为 ProxyType 或 CallableProxyType，具体取决于 object 是否可调用。 Proxy 对象不是 hashable 对象，无论被引用对象是否可哈希；这可避免与它们的基本可变性质相关的多种问题，并可防止它们被用作字典键。 callback 与 ref() 函数的同名形参含义相同。 在 3.8 版更改: 扩展代理对象所支持的运算符，包括矩阵乘法运算符 @ 和 @=。 weakref.`getweakrefcount`(object) 返回指向 object 的弱引用和代理的数量。 weakref.`getweakrefs`(object) 返回由指向 object 的所有弱引用和代理构成的列表。 class weakref.`WeakKeyDictionary`([dict]) 弱引用键的映射类。 当不再有对键的强引用时字典中的条目将被丢弃。 这可被用来将额外数据关联到一个应用中其他部分所拥有的对象而无需在那些对象中添加属性。 这对于重载了属性访问的对象来说特别有用。 WeakKeyDictionary 对象具有一个额外方法可以直接公开内部引用。 这些引用不保证在它们被使用时仍然保持“存活”，因此这些引用的调用结果需要在使用前进行检测。 此方法可用于避免创建会导致垃圾回收器将保留键超出实际需要时长的引用。 WeakKeyDictionary.`keyrefs`() 返回包含对键的弱引用的可迭代对象。 class weakref.`WeakValueDictionary`([dict]) 弱引用值的映射类。 当不再有对键的强引用时字典中的条目将被丢弃。 WeakValueDictionary 对象具有一个额外方法，此方法存在与 WeakKeyDictionary 对象的 keyrefs() 方法相同的问题。 WeakValueDictionary.`valuerefs`() 返回包含对值的弱引用的可迭代对象。 class weakref.`WeakSet`([elements]) 保持对其元素弱引用的集合类。 当不再有对某个元素的强引用时元素将被丢弃。 class weakref.`WeakMethod`(method) 一个模拟对绑定方法（即在类中定义并在实例中查找的方法）进行弱引用的自定义 ref 子类。 由于绑定方法是临时性的，标准弱引用无法保持它。 WeakMethod 包含特别代码用来重新创建绑定方法，直到对象或初始函数被销毁: 1234567891011121314151617&gt;&gt;&gt; class C:... def method(self):... print("method called!")...&gt;&gt;&gt; c = C()&gt;&gt;&gt; r = weakref.ref(c.method)&gt;&gt;&gt; r()&gt;&gt;&gt; r = weakref.WeakMethod(c.method)&gt;&gt;&gt; r()&lt;bound method C.method of &lt;__main__.C object at 0x7fc859830220&gt;&gt;&gt;&gt;&gt; r()()method called!&gt;&gt;&gt; del c&gt;&gt;&gt; gc.collect()0&gt;&gt;&gt; r()&gt;&gt;&gt; class weakref.`finalize`(obj, func, args, kwargs*) 返回一个可调用的终结器对象，该对象将在 obj 作为垃圾回收时被调用。 与普通的弱引用不同，终结器将总是存活，直到引用对象被回收，这极大地简化了生存期管理。 终结器总是被视为 存活 直到它被调用（显式调用或在垃圾回收时隐式调用），调用之后它将 死亡。 调用存活的终结器将返回 func(*arg, **kwargs) 的求值结果，而调用死亡的终结器将返回 None。 在垃圾收集期间由终结器回调所引发异常将显示于标准错误输出，但无法被传播。 它们会按与对象的 __del__() 方法或弱引用的回调所引发异常相同的方式被处理。 当程序退出时，剩余的存活终结器会被调用，除非它们的 atexit 属性已被设为假值。 它们会按与创建时相反的顺序被调用。 终结器在 interpreter shutdown 的后期绝不会发起调用其回调函数，此时模块全局变量很可能已被替换为 None。 __call__() 如果 self 为存活状态则将其标记为已死亡，并返回调用 func(*args, **kwargs) 的结果。 如果 self 已死亡则返回 None。 detach() 如果 self 为存活状态则将其标记为已死亡，并返回元组 (obj, func, args, kwargs)。 如果 self 已死亡则返 None。 peek() 如果 self 为存活状态则返回元组 (obj, func, args, kwargs)。 如果 self 已死亡则返回 None。 alive 如果终结器为存活状态则该特征属性为真值，否则为假值。 atexit 一个可写的布尔型特征属性，默认为真值。 当程序退出时，它会调用所有 atexit 为真值的剩余存活终结器。 它们会按与创建时相反的顺序被调用。 weakref.`ReferenceType` 弱引用对象的类型对象。 weakref.`ProxyType` 不可调用对象的代理的类型对象。 weakref.`CallableProxyType` 可调用对象的代理的类型对象。 weakref.`ProxyTypes` 包含所有代理的类型对象的序列。 这可以用于更方便地检测一个对象是否是代理，而不必依赖于两种代理对象的名称。 exception weakref.`ReferenceError` 当一个代理对象被使用但其下层的对象已被收集时所引发的异常。 这等价于标准的 ReferenceError 异常。 PEP 205 - 弱引用 此特性的提议和理由，包括早期实现的链接和其他语言中类似特性的相关信息。 弱引用对象弱引用对象没有 ref.__callback__ 以外的方法和属性。 一个弱引用对象如果存在，就允许通过调用它来获取引用: 123456789&gt;&gt;&gt; import weakref&gt;&gt;&gt; class Object:... pass...&gt;&gt;&gt; o = Object()&gt;&gt;&gt; r = weakref.ref(o)&gt;&gt;&gt; o2 = r()&gt;&gt;&gt; o is o2True 如果引用已不存在，则调用引用对象将返回 None: 123&gt;&gt;&gt; del o, o2&gt;&gt;&gt; print(r())None 检测一个弱引用对象是否仍然存在应该使用表达式 ref() is not None。 通常，需要使用引用对象的应用代码应当遵循这样的模式: 12345678# r is a weak reference objecto = r()if o is None: # referent has been garbage collected print("Object has been deallocated; can't frobnicate.")else: print("Object is still live!") o.do_something_useful() 使用单独的“存活”测试会在多线程应用中制造竞争条件；其他线程可能导致某个弱引用在该弱引用被调用前就失效；上述的写法在多线程应用和单线程应用中都是安全的。 特别版本的 ref 对象可以通过子类化来创建。 在 WeakValueDictionary 的实现中就使用了这种方式来减少映射中每个条目的内存开销。 这对于将附加信息关联到引用的情况最为适用，但也可以被用于在调用中插入额外处理来提取引用。 这个例子演示了如何将 ref 的一个子类用于存储有关对象的附加信息并在引用被访问时影响其所返回的值: 123456789101112131415161718import weakrefclass ExtendedRef(weakref.ref): def __init__(self, ob, callback=None, /, **annotations): super(ExtendedRef, self).__init__(ob, callback) self.__counter = 0 for k, v in annotations.items(): setattr(self, k, v) def __call__(self): """Return a pair containing the referent and the number of times the reference has been called. """ ob = super(ExtendedRef, self).__call__() if ob is not None: self.__counter += 1 ob = (ob, self.__counter) return ob 示例这个简单的例子演示了一个应用如何使用对象 ID 来提取之前出现过的对象。 然后对象的 ID 可以在其它数据结构中使用，而无须强制对象保持存活，但处于存活状态的对象也仍然可以通过 ID 来提取。 1234567891011import weakref_id2obj_dict = weakref.WeakValueDictionary()def remember(obj): oid = id(obj) _id2obj_dict[oid] = obj return oiddef id2obj(oid): return _id2obj_dict[oid] 终结器对象使用 finalize 的主要好处在于它能更简便地注册回调函数，而无须保留所返回的终结器对象。 例如 123456789&gt;&gt;&gt; import weakref&gt;&gt;&gt; class Object:... pass...&gt;&gt;&gt; kenny = Object()&gt;&gt;&gt; weakref.finalize(kenny, print, "You killed Kenny!") &lt;finalize object at ...; for 'Object' at ...&gt;&gt;&gt;&gt; del kennyYou killed Kenny! 终结器也可以被直接调用。 但是终结器最多只能对回调函数发起一次调用。 123456789101112&gt;&gt;&gt; def callback(x, y, z):... print("CALLBACK")... return x + y + z...&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; f = weakref.finalize(obj, callback, 1, 2, z=3)&gt;&gt;&gt; assert f.alive&gt;&gt;&gt; assert f() == 6CALLBACK&gt;&gt;&gt; assert not f.alive&gt;&gt;&gt; f() # callback not called because finalizer dead&gt;&gt;&gt; del obj # callback not called because finalizer dead 你可以使用 detach() 方法来注销一个终结器。 该方法将销毁终结器并返回其被创建时传给构造器的参数。 123456789&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; f = weakref.finalize(obj, callback, 1, 2, z=3)&gt;&gt;&gt; f.detach() (&lt;...Object object ...&gt;, &lt;function callback ...&gt;, (1, 2), &#123;'z': 3&#125;)&gt;&gt;&gt; newobj, func, args, kwargs = _&gt;&gt;&gt; assert not f.alive&gt;&gt;&gt; assert newobj is obj&gt;&gt;&gt; assert func(*args, **kwargs) == 6CALLBACK 除非你将 atexit 属性设为 False，否则终结器在程序退出时如果仍然存活就将被调用。 例如 12345&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; weakref.finalize(obj, print, "obj dead or exiting")&lt;finalize object at ...; for 'Object' at ...&gt;&gt;&gt;&gt; exit()obj dead or exiting 比较终结器与 __del__() 方法假设我们想创建一个类，用它的实例来代表临时目录。 当以下事件中的某一个发生时，这个目录应当与其内容一起被删除： 对象被作为垃圾回收， 对象的 remove() 方法被调用，或 程序退出。 我们可以尝试使用 __del__() 方法来实现这个类，如下所示: 123456789101112131415class TempDir: def __init__(self): self.name = tempfile.mkdtemp() def remove(self): if self.name is not None: shutil.rmtree(self.name) self.name = None @property def removed(self): return self.name is None def __del__(self): self.remove() 从 Python 3.4 开始，__del__() 方法不会再阻止循环引用被作为垃圾回收，并且模块全局变量在 interpreter shutdown 期间不会被强制设为 None。 因此这段代码在 CPython 上应该会正常运行而不会出现任何问题。 然而，__del__() 方法的处理会严重地受到具体实现的影响，因为它依赖于解释器垃圾回收实现方式的内部细节。 更健壮的替代方式可以是定义一个终结器，只引用它所需要的特定函数和对象，而不是获取对整个对象状态的访问权: 1234567891011class TempDir: def __init__(self): self.name = tempfile.mkdtemp() self._finalizer = weakref.finalize(self, shutil.rmtree, self.name) def remove(self): self._finalizer() @property def removed(self): return not self._finalizer.alive 像这样定义后，我们的终结器将只接受一个对其完成正确清理目录任务所需细节的引用。 如果对象一直未被作为垃圾回收，终结器仍会在退出时被调用。 基于弱引用的终结器还具有另一项优势，就是它们可被用来为定义由第三方控制的类注册终结器，例如当一个模块被卸载时运行特定代码: 1234import weakref, sysdef unloading_module(): # implicit reference to the module globals from the function bodyweakref.finalize(sys.modules[__name__], unloading_module) 备注: 如果当程序退出时你恰好在守护线程中创建终结器对象，则有可能该终结器不会在退出时被调用。 但是，在一个守护线程中 atexit.register(), try: ... finally: ... 和 with: ... 同样不能保证执行清理。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>weakref</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library cmath]]></title>
    <url>%2F2020%2F02%2F10%2Fpython-standard-library-cmath%2F</url>
    <content type="text"><![CDATA[python 标准库 cmath 患难可以试验一个人的品格；非常的境遇方才可以显出非常的气节；风平浪静的海面，所有船只都可以并驱竞胜；命运的铁拳击中要害的时候，只有大勇大智的人才能够处之泰然。 ​ – 莎士比亚 源码这一模块提供了一些关于复数的数学函数。 该模块的函数的参数为整数、浮点数或复数。 这些函数的参数也可为一个拥有 __complex__() 或 __float__() 方法的 Python 对象，这些方法分别用于将对象转换为复数和浮点数，这些函数作用于转换后的结果。 到极坐标和从极坐标的转换使用 矩形坐标 或 笛卡尔坐标 在内部存储 Python 复数 z。 这完全取决于它的 实部 z.real 和 虚部 z.imag。 换句话说: 1z == z.real + z.imag*1j 极坐标 提供了另一种复数的表示方法。在极坐标中，一个复数 z 由模量 r 和相位角 phi 来定义。模量 r 是从 z 到坐标原点的距离，而相位角 phi 是以弧度为单位的，逆时针的，从正X轴到连接原点和 z 的线段间夹角的角度。 下面的函数可用于原生直角坐标与极坐标的相互转换。 cmath.phase(x) 将 x 的相位 (也称为 x 的 参数) 返回为一个浮点数。phase(x) 相当于 math.atan2(x.imag, x.real)。 结果处于 [-π, π] 之间，以及这个操作的分支切断处于负实轴上，从上方连续。 在支持有符号零的系统上（这包涵大多数当前的常用系统），这意味着结果的符号与 x.imag 的符号相同，即使 x.imag 的值是 0: 1234&gt;&gt;&gt; phase(complex(-1.0, 0.0))3.141592653589793&gt;&gt;&gt; phase(complex(-1.0, -0.0))-3.141592653589793 cmath.polar(x) 在极坐标中返回 x 的表达方式。返回一个数对 (r, phi)，r 是 x 的模数，phi 是 x 的相位角。 polar(x) 相当于 (abs(x), phase(x))。 cmath.rect(r, phi) 通过极坐标的 r 和 phi 返回复数 x。相当于 r * (math.cos(phi) + math.sin(phi)*1j)。 幂函数与对数函数 cmath.exp(x) 返回 e 的 x 次方，e 是自然对数的底数。 cmath.log(x[, base]) 返回给定 base 的 x 的对数。如果没有给定 base，返回 x 的自然对数。 从 0 到 -∞ 存在一个分歧点，沿负实轴之上连续。 cmath.log10(x) 返回底数为 10 的 x 的对数。它具有与 log() 相同的分歧点。 cmath.sqrt(x) 返回 x 的平方根。 它具有与 log() 相同的分歧点。 三角函数 cmath.acos(x) 返回 x 的反余弦。这里有两个分歧点：一个沿着实轴从 1 向右延伸到 ∞，从下面连续延伸。另外一个沿着实轴从 -1 向左延伸到 -∞，从上面连续延伸。 cmath.asin(x) 返回 x 的反正弦。它与 acos() 有相同的分歧点。 cmath.atan(x) 返回 x 的反正切。它具有两个分歧点：一个沿着虚轴从 1j 延伸到 ∞j，向右持续延伸。另一个是沿着虚轴从 -1j 延伸到 -∞j ，向左持续延伸。 cmath.cos(x) 返回 x 的余弦。 cmath.sin(x) 返回 x 的正弦。 cmath.tan(x) 返回 x 的正切。 双曲函数 cmath.acosh(x) 返回 x 的反双曲余弦。它有一个分歧点沿着实轴从 1 到 -∞ 向左延伸，从上方持续延伸。 cmath.asinh(x) 返回 x 的反双曲正弦。它有两个分歧点：一个沿着虚轴从 1j 向右持续延伸到 ∞j。另一个是沿着虚轴从 -1j 向左持续延伸到 -∞j。 cmath.atanh(x) 返回 x 的反双曲正切。它有两个分歧点：一个是沿着实轴从 1 延展到 ∞，从下面持续延展。另一个是沿着实轴从 -1 延展到 -∞，从上面持续延展。 cmath.cosh(x) 返回 x 的双曲余弦值。 cmath.sinh(x) 返回 x 的双曲正弦值。 cmath.tanh(x) 返回 x 的双曲正切值。 分类函数 cmath.isfinite(x) 如果 x 的实部和虚部都是有限的，则返回 True，否则返回 False。3.2 新版功能. cmath.isinf(x) 如果 x 的实部或者虚部是无穷大的，则返回 True，否则返回 False。 cmath.isnan(x) 如果 x 的实部或者虚部是 NaN，则返回 True ，否则返回 False。 cmath.isclose(a, b, **, rel_tol=1e-09, abs_tol=0.0*) 若 a 和 b 的值比较接近则返回 True，否则返回 False。根据给定的绝对和相对容差确定两个值是否被认为是接近的。rel_tol 是相对容差 —— 它是 a 和 b 之间允许的最大差值，相对于 a 或 b 的较大绝对值。例如，要设置5％的容差，请传递 rel_tol=0.05 。默认容差为 1e-09，确保两个值在大约9位十进制数字内相同。 rel_tol 必须大于零。abs_tol 是最小绝对容差 —— 对于接近零的比较很有用。 abs_tol 必须至少为零。如果没有错误发生，结果将是： abs(a-b) &lt;= max(rel_tol * max(abs(a), abs(b)), abs_tol) 。IEEE 754特殊值 NaN ， inf 和-inf 将根据IEEE规则处理。具体来说， NaN 不被认为接近任何其他值，包括 NaN 。 inf 和 -inf 只被认为接近自己。 PEP 485 —— 用于测试近似相等的函数 常数 cmath.pi 数学常数 π ，作为一个浮点数。 cmath.e 数学常数 e ，作为一个浮点数。 cmath.tau 数学常数 τ ，作为一个浮点数。3.6 新版功能. cmath.inf 浮点正无穷大。相当于 float(&#39;inf&#39;)。3.6 新版功能. cmath.infj 具有零实部和正无穷虚部的复数。相当于 complex(0.0, float(&#39;inf&#39;))。3.6 新版功能. cmath.nan 浮点“非数字”（NaN）值。相当于 float(&#39;nan&#39;)。3.6 新版功能. cmath.nanj 具有零实部和 NaN 虚部的复数。相当于 complex(0.0, float(&#39;nan&#39;))。 请注意，函数的选择与模块 math 中的函数选择相似，但不完全相同。 拥有两个模块的原因是因为有些用户对复数不感兴趣，甚至根本不知道它们是什么。它们宁愿 math.sqrt(-1) 引发异常，也不想返回一个复数。 另请注意，被 cmath 定义的函数始终会返回一个复数，尽管答案可以表示为一个实数（在这种情况下，复数的虚数部分为零）。 关于分歧点的注释：它们是沿着给定函数无法连续的曲线。它们是许多复杂函数的必要特征。假设您需要使用复杂函数进行计算，您将了解分歧点。请参阅几乎所有关于复杂变量的（不太基本）的书来进行启发。关于分歧点数值目的的正确选择信息，应提供以下良好参考.]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>cmath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library fractions]]></title>
    <url>%2F2020%2F02%2F09%2Fpython-standard-library-fractions%2F</url>
    <content type="text"><![CDATA[python 标准库 fractions 分数 源码源代码 Lib/fractions.py 模块概述fractions 模块支持分数运算。 分数实例可以由一对整数，一个分数，或者一个字符串构建而成。 class fractions.Fraction(numerator=0, denominator=1) class fractions.Fraction(other_fraction) class fractions.Fraction(float) class fractions.Fraction(decimal) class fractions.Fraction(string) 第一个版本要求 numerator 和 denominator 是 numbers.Rational 的实例，并返回一个新的 Fraction 实例，其值为 numerator/denominator。 如果 denominator 为 0 将会引发 ZeroDivisionError。 第二个版本要求 other_fraction 是 numbers.Rational 的实例，并返回一个 Fraction 实例且与传入值相等。 下两个版本接受 float 或 decimal.Decimal 的实例，并返回一个 Fraction 实例且与传入值完全相等。 请注意由于二进制浮点数通常存在的问题 (参见 浮点算术：争议和限制)，Fraction(1.1) 的参数并不会精确等于 11/10，因此 Fraction(1.1) 也 不会 返回用户所期望的 Fraction(11, 10)。 （请参阅下文中 limit_denominator() 方法的文档。） 构造器的最后一个版本接受一个字符串或 unicode 实例。 此实例的通常形式为: 1[sign] numerator ['/' denominator] 其中的可选项 sign 可以为 ‘+’ 或 ‘-‘ 并且 numerator 和 denominator (如果存在) 是十进制数码的字符串。 此外，float 构造器所接受的任何表示一个有限值的字符串也都为 Fraction 构造器所接受。 不论哪种形式的输入字符串也都可以带有前缀和/或后缀的空格符。 这里是一些示例: 123456789101112131415161718192021222324&gt;&gt;&gt; from fractions import Fraction&gt;&gt;&gt; Fraction(16, -10)Fraction(-8, 5)&gt;&gt;&gt; Fraction(123)Fraction(123, 1)&gt;&gt;&gt; Fraction()Fraction(0, 1)&gt;&gt;&gt; Fraction('3/7')Fraction(3, 7)&gt;&gt;&gt; Fraction(' -3/7 ')Fraction(-3, 7)&gt;&gt;&gt; Fraction('1.414213 \t\n')Fraction(1414213, 1000000)&gt;&gt;&gt; Fraction('-.125')Fraction(-1, 8)&gt;&gt;&gt; Fraction('7e-6')Fraction(7, 1000000)&gt;&gt;&gt; Fraction(2.25)Fraction(9, 4)&gt;&gt;&gt; Fraction(1.1)Fraction(2476979795053773, 2251799813685248)&gt;&gt;&gt; from decimal import Decimal&gt;&gt;&gt; Fraction(Decimal('1.1'))Fraction(11, 10) Fraction 类继承自抽象基类 numbers.Rational，并实现了该类的所有方法和操作。 Fraction 实例是可哈希的，并应当被视为不可变对象。 此外，Fraction 还具有以下属性和方法： numerator 最简分数形式的分子。 denominator 最简分数形式的分母。 as_integer_ratio() 返回由两个整数组成的元组，两数之比等于该分数的值且其分母为正数。3.8 新版功能. from_float(flt) : classmethod 此类方法可构造一个 Fraction 来表示 flt 的精确值，该参数必须是一个 float。 请注意 Fraction.from_float(0.3) 的值并不等于 Fraction(3, 10)。 from_decimal(dec) : classmethod 此类方法可构造一个 Fraction 来表示 dec 的精确值，该参数必须是一个 decimal.Decimal 实例。 limit_denominator(max_denominator=1000000) 找到并返回一个 Fraction 使得其值最接近 self 并且分母不大于 max_denominator。 此方法适用于找出给定浮点数的有理数近似值： 123&gt;&gt;&gt; from fractions import Fraction&gt;&gt;&gt; Fraction('3.1415926535897932').limit_denominator(1000)Fraction(355, 113) 或是用来恢复被表示为一个浮点数的有理数： 1234567&gt;&gt;&gt; from math import pi, cos&gt;&gt;&gt; Fraction(cos(pi/3))Fraction(4503599627370497, 9007199254740992)&gt;&gt;&gt; Fraction(cos(pi/3)).limit_denominator()Fraction(1, 2)&gt;&gt;&gt; Fraction(1.1).limit_denominator()Fraction(11, 10) __floor__() 返回最大的 int &lt;= self。 此方法也可通过 math.floor() 函数来使用： 123&gt;&gt;&gt; from math import floor&gt;&gt;&gt; floor(Fraction(355, 113))3 __ceil__() 返回最小的 int &gt;= self。 此方法也可通过 math.ceil() 函数来使用。 __round__() __round__(ndigits) 第一个版本返回一个 int 使得其值最接近 self，位值为二分之一时只对偶数舍入。第二个版本会将 self 舍入到最接近 Fraction(1, 10**ndigits) 的倍数（如果 ndigits 为负值则为逻辑运算），位值为二分之一时同样只对偶数舍入。 此方法也可通过 round() 函数来使用 fractions.gcd(a, b) 返回整数 a 和 b 的最大公约数。如果 a 或 b 之一非零，则 gcd(a, b) 的绝对值是能同时整除 a 和 b 的最大整数。若 b 非零，则 gcd(a,b) 与 b 同号；否则返回值与 a 同号。gcd(0, 0) 返回 0。 3.5 版后已移除: 由 math.gcd() 取代. ​]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>fractions</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library json]]></title>
    <url>%2F2020%2F02%2F08%2Fpython-standard-library-json%2F</url>
    <content type="text"><![CDATA[python 标准库 json 源码源代码: Lib/json/init.py JSON (JavaScript Object Notation)，由 RFC 7159 (which obsoletes RFC 4627) 和 ECMA-404 指定，是一个受 JavaScript 的对象字面量语法启发的轻量级数据交换格式，尽管它不仅仅是一个严格意义上的 JavaScript 的字集。 json 提供了与标准库 marshal 和 pickle 相似的API接口。 对基本的 Python 对象层次结构进行编码： 12345678910111213141516&gt;&gt;&gt; import json&gt;&gt;&gt; json.dumps(['foo', &#123;'bar': ('baz', None, 1.0, 2)&#125;])'["foo", &#123;"bar": ["baz", null, 1.0, 2]&#125;]'&gt;&gt;&gt; print(json.dumps("\"foo\bar"))"\"foo\bar"&gt;&gt;&gt; print(json.dumps('\u1234'))"\u1234"&gt;&gt;&gt; print(json.dumps('\\'))"\\"&gt;&gt;&gt; print(json.dumps(&#123;"c": 0, "b": 0, "a": 0&#125;, sort_keys=True))&#123;"a": 0, "b": 0, "c": 0&#125;&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; io = StringIO()&gt;&gt;&gt; json.dump(['streaming API'], io)&gt;&gt;&gt; io.getvalue()'["streaming API"]' 紧凑编码: 123&gt;&gt;&gt; import json&gt;&gt;&gt; json.dumps([1, 2, 3, &#123;'4': 5, '6': 7&#125;], separators=(',', ':'))'[1,2,3,&#123;"4":5,"6":7&#125;]' 美化输出 123456&gt;&gt;&gt; import json&gt;&gt;&gt; print(json.dumps(&#123;'4': 5, '6': 7&#125;, sort_keys=True, indent=4))&#123; "4": 5, "6": 7&#125; JSON解码 123456789&gt;&gt;&gt; import json&gt;&gt;&gt; json.loads('["foo", &#123;"bar":["baz", null, 1.0, 2]&#125;]')['foo', &#123;'bar': ['baz', None, 1.0, 2]&#125;]&gt;&gt;&gt; json.loads('"\\"foo\\bar"')'"foo\x08ar'&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; io = StringIO('["streaming API"]')&gt;&gt;&gt; json.load(io)['streaming API'] 特殊JSON对象解码: 123456789101112&gt;&gt;&gt; import json&gt;&gt;&gt; def as_complex(dct):... if '__complex__' in dct:... return complex(dct['real'], dct['imag'])... return dct...&gt;&gt;&gt; json.loads('&#123;"__complex__": true, "real": 1, "imag": 2&#125;',... object_hook=as_complex)(1+2j)&gt;&gt;&gt; import decimal&gt;&gt;&gt; json.loads('1.1', parse_float=decimal.Decimal)Decimal('1.1') 扩展 JSONEncoder: 1234567891011121314&gt;&gt;&gt; import json&gt;&gt;&gt; class ComplexEncoder(json.JSONEncoder):... def default(self, obj):... if isinstance(obj, complex):... return [obj.real, obj.imag]... # Let the base class default method raise the TypeError... return json.JSONEncoder.default(self, obj)...&gt;&gt;&gt; json.dumps(2 + 1j, cls=ComplexEncoder)'[2.0, 1.0]'&gt;&gt;&gt; ComplexEncoder().encode(2 + 1j)'[2.0, 1.0]'&gt;&gt;&gt; list(ComplexEncoder().iterencode(2 + 1j))['[2.0', ', 1.0', ']'] 从命令行使用 json.tool 来验证并美化输出： 123456$ echo '&#123;"json":"obj"&#125;' | python -m json.tool&#123; "json": "obj"&#125;$ echo '&#123;1.2:3.4&#125;' | python -m json.toolExpecting property name enclosed in double quotes: line 1 column 2 (char 1) 详细文档请参见 命令行界面。 JSON 是 YAML 1.2 的一个子集。由该模块的默认设置生成的 JSON （尤其是默认的 “分隔符” 设置值）也是 YAML 1.0 and 1.1 的一个子集。因此该模块也能够用于序列化为 YAML。 基本使用 json.dump(obj, fp, , skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, kw*) 使用这个 转换表 将 obj 序列化为 JSON 格式化流形式的 fp (支持 .write() 的 file-like object)。 如果 skipkeys 是 true （默认为 False），那么那些不是基本对象（包括 str, int、float、bool、None）的字典的键会被跳过；否则引发一个 TypeError。 json 模块始终产生 str 对象而非 bytes 对象。因此，fp.write() 必须支持 str 输入。 如果 ensure_ascii 是 true （即默认值），输出保证将所有输入的非 ASCII 字符转义。如果 ensure_ascii 是 false，这些字符会原样输出。 如果 check_circular 是为假值 (默认为 True)，那么容器类型的循环引用检验会被跳过并且循环引用会引发一个 OverflowError (或者更糟的情况)。 如果 allow_nan 是 false（默认为 True），那么在对严格 JSON 规格范围外的 float 类型值（nan、inf 和 -inf）进行序列化时会引发一个 ValueError。如果 allow_nan 是 true，则使用它们的 JavaScript 等价形式（NaN、Infinity 和 -Infinity）。 如果 indent 是一个非负整数或者字符串，那么 JSON 数组元素和对象成员会被美化输出为该值指定的缩进等级。如果缩进等级为零、负数或者 &quot;&quot;，则只会添加换行符。None（默认值）选择最紧凑的表达。使用一个正整数会让每一层缩进同样数量的空格。如果 *indent* 是一个字符串（比如 &quot;\t&quot;），那个字符串会被用于缩进每一层。 在 3.2 版更改: 允许使用字符串作为 indent 而不再仅仅是整数。 当指定时，separators 应当是一个 (item_separator, key_separator) 元组。当 indent 为 None 时，默认值取 (&#39;, &#39;, &#39;: &#39;)，否则取 (&#39;,&#39;, &#39;: &#39;)。为了得到最紧凑的 JSON 表达式，你应该指定其为 (&#39;,&#39;, &#39;:&#39;) 以消除空白字符。 在 3.4 版更改: 现当 indent 不是 None 时，采用 (&#39;,&#39;, &#39;: &#39;) 作为默认值。 当 default 被指定时，其应该是一个函数，每当某个对象无法被序列化时它会被调用。它应该返回该对象的一个可以被 JSON 编码的版本或者引发一个 TypeError。如果没有被指定，则会直接引发 TypeError。 如果 sort_keys 是 true（默认为 False），那么字典的输出会以键的顺序排序。 为了使用一个自定义的 JSONEncoder 子类（比如：覆盖了 default() 方法来序列化额外的类型）， 通过 cls 关键字参数来指定；否则将使用 JSONEncoder。 json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw) 使用这个 转换表 将 obj 序列化为 JSON 格式的 str。 其参数的含义与 dump() 中的相同。 json.load(fp, , cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, kw*) 使用这个 转换表 将 fp (一个支持 .read() 并包含一个 JSON 文档的 text file 或者 binary file) 反序列化为一个 Python 对象。 object_hook 是一个可选的函数，它会被调用于每一个解码出的对象字面量（即一个 dict）。object_hook 的返回值会取代原本的 dict。这一特性能够被用于实现自定义解码器（如 JSON-RPC 的类型提示)。 object_pairs_hook 是一个可选的函数，它会被调用于每一个有序列表对解码出的对象字面量。 object_pairs_hook 的返回值将会取代原本的 dict 。这一特性能够被用于实现自定义解码器。如果 object_hook 也被定义， object_pairs_hook 优先。 在 3.1 版更改: 添加了对 object_pairs_hook 的支持。 parse_float ，如果指定，将与每个要解码 JSON 浮点数的字符串一同调用。默认状态下，相当于 float(num_str) 。可以用于对 JSON 浮点数使用其它数据类型和语法分析程序 （比如 decimal.Decimal ）。 parse_int ，如果指定，将与每个要解码 JSON 整数的字符串一同调用。默认状态下，相当于 int(num_str) 。可以用于对 JSON 整数使用其它数据类型和语法分析程序 （比如 float ）。 parse_constant ，如果指定，将要与以下字符串中的一个一同调用： &#39;-Infinity&#39; ， &#39;Infinity&#39; ， &#39;NaN&#39; 。如果遇到无效的 JSON 数字则可以使用它引发异常。 在 3.1 版更改: parse_constant 不再调用 ‘null’ ， ‘true’ ， ‘false’ 。 要使用自定义的 JSONDecoder 子类，用 cls 指定他；否则使用 JSONDecoder 。额外的关键词参数会通过类的构造函数传递。 如果反序列化的数据不是有效 JSON 文档，引发 JSONDecodeError 错误。 在 3.6 版更改: 所有的可选参数现在是 keyword-only 的了。 在 3.6 版更改: fp 现在可以是 binary file 。输入编码应当是 UTF-8 ， UTF-16 或者 UTF-32 。 json.loads(s, , cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, kw*) 使用这个 转换表 将 s (一个包含 JSON 文档的 str, bytes 或 bytearray 实例) 反序列化为 Python 对象。 除了encoding被忽略和弃用自 Python 3.1 以来，其他参数的含义与 load() 中相同。 如果反序列化的数据不是有效 JSON 文档，引发 JSONDecodeError 错误。 Deprecated since version 3.1, will be removed in version 3.9: encoding 关键字参数。 在 3.6 版更改: s 现在可以为 bytes 或 bytearray 类型。 输入编码应为 UTF-8, UTF-16 或 UTF-32。 编码器和解码器 class json.JSONDecoder(**, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None*) 简单的JSON解码器。 默认情况下，解码执行以下翻译: | JSON | Python || :———— | :—– || object | dict || array | list || string | str || number (int) | int || number (real) | float || true | True || false | False || null | None | ​ 它还将“NaN”、“Infinity”和“-Infinity”理解为它们对应的“float”值，这超出了JSON规范。 ​ object_hook ，如果指定，会被每个解码的 JSON 对象的结果调用，并且返回值会替代给定 dict 。它可被用于提供自定义反序列化（比如去支持 JSON-RPC 类的暗示）。 如果指定了 object_pairs_hook 则它将被调用并传入以对照值有序列表进行解码的每个 JSON 对象的结果。 object_pairs_hook 的结果值将被用来替代 dict。 这一特性可被用于实现自定义解码器。 如果还定义了 object_hook，则 object_pairs_hook 的优先级更高。 在 3.1 版更改: 添加了对 object_pairs_hook 的支持。 parse_float ，如果指定，将与每个要解码 JSON 浮点数的字符串一同调用。默认状态下，相当于 float(num_str) 。可以用于对 JSON 浮点数使用其它数据类型和语法分析程序 （比如 decimal.Decimal ）。 parse_int ，如果指定，将与每个要解码 JSON 整数的字符串一同调用。默认状态下，相当于 int(num_str) 。可以用于对 JSON 整数使用其它数据类型和语法分析程序 （比如 float ）。 parse_constant ，如果指定，将要与以下字符串中的一个一同调用： &#39;-Infinity&#39; ， &#39;Infinity&#39; ， &#39;NaN&#39; 。如果遇到无效的 JSON 数字则可以使用它引发异常。 如果 strict 为 false （默认为 True ），那么控制字符将被允许在字符串内。在此上下文中的控制字符编码在范围 0–31 内的字符，包括 &#39;\t&#39; (制表符）， &#39;\n&#39; ， &#39;\r&#39; 和 &#39;\0&#39; 。 如果反序列化的数据不是有效 JSON 文档，引发 JSONDecodeError 错误。 在 3.6 版更改: 所有形参现在都是 仅限关键字参数。 decode(s) 返回 s 的 Python 表示形式（包含一个 JSON 文档的 str 实例）。 如果给定的 JSON 文档无效则将引发 JSONDecodeError。 raw_decode(s) 从 s 中解码出 JSON 文档（以 JSON 文档开头的一个 str 对象）并返回一个 Python 表示形式为 2 元组以及指明该文档在 s 中结束位置的序号。 这可以用于从一个字符串解码JSON文档，该字符串的末尾可能有无关的数据。 lass json.JSONEncoder(**, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None*) 用于Python数据结构的可扩展JSON编码器。 默认支持以下对象和类型： | Python | JSON || :———————————- | :—– || dict | object || list, tuple | array || str | string || int, float, int 和 float 派生的枚举 | number || True | true || False | false || None | null | 在 3.4 版更改: 添加了对 int 和 float 派生的枚举类的支持 为了将其拓展至识别其他对象，需要子类化并实现 default() 方法于另一种返回 o 的可序列化对象的方法如果可行，否则它应该调用超类实现（来引发 TypeError ）。 如果 skipkeys 为假值（默认），则尝试对不是 str, int, float 或 None 的键进行编码将会引发 TypeError。 如果 skipkeys 为真值，这些条目将被直接跳过。 如果 ensure_ascii 是 true （即默认值），输出保证将所有输入的非 ASCII 字符转义。如果 ensure_ascii 是 false，这些字符会原样输出。 如果 check_circular 为 true （默认），那么列表，字典，和自定义编码的对象在编码期间会被检查重复循环引用防止无限递归（无限递归将导致 OverflowError ）。否则，这样进行检查。 如果 allow_nan 为 true （默认），那么 NaN ， Infinity ，和 -Infinity 进行编码。此行为不符合 JSON 规范，但与大多数的基于 Javascript 的编码器和解码器一致。否则，它将是一个 ValueError 来编码这些浮点数。 如果 sort_keys 为 true （默认为： False ），那么字典的输出是按照键排序；这对回归测试很有用，以确保可以每天比较 JSON 序列化。 如果 indent 是一个非负整数或者字符串，那么 JSON 数组元素和对象成员会被美化输出为该值指定的缩进等级。如果缩进等级为零、负数或者 &quot;&quot;，则只会添加换行符。None（默认值）选择最紧凑的表达。使用一个正整数会让每一层缩进同样数量的空格。如果 *indent* 是一个字符串（比如 &quot;\t&quot;），那个字符串会被用于缩进每一层。 在 3.2 版更改: 允许使用字符串作为 indent 而不再仅仅是整数。 当指定时，separators 应当是一个 (item_separator, key_separator) 元组。当 indent 为 None 时，默认值取 (&#39;, &#39;, &#39;: &#39;)，否则取 (&#39;,&#39;, &#39;: &#39;)。为了得到最紧凑的 JSON 表达式，你应该指定其为 (&#39;,&#39;, &#39;:&#39;) 以消除空白字符。 在 3.4 版更改: 现当 indent 不是 None 时，采用 (&#39;,&#39;, &#39;: &#39;) 作为默认值。 当 default 被指定时，其应该是一个函数，每当某个对象无法被序列化时它会被调用。它应该返回该对象的一个可以被 JSON 编码的版本或者引发一个 TypeError。如果没有被指定，则会直接引发 TypeError。 在 3.6 版更改: 所有形参现在都是 仅限关键字参数。 default(o) 在子类中实现这种方法使其返回 o 的可序列化对象，或者调用基础实现（引发 TypeError ）。 比如说，为了支持任意迭代器，你可以像这样实现默认设置: 123456789def default(self, o): try: iterable = iter(o) except TypeError: pass else: return list(iterable) # Let the base class default method raise the TypeError return json.JSONEncoder.default(self, o) encode(o) 返回 Python o 数据结构的 JSON 字符串表达方式。例如: 12&gt;&gt;&gt; json.JSONEncoder().encode(&#123;"foo": ["bar", "baz"]&#125;)'&#123;"foo": ["bar", "baz"]&#125;' iterencode(o) 编码给定对象 o ，并且让每个可用的字符串表达方式。例如: 12for chunk in json.JSONEncoder().iterencode(bigobject): mysocket.write(chunk) 异常exception json.JSONDecodeError(msg, doc, pos) 拥有以下附加属性的 ValueError 的子类： msg 未格式化的错误消息。 doc 正在解析的 JSON 文档。 pos 从文档开始解析失败的索引 lineno 定位的行号 colno 定位的列号 标准符合性和互操作性JSON 格式由 RFC 7159 和 ECMA-404 指定。此段落详细讲了这个模块符合 RFC 的级别。简单来说， JSONEncoder 和 JSONDecoder 子类，和明确提到的参数以外的参数，不作考虑。 此模块不严格遵循于 RFC ，它实现了一些扩展是有效的 Javascript 但不是有效的 JSON。尤其是： 无限和 NaN 数值是被接受并输出； 对象内的重复名称是接受的，并且仅使用最后一对属性-值对的值。 自从 RFC 允许符合 RFC 的语法分析程序接收 不符合 RFC 的输入文本以来，这个模块的解串器在默认状态下默认符合 RFC 。 字符编码RFC 要求使用 UTF-8 ， UTF-16 ，或 UTF-32 之一来表示 JSON ，为了最大互通性推荐使用 UTF-8 。 RFC允许，尽管不是必须的，这个模块的序列化默认设置为 ensure_ascii=True ，这样消除输出以便结果字符串至容纳 ASCII 字符。 ensure_ascii 参数以外，此模块是严格的按照在 Python 对象和 Unicode strings 间的转换定义的，并且因此不能直接解决字符编码的问题。 RFC 禁止添加字符顺序标记（ BOM ）在 JSON 文本的开头，这个模块的序列化器不添加 BOM 标记在它的输出上。 RFC，准许 JSON 反序列化器忽略它们输入中的初始 BOM 标记，但不要求。此模块的反序列化器引发 ValueError 当存在初始 BOM 标记。 RFC 不会明确禁止包含字节序列的 JSON 字符串这不对应有效的 Unicode 字符（比如 不成对的 UTF-16 的替代物），但是它确实指出它们可能会导致互操作性问题。默认下，模块对这样的序列接受和输出（当在原始 str 存在时）代码点。 Infinite 和 NaN 数值RFC 不允许 infinite 或者 NaN 数值的表达方式。尽管这样，默认情况下，此模块接受并且输出 Infinity ， -Infinity，和 NaN 好像它们是有效的JSON数字字面值 12345678910&gt;&gt;&gt; # Neither of these calls raises an exception, but the results are not valid JSON&gt;&gt;&gt; json.dumps(float('-inf'))'-Infinity'&gt;&gt;&gt; json.dumps(float('nan'))'NaN'&gt;&gt;&gt; # Same when deserializing&gt;&gt;&gt; json.loads('-Infinity')-inf&gt;&gt;&gt; json.loads('NaN')nan 序列化器中， allow_nan 参数可用于替代这个行为。反序列化器中， parse_constant 参数，可用于替代这个行为。 对象中的重复名称RFC 具体说明了 在 JSON对象里的名字应该是唯一的，但没有规定如何处理JSON对象中的重复名称。默认下，此模块不引发异常；作为替代，对于给定名它将忽略除姓-值对之外的所有对: >&gt;&gt; 123&gt;&gt;&gt; weird_json = &apos;&#123;&quot;x&quot;: 1, &quot;x&quot;: 2, &quot;x&quot;: 3&#125;&apos;&gt;&gt;&gt; json.loads(weird_json)&#123;&apos;x&apos;: 3&#125; 参数 *object_pairs_hook* 可以改变这个行为 顶级非对象，非数组值老版本的JSON声明遵循RFC 4627 ,需要顶级的JSON 文本必须是JSON对象或数组(Python中的字典或列表),并且不能是null,boolean,number或字符串。RFC 7159 移除了这个限制,意味着无需在序列化和反序列化时实现该规范。 除此以外,为了获得最大限度的操作灵活性,你可以根据自己的实际情况选择是否遵循该规范。 实现限制一些json 实现可能有下面的限制: 可以接受的 JSON 文本大小 对象和数组的最大层数 JSON numbers的范围以及小数位数。 JSON字符串的内容和最大长度 json模块并不会强制这些限制,这取决于自定义Python数据类型自身的实现。 命令行界面 json.tool 模块实现了一个简易的命令行接口,用来验证和打印格式良好的JSON 对象。 如果没有设定可选参数infile and outfile,将会使用sys.stdin and sys.stdout 标准输入输出代替。 123456$ echo '&#123;"json": "obj"&#125;' | python -m json.tool&#123; "json": "obj"&#125;$ echo '&#123;1.2:3.4&#125;' | python -m json.toolExpecting property name enclosed in double quotes: line 1 column 2 (char 1) 命令行选项 infile JSON 文件校验或美化打印。 1234567891011$ python -m json.tool mp_films.json[ &#123; "title": "And Now for Something Completely Different", "year": 1971 &#125;, &#123; "title": "Monty Python and the Holy Grail", "year": 1975 &#125;] If infile is not specified, read from sys.stdin. outfile Write the output of the infile to the given outfile. Otherwise, write it to 输出到文件,如果没有设置则使用sys.stdout(标准输出) –sort-keys 根据输出的字典的键根据字母顺序排序 –json-lines 解析每一行作为单独的JSON对象 -h, --help 显示帮助信息]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library types]]></title>
    <url>%2F2020%2F02%2F07%2Fpython-standard-library-types%2F</url>
    <content type="text"><![CDATA[python 标准库 types 今天心情很沉重,李文亮医生一路走好！R.I.P https://v.youku.com/v_show/id_XNDQ1MTYyMDI4OA==.html 源码源代码: Lib/types.py 此模块定义了一些工具函数，用于协助动态创建新的类型。 它还为某些对象类型定义了名称，这些名称由标准 Python 解释器所使用，但并不像内置的 int 或 str 那样对外公开。 最后，它还额外提供了一些类型相关但重要程度不足以作为内置对象的工具类和函数。 动态类型创建 types.new_class(name, bases=(), kwds=None, exec_body=None) 使用适当的元类动态地创建一个类对象。 前三个参数是组成类定义头的部件：类名称，基类 (有序排列)，关键字参数 (例如 metaclass)。 exec_body 参数是一个回调函数，用于填充新创建类的命名空间。 它应当接受类命名空间作为其唯一的参数并使用类内容直接更新命名空间。 如果未提供回调函数，则它就等效于传入 lambda ns: ns。 3.3 新版功能. types.prepare_class(name, bases=(), kwds=None) 计算适当的元类并创建类命名空间。 参数是组成类定义头的部件：类名称，基类 (有序排列) 以及关键字参数 (例如 metaclass)。 返回值是一个 3 元组: metaclass, namespace, kwds metaclass 是适当的元类，namespace 是预备好的类命名空间而 kwds 是所传入 kwds 参数移除每个 &#39;metaclass&#39; 条目后的已更新副本。 如果未传入 kwds 参数，这将为一个空字典。 3.3 新版功能. 在 3.6 版更改: 所返回元组中 namespace 元素的默认值已被改变。 现在当元类没有 __prepare__ 方法时将会使用一个保留插入顺序的映射。 types.resolve_bases(bases) 动态地解析 MRO 条目，具体描述见 PEP 560。 此函数会在 bases 中查找不是 type 的实例的项，并返回一个元组，其中每个具有 __mro_entries__ 方法的此种对象对象将被替换为调用该方法解包后的结果。 如果一个 bases 项是 type 的实例，或它不具有 __mro_entries__ 方法，则它将不加改变地被包含在返回的元组中。 标准解释器类型此模块为许多类型提供了实现 Python 解释器所要求的名称。 它刻意地避免了包含某些仅在处理过程中偶然出现的类型，例如 listiterator 类型。 此种名称的典型应用如 isinstance() 或 issubclass() 检测。 如果你要实例化这些类型中的任何一种，请注意其签名在不同 Python 版本之间可能出现变化。 以下类型有相应的标准名称定义： types.FunctionType types.LambdaType 用户自定义函数以及由 lambda 表达式所创建函数的类型。 types.GeneratorType generator 迭代器对象的类型，由生成器函数创建。 types.CoroutineType coroutine 对象的类型，由 async def 函数创建。 types.AsyncGeneratorType asynchronous generator 迭代器对象的类型，由异步生成器函数创建。 class types.CodeType(kwargs) 代码对象的类型，例如 compile() 的返回值。 引发 审计事件 code.__new__ 附带参数 code, filename, name, argcount, posonlyargcount, kwonlyargcount, nlocals, stacksize, flags。 请注意被审核参数可能不匹配初始化器所要求的名称或位置。 replace(*kwargs*) 返回代码对象的一个副本，使用指定的新字段值。 types.CellType 单元对象的类型：这种对象被用作函数中自由变量的容器。 types.MethodType 用户自定义类实例方法的类型。 types.BuiltinFunctionType types.BuiltinMethodType 内置函数例如 len() 或 sys.exit() 以及内置类方法的类型。 （这里所说的“内置”是指“以 C 语言编写”。） types.WrapperDescriptorType 某些内置数据类型和基类的方法的类型，例如 object.__init__() 或 object.__lt__()。 types.MethodWrapperType 某些内置数据类型和基类的 绑定 方法的类型。 例如 object().__str__ 所属的类型。 types.MethodDescriptorType 某些内置数据类型方法例如 str.join() 的类型。 types.MethodDescriptorType 某些内置数据类型 非绑定 类方法例如 dict.__dict__[&#39;fromkeys&#39;] 的类型 types.ClassMethodDescriptorType 某些内置数据类型 非绑定 类方法例如 dict.__dict__[&#39;fromkeys&#39;] 的类型。 class types.ModuleType(name, doc=None) 模块 的类型。 构造器接受待创建模块的名称及其作为可选项 docstring。 如果你希望设置各种由导入控制的属性，请使用 importlib.util.module_from_spec() 来创建一个新模块。 __doc__ 模块的 docstring。 默认为 None。 __loader__ 用于加载模块的 loader。 默认为 None。在 3.4 版更改: 默认为 None。 之前该属性为可选项。 __name__ 模块的名字 __package__ 一个模块所属的 package。 如果模块为最高层级的（即不是任何特定包的组成部分）则该属性应设为 &#39;&#39;，否则它应设为特定包的名称 (如果模块本身也是一个包则名称可以为 __name__)。 默认为 None。 class types.TracebackType(tb_next, tb_frame, tb_lasti, tb_lineno) 回溯对象的类型，例如 sys.exc_info()[2] 中的对象。 请查看 语言参考 了解可用属性和操作的细节，以及动态地创建回溯对象的指南。 types.FrameType 帧对象的类型，例如 tb.tb_frame 中的对象，其中 tb 是一个回溯对象。请查看 语言参考 了解可用属性和操作的细节。 types.GetSetDescriptorType 使用 PyGetSetDef 在扩展模块中定义的对象的类型，例如 FrameType.f_locals 或 array.array.typecode。 此类型被用作对象属性的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 types.MemberDescriptorType 使用 PyMemberDef 在扩展模块中定义的对象的类型，例如 datetime.timedelta.days。 此类型被用作使用标准转换函数的简单 C 数据成员的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 CPython implementation detail: 在 Python 的其它实现中，此类型可能与 GetSetDescriptorType 完全相同。 class types.MappingProxyType(mapping) 一个映射的只读代理。 它提供了对映射条目的动态视图，这意味着当映射发生改变时，视图会反映这些改变。 3.3 新版功能. key in proxy 如果下层的映射中存在键 key 则返回 True，否则返回 False。 proxy[key] 返回下层的映射中以 key 为键的项。 如果下层的映射中不存在键 key 则引发 KeyError。 iter(proxy) 返回由下层映射的键为元素的迭代器。 这是 iter(proxy.keys()) 的快捷方式。 len(proxy) 返回下层映射中的项数。 copy() 返回下层映射的浅拷贝。 get(key[, default]) 如果 key 存在于下层映射中则返回 key 的值，否则返回 default。 如果 default 未给出则默认为 None，因而此方法绝不会引发 KeyError。 items() 返回由下层映射的项 ((键, 值) 对) 组成的一个新视图。 keys() 返回由下层映射的键组成的一个新视图。 values() 返回由下层映射的值组成的一个新视图。 附加工具类和函数 class* types.SimpleNamespace 一个简单的 object 子类，提供了访问其命名空间的属性，以及一个有意义的 repr。 不同于 object，对于 SimpleNamespace 你可以添加和移除属性。 如果一个 SimpleNamespace 对象使用关键字参数进行初始化，这些参数会被直接加入下层命名空间。 此类型大致等价于以下代码: 1234567891011class SimpleNamespace: def __init__(self, /, **kwargs): self.__dict__.update(kwargs) def __repr__(self): keys = sorted(self.__dict__) items = ("&#123;&#125;=&#123;!r&#125;".format(k, self.__dict__[k]) for k in keys) return "&#123;&#125;(&#123;&#125;)".format(type(self).__name__, ", ".join(items)) def __eq__(self, other): return self.__dict__ == other.__dict__ SimpleNamespace 可被用于替代 class NS: pass。 但是，对于结构化记录类型则应改用 namedtuple()。 types.DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None) 在类上访问 getattr 的路由属性。 这是一个描述器，用于定义通过实例与通过类访问时具有不同行为的属性。 当实例访问时保持正常行为，但当类访问属性时将被路由至类的 getattr 方法；这是通过引发 AttributeError 来完成的。 这样就允许有在实例上激活的特征属性，同时又有在类上的同名虚拟属性（一个这样的例子是 Enum）。 协程工具函数 types.coroutine(gen_func) 此函数可将 generator 函数转换为返回基于生成器的协程的 coroutine function。 基于生成器的协程仍然属于 generator iterator，但同时又可被视为 coroutine 对象兼 awaitable。 不过，它没有必要实现 __await__() 方法。 如果 gen_func 是一个生成器函数，它将被原地修改。 如果 gen_func 不是一个生成器函数，则它会被包装。 如果它返回一个 collections.abc.Generator 的实例，该实例将被包装在一个 awaitable 代理对象中。 所有其他对象类型将被原样返回。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>types</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library statistics]]></title>
    <url>%2F2020%2F02%2F06%2Fpython-standard-library-statistics%2F</url>
    <content type="text"><![CDATA[python 标准库 statistics 数学统计函数 I have self-doubt. I have insecurity. I have fear of failure. I have nights when I show up at the arena and I’m like, ‘My back hurts, my feet hurt, my knees hurt. I don’t have it. I just want to chill.’ We all have self-doubt. You don’t deny it, but you also don’t capitulate to it. You embrace it.我有自我怀疑。我有不安全感。我害怕失败。当我出现在竞技场的时候，我会说，‘我的背疼，我的脚疼，我的膝盖疼。我没有打赢的信心。我只是想冷静一下。’我们都有自我怀疑。你不要否认，但你也不屈服于它。你要拥抱它。 ​ by Kobe Bryant 源码源代码: Lib/statistics.py 主要方法 123456789101112131415================== ==================================================Function Description================== ==================================================mean Arithmetic mean (average) of data.fmean Fast, floating point arithmetic mean.geometric_mean Geometric mean of data.harmonic_mean Harmonic mean of data.median Median (middle value) of data.median_low Low median of data.median_high High median of data.median_grouped Median, or 50th percentile, of grouped data.mode Mode (most common value) of data.multimode List of modes (most common values of data).quantiles Divide data into intervals with equal probability.================== ================================================== 该模块提供了用于计算数字 (Real-valued) 数据的数理统计量的函数。 此模块并不是诸如 NumPy ， SciPy 等第三方库或者诸如 Minitab ， SAS ， Matlab 等针对专业统计学家的专有全功能统计软件包的竟品。此模块针对图形和科学计算器的水平。 除非明确注释，这些函数支持 int ， float ， Decimal 和 Fraction 。当前不支持同其他类型（是否在数字塔中）的行为。混合类型的集合也是未定义的，并且依赖于实现。如果你输入的数据由混合类型组成，你应该能够使用 map() 来确保一个一致的结果，比如： map(float, input_data) 。 中心位置的平均值和度量 这些函数计算一个整体或样本的平均值或者特定值 mean() 数据的算术平均数（“平均数”）。 fmean() 快速的，浮点算数平均数。 geometric_mean() 数据的几何平均数 harmonic_mean() 数据的调和均值 median() 数据的中位数（中间值） median_low() 数据的低中位数 median_high() 数据的高中位数 median_grouped() 分组数据的中位数，即第50个百分点。 mode() 离散的或标称的数据的单模（最常见的值）。 multimode() 离散的或标称的数据的模式列表（最常见的值）。 quantiles() 将数据以相等的概率分为多个间隔。 传播措施这些函数计算多少总体或者样本偏离典型值或平均值的度量。 pstdev() 数据的总体标准差 pvariance() 数据的总体方差 stdev() 数据的样本标准差 variance() 数据的样本方差 函数细节这些函数不需要对提供给它们的数据进行排序。但是，为了方便阅读，大多数例子展示的是已排序的序列。 statistics.mean(data) 返回 data 的样本算术平均数，形式为序列或迭代器。算术平均数是数据之和与数据点个数的商。通常称作“平均数”，尽管它指示诸多数学平均数之一。它是数据的中心位置的度量。若 data 为空，将会引发 StatisticsError。一些用法示例： 123456789101112&gt;&gt;&gt; mean([1, 2, 3, 4, 4])2.8&gt;&gt;&gt; mean([-1.0, 2.5, 3.25, 5.75])2.625&gt;&gt;&gt; from fractions import Fraction as F&gt;&gt;&gt; mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])Fraction(13, 21)&gt;&gt;&gt; from decimal import Decimal as D&gt;&gt;&gt; mean([D("0.5"), D("0.75"), D("0.625"), D("0.375")])Decimal('0.5625') statistics.fmean(data) 123将浮点数转换成 data 并且计算算术平均数。此函数的运行速度比 mean() 函数快并且它总是返回一个 float。 data 可以为序列或迭代器。 如果输入数据集为空，则会引发 StatisticsError。 statistics.geometric_mean(data) 返回 data 调和均值，该参数可以是序列或包含实数值的可迭代对象。 调和均值,也叫次相反均值，所有数据的倒数的算术平均数 mean() 的倒数。比如说，数据 a ， b ， c 的调和均值等于 3/(1/a + 1/b + 1/c) 。如果其中一个值为零，结果为零。 调和均值是一种均值类型，是数据中心位置的度量。它通常适合于求比率和比例的平均值，比如速率。 假设一辆车在 40 km/hr 的速度下行驶了 10 km ，然后又以 60 km/hr 的速度行驶了 10 km 。车辆的平均速率是多少？ 12&gt;&gt;&gt; harmonic_mean([40, 60])48.0 假设一名投资者在三家公司各购买了等价值的股票，以 2.5， 3 ， 10 的 P/E (价格/收益) 率。投资者投资组合的平均市盈率是多少？ 12&gt;&gt;&gt; harmonic_mean([2.5, 3, 10]) # For an equal investment portfolio.3.6 如果 data 为空或者 任何一个元素的值小于零，会引发 StatisticsError 。 当前算法在输入中遇到零时会提前退出。这意味着不会测试后续输入的有效性。（此行为将来可能会更改。） statistics.median(data) 使用普通的“取中间两数平均值”方法返回数值数据的中位数（中间值）。 如果 data 为空，则将引发 StatisticsError。 data 可以是序列或可迭代对象。 中位数是衡量中间位置的可靠方式，并且较少受到极端值的影响。 当数据点的总数为奇数时，将返回中间数据点： 12&gt;&gt;&gt; median([1, 3, 5])3 当数据点的总数为偶数时，中位数将通过对两个中间值求平均进行插值得出： 12&gt;&gt;&gt; median([1, 3, 5, 7])4.0 这适用于当你的数据是离散的，并且你不介意中位数不是实际数据点的情况。 如果数据是有序的（支持排序操作）但不是数字（不支持加法），请考虑改用 median_low() 或 median_high()。 statistics.median_low(data) 返回数值数据的低中位数。 如果 data 为空则将引发 StatisticsError。 data 可以是序列或可迭代对象。 低中位数一定是数据集的成员。 当数据点总数为奇数时，将返回中间值。 当其为偶数时，将返回两个中间值中较小的那个。 1234&gt;&gt;&gt; median_low([1, 3, 5])3&gt;&gt;&gt; median_low([1, 3, 5, 7])3 当你的数据是离散的，并且你希望中位数是一个实际数据点而非插值结果时可以使用低中位数。 statistics.median_high(data) ​ 返回数据的高中位数。 如果 data 为空则将引发 StatisticsError。 data 可以是序列或可迭代对象。 高中位数一定是数据集的成员。 当数据点总数为奇数时，将返回中间值。 当其为偶数时，将返回两个中间值中较大的那个。 1234&gt;&gt;&gt; median_high([1, 3, 5])3&gt;&gt;&gt; median_high([1, 3, 5, 7])5 当你的数据是离散的，并且你希望中位数是一个实际数据点而非插值结果时可以使用高中位数。 statistics.median_grouped(data, interval=1) 返回分组的连续数据的中位数，根据第 50 个百分点的位置使用插值来计算。 如果 data 为空则将引发 StatisticsError。 data 可以是序列或可迭代对象。 12&gt;&gt;&gt; median_grouped([52, 52, 53, 54])52.5 在下面的示例中，数据已经过舍入，这样每个值都代表数据分类的中间点，例如 1 是 0.5–1.5 分类的中间点，2 是 1.5–2.5 分类的中间点，3 是 2.5–3.5 的中间点等待。 根据给定的数据，中间值应落在 3.5–4.5 分类之内，并可使用插值法来进行估算： 12&gt;&gt;&gt; median_grouped([1, 2, 2, 3, 4, 4, 4, 4, 4, 5])3.7 可选参数 interval 表示分类间隔，默认值为 1。 改变分类间隔自然会改变插件结果： 1234&gt;&gt;&gt; median_grouped([1, 3, 3, 5, 7], interval=1)3.25&gt;&gt;&gt; median_grouped([1, 3, 3, 5, 7], interval=2)3.5 此函数不会检查数据点之间是否至少相隔 interval 的距离。 statistics.mode(data) 根据离散或标称的 data 返回单个最觉的数据点。 此模式（如果存在）是最典型的值，并可用来度量中心的位置。 如果存在具有相同频率的多个模式，则返回在 data 中遇到的第一个。 如果想要其中最小或最大的一个，请使用 min(multimode(data)) 或 max(multimode(data))。 如果输入的 data 为空，则会引发 StatisticsError。 mode 将假定是离散数据并返回一个单一的值。 这是通常的学校教学中标准的处理方式： 12&gt;&gt;&gt; mode([1, 1, 2, 3, 3, 3, 3, 4])3 此模式的独特之处在于它是这个包中唯一还可应用于标称（非数字）数据的统计信息： 12&gt;&gt;&gt; mode([&quot;red&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;])&apos;red&apos; 在 3.8 版更改: 现在会通过返回所遇到的第一个模式来处理多模数据集。 之前它会在遇到超过一个的模式时引发 StatisticsError。 statistics.multimode(data) 返回最频繁出现的值的列表，并按它们在 data 中首次出现的位置排序。 如果存在多种模式则将返回一个以上的模式，或者如果 data 为空则将返回空列表： 1234&gt;&gt;&gt; multimode('aabbbbccddddeeffffgg')['b', 'd', 'f']&gt;&gt;&gt; multimode('')[] 3.8 新版功能. statistics.pstdev(data, mu=None) 返回总体标准差（总体方差的平方根）。 请参阅 pvariance() 了解参数和其他细节。 12&gt;&gt;&gt; pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])0.986893273527251 statistics.pvariance(data, mu=None) 返回非空序列或包含实数值的可迭代对象 data 的总体方差。 方差或称相对于均值的二阶距，是对数据变化幅度（延展度或分散度）的度量。 方差值较大表明数据的散布范围较大；方差值较小表明它紧密聚集于均值附近。 如果给出了可选的第二个参数 mu，它通常是 data 的均值。 它也可以被用来计算相对于一个非均值点的二阶距。 如果该参数省略或为 None (默认值)，则会自动进行算术均值的计算。 使用此函数可根据所有数值来计算方差。 要根据一个样本来估算方差，通常 variance() 函数是更好的选择。 如果 data 为空则会引发 StatisticsError。 示例： 123&gt;&gt;&gt; data = [0.0, 0.25, 0.25, 1.25, 1.5, 1.75, 2.75, 3.25]&gt;&gt;&gt; pvariance(data)1.25 如果你已经计算过数据的平均值，你可以将其作为可选的第二个参数 mu 传入以避免重复计算： 123&gt;&gt;&gt; mu = mean(data)&gt;&gt;&gt; pvariance(data, mu)1.25 同样也支持使用 Decimal 和 Fraction 值： 1234567&gt;&gt;&gt; from decimal import Decimal as D&gt;&gt;&gt; pvariance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])Decimal('24.815')&gt;&gt;&gt; from fractions import Fraction as F&gt;&gt;&gt; pvariance([F(1, 4), F(5, 4), F(1, 2)])Fraction(13, 72) statistics.stdev(data, xbar=None) 返回样本标准差（样本方差的平方根）。 请参阅 variance() 了解参数和其他细节。 12&gt;&gt;&gt; stdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])1.0810874155219827 statistics.variance(data, xbar=None) 返回包含至少两个实数值的可迭代对象 data 的样本方差。 方差或称相对于均值的二阶矩，是对数据变化幅度（延展度或分散度）的度量。 方差值较大表明数据的散布范围较大；方差值较小表明它紧密聚集于均值附近。 如果给出了可选的第二个参数 xbar，它应当是 data 的均值。 如果该参数省略或为 None (默认值)，则会自动进行均值的计算。 当你的数据是总体数据的样本时请使用此函数。 要根据整个总体数据来计算方差，请参见 pvariance()。 如果 data 包含的值少于两个则会引发 StatisticsError。 示例： 123&gt;&gt;&gt; data = [2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]&gt;&gt;&gt; variance(data)1.3720238095238095 如果你已经计算过数据的平均值，你可以将其作为可选的第二个参数 xbar 传入以避免重复计算： 123&gt;&gt;&gt; m = mean(data)&gt;&gt;&gt; variance(data, m)1.3720238095238095 此函数不会试图检查你所传入的 xbar 是否为真实的平均值。 使用任意值作为 xbar 可能导致无效或不可能的结果。 同样也支持使用 Decimal 和 Fraction 值： 1234567&gt;&gt;&gt; from decimal import Decimal as D&gt;&gt;&gt; variance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])Decimal('31.01875')&gt;&gt;&gt; from fractions import Fraction as F&gt;&gt;&gt; variance([F(1, 6), F(1, 2), F(5, 3)])Fraction(67, 108) statistics.quantiles(data, **, n=4, method=’exclusive’*) 将 data 分隔为具有相等概率的 n 个连续区间。 返回分隔这些区间的 n - 1 个分隔点的列表。 将 n 设为 4 以使用四分位（默认值）。 将 n 设为 10 以使用十分位。 将 n 设为 100 以使用百分位，即给出 99 个分隔点来将 data 分隔为 100 个大小相等的组。 如果 n 小于 1 则将引发 StatisticsError。 data 可以是包含样本数据的任意可迭代对象。 为了获得有意义的结果，data 中数据点的数量应当大于 n。 如果数据点的数量小于两个则将引发 StatisticsError。 分隔点是通过对两个最接近的数据点进行线性插值得到的。 例如，如果一个分隔点落在两个样本值 100 和 112 之间距离三分之一的位置，则分隔点的取值将为 104。 method 用于计算分位值，它会由于 data 是包含还是排除总体的最低和最高可能值而有所不同。 默认 method 是 “唯一的” 并且被用于在总体中数据采样这样可以有比样本中找到的更多的极端值。落在 m 个排序数据点的第 i-th 个以下的总体部分被计算为 i / (m + 1) 。给定九个样本值，方法排序它们并且分配一下的百分位： 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90% 。 将 method 设为 “inclusive” 可用于描述总体数据或已明确知道包含有总体数据中最极端值的样本。 data 中的最小值会被作为第 0 个百分位而最大值会被作为第 100 个百分位。 总体数据里处于 m 个已排序数据点中 第 i 个 以下的部分会以 (i - 1) / (m - 1) 来计算。 给定 11 个样本值，该方法会对它们进行排序并赋予以下百分位: 0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%。 12345678# Decile cut points for empirically sampled data&gt;&gt;&gt; data = [105, 129, 87, 86, 111, 111, 89, 81, 108, 92, 110,... 100, 75, 105, 103, 109, 76, 119, 99, 91, 103, 129,... 106, 101, 84, 111, 74, 87, 86, 103, 103, 106, 86,... 111, 75, 87, 102, 121, 111, 88, 89, 101, 106, 95,... 103, 107, 101, 81, 109, 104]&gt;&gt;&gt; [round(q, 1) for q in quantiles(data, n=10)][81.0, 86.2, 89.0, 99.4, 102.5, 103.6, 106.0, 109.8, 111.0] 3.8 新版功能. 异常只定义了一个异常： exception statistics.StatisticsError ValueError 的子类，表示统计相关的异常。 NormalDist对象NormalDist 工具可用于创建和操纵 随机变量 的正态分布。 这个类将数据度量值的平均值和标准差作为单一实体来处理。 正态分布的概念来自于 中央极限定理 并且在统计学中有广泛的应用。 class statistics.NormalDist(mu=0.0, sigma=1.0 返回一个新的 NormalDist 对象，其中 mu 代表 算术平均值 而 sigma 代表 标准差。 若 sigma 为负数，将会引发 StatisticsError。 mean 一个只读特征属性，表示特定正态分布的 算术平均值。 median 一个只读特征属性，表示特定正态分布的 中位数。 mode 一个只读特征属性，表示特定正态分布的 模式)。 stdev 一个只读特征属性，表示特定正态分布的 标准差。 variance¶ 一个只读特征属性，表示特定正态分布的 方差。 等于标准差的平方 classmethod from_samples(data) 传入使用 fmean() 和 stdev() 基于 data 估算出的 mu 和 sigma 形参创建一个正态分布实例。data 可以是任何 iterable 并且应当包含能被转换为 float 类型的值。 如果 data 不包含至少两个元素，则会引发 StatisticsError，因为估算中心值至少需要一个点而估算分散度至少需要两个点。 samples(n, **, seed=None*) 对于给定的平均值和标准差生成 n 个随机样本。 返回一个由 float 值组成的 list。当给定 seed 时，创建一个新的底层随机数生成器实例。 这适用于创建可重现的结果，即使对于多线程上下文也有效。 pdf(x) 使用 概率密度函数 (pdf)，计算一个随机变量 X 趋向于给定值 x 的相对可能性。 在数学意义上，它是当 dx 趋向于零时比率 P(x &lt;= X &lt; x+dx) / dx 的极限。相对可能性的计算方法是用一个狭窄区间内某个样本出现的概率除以区间的宽度（因此使用“密度”一词）。 由于可能性是相对于其他点的，它的值可以大于 1.0。 cdf(x) 使用 累积分布函数 (cdf)，计算一个随机变量 X 小于等于 x 的概率。 在数学上，它表示为 P(X &lt;= x)。 inv_cdf(p) 计算反向累积分布函数，也称为 分位数函数 或 百分点 函数。 在数学上，它表示为 x : P(X &lt;= x) = p。找出随机变量 X 的值 x 使得该变量小于等于该值的概率等于给定的概率 p。 overlap(other) 测量两个正态概率分布之间的一致性。 返回介于 0.0 和 1.0 之间的值，给出 两个概率密度函数的重叠区域。 quantiles(n=4) 将指定正态分布划分为 n 个相等概率的连续分隔区。 返回这些分隔区对应的 (n - 1) 个分隔点的列表。将 n 设为 4 以使用四分位（默认值）。 将 n 设为 10 以使用十分位。将 n 设为 100 以使用百分位，即给出 99 个分隔点来将正态分布分隔为 100 个大小相等的组。 NormalDist 的实例支持加上、减去、乘以或除以一个常量。 这些运算被用于转换和缩放。 例如： 123&gt;&gt;&gt; temperature_february = NormalDist(5, 2.5) # Celsius&gt;&gt;&gt; temperature_february * (9/5) + 32 # FahrenheitNormalDist(mu=41.0, sigma=4.5) 不允许一个常量除以 NormalDist 的实例，因为结果将不是正态分布。 由于正态分布是由独立变量的累加效应产生的，因此允许表示为 NormalDist 实例的 两组独立正态分布的随机变量相加和相减。 例如： 1234567&gt;&gt;&gt; birth_weights = NormalDist.from_samples([2.5, 3.1, 2.1, 2.4, 2.7, 3.5])&gt;&gt;&gt; drug_effects = NormalDist(0.4, 0.15)&gt;&gt;&gt; combined = birth_weights + drug_effects&gt;&gt;&gt; round(combined.mean, 1)3.1&gt;&gt;&gt; round(combined.stdev, 1)0.5 NormalDist 示例和用法NormalDist 适合用来解决经典概率问题。 举例来说，如果 SAT 考试的历史数据 显示分数呈平均值为 1060 且标准差为 195 的正态分布，则可以确定考试分数处于 1100 和 1200 之间的学生的百分比舍入到最接近的整数应为： 1234&gt;&gt;&gt; sat = NormalDist(1060, 195)&gt;&gt;&gt; fraction = sat.cdf(1200 + 0.5) - sat.cdf(1100 - 0.5)&gt;&gt;&gt; round(fraction * 100.0, 1)18.4 求 SAT 分数的 四分位 和 十分位： 1234&gt;&gt;&gt; list(map(round, sat.quantiles()))[928, 1060, 1192]&gt;&gt;&gt; list(map(round, sat.quantiles(n=10)))[810, 896, 958, 1011, 1060, 1109, 1162, 1224, 1310] 为了估算一个不易解析的模型分布，NormalDist 可以生成用于 蒙特卡洛模拟 的输入样本： 123456789&gt;&gt;&gt; def model(x, y, z):... return (3*x + 7*x*y - 5*y) / (11 * z)...&gt;&gt;&gt; n = 100_000&gt;&gt;&gt; X = NormalDist(10, 2.5).samples(n, seed=3652260728)&gt;&gt;&gt; Y = NormalDist(15, 1.75).samples(n, seed=4582495471)&gt;&gt;&gt; Z = NormalDist(50, 1.25).samples(n, seed=6582483453)&gt;&gt;&gt; quantiles(map(model, X, Y, Z)) [1.4591308524824727, 1.8035946855390597, 2.175091447274739] 当样本量较大并且成功试验的可能性接近 50% 时，正态分布可以被用来模拟 二项分布。 例如，一次开源会议有 750 名与会者和两个可分别容纳 500 人的会议厅。 会上有一场关于 Python 的演讲和一场关于 Ruby 的演讲。 在往届会议中，65% 的与会者更愿意去听关于 Python 的演讲。 假定人群的偏好没有发生改变，那么 Python 演讲的会议厅不超出其容量上限的可能性是多少？ 12345678910111213141516171819202122&gt;&gt;&gt; n = 750 # Sample size&gt;&gt;&gt; p = 0.65 # Preference for Python&gt;&gt;&gt; q = 1.0 - p # Preference for Ruby&gt;&gt;&gt; k = 500 # Room capacity&gt;&gt;&gt; # Approximation using the cumulative normal distribution&gt;&gt;&gt; from math import sqrt&gt;&gt;&gt; round(NormalDist(mu=n*p, sigma=sqrt(n*p*q)).cdf(k + 0.5), 4)0.8402&gt;&gt;&gt; # Solution using the cumulative binomial distribution&gt;&gt;&gt; from math import comb, fsum&gt;&gt;&gt; round(fsum(comb(n, r) * p**r * q**(n-r) for r in range(k+1)), 4)0.8402&gt;&gt;&gt; # Approximation using a simulation&gt;&gt;&gt; from random import seed, choices&gt;&gt;&gt; seed(8675309)&gt;&gt;&gt; def trial():... return choices(('Python', 'Ruby'), (p, q), k=n).count('Python')&gt;&gt;&gt; mean(trial() &lt;= k for i in range(10_000))0.8398 在机器学习问题中也经常会出现正态分布。 Wikipedia 上有一个 朴素贝叶斯分类器的好例子。 挑战的问题是根据对多个正态分布的特征测量值包括身高、体重和足部尺码来预测一个人的性别。 我们得到了由八个人的测量值组成的训练数据集。 假定这些测量值是正态分布的，因此我们用 NormalDist 来总结数据： 123456&gt;&gt;&gt; height_male = NormalDist.from_samples([6, 5.92, 5.58, 5.92])&gt;&gt;&gt; height_female = NormalDist.from_samples([5, 5.5, 5.42, 5.75])&gt;&gt;&gt; weight_male = NormalDist.from_samples([180, 190, 170, 165])&gt;&gt;&gt; weight_female = NormalDist.from_samples([100, 150, 130, 150])&gt;&gt;&gt; foot_size_male = NormalDist.from_samples([12, 11, 12, 10])&gt;&gt;&gt; foot_size_female = NormalDist.from_samples([6, 8, 7, 9]) 接下来，我们遇到一个特征测量值已知但性别未知的新人： 123&gt;&gt;&gt; ht = 6.0 # height&gt;&gt;&gt; wt = 130 # weight&gt;&gt;&gt; fs = 8 # foot size 从是男是女各 50% 的 先验概率 出发，我们通过将该先验概率乘以给定性别的特征度量值的可能性累积值来计算后验概率： 1234567&gt;&gt;&gt; prior_male = 0.5&gt;&gt;&gt; prior_female = 0.5&gt;&gt;&gt; posterior_male = (prior_male * height_male.pdf(ht) *... weight_male.pdf(wt) * foot_size_male.pdf(fs))&gt;&gt;&gt; posterior_female = (prior_female * height_female.pdf(ht) *... weight_female.pdf(wt) * foot_size_female.pdf(fs)) 最终预测值应为最大后验概率值。 这种算法被称为 maximum a posteriori 或 MAP： 12&gt;&gt;&gt; 'male' if posterior_male &gt; posterior_female else 'female''female']]></content>
      <categories>
        <category>python</category>
        <category>standard_libray</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>statistics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library uuid]]></title>
    <url>%2F2020%2F02%2F05%2Fpython-standard-library-uuid%2F</url>
    <content type="text"><![CDATA[python 标准库 之 uuid 何谓UUID1234567891011121314151617181920212223242526272829303132UUID是128位的全局唯一标识符，通常由32字节的字符串表示。 它可以保证时间和空间的唯一性，也称为GUID，全称为： UUID —— Universally Unique IDentifier Python 中叫 UUID UUID -- java.util.UUID Java 中也叫 UUID GUID —— Globally Unique IDentifier C# 中叫 GUID 它通过MAC地址、时间戳、命名空间、随机数、伪随机数来保证生成ID的唯一性。 UUID主要有五个算法，也就是五种方法来实现： 1、uuid1()——基于时间戳 由MAC地址、当前时间戳、随机数生成。可以保证全球范围内的唯一性， 但MAC的使用同时带来安全性问题，局域网中可以使用IP来代替MAC。 2、uuid2()——基于分布式计算环境DCE（Python中没有这个函数） 算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。 实际中很少用到该方法。 3、uuid3()——基于名字的MD5散列值 通过计算名字和命名空间的MD5散列值得到，保证了同一命名空间中不同名字的唯一性， 和不同命名空间的唯一性，但同一命名空间的同一名字生成相同的uuid。 4、uuid4()——基于随机数 由伪随机数得到，有一定的重复概率，该概率可以计算出来。 5、uuid5()——基于名字的SHA-1散列值 算法与uuid3相同，不同的是使用 Secure Hash Algorithm 1 算法 源码 Source code: Lib/uuid.py uuid模块包括：不可变对象UUID（UUID类）和函数uuid1()、uuid3()、uuid4()和uuid5()，后面的四个函数用于生成 RFC 4122 规范中指定的第1、3、4、5版UUID。使用uuid1()或uuid4()可以获得一个唯一的ID，uuid1()包含了主机的网络名称，uuid4()不涉及网络主机名，仅生成一个随机UUID，因此从隐私保护角度uuid4()更加安全。 枚举类型的SafeUUID 类 class uuid.SafeUUID 123safe = 0unsafe = -1unknown = None UUID 类(接口)基本语法:class uuid.UUID(hex=None, bytes=None, bytes_le=None, fields=None, int=None, version=None, **, is_safe=SafeUUID.unknown*) 下面的各种方法创建相同的UUID对象， 12345678UUID('&#123;12345678-1234-5678-1234-567812345678&#125;')UUID('12345678123456781234567812345678')UUID('urn:uuid:12345678-1234-5678-1234-567812345678')UUID(bytes=b'\x12\x34\x56\x78'*4)UUID(bytes_le=b'\x78\x56\x34\x12\x34\x12\x78\x56' + b'\x12\x34\x56\x78\x12\x34\x56\x78')UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))UUID(int=0x12345678123456781234567812345678) 其中: 如果尝试比较一个非UUID对象会引发TypeError使用str()函数强制转换一个uuid对象,将会生成一个从12345678-1234-5678-1234-567812345678.中创建的字符串 只读属性 UUID.bytes 指定一个大端字节序的总长16字节的字节串来创建UUID对象； 123&gt;&gt;&gt; u = uuid.UUID('&#123;12345678-1234-5678-1234-567812345678&#125;')&gt;&gt;&gt; u.bytesb'\x124Vx\x124Vx\x124Vx\x124Vx' UUID.bytes_le 指定一个小端字节序的总长16字节的字节串来创建UUID对象； 12&gt;&gt;&gt; u.bytes_leb'xV4\x124\x12xV\x124Vx\x124Vx' UUID.fields 以元组形式存放的UUID的6个整数域，有六个单独的属性和两个派生属性： | 域 | 意义 || :———————————————————– | :——————— || time_low | UUID的前32位 || time_mid | 接前一域的16位 || time_hi_version | 接前一域的16位 || clock_seq_hi_variant | 接前一域的8位 || clock_seq_low | 接前一域的8位 || node | UUID的最后48位 || time | UUID的总长60位的时间戳 || clock_seq | 14位的序列号 | 12&gt;&gt;&gt; u.fields(305419896, 4660, 22136, 18, 52, 95073701484152) UUID.hex 以32个字符表示的UUID 12&gt;&gt;&gt; u.hex'12345678123456781234567812345678' UUID.int 以一个长度为128个二进制位的整数表示的UUID； 12&gt;&gt;&gt; u.int24197857161011715162171839636988778104 UUID.urn 以 RFC 4122 中指定的URN形式表示的UUID； 12&gt;&gt;&gt; u.urn'urn:uuid:12345678-1234-5678-1234-567812345678' UUID.variant UUID变体（variant），决定UUID内部的布局，已有的值为 RESERVED_NCS、RFC_4122、RESERVED_MICROSOFT 或 RESERVED_FUTURE； 12&gt;&gt;&gt; u.variant'reserved for NCS compatibility' UUID.version 返回UUID的版本 12&gt;&gt;&gt; u.version&gt;&gt;&gt; 这里由于u.variant == ‘reserved for NCS compatibility’，所以此处u.version为空。 UUID.is_safe 枚举类型的SafeUUID对象,为了标识创建的UUID是否是线程安全的。 12&gt;&gt;&gt; u.is_safe&lt;SafeUUID.unknown: None&gt; 常量 关于属性variant，uuid模块定义了如下的常量 uuid.RESERVED_NCS 该常量为兼容NCS而保留； uuid.RFC_4122 按照 RFC 4122 的规定来确定UUID的布局； uuid.RESERVED_MICROSOFT 该常量位兼容微软而保留 uuid.RESERVED_FUTURE 该常量为未来可能的定义保留 12345678910可以在Python中查看这些常量：&gt;&gt;&gt; uuid.RESERVED_NCS'reserved for NCS compatibility'&gt;&gt;&gt; uuid.RFC_4122'specified in RFC 4122'&gt;&gt;&gt; uuid.RESERVED_MICROSOFT'reserved for Microsoft compatibility'&gt;&gt;&gt; uuid.RESERVED_FUTURE'reserved for future definition' 方法 uuid.getnode() 获取硬件的地址并以48位二进制长度的正整数形式返回，这里所说的硬件地址是指网络接口的MAC地址，如果一个机器有多个网络接口，可能返回其中的任一个。如果获取失败，将按照RFC 4122的规定将随机返回的48位二进制整数的第8位设置成1。 12&gt;&gt;&gt; uuid.getnode()202960192043486 uuid.uuid1(node=None, clock_seq=None) 利用主机ID、序列号和当前时间生成一个UUID，如果参数 node 没有给定，会调用 getnode() 来获取硬件地址。如果参数中指定了 clock_seq ，使用参数中给定的时钟序列作为序列号，否则使用一个随机的14位长的序列号。 12&gt;&gt;&gt; uuid.uuid1()UUID('97344912-4827-11ea-9c91-b8975a2679de') uuid.uuid3(namespace, name) 基于命名空间标识符（实质上是一个UUID）和一个名称（实质上是一个字符串）的MD5哈希值生成UUID。 uuid.uuid4() 生成一个随机的UUID。 12&gt;&gt;&gt; uuid.uuid4()UUID('ff3c991e-df64-4cfc-900e-ef83c991b513') uuid.uuid5(namespace, name) 基于命名空间标识符（实质上是一个UUID）和一个名称（实质上是一个字符串）的SHA-1哈希值生成UUID 下面的几个标准uuid在使用uuid3() 或uuid5()的时候使用 uuid.NAMESPACE_DNS 当指定该命名空间时，参数 name 是一个完全限定的（fully-qualified）域名 uuid.NAMESPACE_URL 当指定该命名空间时，参数 name 是一个URL uuid.NAMESPACE_OID 当指定该命名空间时，参数 name 是一个ISO OID uuid.NAMESPACE_X500 当指定该命名空间时，参数 name 是一个DER格式或文本格式的X.500 DN。 实例1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; import uuid&gt;&gt;&gt; # make a UUID based on the host ID and current time&gt;&gt;&gt; uuid.uuid1()UUID('a8098c1a-f86e-11da-bd1a-00112444be1e')&gt;&gt;&gt; # make a UUID using an MD5 hash of a namespace UUID and a name&gt;&gt;&gt; uuid.uuid3(uuid.NAMESPACE_DNS, 'python.org')UUID('6fa459ea-ee8a-3ca4-894e-db77e160355e')&gt;&gt;&gt; # make a random UUID&gt;&gt;&gt; uuid.uuid4()UUID('16fd2706-8baf-433b-82eb-8c7fada847da')&gt;&gt;&gt; # make a UUID using a SHA-1 hash of a namespace UUID and a name&gt;&gt;&gt; uuid.uuid5(uuid.NAMESPACE_DNS, 'python.org')UUID('886313e1-3b8a-5372-9b90-0c9aee199e5d')&gt;&gt;&gt; # make a UUID from a string of hex digits (braces and hyphens ignored)&gt;&gt;&gt; x = uuid.UUID('&#123;00010203-0405-0607-0809-0a0b0c0d0e0f&#125;')&gt;&gt;&gt; # convert a UUID to a string of hex digits in standard form&gt;&gt;&gt; str(x)'00010203-0405-0607-0809-0a0b0c0d0e0f'&gt;&gt;&gt; # get the raw 16 bytes of the UUID&gt;&gt;&gt; x.bytesb'\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f'&gt;&gt;&gt; # make a UUID from a 16-byte string&gt;&gt;&gt; uuid.UUID(bytes=x.bytes)UUID('00010203-0405-0607-0809-0a0b0c0d0e0f') 补充如何去除UUID字符串中的横杠1234uid = str(uuid.uuid4())suid = ''.join(uid.split('-'))## 等价于print(uuid.uuid1().hex)]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>uuid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library urllib robotparser]]></title>
    <url>%2F2020%2F02%2F04%2Fpython-standard-library-urllib-robotparser%2F</url>
    <content type="text"><![CDATA[python 标准库 urllib.robotparser 一切终将过去,我们仍旧前行,如同黑暗中的舞者。 ​ – 临风语录 源码源代码： Lib/urllib/robotparser.py robotparser 实现了一个用于分析 robots.txt 文件格式的解析器， 它含有一个检查给定用户代理是否可以访问给定资源的函数。它的目的是给那些品行端正的爬虫用的，或用来指导需要节流，否则就会被限制访问的其他抓取器。 robots.txt robots.txt 文件是一个简单的基于文本的访问控制系统，用于控制那些自动访问网络资源的程序（如「爬虫」，「抓取器」，等等）。文件由特定的用户代理程序标识的记录以及代理不允许访问的 URLs （或 URL 前缀） 的一个列表组成。 以我的博客为例 1234567891011121314# hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://pinghailinfeng.gitee.io/sitemap.xmlSitemap: https://pinghailinfeng.gitee.io/baidusitemap.xml 允许所有爬虫访问内容 123User-Agent: *Allow: /Allow: /archives/ 不允许爬虫访问的内容 123456Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/ 函数class urllib.robotparser.RobotFileParser(url=’’) 核心类通过下面方法读取、解析 通过url访问的robots.txt文件 set_url(url) 设定需要读取 robots.txt文件url路径 read() 读取制定URL路径对应的 robots.txt 文件 parse(lines) 解析参数指定的行 can_fetch(useragent, url) 如果useragent被允许抓取url对应的robots.txt文件中包含了允许的规则,则返回True mtime() 返回最后一次抓取robots.txt文件的时间。这是一个对长时间运行的网络爬虫用检查周期性robots.txt文件是否更新的很有用的方法。 modified() 设定最后一次抓取 robots.txt 文件的时间。 crawl_delay(useragent) 返回 从robots.txt 中 useragent定义的 Crawl-delay 的值。如果没有这个参数或 在useragent中声明的参数格式不正确,返回None。 3.6 新版功能. request_rate(useragent) 返回作为命名元组类型的从 robots.txt 文件中 定义的 Request-rate参数内容。如果没有这个参数或在 robots.txt 文件中定义的useragent参数格式不正确,则返回None。 3.6 新版功能. site_maps() 返回 list() 类型的Sitemap参数内容。如果参数不存在或参数格式不正确,都返回None。 官方栗子123456789101112131415&gt;&gt;&gt; import urllib.robotparser&gt;&gt;&gt; rp = urllib.robotparser.RobotFileParser()&gt;&gt;&gt; rp.set_url("http://www.musi-cal.com/robots.txt")&gt;&gt;&gt; rp.read()&gt;&gt;&gt; rrate = rp.request_rate("*")&gt;&gt;&gt; rrate.requests3&gt;&gt;&gt; rrate.seconds20&gt;&gt;&gt; rp.crawl_delay("*")6&gt;&gt;&gt; rp.can_fetch("*", "http://www.musi-cal.com/cgi-bin/search?city=San+Francisco")False&gt;&gt;&gt; rp.can_fetch("*", "http://www.musi-cal.com/")True 分析知乎1234567891011121314151617181920212223242526272829303132"""分析知乎 Robots 协议"""import urllib.robotparserrp = urllib.robotparser.RobotFileParser()# 设置 robots.txt 文件 URLrp.set_url('https://www.zhihu.com/robots.txt')# 读取操作必须有, 不然后面解析不到rp.read()# 判断网址是否运行爬取print(rp.can_fetch('Googlebot', 'https://www.zhihu.com/question/264161961/answer/278828570'))print(rp.can_fetch('*', 'https://www.zhihu.com/question/264161961/answer/278828570'))# 返回上次抓取分析 robots.txt 时间print(rp.mtime())# 将当前时间设置为上次抓取和分析 robots.txt 的时间rp.modified()print(rp.mtime()) # 再次打印时间会有变化# 返回 robots.txt 文件对请求速率限制的值print(rp.request_rate('*'))print(rp.request_rate('MSNBot').requests)# 返回 robotx.txt 文件对抓取延迟限制的值print(rp.crawl_delay('*'))print(rp.crawl_delay('MSNBot')) 分析我自己博客12345678910111213141516171819202122232425262728293031import urllib.robotparserblog_url = 'https://pinghailinfeng.gitee.io/robots.txt'rp = urllib.robotparser.RobotFileParser()# 设置 robots.txt 文件 URLrp.set_url(blog_url)# 读取操作必须有, 不然后面解析不到rp.read()# 判断网址是否运行爬取print(rp.can_fetch('*','https://pinghailinfeng.gitee.io/archives/'))# 返回上次抓取分析 robots.txt 时间print(rp.mtime())# 将当前时间设置为上次抓取和分析 robots.txt 的时间rp.modified()print(rp.mtime()) # 再次打印时间会有变化&gt;&gt;&gt; print(rp.crawl_delay('*'))&gt;&gt;&gt; print(rp.site_maps())&gt;&gt;&gt; True&gt;&gt;&gt; 1580804333.889091&gt;&gt;&gt; 1580804333.889091&gt;&gt;&gt; None&gt;&gt;&gt; ['https://pinghailinfeng.gitee.io/sitemap.xml', 'https://pinghailinfeng.gitee.io/baidusitemap.xml']]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>urllib.robotparser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library itertools]]></title>
    <url>%2F2020%2F02%2F03%2Fpython-standard-library-itertools%2F</url>
    <content type="text"><![CDATA[python 标准库 itertools 为高效循环而创建迭代器的函数本模块实现一系列 iterator ，这些迭代器受到APL，Haskell和SML的启发。为了适用于Python，它们都被重新写过。 本模块标准化了一个快速、高效利用内存的核心工具集，这些工具本身或组合都很有用。它们一起形成了“迭代器代数”，这使得在纯Python中有可能创建简洁又高效的专用工具。 例如，SML有一个制表工具： tabulate(f)，它可产生一个序列 f(0), f(1), ...。在Python中可以组合 map() 和 count() 实现： map(f, count())。 这些内置工具同时也能很好地与 operator 模块中的高效函数配合使用。例如，我们可以将两个向量的点积映射到乘法运算符： sum(map(operator.mul, vector1, vector2)) 。 无穷迭代器： 迭代器 实参 结果 示例 count() start, [step] start, start+step, start+2*step, … count(10) --&gt; 10 11 12 13 14 ... cycle() p p0, p1, … plast, p0, p1, … cycle(&#39;ABCD&#39;) --&gt; A B C D A B C D ... repeat() elem [,n] elem, elem, elem, … 重复无限次或n次 repeat(10, 3) --&gt; 10 10 10 根据最短输入序列长度停止的迭代器： 迭代器 实参 结果 示例 accumulate() p [,func] p0, p0+p1, p0+p1+p2, … accumulate([1,2,3,4,5]) --&gt; 1 3 6 10 15 chain() p, q, … p0, p1, … plast, q0, q1, … chain(&#39;ABC&#39;, &#39;DEF&#39;) --&gt; A B C D E F chain.from_iterable() iterable p0, p1, … plast, q0, q1, … chain.from_iterable([&#39;ABC&#39;, &#39;DEF&#39;]) --&gt; A B C D E F compress() data, selectors (d[0] if s[0]), (d[1] if s[1]), … compress(&#39;ABCDEF&#39;, [1,0,1,0,1,1]) --&gt; A C E F dropwhile() pred, seq seq[n], seq[n+1], … 从pred首次真值测试失败开始 dropwhile(lambda x: x&lt;5, [1,4,6,4,1]) --&gt; 6 4 1 filterfalse() pred, seq seq中pred(x)为假值的元素，x是seq中的元素。 filterfalse(lambda x: x%2, range(10)) --&gt; 0 2 4 6 8 groupby() iterable[, key] 根据key(v)值分组的迭代器 islice() seq, [start,] stop [, step] seq[start:stop:step]中的元素 islice(&#39;ABCDEFG&#39;, 2, None) --&gt; C D E F G starmap() func, seq func(seq[0]), func(seq[1]), … starmap(pow, [(2,5), (3,2), (10,3)]) --&gt; 32 9 1000 takewhile() pred, seq seq[0], seq[1], …, 直到pred真值测试失败 takewhile(lambda x: x&lt;5, [1,4,6,4,1]) --&gt; 1 4 tee() it, n it1, it2, … itn 将一个迭代器拆分为n个迭代器 zip_longest() p, q, … (p[0], q[0]), (p[1], q[1]), … zip_longest(&#39;ABCD&#39;, &#39;xy&#39;, fillvalue=&#39;-&#39;) --&gt; Ax By C- D- 排列组合迭代器： 迭代器 实参 结果 product() p, q, … [repeat=1] 笛卡尔积，相当于嵌套的for循环 permutations() p[, r] 长度r元组，所有可能的排列，无重复元素 combinations() p, r 长度r元组，有序，无重复元素 combinations_with_replacement() p, r 长度r元组，有序，元素可重复 例子 结果 product(&#39;ABCD&#39;, repeat=2) AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD permutations(&#39;ABCD&#39;, 2) AB AC AD BA BC BD CA CB CD DA DB DC combinations(&#39;ABCD&#39;, 2) AB AC AD BC BD CD combinations_with_replacement(&#39;ABCD&#39;, 2) AA AB AC AD BB BC BD CC CD DD Itertools数下列模块函数均创建并返回迭代器。有些迭代器不限制输出流长度，所以它们只应在能截断输出流的函数或循环中使用。 itertools.accumulate(iterable[, func, **, initial=None*]) 创建一个迭代器，返回累积汇总值或其他双目运算函数的累积结果值（通过可选的 func 参数指定）。如果提供了 func，它应当为带有两个参数的函数。 输入 iterable 的元素可以是能被 func 接受为参数的任意类型。 （例如，对于默认的加法运算，元素可以是任何可相加的类型包括 Decimal 或 Fraction。）通常，输出的元素数量与输入的可迭代对象是一致的。 但是，如果提供了关键字参数 initial，则累加会以 initial 值开始，这样输出就比输入的可迭代对象多一个元素。大致相当于： 12345678910111213141516def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --&gt; 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --&gt; 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --&gt; 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total func 参数有几种用法。它可以被设为 min() 最终得到一个最小值，或者设为 max() 最终得到一个最大值，或设为 operator.mul() 最终得到一个乘积。摊销表可通过累加利息和支付款项得到。给iterable设置初始值并只将参数 func 参数有几种用法。它可以被设为 min() 最终得到一个最小值，或者设为 max() 最终得到一个最大值，或设为 operator.mul() 最终得到一个乘积。摊销表可通过累加利息和支付款项得到。给iterable设置初始值并只将参数 func 设为累加总数可以对一阶 递归关系 建模。 123456789101112131415161718192021&gt;&gt;&gt; data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]&gt;&gt;&gt; list(accumulate(data, operator.mul)) # running product[3, 12, 72, 144, 144, 1296, 0, 0, 0, 0]&gt;&gt;&gt; list(accumulate(data, max)) # running maximum[3, 4, 6, 6, 6, 9, 9, 9, 9, 9]# Amortize a 5% loan of 1000 with 4 annual payments of 90&gt;&gt;&gt; cashflows = [1000, -90, -90, -90, -90]&gt;&gt;&gt; list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt))[1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001]# Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map&gt;&gt;&gt; logistic_map = lambda x, _: r * x * (1 - x)&gt;&gt;&gt; r = 3.8&gt;&gt;&gt; x0 = 0.4&gt;&gt;&gt; inputs = repeat(x0, 36) # only the initial value is used&gt;&gt;&gt; [format(x, '.2f') for x in accumulate(inputs, logistic_map)]['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] 参考一个类似函数 functools.reduce() ，它只返回一个最终累积值。 3.2 新版功能. 在 3.3 版更改: 增加可选参数 func 。 在 3.8 版更改: 添加了可选的 initial 形参。 itertools.chain(iterables) 创建一个迭代器，它首先返回第一个可迭代对象中所有元素，接着返回下一个可迭代对象中所有元素，直到耗尽所有可迭代对象中的元素。可将多个序列处理为单个序列。大致相当于： 12345def chain(*iterables): # chain('ABC', 'DEF') --&gt; A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) 构建类似 chain() 迭代器的另一个选择。从一个单独的可迭代参数中得到链式输入，该参数是延迟计算的。大致相当于： 12345def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --&gt; A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) 返回由输入 iterable 中元素组成长度为 r 的子序列。组合按照字典序返回。所以如果输入 iterable 是有序的，生成的组合元组也是有序的。即使元素的值相同，不同位置的元素也被认为是不同的。如果元素各自不同，那么每个组合中没有重复元素。大致相当于: 12345678910111213141516171819def combinations(iterable, r): # combinations('ABCD', 2) --&gt; AB AC AD BC BD CD # combinations(range(4), 3) --&gt; 012 013 023 123 pool = tuple(iterable) n = len(pool) if r &gt; n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) combinations() 的代码可被改写为 permutations() 过滤后的子序列，（相对于元素在输入中的位置）元素不是有序的。 123456def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) 当 0 &lt;= r &lt;= n 时，返回项的个数是 n! / r! / (n-r)!；当 r &gt; n 时，返回项个数为0。 itertools.combinations_with_replacement(iterable, r) 返回由输入 iterable 中元素组成的长度为 r 的子序列，允许每个元素可重复出现。组合按照字典序返回。所以如果输入 iterable 是有序的，生成的组合元组也是有序的。不同位置的元素是不同的，即使它们的值相同。因此如果输入中的元素都是不同的话，返回的组合中元素也都会不同。大致相当于： 12345678910111213141516def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --&gt; AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) combinations_with_replacement() 的代码可被改写为production()` 过滤后的子序列，（相对于元素在输入中的位置）元素不是有序的。 123456def combinations_with_replacement(iterable, r): pool = tuple(iterable) n = len(pool) for indices in product(range(n), repeat=r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) itertools.compress(data, selectors) 创建一个迭代器，它返回 data 中经 selectors 真值测试为 True 的元素。迭代器在两者较短的长度处停止。大致相当于： 123def compress(data, selectors): # compress('ABCDEF', [1,0,1,0,1,1]) --&gt; A C E F return (d for d, s in zip(data, selectors) if s) itertools.count(start=0, step=1) 创建一个迭代器，它从 start 值开始，返回均匀间隔的值。常用于 map() 中的实参来生成连续的数据点。此外，还用于 zip() 来添加序列号。大致相当于： 12345678 def count(start=0, step=1): # count(10) --&gt; 10 11 12 13 14 ... # count(2.5, 0.5) -&gt; 2.5 3.0 3.5 ... n = start while True: yield n n += step~ 当对浮点数计数时，替换为乘法代码有时精度会更好，例如： (start + step * i for i in count()) 。在 3.1 版更改: 增加参数 step ，允许非整型。 itertools.cycle(iterable) 创建一个迭代器，返回 iterable 中所有元素并保存一个副本。当取完 iterable 中所有元素，返回副本中的所有元素。无限重复。大致相当于： 123456789def cycle(iterable): # cycle('ABCD') --&gt; A B C D A B C D A B C D ... saved = [] for element in iterable: yield element saved.append(element) while saved: for element in saved: yield element `注意，该函数可能需要相当大的辅助空间（取决于 iterable 的长度）。 itertools.dropwhile(predicate, iterable) 创建一个迭代器，如果 predicate 为true，迭代器丢弃这些元素，然后返回其他元素。注意，迭代器在 predicate 首次为false之前不会产生任何输出，所以可能需要一定长度的启动时间。大致相当于： 123456789def dropwhile(predicate, iterable): # dropwhile(lambda x: x&lt;5, [1,4,6,4,1]) --&gt; 6 4 1 iterable = iter(iterable) for x in iterable: if not predicate(x): yield x break for x in iterable: yield x itertools.filterfalse(predicate, iterable) 创建一个迭代器，只返回 iterable 中 predicate 为 False 的元素。如果 predicate 是 None，返回真值测试为false的元素。大致相当于： 1234567def filterfalse(predicate, iterable): # filterfalse(lambda x: x%2, range(10)) --&gt; 0 2 4 6 8 if predicate is None: predicate = bool for x in iterable: if not predicate(x): yield x itertools.groupby(iterable, key=None) 创建一个迭代器，返回 iterable 中连续的键和组。key 是一个计算元素键值函数。如果未指定或为 None，key 缺省为恒等函数（identity function），返回元素不变。一般来说，iterable 需用同一个键值函数预先排序。 groupby() 操作类似于Unix中的 uniq。当每次 key 函数产生的键值改变时，迭代器会分组或生成一个新组（这就是为什么通常需要使用同一个键值函数先对数据进行排序）。这种行为与SQL的GROUP BY操作不同，SQL的操作会忽略输入的顺序将相同键值的元素分在同组中。 返回的组本身也是一个迭代器，它与 groupby() 共享底层的可迭代对象。因为源是共享的，当 groupby() 对象向后迭代时，前一个组将消失。因此如果稍后还需要返回结果，可保存为列表： 123456groups = []uniquekeys = []data = sorted(data, key=keyfunc)for k, g in groupby(data, keyfunc): groups.append(list(g)) # Store group iterator as a list uniquekeys.append(k) groupby() 大致相当于： 1234567891011121314151617181920212223242526class groupby: # [k for k, g in groupby('AAAABBBCCDAABBB')] --&gt; A B C D A B # [list(g) for k, g in groupby('AAAABBBCCD')] --&gt; AAAA BBB CC D def __init__(self, iterable, key=None): if key is None: key = lambda x: x self.keyfunc = key self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() def __iter__(self): return self def __next__(self): self.id = object() while self.currkey == self.tgtkey: self.currvalue = next(self.it) # Exit on StopIteration self.currkey = self.keyfunc(self.currvalue) self.tgtkey = self.currkey return (self.currkey, self._grouper(self.tgtkey, self.id)) def _grouper(self, tgtkey, id): while self.id is id and self.currkey == tgtkey: yield self.currvalue try: self.currvalue = next(self.it) except StopIteration: return self.currkey = self.keyfunc(self.currvalue) itertools.islice(iterable, stop) itertools.islice(iterable, start, stop[, step]) 创建一个迭代器，返回从 iterable 里选中的元素。如果 start 不是0，跳过 iterable 中的元素，直到到达 start 这个位置。之后迭代器连续返回元素，除非 step 设置的值很高导致被跳过。如果 stop 为 None，迭代器耗光为止；否则，在指定的位置停止。与普通的切片不同，islice() 不支持将 start ， stop ，或 step 设为负值。可用来从内部数据结构被压平的数据中提取相关字段（例如一个多行报告，它的名称字段出现在每三行上）。大致相当于： 123456789101112131415161718192021222324def islice(iterable, *args): # islice('ABCDEFG', 2) --&gt; A B # islice('ABCDEFG', 2, 4) --&gt; C D # islice('ABCDEFG', 2, None) --&gt; C D E F G # islice('ABCDEFG', 0, None, 2) --&gt; A C E G s = slice(*args) start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1 it = iter(range(start, stop, step)) try: nexti = next(it) except StopIteration: # Consume *iterable* up to the *start* position. for i, element in zip(range(start), iterable): pass return try: for i, element in enumerate(iterable): if i == nexti: yield element nexti = next(it) except StopIteration: # Consume to *stop*. for i, element in zip(range(i + 1, stop), iterable): pass 如果 start 为 None，迭代从0开始。如果 step 为 None ，步长缺省为1。 itertools.permutations(iterable, r=None) 连续返回由 iterable 元素生成长度为 r 的排列。如果 r 未指定或为 None ，r 默认设置为 iterable 的长度，这种情况下，生成所有全长排列。排列依字典序发出。因此，如果 iterable 是已排序的，排列元组将有序地产出。即使元素的值相同，不同位置的元素也被认为是不同的。如果元素值都不同，每个排列中的元素值不会重复。大致相当于： 123456789101112131415161718192021222324def permutations(iterable, r=None): # permutations('ABCD', 2) --&gt; AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --&gt; 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r &gt; n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return permutations() 的代码也可被改写为 product() 的子序列，只要将含有重复元素（来自输入中同一位置的）的项排除。 1234567def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) 当 0 &lt;= r &lt;= n ，返回项个数为 n! / (n-r)! ；当 r &gt; n ，返回项个数为0。 itertools.product(*iterables, repeat=1) 可迭代对象输入的笛卡儿积。大致相当于生成器表达式中的嵌套循环。例如， product(A, B) 和 ((x,y) for x in A for y in B) 返回结果一样。 嵌套循环像里程表那样循环变动，每次迭代时将最右侧的元素向后迭代。这种模式形成了一种字典序，因此如果输入的可迭代对象是已排序的，笛卡尔积元组依次序发出。 要计算可迭代对象自身的笛卡尔积，将可选参数 repeat 设定为要重复的次数。例如，product(A, repeat=4) 和 product(A, A, A, A) 是一样的。 该函数大致相当于下面的代码，只不过实际实现方案不会在内存中创建中间结果。 123456789def product(*args, repeat=1): # product('ABCD', 'xy') --&gt; Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --&gt; 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) itertools.repeat(object[, times]) 创建一个迭代器，不断重复 object 。除非设定参数 times ，否则将无限重复。可用于 map() 函数中的参数，被调用函数可得到一个不变参数。也可用于 zip() 的参数以在元组记录中创建一个不变的部分。大致相当于： 12345678def repeat(object, times=None): # repeat(10, 3) --&gt; 10 10 10 if times is None: while True: yield object else: for i in range(times): yield object repeat 最常见的用途就是在 map 或 zip 提供一个常量流： 12&gt;&gt;&gt; list(map(pow, range(10), repeat(2)))[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] itertools.starmap(function, iterable) 创建一个迭代器，使用从可迭代对象中获取的参数来计算该函数。当参数对应的形参已从一个单独可迭代对象组合为元组时（数据已被“预组对”）可用此函数代替 map()。map() 与 starmap() 之间的区别可以类比 1234def starmap(function, iterable): # starmap(pow, [(2,5), (3,2), (10,3)]) --&gt; 32 9 1000 for args in iterable: yield function(*args) itertools.takewhile(predicate, iterable) 创建一个迭代器，只要 predicate 为真就从可迭代对象中返回元素。大致相当于: 1234567def takewhile(predicate, iterable): # takewhile(lambda x: x&lt;5, [1,4,6,4,1]) --&gt; 1 4 for x in iterable: if predicate(x): yield x else: break itertools.tee(iterable, n=2) 从一个可迭代对象中返回 n 个独立的迭代器。下面的Python代码能帮助解释 tee 做了什么（尽管实际的实现更复杂，而且仅使用了一个底层的 FIFO 队列）。大致相当于： 1234567891011121314def tee(iterable, n=2): it = iter(iterable) deques = [collections.deque() for i in range(n)] def gen(mydeque): while True: if not mydeque: # when the local deque is empty try: newval = next(it) # fetch a new value and except StopIteration: return for d in deques: # load it to all the deques d.append(newval) yield mydeque.popleft() return tuple(gen(d) for d in deques) 一旦 tee() 实施了一次分裂，原有的 iterable 不应再被使用；否则tee对象无法得知 iterable 可能已向后迭代。 tee 迭代器不是线程安全的。当同时使用由同一个 tee() 调用所返回的迭代器时可能引发 RuntimeError，即使原本的 iterable 是线程安全的。 该迭代工具可能需要相当大的辅助存储空间（这取决于要保存多少临时数据）。通常，如果一个迭代器在另一个迭代器开始之前就要使用大部份或全部数据，使用 list() 会比 tee() 更快。 itertools.zip_longest(*iterables, fillvalue=None) 创建一个迭代器，从每个可迭代对象中收集元素。如果可迭代对象的长度未对齐，将根据 fillvalue 填充缺失值。迭代持续到耗光最长的可迭代对象。大致相当于： 12345678910111213141516171819def zip_longest(*args, fillvalue=None): # zip_longest('ABCD', 'xy', fillvalue='-') --&gt; Ax By C- D- iterators = [iter(it) for it in args] num_active = len(iterators) if not num_active: return while True: values = [] for i, it in enumerate(iterators): try: value = next(it) except StopIteration: num_active -= 1 if not num_active: return iterators[i] = repeat(fillvalue) value = fillvalue values.append(value) yield tuple(values) 如果其中一个可迭代对象有无限长度，zip_longest() 函数应封装在限制调用次数的场景中（例如 islice() 或 takewhile()）。除非指定， fillvalue 默认为 None 。 itertools 扩展本节将展示如何使用现有的 itertools 作为基础构件来创建扩展的工具集。 基本上所有这些西方和许许多多其他的配方都可以通过 Python Package Index 上的 more-itertools 项目 来安装: 1pip install more-itertools 扩展的工具提供了与底层工具集相同的高性能。保持了超棒的内存利用率，因为一次只处理一个元素，而不是将整个可迭代对象加载到内存。代码量保持得很小，以函数式风格将这些工具连接在一起，有助于消除临时变量。速度依然很快，因为倾向于使用“矢量化”构件来取代解释器开销大的 for 循环和 generator 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211def take(n, iterable): "Return first n items of the iterable as a list" return list(islice(iterable, n))def prepend(value, iterator): "Prepend a single value in front of an iterator" # prepend(1, [2, 3, 4]) -&gt; 1 2 3 4 return chain([value], iterator)def tabulate(function, start=0): "Return function(0), function(1), ..." return map(function, count(start))def tail(n, iterable): "Return an iterator over the last n items" # tail(3, 'ABCDEFG') --&gt; E F G return iter(collections.deque(iterable, maxlen=n))def consume(iterator, n=None): "Advance the iterator n-steps ahead. If n is None, consume entirely." # Use functions that consume iterators at C speed. if n is None: # feed the entire iterator into a zero-length deque collections.deque(iterator, maxlen=0) else: # advance to the empty slice starting at position n next(islice(iterator, n, n), None)def nth(iterable, n, default=None): "Returns the nth item or a default value" return next(islice(iterable, n, None), default)def all_equal(iterable): "Returns True if all the elements are equal to each other" g = groupby(iterable) return next(g, True) and not next(g, False)def quantify(iterable, pred=bool): "Count how many times the predicate is true" return sum(map(pred, iterable))def padnone(iterable): """Returns the sequence elements and then returns None indefinitely. Useful for emulating the behavior of the built-in map() function. """ return chain(iterable, repeat(None))def ncycles(iterable, n): "Returns the sequence elements n times" return chain.from_iterable(repeat(tuple(iterable), n))def dotproduct(vec1, vec2): return sum(map(operator.mul, vec1, vec2))def flatten(list_of_lists): "Flatten one level of nesting" return chain.from_iterable(list_of_lists)def repeatfunc(func, times=None, *args): """Repeat calls to func with specified arguments. Example: repeatfunc(random.random) """ if times is None: return starmap(func, repeat(args)) return starmap(func, repeat(args, times))def pairwise(iterable): "s -&gt; (s0,s1), (s1,s2), (s2, s3), ..." a, b = tee(iterable) next(b, None) return zip(a, b)def grouper(iterable, n, fillvalue=None): "Collect data into fixed-length chunks or blocks" # grouper('ABCDEFG', 3, 'x') --&gt; ABC DEF Gxx" args = [iter(iterable)] * n return zip_longest(*args, fillvalue=fillvalue)def roundrobin(*iterables): "roundrobin('ABC', 'D', 'EF') --&gt; A D E B F C" # Recipe credited to George Sakkis num_active = len(iterables) nexts = cycle(iter(it).__next__ for it in iterables) while num_active: try: for next in nexts: yield next() except StopIteration: # Remove the iterator we just exhausted from the cycle. num_active -= 1 nexts = cycle(islice(nexts, num_active))def partition(pred, iterable): 'Use a predicate to partition entries into false entries and true entries' # partition(is_odd, range(10)) --&gt; 0 2 4 6 8 and 1 3 5 7 9 t1, t2 = tee(iterable) return filterfalse(pred, t1), filter(pred, t2)def powerset(iterable): "powerset([1,2,3]) --&gt; () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)" s = list(iterable) return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))def unique_everseen(iterable, key=None): "List unique elements, preserving order. Remember all elements ever seen." # unique_everseen('AAAABBBCCDAABBB') --&gt; A B C D # unique_everseen('ABBCcAD', str.lower) --&gt; A B C D seen = set() seen_add = seen.add if key is None: for element in filterfalse(seen.__contains__, iterable): seen_add(element) yield element else: for element in iterable: k = key(element) if k not in seen: seen_add(k) yield elementdef unique_justseen(iterable, key=None): "List unique elements, preserving order. Remember only the element just seen." # unique_justseen('AAAABBBCCDAABBB') --&gt; A B C D A B # unique_justseen('ABBCcAD', str.lower) --&gt; A B C A D return map(next, map(operator.itemgetter(1), groupby(iterable, key)))def iter_except(func, exception, first=None): """ Call a function repeatedly until an exception is raised. Converts a call-until-exception interface to an iterator interface. Like builtins.iter(func, sentinel) but uses an exception instead of a sentinel to end the loop. Examples: iter_except(functools.partial(heappop, h), IndexError) # priority queue iterator iter_except(d.popitem, KeyError) # non-blocking dict iterator iter_except(d.popleft, IndexError) # non-blocking deque iterator iter_except(q.get_nowait, Queue.Empty) # loop over a producer Queue iter_except(s.pop, KeyError) # non-blocking set iterator """ try: if first is not None: yield first() # For database APIs needing an initial cast to db.first() while True: yield func() except exception: passdef first_true(iterable, default=False, pred=None): """Returns the first true value in the iterable. If no true value is found, returns *default* If *pred* is not None, returns the first item for which pred(item) is true. """ # first_true([a,b,c], x) --&gt; a or b or c or x # first_true([a,b], x, f) --&gt; a if f(a) else b if f(b) else x return next(filter(pred, iterable), default)def random_product(*args, repeat=1): "Random selection from itertools.product(*args, **kwds)" pools = [tuple(pool) for pool in args] * repeat return tuple(random.choice(pool) for pool in pools)def random_permutation(iterable, r=None): "Random selection from itertools.permutations(iterable, r)" pool = tuple(iterable) r = len(pool) if r is None else r return tuple(random.sample(pool, r))def random_combination(iterable, r): "Random selection from itertools.combinations(iterable, r)" pool = tuple(iterable) n = len(pool) indices = sorted(random.sample(range(n), r)) return tuple(pool[i] for i in indices)def random_combination_with_replacement(iterable, r): "Random selection from itertools.combinations_with_replacement(iterable, r)" pool = tuple(iterable) n = len(pool) indices = sorted(random.randrange(n) for i in range(r)) return tuple(pool[i] for i in indices)def nth_combination(iterable, r, index): 'Equivalent to list(combinations(iterable, r))[index]' pool = tuple(iterable) n = len(pool) if r &lt; 0 or r &gt; n: raise ValueError c = 1 k = min(r, n-r) for i in range(1, k+1): c = c * (n - k + i) // i if index &lt; 0: index += c if index &lt; 0 or index &gt;= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index &gt;= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>itertools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library copy]]></title>
    <url>%2F2020%2F02%2F02%2Fpython-standard-library-copy%2F</url>
    <content type="text"><![CDATA[python 标准库 copy 源码 源代码: Lib/copy.py 类层次结构 1234Interface summary: import copy x = copy.copy(y) # make a shallow copy of y x = copy.deepcopy(y) # make a deep copy of y Python 中赋值语句不复制对象，而是在目标和对象之间创建绑定 (bindings) 关系。对于自身可变或者包含可变项的集合对象，开发者有时会需要生成其副本用于改变操作，进而避免改变原对象。本模块提供了通用的浅层复制和深层复制操作（如下所述）。 接口摘要： copy.copy(x) 返回 x 的浅层复制。 copy.deepcopy(x[, memo]) 返回 x 的深层复制。 exception copy.error 针对模块特定错误引发。 浅层复制和深层复制之间的区别仅与复合对象 (即包含其他对象的对象，如列表或类的实例) 相关: 一个 浅层复制 会构造一个新的复合对象，然后（在可能的范围内）将原对象中找到的 引用 插入其中。 一个 深层复制 会构造一个新的复合对象，然后递归地将原始对象中所找到的对象的 副本 插入。 深度复制操作通常存在两个问题, 而浅层复制操作并不存在这些问题： 递归对象 (直接或间接包含对自身引用的复合对象) 可能会导致递归循环。 由于深层复制会复制所有内容，因此可能会过多复制（例如本应该在副本之间共享的数据）。 The deepcopy() function avoids these problems by: 保留在当前复制过程中已复制的对象的 “备忘录” （memo） 字典；以及 允许用户定义的类重载复制操作或复制的组件集合。 该模块不复制模块、方法、栈追踪（stack trace）、栈帧（stack frame）、文件、套接字、窗口、数组以及任何类似的类型。它通过不改变地返回原始对象来（浅层或深层地）“复制”函数和类；这与 pickle 模块处理这类问题的方式是相似的。 制作字典的浅层复制可以使用 dict.copy() 方法，而制作列表的浅层复制可以通过赋值整个列表的切片完成，例如，copied_list = original_list[:]。 类可以使用与控制序列化（pickling）操作相同的接口来控制复制操作，关于这些方法的描述信息请参考 pickle 模块。实际上，copy 模块使用的正是从 copyreg 模块中注册的 pickle 函数。 想要给一个类定义它自己的拷贝操作实现，可以通过定义特殊方法 __copy__() 和 __deepcopy__()。 调用前者以实现浅层拷贝操作，该方法不用传入额外参数。 调用后者以实现深层拷贝操作；它应传入一个参数即 memo 字典。 如果 __deepcopy__() 实现需要创建一个组件的深层拷贝，它应当调用 deepcopy() 函数并以该组件作为第一个参数，而将 memo 字典作为第二个参数。 实例字典拷贝1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import copy def displayList(text, dictOfElements) : print("--------") print(text) for key , value in dictOfElements.items(): print(key, " :: ", value) def main(): # Dictionary of strings and ints wordsDict = &#123; "Hello": 56, "at" : 23 , "test" : 43, "this" : 43, "who" : [56, 34, 44] &#125; ''' Shallow Copying dictionaries using dict.copy() ''' print("***** Shallow Copy *********") displayList("Original Dictionary : " , wordsDict) # create a Shallow copy the original dictionary newDict = wordsDict.copy() # Modify the value of key in new dictionary newDict["at"] = 200 print("Contents of copied dictionary changed") displayList("Modified copied dictionary : " , newDict) displayList("Original Dictionary : " , wordsDict) ''' Modify the contents of list object in shallow copied dictionary will modify the contents of original dictionary too because its a shallow copy. ''' newDict["who"].append(222) print("Contents of list in copied dictionary changed") displayList("Modified copied dictionary : " , newDict) displayList("Original Dictionary : " , wordsDict) print("***** Deep Copy *******") displayList("Original Dictionary : " , wordsDict) # Create a deep copy of the dictionary otherDict = copy.deepcopy(wordsDict) displayList("Deep copy of Dictionary : " , otherDict) ''' Modify the contents of list object in deep copied dictionary will have no impact on original dictionary because its a deep copy. ''' newDict["who"].append(100) displayList("Modified Deep copy of Dictionary : " , otherDict) displayList("Original Dictionary : " , wordsDict) if __name__ == '__main__': main() 结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566--------Original Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44]Contents of copied dictionary changed--------Modified copied dictionary : at :: 200this :: 43Hello :: 56test :: 43who :: [56, 34, 44]--------Original Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44]Contents of list in copied dictionary changed--------Modified copied dictionary : at :: 200this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222]--------Original Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222]***** Deep Copy *******--------Original Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222]--------Deep copy of Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222]--------Modified Deep copy of Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222]--------Original Dictionary : at :: 23this :: 43Hello :: 56test :: 43who :: [56, 34, 44, 222, 100] 列表拷贝浅拷贝 使用 =赋值运算符 12345678910old_list = [[1, 2, 3], [4, 5, 6], [7, 8, 'a']]new_list = old_listnew_list[2][2] = 9print('Old List:', old_list)print('ID of Old List:', id(old_list))print('New List:', new_list)print('ID of New List:', id(new_list)) 使用copy浅拷贝 1234567import copyold_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]new_list = copy.copy(old_list)print("Old list:", old_list)print("New list:", new_list) 使用deepcopy 深拷贝 1234567import copyold_list = [[1, 1, 1], [2, 2, 2], [3, 3, 3]]new_list = copy.deepcopy(old_list)print("Old list:", old_list)print("New list:", new_list) 类拷贝123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import copyclass Point: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return f'Point(&#123;self.x!r&#125;, &#123;self.y!r&#125;)' &gt;&gt;&gt; a = Point(23, 42)&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; aPoint(23, 42)&gt;&gt;&gt; bPoint(23, 42)&gt;&gt;&gt; a is bFalse## 使用copy模块的copy方法class Rectangle: def __init__(self, topleft, bottomright): self.topleft = topleft self.bottomright = bottomright def __repr__(self): return (f'Rectangle(&#123;self.topleft!r&#125;, ' f'&#123;self.bottomright!r&#125;)')rect = Rectangle(Point(0, 1), Point(5, 6))srect = copy.copy(rect)&gt;&gt;&gt; rectRectangle(Point(0, 1), Point(5, 6))&gt;&gt;&gt; srectRectangle(Point(0, 1), Point(5, 6))&gt;&gt;&gt; rect is srectFalse&gt;&gt;&gt; rect.topleft.x = 999&gt;&gt;&gt; rectRectangle(Point(999, 1), Point(5, 6))&gt;&gt;&gt; srectRectangle(Point(999, 1), Point(5, 6))&gt;&gt;&gt; drect = copy.deepcopy(srect)&gt;&gt;&gt; drect.topleft.x = 222&gt;&gt;&gt; drectRectangle(Point(222, 1), Point(5, 6))&gt;&gt;&gt; rectRectangle(Point(999, 1), Point(5, 6))&gt;&gt;&gt; srectRectangle(Point(999, 1), Point(5, 6)) ## 使用copy方法class Rectangle(object): def __init__(self, topleft, bottomright): self.topleft = topleft self.bottomright = bottomright def __repr__(self): return (f'Rectangle(&#123;self.topleft!r&#125;, ' f'&#123;self.bottomright!r&#125;)') def copy(self): return Rectangle(self.topleft, self.bottomright)r1 = Rectangle(20,30)r2 =r1.copy()print("r1:",r1)print("r2:",r2)&gt;&gt;&gt; r1: Rectangle(20, 30)&gt;&gt;&gt; r2: Rectangle(20, 30) 一个深入的例子123456789101112131415161718192021222324252627282930class B(object): x = 3CopyOfB = type('CopyOfB', B.__bases__, dict(B.__dict__))b = B()cob = CopyOfB()print b.x # Prints '3'print cob.x # Prints '3'b.x = 2cob.x = 4print b.x # Prints '2'print cob.x # Prints '4'class C(object): x = []CopyOfC = type('CopyOfC', C.__bases__, dict(C.__dict__))c = C()coc = CopyOfC()c.x.append(1)coc.x.append(2)print c.x # Prints '[1, 2]' (!)print coc.x # Prints '[1, 2]' (!) 参考文档how to deep copy a list shallow-deep-copy how-to-copy-a-python-class 最后最近学到一个新词:共克时艰 翻译成 英文 We are suffering,希望和朋友们共勉。 我们都是蝴蝶翅膀上的那粒灰尘，被裹挟在龙卷风里，谁都晕头转向]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>copy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library functools]]></title>
    <url>%2F2020%2F02%2F01%2Fpython-standard-library-functools%2F</url>
    <content type="text"><![CDATA[python 标准库 functools 高阶函数工具 每日一词: 这里我们换种记忆方法 ,词根 tach代表 固定 attach 英 [əˈtætʃ] 美 [əˈtætʃ] vt.&amp; vi. 贴上，系； 附上； vt.（有时不受欢迎或未受邀请而）参加； 把…固定； 把…归因于； （使）与…有联系 vi. 从属； 附着； 伴随而来； 联在一起(to, upon) attachment n 邮件的附件 de 是反义前缀 detach v 分离 detached adj 冷漠的,离群的 detachment n 公平 functools 模块应用于高阶函数，即参数或（和）返回值为其他函数的函数。 通常来说，此模块的功能适用于所有可调用对象。 函数functools 模块定义了以下函数: `@functools.cached_property`(func) 将一个类方法转换为特征属性，一次性计算该特征属性的值，然后将其缓存为实例生命周期内的普通属性。 类似于 property() 但增加了缓存功能。 对于在其他情况下实际不可变的高计算资源消耗的实例特征属性来说该函数非常有用。 示例: 1234567891011class DataSet: def __init__(self, sequence_of_numbers): self._data = sequence_of_numbers @cached_property def stdev(self): return statistics.stdev(self._data) @cached_property def variance(self): return statistics.variance(self._data) 3.8 新版功能. 此装饰器要求每个实例上的 __dict__ 属性是可变的映射。 这意味着它将不适用于某些类型，例如元类（因为类型实例上的 __dict__ 属性是类命名空间的只读代理），以及那些指定了 __slots__ 但未包含 __dict__ 作为所定义的空位之一的类（因为这样的类根本没有提供 __dict__ 属性）。 functools.cmp_to_key(func) 将(旧式的)比较函数转换为新式的 key function . 在类似于 sorted() ， min() ， max() ， heapq.nlargest() ， heapq.nsmallest() ， itertools.groupby() 等函数的 key 参数中使用。此函数主要用作将 Python 2 程序转换至新版的转换工具，以保持对比较函数的兼容。比较函数意为一个可调用对象，该对象接受两个参数并比较它们，结果为小于则返回一个负数，相等则返回零，大于则返回一个正数。key function则是一个接受一个参数，并返回另一个用以排序的值的可调用对象。 示例: 1sorted(iterable, key=cmp_to_key(locale.strcoll)) # locale-aware sort order 有关排序示例和简要排序教程，请参阅 排序指南 。3.2 新版功能. `@functools.lru_cache`(user_function) `@functools.lru_cache`(maxsize=128, typed=False) 一个为函数提供缓存功能的装饰器，缓存 maxsize 组传入参数，在下次以相同参数调用时直接返回上一次的结果。用以节约高开销或I/O函数的调用时间。 由于使用了字典存储缓存，所以该函数的固定参数和关键字参数必须是可哈希的。 不同模式的参数可能被视为不同从而产生多个缓存项，例如, f(a=1, b=2) 和 f(b=2, a=1) 因其参数顺序不同，可能会被缓存两次。 如果指定了 user_function，它必须是一个可调用对象。 这允许 lru_cache 装饰器被直接应用于一个用户自定义函数，让 maxsize 保持其默认值 128: 1234@lru_cachedef count_vowels(sentence): sentence = sentence.casefold() return sum(sentence.count(vowel) for vowel in 'aeiou') 如果 maxsize 设置为 None ，LRU功能将被禁用且缓存数量无上限。 maxsize 设置为2的幂时可获得最佳性能。 如果 typed 设置为true，不同类型的函数参数将被分别缓存。例如， f(3) 和 f(3.0) 将被视为不同而分别缓存。 为了衡量缓存的有效性以便调整 maxsize 形参，被装饰的函数带有一个 cache_info() 函数。当调用 cache_info() 函数时，返回一个具名元组，包含命中次数 hits，未命中次数 misses ，最大缓存数量 maxsize 和 当前缓存大小 currsize。在多线程环境中，命中数与未命中数是不完全准确的。 该装饰器也提供了一个用于清理/使缓存失效的函数 cache_clear() 。 原始的未经装饰的函数可以通过 __wrapped__ 属性访问。它可以用于检查、绕过缓存，或使用不同的缓存再次装饰原始函数。 “最久未使用算法”（LRU）缓存 在“最近的调用是即将到来的调用的最佳预测因子”时性能最好（比如，新闻服务器上最受欢迎的文章倾向于每天更改）。 “缓存大小限制”参数保证缓存不会在长时间运行的进程比如说网站服务器上无限制的增加自身的大小。 一般来说，LRU缓存只在当你想要重用之前计算的结果时使用。因此，用它缓存具有副作用的函数、需要在每次调用时创建不同、易变的对象的函数或者诸如time（）或random（）之类的不纯函数是没有意义的。 静态 Web 内容的 LRU 缓存示例: 12345678910111213141516@lru_cache(maxsize=32)def get_pep(num): 'Retrieve text of a Python Enhancement Proposal' resource = 'http://www.python.org/dev/peps/pep-%04d/' % num try: with urllib.request.urlopen(resource) as s: return s.read() except urllib.error.HTTPError: return 'Not Found'&gt;&gt;&gt; for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:... pep = get_pep(n)... print(n, len(pep))&gt;&gt;&gt; get_pep.cache_info()CacheInfo(hits=3, misses=8, maxsize=32, currsize=8) 以下是使用缓存通过 动态规划 计算 斐波那契数列 的例子。 1234567891011@lru_cache(maxsize=None)def fib(n): if n &lt; 2: return n return fib(n-1) + fib(n-2)&gt;&gt;&gt; [fib(n) for n in range(16)][0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]&gt;&gt;&gt; fib.cache_info()CacheInfo(hits=28, misses=16, maxsize=None, currsize=16) 在 3.3 版更改: 添加 typed 选项。 在 3.8 版更改: 添加了 user_function 选项。 `@functools.total_ordering` 给定一个声明一个或多个全比较排序方法的类，这个类装饰器实现剩余的方法。这减轻了指定所有可能的全比较操作的工作。 此类必须包含以下方法之一：__lt__() 、__le__()、__gt__() 或 __ge__()。另外，此类必须支持 __eq__() 方法。 例如: 123456789101112131415@total_orderingclass Student: def _is_valid_operand(self, other): return (hasattr(other, "lastname") and hasattr(other, "firstname")) def __eq__(self, other): if not self._is_valid_operand(other): return NotImplemented return ((self.lastname.lower(), self.firstname.lower()) == (other.lastname.lower(), other.firstname.lower())) def __lt__(self, other): if not self._is_valid_operand(other): return NotImplemented return ((self.lastname.lower(), self.firstname.lower()) &lt; (other.lastname.lower(), other.firstname.lower())) 虽然此装饰器使得创建具有良好行为的完全有序类型变得非常容易，但它 确实 是以执行速度更缓慢和派生比较方法的堆栈回溯更复杂为代价的。 如果性能基准测试表明这是特定应用的瓶颈所在，则改为实现全部六个富比较方法应该会轻松提升速度。 在 3.4 版更改: 现在已支持从未识别类型的下层比较函数返回 NotImplemented 异常。 functools.partial(func, /, args, keywords*) 返回一个新的 部分对象，当被调用时其行为类似于 func 附带位置参数 args 和关键字参数 keywords 被调用。 如果为调用提供了更多的参数，它们会被附加到 args。 如果提供了额外的关键字参数，它们会扩展并重载 keywords。 大致等价于: 12345678def partial(func, /, *args, **keywords): def newfunc(*fargs, **fkeywords): newkeywords = &#123;**keywords, **fkeywords&#125; return func(*args, *fargs, **newkeywords) newfunc.func = func newfunc.args = args newfunc.keywords = keywords return newfunc partial() 会被“冻结了”一部分函数参数和/或关键字的部分函数应用所使用，从而得到一个具有简化签名的新对象。 例如，partial() 可用来创建一个行为类似于 int() 函数的可调用对象，其中 base 参数默认为二： 12345&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; basetwo = partial(int, base=2)&gt;&gt;&gt; basetwo.__doc__ = 'Convert base 2 string to an int.'&gt;&gt;&gt; basetwo('10010')18 class functools.partialmethod(func, /, args, keywords*) 返回一个新的 partialmethod 描述器，其行为类似 partial 但它被设计用作方法定义而非直接用作可调用对象。 func 必须是一个 descriptor 或可调用对象（同属两者的对象例如普通函数会被当作描述器来处理）。 当 func 是一个描述器（例如普通 Python 函数, classmethod(), staticmethod(), abstractmethod() 或其他 partialmethod 的实例）时, 对 __get__ 的调用会被委托给底层的描述器，并会返回一个适当的 部分对象 作为结果。 当 func 是一个非描述器类可调用对象时，则会动态创建一个适当的绑定方法。 当用作方法时其行为类似普通 Python 函数：将会插入 self 参数作为第一个位置参数，其位置甚至会处于提供给 partialmethod 构造器的 args 和 keywords 之前。 示例: 1234567891011121314151617&gt;&gt;&gt; class Cell(object):... def __init__(self):... self._alive = False... @property... def alive(self):... return self._alive... def set_state(self, state):... self._alive = bool(state)... set_alive = partialmethod(set_state, True)... set_dead = partialmethod(set_state, False)...&gt;&gt;&gt; c = Cell()&gt;&gt;&gt; c.aliveFalse&gt;&gt;&gt; c.set_alive()&gt;&gt;&gt; c.aliveTrue functools.reduce(function, iterable[, initializer]) 将两个参数的 function 从左至右积累地应用到 iterable 的条目，以便将该可迭代对象缩减为单一的值。 例如，reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) 是计算 ((((1+2)+3)+4)+5) 的值。 左边的参数 x 是积累值而右边的参数 y 则是来自 iterable 的更新值。 如果存在可选项 initializer，它会被放在参与计算的可迭代对象的条目之前，并在可迭代对象为空时作为默认值。 如果没有给出 initializer 并且 iterable 仅包含一个条目，则将返回第一项。 大致相当于： 123456789def reduce(function, iterable, initializer=None): it = iter(iterable) if initializer is None: value = next(it) else: value = initializer for element in it: value = function(value, element) return value 请参阅 itertools.accumulate() 了解有关可产生所有中间值的迭代器。 `@functools.singledispatch` 将一个函数转换为 单分派 generic function。 要定义一个泛型函数，应使用 @singledispatch 装饰器进行装饰。 请注意分派是作用于第一个参数的类型，要相应地创建你的函数: >&gt;&gt; 123456&gt;&gt;&gt; from functools import singledispatch&gt;&gt;&gt; @singledispatch... def fun(arg, verbose=False):... if verbose:... print("Let me just say,", end=" ")... print(arg) 要将重载的实现添加到函数中，请使用泛型函数的 register() 属性。 它是一个装饰器。 对于带有类型标注的函数，该装饰器将自动推断第一个参数的类型: >&gt;&gt; 123456789101112&gt;&gt;&gt; @fun.register... def _(arg: int, verbose=False):... if verbose:... print("Strength in numbers, eh?", end=" ")... print(arg)...&gt;&gt;&gt; @fun.register... def _(arg: list, verbose=False):... if verbose:... print("Enumerate this:")... for i, elem in enumerate(arg):... print(i, elem) 对于不使用类型标注的代码，可以将适当的类型参数显式地传给装饰器本身: 123456&gt;&gt;&gt; @fun.register(complex)... def _(arg, verbose=False):... if verbose:... print("Better than complicated.", end=" ")... print(arg.real, arg.imag)... 要启用注册 lambda 和现有函数，可以使用函数形式的 register() 属性: 1234&gt;&gt;&gt; def nothing(arg, verbose=False):... print("Nothing.")...&gt;&gt;&gt; fun.register(type(None), nothing) register() 属性将返回启用了装饰器堆栈、封存的未装饰函数，并会为每个变量单独创建单元测试: 123456789&gt;&gt;&gt; @fun.register(float)... @fun.register(Decimal)... def fun_num(arg, verbose=False):... if verbose:... print("Half of your number:", end=" ")... print(arg / 2)...&gt;&gt;&gt; fun_num is funFalse 在调用时，泛型函数会根据第一个参数的类型进行分派: 12345678910111213141516&gt;&gt;&gt; fun("Hello, world.")Hello, world.&gt;&gt;&gt; fun("test.", verbose=True)Let me just say, test.&gt;&gt;&gt; fun(42, verbose=True)Strength in numbers, eh? 42&gt;&gt;&gt; fun(['spam', 'spam', 'eggs', 'spam'], verbose=True)Enumerate this:0 spam1 spam2 eggs3 spam&gt;&gt;&gt; fun(None)Nothing.&gt;&gt;&gt; fun(1.23)0.615 在没有用于特定类型的已注册实现的情况下，则会使用其方法解析顺序来查找更通用的实现。 以 @singledispatch 装饰的原始函数将为最基本的 object 类型进行注册，这意味着它将在找不到更好的实现时被使用。 要检查泛型函数将为给定类型选择哪个实现，请使用 dispatch() 属性: 1234&gt;&gt;&gt; fun.dispatch(float)&lt;function fun_num at 0x1035a2840&gt;&gt;&gt;&gt; fun.dispatch(dict) # note: default implementation&lt;function fun at 0x103fe0000&gt; 要访问所有忆注册实现，请使用只读的 registry 属性: 12345678&gt;&gt;&gt; fun.registry.keys()dict_keys([&lt;class 'NoneType'&gt;, &lt;class 'int'&gt;, &lt;class 'object'&gt;, &lt;class 'decimal.Decimal'&gt;, &lt;class 'list'&gt;, &lt;class 'float'&gt;])&gt;&gt;&gt; fun.registry[float]&lt;function fun_num at 0x1035a2840&gt;&gt;&gt;&gt; fun.registry[object]&lt;function fun at 0x103fe0000&gt; 在 3.7 版更改: register() 属性支持使用类型标注。 class functools.singledispatchmethod(func) 将一个方法转换为 单分派 generic function。 要定义一个泛型方法，应使用 @singledispatchmethod 装饰器进行装饰。 请注意分派是作用于第一个非 self 或非 cls 参数的类型，要相应地创建你的函数: 123456789101112class Negator: @singledispatchmethod def neg(self, arg): raise NotImplementedError("Cannot negate a") @neg.register def _(self, arg: int): return -arg @neg.register def _(self, arg: bool): return not arg @singledispatchmethod 支持与其他装饰器如 @classmethod 相嵌套。 请注意如果要允许 dispatcher.register，则 singledispatchmethod 必须是 最外层 的装饰器。 下面的示例定义了 Negator 类，其中包含绑定到类的 neg 方法: 123456789101112131415class Negator: @singledispatchmethod @classmethod def neg(cls, arg): raise NotImplementedError("Cannot negate a") @neg.register @classmethod def _(cls, arg: int): return -arg @neg.register @classmethod def _(cls, arg: bool): return not arg 同样的模式也被用于其他类似的装饰器: staticmethod, abstractmethod 等等。 3.8 新版功能. functools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) 更新一个 wrapper 函数以使其类似于 wrapped 函数。 可选参数为指明原函数的哪些属性要直接被赋值给 wrapper 函数的匹配属性的元组，并且这些 wrapper 函数的属性将使用原函数的对应属性来更新。 这些参数的默认值是模块级常量 WRAPPER_ASSIGNMENTS (它将被赋值给 wrapper 函数的 __module__, __name__, __qualname__, __annotations__ 和 __doc__ 即文档字符串) 以及 WRAPPER_UPDATES (它将更新 wrapper 函数的 __dict__ 即实例字典)。 为了允许出于内省和其他目的访问原始函数（例如绕过 lru_cache() 之类的缓存装饰器），此函数会自动为 wrapper 添加一个指向被包装函数的 __wrapped__ 属性。 此函数的主要目的是在 decorator 函数中用来包装被装饰的函数并返回包装器。 如果包装器函数未被更新，则被返回函数的元数据将反映包装器定义而不是原始函数定义，这通常没有什么用处。 update_wrapper() 可以与函数之外的可调用对象一同使用。 在 assigned 或 updated 中命名的任何属性如果不存在于被包装对象则会被忽略（即该函数将不会尝试在包装器函数上设置它们）。 如果包装器函数自身缺少在 updated 中命名的任何属性则仍将引发 AttributeError。 3.2 新版功能: 自动添加 __wrapped__ 属性。 3.2 新版功能: 默认拷贝 __annotations__ 属性。 在 3.2 版更改: 不存在的属性将不再触发 AttributeError。 在 3.4 版更改: __wrapped__ 属性现在总是指向被包装的函数，即使该函数定义了 __wrapped__ 属性。 (参见 bpo-17482) wrapped是被装饰的原函数 wrapper是被装饰器装饰后的新函数。 补充例子：1234567891011121314def outer(func): @functools.wraps(func) def inner(*args, **kwargs): print(f"before...") func(*args, **kwargs) print("after...") return inner@outerdef add(a, b): """ 求和运算 """ print(a + b) 1、原函数为add。 2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。 3、执行outer函数时，加载inner函数，此时会直接执行functools.wraps(func)返回一个可调用对象，即partial对象。 4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。 5、把add指向inner函数。 6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。 update_wrapper函数参数对应： wrapper指的是inner函数 wrapped指的是func即原始的add函数 `@functools.wraps`(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) 这是一个便捷函数，用于在定义包装器函数时发起调用 update_wrapper() 作为函数装饰器。 它等价于 partial(update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated)。 例如: 1234567891011121314151617181920&gt;&gt;&gt; from functools import wraps&gt;&gt;&gt; def my_decorator(f):... @wraps(f)... def wrapper(*args, **kwds):... print('Calling decorated function')... return f(*args, **kwds)... return wrapper...&gt;&gt;&gt; @my_decorator... def example():... """Docstring"""... print('Called example function')...&gt;&gt;&gt; example()Calling decorated functionCalled example function&gt;&gt;&gt; example.__name__'example'&gt;&gt;&gt; example.__doc__'Docstring' 如果不使用这个装饰器工厂函数，则 example 函数的名称将变为 &#39;wrapper&#39;，并且 example() 原本的文档字符串将会丢失。 partial 对象partial 对象是由 partial() 创建的可调用对象。 它们具有三个只读属性： partial.func 一个可调用对象或函数。 对 partial 对象的调用将被转发给 func 并附带新的参数和关键字。 partial.args 最左边的位置参数将放置在提供给 partial 对象调用的位置参数之前。 partial.keywords 当调用 partial 对象时将要提供的关键字参数。 partial 对象与 function 对象的类似之处在于它们都是可调用、可弱引用的对象并可拥有属性。 但两者也存在一些重要的区别。 例如前者不会自动创建 __name__ 和 __doc__ 属性。 而且，在类中定义的 partial 对象的行为类似于静态方法，并且不会在实例属性查找期间转换为绑定方法。 小结 functools.wraps目的消除装饰器对原函数造成的影响, 通过对原函数相关属性拷贝,已达到装饰器不修改原函数的目的。 wraps内部通过partial对象和update_wrapper函数实现 partial是一个类，通过实现了双下方法new，自定义实例化对象过程，使得对象内部保留原函数和固定参数，通过实现双下方法call，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>functools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library queue]]></title>
    <url>%2F2020%2F01%2F31%2Fpython-standard-library-queue%2F</url>
    <content type="text"><![CDATA[python 标准库 queue 源码 源代码: Lib/queue.py queue 模块实现了多生产者、多消费者队列。这特别适用于消息必须安全地在多线程间交换的线程编程。模块中的 Queue 类实现了所有所需的锁定语义。 模块实现了三种类型的队列，它们的区别仅仅是条目取回的顺序。在 FIFO 队列中，先添加的任务先取回。在 LIFO 队列中，最近被添加的条目先取回(操作类似一个堆栈)。优先级队列中，条目将保持排序( 使用 heapq 模块 ) 并且最小值的条目第一个返回。 在内部，这三个类型的队列使用锁来临时阻塞竞争线程；然而，它们并未被设计用于线程的重入性处理。 此外，模块实现了一个 “简单的” FIFO 队列类型， SimpleQueue ，这个特殊实现为小功能在交换中提供额外的保障。 queue 模块定义了下列类和异常： class queue.Queue(maxsize=0) Constructor for a FIFO queue. maxsize is an integer that sets the upperbound limit on the number of items that can be placed in the queue. Insertion will block once this size has been reached, until queue items are consumed. If maxsize is less than or equal to zero, the queue size is infinite. class queue.LifoQueue(maxsize=0) LIFO 队列构造函数。 maxsize 是个整数，用于设置可以放入队列中的项目数的上限。当达到这个大小的时候，插入操作将阻塞至队列中的项目被消费掉。如果 maxsize 小于等于零，队列尺寸为无限大。 class queue.PriorityQueue(maxsize=0) 优先级队列构造函数。 maxsize 是个整数，用于设置可以放入队列中的项目数的上限。当达到这个大小的时候，插入操作将阻塞至队列中的项目被消费掉。如果 maxsize 小于等于零，队列尺寸为无限大。最小值先被取出( 最小值条目是由 sorted(list(entries))[0] 返回的条目)。条目的典型模式是一个以下形式的元组： (priority_number, data) 。如果 data 元素没有可比性，数据将被包装在一个类中，忽略数据值，仅仅比较优先级数字 ：from dataclasses import dataclass, field from typing import Any @dataclass(order=True) class PrioritizedItem: priority: int item: Any=field(compare=False) class queue.SimpleQueue 无界的 FIFO 队列构造函数。简单的队列，缺少任务跟踪等高级功能。3.7 新版功能. exception queue.Empty 对空的 Queue 对象，调用非阻塞的 get() (or get_nowait()) 时，引发的异常。 exception queue.Full 对满的 Queue 对象，调用非阻塞的 put() (or put_nowait()) 时，引发的异常。 Queue对象队列对象 (Queue, LifoQueue, 或者 PriorityQueue) 提供下列描述的公共方法。 Queue.qsize() 返回队列的大致大小。注意，qsize() &gt; 0 不保证后续的 get() 不被阻塞，qsize() &lt; maxsize 也不保证 put() 不被阻塞。 Queue.empty() 如果队列为空，返回 True ，否则返回 False 。如果 empty() 返回 True ，不保证后续调用的 put() 不被阻塞。类似的，如果 empty() 返回 False ，也不保证后续调用的 get() 不被阻塞。 Queue.full() 如果队列是满的返回 True ，否则返回 False 。如果 full() 返回 True 不保证后续调用的 get() 不被阻塞。类似的，如果 full() 返回 False 也不保证后续调用的 put() 不被阻塞。 Queue.put(item, block=True, timeout=None) 将 item 放入队列。如果可选参数 block 是 true 并且 timeout 是 None (默认)，则在必要时阻塞至有空闲插槽可用。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间没有可用的空闲插槽，将引发 Full 异常。反之 (block 是 false)，如果空闲插槽立即可用，则把 item 放入队列，否则引发 Full 异常 ( 在这种情况下，timeout 将被忽略)。 Queue.put_nowait(item) 相当于 put(item, False) 。 Queue.get(block=True, timeout=None) 从队列中移除并返回一个项目。如果可选参数 block 是 true 并且 timeout 是 None (默认值)，则在必要时阻塞至项目可得到。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间内项目不能得到，将引发 Empty 异常。反之 (block 是 false) , 如果一个项目立即可得到，则返回一个项目，否则引发 Empty 异常 (这种情况下，timeout 将被忽略)。POSIX系统3.0之前，以及所有版本的Windows系统中，如果 block 是 true 并且 timeout 是 None ， 这个操作将进入基础锁的不间断等待。这意味着，没有异常能发生，尤其是 SIGINT 将不会触发 KeyboardInterrupt 异常。 Queue.get_nowait() 相当于 get(False) 。 提供了两个方法，用于支持跟踪 排队的任务 是否 被守护的消费者线程 完整的处理。 Queue.task_done() 表示前面排队的任务已经被完成。被队列的消费者线程使用。每个 get() 被用于获取一个任务， 后续调用 task_done() 告诉队列，该任务的处理已经完成。如果 join() 当前正在阻塞，在所有条目都被处理后，将解除阻塞(意味着每个 put() 进队列的条目的 task_done() 都被收到)。如果被调用的次数多于放入队列中的项目数量，将引发 ValueError 异常 。 Queue.join() 阻塞至队列中所有的元素都被接收和处理完毕。当条目添加到队列的时候，未完成任务的计数就会增加。每当消费者线程调用 task_done() 表示这个条目已经被回收，该条目所有工作已经完成，未完成计数就会减少。当未完成计数降到零的时候， join() 阻塞被解除。 如何等待排队的任务被完成的示例： 1234567891011121314151617181920212223242526def worker(): while True: item = q.get() if item is None: break do_work(item) q.task_done()q = queue.Queue()threads = []for i in range(num_worker_threads): t = threading.Thread(target=worker) t.start() threads.append(t)for item in source(): q.put(item)# block until all tasks are doneq.join()# stop workersfor i in range(num_worker_threads): q.put(None)for t in threads: t.join() SimpleQueue 对象SimpleQueue 对象提供下列描述的公共方法。 SimpleQueue.qsize() 返回队列的大致大小。注意，qsize() &gt; 0 不保证后续的 get() 不被阻塞。 SimpleQueue.empty() 如果队列为空，返回 True ，否则返回 False 。如果 empty() 返回 False ，不保证后续调用的 get() 不被阻塞。 SimpleQueue.put(item, block=True, timeout=None) 将 item 放入队列。此方法永不阻塞，始终成功（除了潜在的低级错误，例如内存分配失败）。可选参数 block 和 timeout 仅仅是为了保持 Queue.put() 的兼容性而提供，其值被忽略。CPython implementation detail: This method has a C implementation which is reentrant. That is, a put() or get() call can be interrupted by another put() call in the same thread without deadlocking or corrupting internal state inside the queue. This makes it appropriate for use in destructors such as __del__ methods or weakref callbacks. SimpleQueue.put_nowait(item) 相当于 put(item) ，仅为保持 Queue.put_nowait() 兼容性而提供。 SimpleQueue.get(block=True, timeout=None) 从队列中移除并返回一个项目。如果可选参数 block 是 true 并且 timeout 是 None (默认值)，则在必要时阻塞至项目可得到。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间内项目不能得到，将引发 Empty 异常。反之 (block 是 false) , 如果一个项目立即可得到，则返回一个项目，否则引发 Empty 异常 (这种情况下，timeout 将被忽略)。 SimpleQueue.get_nowait() 相当于 get(False) 。 小结Queue的种类： FIFO： Queue.Queue(maxsize=0) FIFO即First in First Out,先进先出。Queue提供了一个基本的FIFO容器，使用方法很简单,maxsize是个整数，指明了队列中能存放的数据个数的上限。一旦达到上限，插入会导致阻塞，直到队列中的数据被消费掉。如果maxsize小于或者等于0，队列大小没有限制。 LIFO Queue.LifoQueue(maxsize=0) LIFO即Last in First Out,后进先出。与栈的类似，使用也很简单,maxsize用法同上 priority class Queue.PriorityQueue(maxsize=0) 构造一个优先队列。maxsize用法同上。 例子1：LifoQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445import queueimport threadingimport time # 可以设置队列的长度 q=queue.LifoQueue(5)，意味着队列中最多存放5个元素,当队列满的时候自动进入阻塞状态q=queue.LifoQueue()def put(): for i in range(10): q.put(i) print("数据%d被存入到队列中" % i) q.join() print('ok') def get(): for i in range(10): value = q.get() print("数据%d从队列中取出" % value) q.task_done() t1=threading.Thread(target=put,args=())t1.start()t2=threading.Thread(target=get,args=())t2.start()&gt;&gt;&gt; 数据0被存入到队列中&gt;&gt;&gt; 数据1被存入到数据中&gt;&gt;&gt; 数据2被存入到队列中&gt;&gt;&gt; 数据3被存入到队列中&gt;&gt;&gt; 数据4被存入到队列中&gt;&gt;&gt; 数据5被存入到队列中&gt;&gt;&gt; 数据6被存入到队列中&gt;&gt;&gt; 数据7被存入到队列中&gt;&gt;&gt; 数据8被存入到队列中&gt;&gt;&gt; 数据9被存入到队列中&gt;&gt;&gt; 数据9从队列中取出&gt;&gt;&gt; 数据8从队列中取出&gt;&gt;&gt; 数据7从队列中取出&gt;&gt;&gt; 数据6从队列中取出&gt;&gt;&gt; 数据5从队列中取出&gt;&gt;&gt; 数据4从队列中取出&gt;&gt;&gt; 数据3从队列中取出&gt;&gt;&gt; 数据2从队列中取出&gt;&gt;&gt; 数据1从队列中取出&gt;&gt;&gt; 数据0从队列中取出&gt;&gt;&gt; ok 例子2：Priortity Queue in Python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# A simple implementation of Priority Queue # using Queue. class PriorityQueue(object): def __init__(self): self.queue = [] def __str__(self): return ' '.join([str(i) for i in self.queue]) # for checking if the queue is empty def isEmpty(self): return len(self.queue) == [] # for inserting an element in the queue def insert(self, data): self.queue.append(data) # for popping an element based on Priority def delete(self): try: max = 0 for i in range(len(self.queue)): if self.queue[i] &gt; self.queue[max]: max = i item = self.queue[max] del self.queue[max] return item except IndexError: print() exit() if __name__ == '__main__': myQueue = PriorityQueue() myQueue.insert(12) myQueue.insert(1) myQueue.insert(14) myQueue.insert(7) print(myQueue) while not myQueue.isEmpty(): print(myQueue.delete()) &gt;&gt;&gt; 12 1 14 7&gt;&gt;&gt; 14&gt;&gt;&gt; 12&gt;&gt;&gt; 7&gt;&gt;&gt; 1&gt;&gt;&gt; () 扩展:第三方队列下面介绍五个第三方队列框架,看来造轮子也是个好方法，:) Celery 官方栗子 RQ 一个栗子 12345import requestsdef count_words_at_url(url): resp = requests.get(url) return len(resp.text.split()) 创建一个RQ queue 1234from redis import Redisfrom rq import Queueq = Queue(connection=Redis()) 方法调用 123from my_module import count_words_at_urlresult = q.enqueue( count_words_at_url, 'http://nvie.com') Worker实例 12345$ rq worker*** Listening for work on defaultGot count_words_at_url('http://nvie.com') from defaultJob result = 818*** Listening for work on default huey 一个轻量级队列框架 一个栗子 1234567891011121314151617from huey import RedisHuey, crontabhuey = RedisHuey('my-app', host='redis.myapp.com')@huey.task()def add_numbers(a, b): return a + b@huey.task(retries=2, retry_delay=60)def flaky_task(url): # This task might fail, in which case it will be retried up to 2 times # with a delay of 60s between retries. return this_might_fail(url)@huey.periodic_task(crontab(minute='0', hour='3'))def nightly_backup(): sync_all_data() kuyruk 创建Task 12345678# tasks.pyfrom kuyruk import Kuyrukkuyruk = Kuyruk()@kuyruk.task()def echo(message): print message 发送Task 去 RabbitMQ 12import taskstasks.echo("Hello, World!") 运行Worker 1kuyruk --app tasks.kuyruk worker Dramatiq 一个栗子 1234567891011121314151617import dramatiqimport requests@dramatiq.actordef count_words(url): response = requests.get(url) count = len(response.text.split(" ")) print(f"There are &#123;count&#125; words at &#123;url!r&#125;.")# Synchronously count the words on example.com in the current processcount_words("http://example.com")# or send the actor a message so that it may perform the count# later, in a separate process.count_words.send("http://example.com")]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>queue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library concurrent]]></title>
    <url>%2F2020%2F01%2F30%2Fpython-standard-library-concurrent%2F</url>
    <content type="text"><![CDATA[python 标准库 concurrent what is love？ 也许一千个人有一千个人的说法。也许当你知道什么是爱的时候,我们已经忘记了曾经也爱过。一生都没弄明白什么是爱。学会爱别人,也学着如何去爱一个人,是一辈子的事。 ​ — 临风语录 送给大家一首歌 How Long Will I Love You.在这个寒冷的季节里,唯有爱才是唯一可以温暖人们的东西吧。 源码源码: Lib/concurrent/futures/thread.py 和 Lib/concurrent/futures/process.py concurrent模块层次结构如下: 1234567concurrent |-- futures/ |-----|--__init__.py |-----|--_base.py |-----|--process.py |-----|--thread.py |-- __init__.py concurrent.futures 模块提供异步执行回调高层接口。 异步执行可以由 ThreadPoolExecutor 使用线程或由 ProcessPoolExecutor 使用单独的进程来实现。 两者都是实现抽像类 Executor 定义的接口。 Executor对象class concurrent.futures.Executor 抽象类提供异步执行调用方法。要通过它的子类调用，而不是直接调用。 submit(fn, args, kwargs*) 调度可调用对象 fn，以 fn(*args **kwargs) 方式执行并返回 Future 对像代表可调用对象的执行。: 123with ThreadPoolExecutor(max_workers=1) as executor: future = executor.submit(pow, 323, 1235) print(future.result()) map(func, *iterables, timeout=None, chunksize=1) 类似于 map(func, *iterables) 除去： 应立即收集 iterables 不要延迟再收集; func 是异步执行的且对 func 的调用可以并发执行。 如果 __next__() 已被调用且返回的结果在对 Executor.map() 的原始调用经过 timeout 秒后还不可用，则已返回的迭代器将引发 concurrent.futures.TimeoutError。 timeout 可以为 int 或 float 类型。 如果 timeout 未指定或为 None，则不限制等待时间。 如果 func 调用引发一个异常，当从迭代器中取回它的值时这个异常将被引发。 使用 ProcessPoolExecutor 时，这个方法会将 iterables 分割任务块并作为独立的任务并提交到执行池中。这些块的大概数量可以由 chunksize 指定正整数设置。 对很长的迭代器来说，使用大的 chunksize 值比默认值 1 能显著地提高性能。 chunksize 对 ThreadPoolExecutor 没有效果。 在 3.5 版更改: 加入 chunksize 参数。 shutdown(wait=True) 当待执行的期程完成执行后向执行者发送信号，它就会释放正在使用的任何资源。调用 Executor.submit() 和 Executor.submit() 会在关闭后触发 RuntimeError。 如果 wait 为 True 则此方法只有在所有待执行的期程完成执行且释放已分配的资源后才会返回。 如果 wait 为 False，方法立即返回，所有待执行的期程完成执行后会释放已分配的资源。 不管 wait 的值是什么，整个 Python 程序将等到所有待执行的期程完成执行后才退出。 如果使用 with 语句，你就可以避免显式调用这个方法，它将会停止 Executor (就好像 Executor.shutdown() 调用时 wait 设为 True 一样等待): 123456import shutilwith ThreadPoolExecutor(max_workers=4) as e: e.submit(shutil.copy, 'src1.txt', 'dest1.txt') e.submit(shutil.copy, 'src2.txt', 'dest2.txt') e.submit(shutil.copy, 'src3.txt', 'dest3.txt') e.submit(shutil.copy, 'src4.txt', 'dest4.txt') ThreadPoolExecutorThreadPoolExecutor 是 Executor 的子类，它使用线程池来异步执行调用。 当回调已关联了一个 Future 然后再等待另一个 Future 的结果时就会发生死锁情况。 例如: 123456789101112131415import timedef wait_on_b(): time.sleep(5) print(b.result()) # b will never complete because it is waiting on a. return 5def wait_on_a(): time.sleep(5) print(a.result()) # a will never complete because it is waiting on b. return 6executor = ThreadPoolExecutor(max_workers=2)a = executor.submit(wait_on_b)b = executor.submit(wait_on_a) 和下面的情况: 12345678def wait_on_future(): f = executor.submit(pow, 5, 2) # This will never complete because there is only one worker thread and # it is executing this function. print(f.result())executor = ThreadPoolExecutor(max_workers=1)executor.submit(wait_on_future) class concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix=’’, initializer=None, initargs=()) Executor 的一个子类，使用最多 max_workers 个线程的线程池来异步执行调用。 initializer 是在每个工作者线程开始处调用的一个可选可调用对象。 initargs 是传递给初始化器的元组参数。任何向池提交更多工作的尝试， initializer 都将引发一个异常，当前所有等待的工作都会引发一个 BrokenThreadPool。 在 3.5 版更改: 如果 max_workers 为 None 或没有指定，将默认为机器处理器的个数，假如 ThreadPoolExecutor 则重于 I/O 操作而不是 CPU 运算，那么可以乘以 5，同时工作线程的数量可以比 ProcessPoolExecutor 的数量高。 3.6 新版功能: 添加 thread_name_prefix 参数允许用户控制由线程池创建的 threading.Thread 工作线程名称以方便调试。 在 3.7 版更改: 加入 initializer 和initargs 参数。 在 3.8 版更改: max_workers 的默认值已改为 min(32, os.cpu_count() + 4)。 这个默认值会保留至少 5 个工作线程用于 I/O 密集型任务。 它会使用至多 32 个 CPU 核心用于 CPU 密集型任务并将释放 GIL。 它还会避免在多核机器上隐式地使用非常大量的资源。 现在 ThreadPoolExecutor 在启动 max_workers 个工作线程之前也会重用空闲的工作线程。 ThreadPoolExecutor 例子1234567891011121314151617181920212223242526import concurrent.futuresimport urllib.requestURLS = ['http://www.foxnews.com/', 'http://www.cnn.com/', 'http://europe.wsj.com/', 'http://www.bbc.co.uk/', 'http://some-made-up-domain.com/']# Retrieve a single page and report the URL and contentsdef load_url(url, timeout): with urllib.request.urlopen(url, timeout=timeout) as conn: return conn.read()# We can use a with statement to ensure threads are cleaned up promptlywith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: # Start the load operations and mark each future with its URL future_to_url = &#123;executor.submit(load_url, url, 60): url for url in URLS&#125; for future in concurrent.futures.as_completed(future_to_url): url = future_to_url[future] try: data = future.result() except Exception as exc: print('%r generated an exception: %s' % (url, exc)) else: print('%r page is %d bytes' % (url, len(data))) ProcessPoolExecutor源码中的图示: 12345678910111213141516171819"""Implements ProcessPoolExecutor.The following diagram and text describe the data-flow through the system:|======================= In-process =====================|== Out-of-process ==|+----------+ +----------+ +--------+ +-----------+ +---------+| | =&gt; | Work Ids | | | | Call Q | | Process || | +----------+ | | +-----------+ | Pool || | | ... | | | | ... | +---------+| | | 6 | =&gt; | | =&gt; | 5, call() | =&gt; | || | | 7 | | | | ... | | || Process | | ... | | Local | +-----------+ | Process || Pool | +----------+ | Worker | | #1..n || Executor | | Thread | | || | +----------- + | | +-----------+ | || | &lt;=&gt; | Work Items | &lt;=&gt; | | &lt;= | Result Q | &lt;= | || | +------------+ | | +-----------+ | || | | 6: call() | | | | ... | | || | | future | | | | 4, result | | || | | ... | | | | 3, except | | |+----------+ +------------+ +--------+ +-----------+ +---------+ ProcessPoolExecutor 是 Executor 的子类，它使用进程池来实现异步执行调用。 ProcessPoolExecutor 使用 multiprocessing 回避 Global Interpreter Lock 但也意味着只可以处理和返回可序列化的对象。 __main__ 模块必须可以被工作者子进程导入。这意味着 ProcessPoolExecutor 不可以工作在交互式解释器中。 从提交给 ProcessPoolExecutor 的回调中调用 Executor 或 Future 方法会导致死锁。 class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=()) 异步执行调用的 Executor 子类使用一个最多有 max_workers 个进程的进程池。 如果 max_workers 为 None 或未给出，它将默认为机器的处理器个数。 如果 max_workers 小于等于 0，则将引发 ValueError。 在 Windows 上，max_workers 必须小于等于 61，否则将引发 ValueError。 如果 max_workers 为 None，则所选择的默认最多为 61，即使存在更多处理器。 mp_context 可以是一个多进程上下文或是 None。 它将被用来启动工作者。 如果 mp_context 为 None 或未给出，将使用默认的多进程上下文。 initializer 是在每个工作者进程开始处调用的一个可选可调用对象。 initargs 是传递给初始化器的元组参数。任何向池提交更多工作的尝试， initializer 都将引发一个异常，当前所有等待的工作都会引发一个 BrokenProcessPool。 在 3.3 版更改: 如果其中一个工作进程被突然终止，BrokenProcessPool 就会马上触发。可预计的行为没有定义，但执行器上的操作或它的期程会被冻结或死锁。 在 3.7 版更改: 添加 mp_context 参数允许用户控制由进程池创建给工作者进程的开始方法 。 加入 initializer 和initargs 参数。 ProcessPoolExecutor 例子1234567891011121314151617181920212223242526272829303132import concurrent.futuresimport mathPRIMES = [ 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419]def is_prime(n): if n &lt; 2: return False if n == 2: return True if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return Truedef main(): with concurrent.futures.ProcessPoolExecutor() as executor: for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)): print('%d is prime: %s' % (number, prime))if __name__ == '__main__': main() Future对象Future 类将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建。 class concurrent.futures.Future 将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建，除非测试，不应直接创建。 cancel() 尝试取消调用。 如果调用正在执行或已结束运行不能被取消则该方法将返回 False，否则调用会被取消并且该方法将返回 True。 cancelled() 如果调用成功取消返回 True。 running() 如果调用正在执行而且不能被取消那么返回True。 done() 如果调用已被取消或正常结束那么返回 True。 result(timeout=None) 返回调用返回的值。如果调用还没完成那么这个方法将等待 timeout 秒。如果在 timeout 秒内没有执行完成，concurrent.futures.TimeoutError 将会被触发。timeout 可以是整数或浮点数。如果 timeout 没有指定或为 None，那么等待时间就没有限制。如果 futrue 在完成前被取消则 CancelledError 将被触发。如果调用引发了一个异常，这个方法也会引发同样的异常。 exception(timeout=None) 返回由调用引发的异常。如果调用还没完成那么这个方法将等待 timeout 秒。如果在 timeout 秒内没有执行完成，concurrent.futures.TimeoutError 将会被触发。timeout 可以是整数或浮点数。如果 timeout 没有指定或为 None，那么等待时间就没有限制。如果 futrue 在完成前被取消则 CancelledError 将被触发。如果调用正常完成那么返回 None。 add_done_callback(fn) 附加可调用 fn 到期程。当期程被取消或完成运行时，将会调用 fn，而这个期程将作为它唯一的参数。加入的可调用对象总被属于添加它们的进程中的线程按加入的顺序调用。如果可调用对象引发一个 Exception 子类，它会被记录下来并被忽略掉。如果可调用对象引发一个 BaseException 子类，这个行为没有定义。如果期程已经完成或已取消，fn 会被立即调用。 下面这些 Future 方法用于单元测试和 Executor 实现。 set_running_or_notify_cancel() 这个方法只可以在执行关联 Future 工作之前由 Executor 实现调用或由单测试调用。如果这个方法返回 False 那么 Future 已被取消，即 Future.cancel() 已被调用并返回 True 。等待 Future 完成 (即通过 as_completed() 或 wait()) 的线程将被唤醒。如果这个方法返回 True 那么 Future 不会被取消并已将它变为正在运行状态，也就是说调用 Future.running() 时将返回 True。这个方法只可以被调用一次并且不能在调用 Future.set_result() 或 Future.set_exception() 之后再调用。 set_result(result) 设置将 Future 关联工作的结果给 result 。这个方法只可以由 Executor 实现和单元测试使用。在 3.8 版更改: 如果 Future 已经完成则此方法会引发 concurrent.futures.InvalidStateError。 set_exception(exception) 设置 Future 关联工作的结果给 Exception exception 。这个方法只可以由 Executor 实现和单元测试使用。在 3.8 版更改: 如果 Future 已经完成则此方法会引发 concurrent.futures.InvalidStateError。 模块函数concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED) 等待 fs 指定的 Future 实例（可能由不同的 Executor 实例创建）完成。 返回一个由集合构成的具名 2 元组。 第一个集合名称为 done，包含在等待完成之前已完成的期程（包括正常结束或被取消的期程）。 第二个集合名称为 not_done，包含未完成的期程（包括挂起的或正在运行的期程）。 timeout 可以用来控制返回前最大的等待秒数。 timeout 可以为 int 或 float 类型。 如果 timeout 未指定或为 None ，则不限制等待时间。 return_when 指定此函数应在何时返回。它必须为以下常数之一: 常数 描述 FIRST_COMPLETED 函数将在任意可等待对象结束或取消时返回。 FIRST_EXCEPTION 函数将在任意可等待对象因引发异常而结束时返回。当没有引发任何异常时它就相当于 ALL_COMPLETED。 ALL_COMPLETED 函数将在所有可等待对象结束或取消时返回。 concurrent.futures.as_completed(fs, timeout=None) 返回一个包含 fs 所指定的 Future 实例（可能由不同的 Executor 实例创建）的迭代器，这些实例会在完成时生成期程（包括正常结束或被取消的期程）。 任何由 fs 所指定的重复期程将只被返回一次。 任何在 as_completed() 被调用之前完成的期程将优先被生成。 如果 __next__() 被调用并且在对 as_completed() 的原始调用 timeout 秒之后结果仍不可用，则返回的迭代器将引发 concurrent.futures.TimeoutError。 timeout 可以为整数或浮点数。 如果 timeout 未指定或为 None，则不限制等待时间。 PEP 3148 – futures - 异步执行指令。 该提案描述了Python标准库中包含的这个特性。 Exception类 exception concurrent.futures.CancelledError future被取消时会触发。 exception concurrent.futures.TimeoutError future运算超出给定的超时数值时触发。 exception concurrent.futures.BrokenExecutor 当执行器被某些原因中断而且不能用来提交或执行新任务时就会被引发派生于 RuntimeError 的异常类。3.7 新版功能. exception concurrent.futures.InvalidStateError 当某个操作在一个当前状态所不允许的 future 上执行时将被引发。3.8 新版功能. exception concurrent.futures.thread.BrokenThreadPool 当 ThreadPoolExecutor 中的其中一个工作者初始化失败时会引发派生于 BrokenExecutor 的异常类。3.7 新版功能. exception concurrent.futures.process.BrokenProcessPool 当 ThreadPoolExecutor 中的其中一个工作者不完整终止时(比如，被外部杀死)会引发派生于 BrokenExecutor ( 原名 RuntimeError ) 的异常类。 补充例子submit例子1234567891011121314#线程执行的函数def add(n1,n2): v = n1 + n2 print('add :', v , ', tid:',threading.currentThread().ident) time.sleep(n1) return v#通过submit把需要执行的函数扔进线程池中.#submit 直接返回一个future对象ex = ThreadPoolExecutor(max_workers=3) #制定最多运行N个线程f1 = ex.submit(add,2,3)f2 = ex.submit(add,2,2)print('main thread running')print(f1.done()) #done 看看任务结束了没print(f1.result()) #获取结果 ,阻塞方法 返回 map 例子123456789#下面是map 方法的简单使用. 注意:map 返回是一个生成器 ,并且是*有序的*URLS = ['http://www.baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn']def get_html(url): print('thread id:',threading.currentThread().ident,' 访问了:',url) return requests.get(url) #这里使用了requests 模块ex = ThreadPoolExecutor(max_workers=3)res_iter = ex.map(get_html,URLS) #内部迭代中, 每个url 开启一个线程for res in res_iter: #此时将阻塞 , 直到线程完成或异常 print('url:%s ,len: %d'%(res.url,len(res.text))) as_complated 例子1234567891011URLS = ['http://www.baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn']def get_html(url): time.sleep(3) print('thread id:',threading.currentThread().ident,' 访问了:',url) return requests.get(url) #这里使用了requests 模块ex = ThreadPoolExecutor(max_workers=3)f = ex.submit(get_html,URLS[0]) #提交一个任务,放入线程池中,准备执行print('main thread running')for future in as_completed([f]): #as_completed()接受一个可迭代的Future序列,返回一个生成器,在完成或异常时返回这个Future对象 print('一个任务完成.') print(future.result()) as_complated 详细例子123456789101112131415161718192021222324#as_completed 完整的例子#as_completed 返回一个生成器，用于迭代， 一旦一个线程完成(或失败) 就返回URLS = ['http://www.baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn']def get_html(url): time.sleep(1) print('thread id:',threading.currentThread().ident,' 访问了:',url) return requests.get(url) #这里使用了requests 模块ex = ThreadPoolExecutor(max_workers=3) #最多3个线程future_tasks = [ex.submit(get_html,url) for url in URLS] #创建3个future对象for future in as_completed(future_tasks): #迭代生成器 try: resp = future.result() except Exception as e: print('%s'%e) else: print('%s has %d bytes!'%(resp.url, len(resp.text)))"""thread id: 5160 访问了: http://www.baidu.comthread id: 7752 访问了: http://www.sina.com.cnthread id: 5928 访问了: http://www.qq.comhttp://www.qq.com/ has 240668 bytes!http://www.baidu.com/ has 2381 bytes!https://www.sina.com.cn/ has 577244 bytes!""" as_complated 返回的是迭代器,在迭代过程中会阻塞 直到线程完成或者异常时,返回一个被 set_result的Future对象 map方法返回的是有序的,as_complated 是哪个线程先完成/失败时就返回 wait例子（阻塞)123456789101112131415161718192021222324"""wait 例子参数: FIRST_COMPLETED 当任何未来完成或被取消时，该函数将返回。 FIRST_EXCEPTION 当任何未来通过提出异常完成时，函数将返回。如果没有未来引发异常，那么它等同于 ALL_COMPLETED。 ALL_COMPLETED(默认) 当所有future完成或被取消时，函数将返回。"""URLS = ['http://www.baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn']def get_html(url): time.sleep(1) print('thread id:',threading.currentThread().ident,' 访问了:',url) return requests.get(url) #这里使用了requests 模块ex = ThreadPoolExecutor(max_workers=3) #最多3个线程future_tasks = [ex.submit(get_html,url) for url in URLS] #创建3个future对象try: result = wait(future_tasks,return_when = fu.FIRST_COMPLETED) done_set = result[0] for future in done_set: resp = future.result() print('第一个网页任务完成 url:%s , len:%d bytes! ' % (resp.url, len(resp.text)))except Exception as e: print('exception :' , e) add_done__callback(fn)例子1234567891011121314151617181920212223242526272829303132333435363738394041424344import os,sys,time,requests,threadingfrom concurrent import futures URLS = [ 'http://baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn' ] def load_url(url): print('tid:',threading.currentThread().ident,',url:',url) with requests.get(url) as resp: return resp.contentdef call_back(obj): print('-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid:',threading.currentThread().ident, ',obj:',obj) with futures.ThreadPoolExecutor(max_workers=3) as ex: # mp = &#123;ex.submit(load_url,url) : url for url in URLS&#125; mp = dict() for url in URLS: f = ex.submit(load_url,url) mp[f] = url f.add_done_callback(call_back) for f in futures.as_completed(mp): url = mp[f] try: data = f.result() except Exception as exc: print(exc, ',url:',url) else: print('url:', url, ',len:',len(data),',data[:20]:',data[:20])"""tid: 7128 ,url: http://baidu.comtid: 7892 ,url: http://www.qq.comtid: 3712 ,url: http://www.sina.com.cn-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 7892 ,obj: &lt;Future at 0x2dd64b0 state=finished returned bytes&gt;url: http://www.qq.com ,len: 251215 ,data[:20]: b'&lt;!DOCTYPE html&gt;\n&lt;htm'-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 3712 ,obj: &lt;Future at 0x2de07b0 state=finished returned bytes&gt;url: http://www.sina.com.cn ,len: 577333 ,data[:20]: b'&lt;!DOCTYPE html&gt;\n&lt;!--'-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 7128 ,obj: &lt;Future at 0x2d533d0 state=finished returned bytes&gt;url: http://baidu.com ,len: 81 ,data[:20]: b'&lt;html&gt;\n&lt;meta http-eq'""" futures例子1234567891011121314151617181920212223242526272829303132333435363738394041424344import os,sys,time,requests,threadingfrom concurrent import futures URLS = [ 'http://baidu.com', 'http://www.qq.com', 'http://www.sina.com.cn' ] def load_url(url): print('tid:',threading.currentThread().ident,',url:',url) with requests.get(url) as resp: return resp.contentdef call_back(obj): print('-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid:',threading.currentThread().ident, ',obj:',obj) with futures.ThreadPoolExecutor(max_workers=3) as ex: # mp = &#123;ex.submit(load_url,url) : url for url in URLS&#125; mp = dict() for url in URLS: f = ex.submit(load_url,url) mp[f] = url f.add_done_callback(call_back) for f in futures.as_completed(mp): url = mp[f] try: data = f.result() except Exception as exc: print(exc, ',url:',url) else: print('url:', url, ',len:',len(data),',data[:20]:',data[:20])"""tid: 7128 ,url: http://baidu.comtid: 7892 ,url: http://www.qq.comtid: 3712 ,url: http://www.sina.com.cn-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 7892 ,obj: &lt;Future at 0x2dd64b0 state=finished returned bytes&gt;url: http://www.qq.com ,len: 251215 ,data[:20]: b'&lt;!DOCTYPE html&gt;\n&lt;htm'-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 3712 ,obj: &lt;Future at 0x2de07b0 state=finished returned bytes&gt;url: http://www.sina.com.cn ,len: 577333 ,data[:20]: b'&lt;!DOCTYPE html&gt;\n&lt;!--'-&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;call_back , tid: 7128 ,obj: &lt;Future at 0x2d533d0 state=finished returned bytes&gt;url: http://baidu.com ,len: 81 ,data[:20]: b'&lt;html&gt;\n&lt;meta http-eq'""" 小结 切记一定要使用with，而不要使用for，如果你一定要用for，那么一定要手动进行executor.shutdown，而你使用了with方法的话，再with方法内部已经实现了wait(),在使用完毕之后可以自行关闭线程池，减少资源浪费。 ProcessPoolExecutor类会利用multiprocessing模块所提供的底层机制，multiprocessing是基于进程的并行。]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library html.parser]]></title>
    <url>%2F2020%2F01%2F29%2Fpython-standard-library-html-parser%2F</url>
    <content type="text"><![CDATA[python 标准库 html.parser 简单HTML和XHTML解析器 源代码： Lib/html/parser.py这个模块定义了一个 HTMLParser 类，为 HTML（超文本标记语言）和 XHTML 文本文件解析提供基础。 class html.parser.HTMLParser(**, convert_charrefs=True*) 创建一个能解析无效标记的解析器实例。如果 convert_charrefs 为 True (默认值)，则所有字符引用( script/style 元素中的除外)都会自动转换为相应的 Unicode 字符。一个 HTMLParser 类的实例用来接受 HTML 数据，并在标记开始、标记结束、文本、注释和其他元素标记出现的时候调用对应的方法。要实现具体的行为，请使用 HTMLParser 的子类并重载其方法。这个解析器不检查结束标记是否与开始标记匹配，也不会因外层元素完毕而隐式关闭了的元素引发结束标记处理。 HTML 解析器的示例程序下面是简单的 HTML 解析器的一个基本示例，使用 HTMLParser 类，当遇到开始标记、结束标记以及数据的时候将内容打印出来。 123456789101112131415from html.parser import HTMLParserclass MyHTMLParser(HTMLParser): def handle_starttag(self, tag, attrs): print("Encountered a start tag:", tag) def handle_endtag(self, tag): print("Encountered an end tag :", tag) def handle_data(self, data): print("Encountered some data :", data)parser = MyHTMLParser()parser.feed('&lt;html&gt;&lt;head&gt;&lt;title&gt;Test&lt;/title&gt;&lt;/head&gt;' '&lt;body&gt;&lt;h1&gt;Parse me!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;') 输出是: 123456789101112Encountered a start tag: htmlEncountered a start tag: headEncountered a start tag: titleEncountered some data : TestEncountered an end tag : titleEncountered an end tag : headEncountered a start tag: bodyEncountered a start tag: h1Encountered some data : Parse me!Encountered an end tag : h1Encountered an end tag : bodyEncountered an end tag : html HTMLParser 方法HTMLParser 实例有下列方法： HTMLParser.feed(data) 填充一些文本到解析器中。如果包含完整的元素，则被处理；如果数据不完整，将被缓冲直到更多的数据被填充，或者 close() 被调用。data 必须为 str 类型。 HTMLParser.close() 如同后面跟着一个文件结束标记一样，强制处理所有缓冲数据。这个方法能被派生类重新定义，用于在输入的末尾定义附加处理，但是重定义的版本应当始终调用基类 HTMLParser 的 close() 方法。 HTMLParser.reset() 重置实例。丢失所有未处理的数据。在实例化阶段被隐式调用。 HTMLParser.getpos() 返回当前行号和偏移值。 HTMLParser.get_starttag_text() 返回最近打开的开始标记中的文本。 结构化处理时通常应该不需要这个，但在处理“已部署”的 HTML 或是在以最小改变来重新生成输入时可能会有用处（例如可以保留属性间的空格等）。 下列方法将在遇到数据或者标记元素的时候被调用。他们需要在子类中重载。基类的实现中没有任何实际操作（除了 handle_startendtag() ）： HTMLParser.handle_starttag(tag, attrs) 这个方法在标签开始的时候被调用（例如： ）。tag 参数是小写的标记名。attrs 参数是一个 (name, value) 形式的列表，包含了所有在标记的 &lt;&gt; 括号中找到的属性。name 转换为小写，value 的引号被去除，字符和实体引用都会被替换。实例中，对于标签 ，这个方法将以下列形式被调用 handle_starttag(&#39;a&#39;, [(&#39;href&#39;, &#39;https://www.cwi.nl/&#39;)]) 。html.entities 中的所有实体引用，会被替换为属性值。 HTMLParser.handle_endtag(tag) 此方法被用来处理元素的结束标记（例如： ）。tag 参数是小写的标签名。 HTMLParser.handle_startendtag(tag, attrs) 类似于 handle_starttag(), 只是在解析器遇到 XHTML 样式的空标记时被调用（ ）。这个方法能被需要这种特殊词法信息的子类重载；默认实现仅简单调用 handle_starttag() 和 handle_endtag() 。 HTMLParser.handle_data(data) 这个方法被用来处理任意数据（例如：文本节点和 ... 以及 ... 中的内容）。 HTMLParser.handle_entityref(name) 这个方法被用于处理 &amp;name; 形式的命名字符引用（例如 &gt;），其中 name 是通用的实体引用（例如： &#39;gt&#39;）。如果 convert_charrefs 为 True，该方法永远不会被调用。 HTMLParser.handle_charref(name) 这个方法被用来处理 &amp;#NNN; 和 &amp;#xNNN; 形式的十进制和十六进制字符引用。例如，&gt; 等效的十进制形式为 &gt; ，而十六进制形式为 &gt; ；在这种情况下，方法将收到 &#39;62&#39; 或 &#39;x3E&#39; 。如果 convert_charrefs 为 True ，则该方法永远不会被调用。 HTMLParser.handle_comment(data) 这个方法在遇到注释的时候被调用（例如： ）。例如， 这个注释会用 &#39; comment &#39; 作为参数调用此方法。Internet Explorer 条件注释（condcoms）的内容也被发送到这个方法，因此，对于 ，这个方法将接收到 `’[if IE 9]&gt;IE9-specific content 。 HTMLParser.handle_decl(decl) 这个方法用来处理 HTML doctype 申明（例如 ）。decl 形参为 标记中的所有内容（例如： &#39;DOCTYPE html&#39; ）。 HTMLParser.handle_pi(data) 此方法在遇到处理指令的时候被调用。data 形参将包含整个处理指令。例如，对于处理指令 ，这个方法将以 handle_pi(&quot;proc color=&#39;red&#39;&quot;) 形式被调用。它旨在被派生类重载；基类实现中无任何实际操作。注解 HTMLParser 类使用 SGML 语法规则处理指令。使用 &#39;?&#39; 结尾的 XHTML 处理指令将导致 &#39;?&#39; 包含在 data 中。 HTMLParser.unknown_decl(data) 当解析器读到无法识别的声明时，此方法被调用。data 形参为 标记中的所有内容。某些时候对派生类的重载很有用。基类实现中无任何实际操作。 示例下面的类实现了一个解析器，用于更多示例的演示: 123456789101112131415161718192021222324252627282930313233from html.parser import HTMLParserfrom html.entities import name2codepointclass MyHTMLParser(HTMLParser): def handle_starttag(self, tag, attrs): print("Start tag:", tag) for attr in attrs: print(" attr:", attr) def handle_endtag(self, tag): print("End tag :", tag) def handle_data(self, data): print("Data :", data) def handle_comment(self, data): print("Comment :", data) def handle_entityref(self, name): c = chr(name2codepoint[name]) print("Named ent:", c) def handle_charref(self, name): if name.startswith('x'): c = chr(int(name[1:], 16)) else: c = chr(int(name)) print("Num ent :", c) def handle_decl(self, data): print("Decl :", data)parser = MyHTMLParser() 解析一个文档类型声明: 123&gt;&gt;&gt; parser.feed('&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" '... '"http://www.w3.org/TR/html4/strict.dtd"&gt;')Decl : DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd" 解析一个具有一些属性和标题的元素: 123456789&gt;&gt;&gt; parser.feed('&lt;img src="python-logo.png" alt="The Python logo"&gt;')Start tag: img attr: ('src', 'python-logo.png') attr: ('alt', 'The Python logo')&gt;&gt;&gt;&gt;&gt;&gt; parser.feed('&lt;h1&gt;Python&lt;/h1&gt;')Start tag: h1Data : PythonEnd tag : h1 script 和 style 元素中的内容原样返回，无需进一步解析: 123456789101112&gt;&gt;&gt; parser.feed('&lt;style type="text/css"&gt;#python &#123; color: green &#125;&lt;/style&gt;')Start tag: style attr: ('type', 'text/css')Data : #python &#123; color: green &#125;End tag : style&gt;&gt;&gt; parser.feed('&lt;script type="text/javascript"&gt;'... 'alert("&lt;strong&gt;hello!&lt;/strong&gt;");&lt;/script&gt;')Start tag: script attr: ('type', 'text/javascript')Data : alert("&lt;strong&gt;hello!&lt;/strong&gt;");End tag : script 解析注释: 1234&gt;&gt;&gt; parser.feed('&lt;!-- a comment --&gt;'... '&lt;!--[if IE 9]&gt;IE-specific content&lt;![endif]--&gt;')Comment : a commentComment : [if IE 9]&gt;IE-specific content&lt;![endif] 解析命名或数字形式的字符引用，并把他们转换到正确的字符（注意：这 3 种转义都是 &#39;&gt;&#39; ）: 1234&gt;&gt;&gt; parser.feed('&amp;gt;&amp;#62;&amp;#x3E;')Named ent: &gt;Num ent : &gt;Num ent : &gt; 填充不完整的块给 feed() 执行，handle_data() 可能会多次调用（除非 convert_charrefs 被设置为 True ）: 12345678&gt;&gt;&gt; for chunk in ['&lt;sp', 'an&gt;buff', 'ered ', 'text&lt;/s', 'pan&gt;']:... parser.feed(chunk)...Start tag: spanData : buffData : eredData : textEnd tag : span 解析无效的 HTML (例如：未引用的属性）也能正常运行: 12345678&gt;&gt;&gt; parser.feed('&lt;p&gt;&lt;a class=link href=#main&gt;tag soup&lt;/p &gt;&lt;/a&gt;')Start tag: pStart tag: a attr: ('class', 'link') attr: ('href', '#main')Data : tag soupEnd tag : pEnd tag : a]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>html.parser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library enum]]></title>
    <url>%2F2020%2F01%2F28%2Fpython-standard-library-enum%2F</url>
    <content type="text"><![CDATA[python 标准库 enum 枚举类型支持 源码源代码： Lib/enum.py 枚举是一组符号名称（枚举成员）的集合，枚举成员应该是唯一的、不可变的。在枚举中，可以对成员进行恒等比较，并且枚举本身是可迭代的。 类此模块定义了四个枚举类，它们可被用来定义名称和值的不重复集合: Enum, IntEnum, Flag 和 IntFlag。 此外还定义了一个装饰器 unique() 和一个辅助类 auto。 class enum.Enum 此基类用于创建枚举常量。 请参阅 Functional API 小节了解另一种替代性的构建语法。 class enum.IntEnum 此基类用于创建属于 int 的子类的枚举常量。 class enum.IntFlag 此基类用于创建可使用按位运算符进行组合而不会丢失其 IntFlag 成员资格的枚举常量。 IntFlag 成员同样也是 int 的子类。 class enum.Flag 此基类用于创建枚举常量 可使用按位运算符进行组合而不会丢失其 Flag 成员资格的枚举常量。 enum.unique() 此 Enum 类装饰器可确保只将一个名称绑定到任意一个值。 class enum.auto 实例会被替换为一个可作为 Enum 成员的适当的值。 初始值从 1 开始。 创建一个 Enum 枚举是使用 class 语法来创建的，这使得它们易于读写。 另一种替代创建方法的描述见 Functional API。 要定义一个枚举，可以对 Enum 进行如下的子类化: 123456&gt;&gt;&gt; from enum import Enum&gt;&gt;&gt; class Color(Enum):... RED = 1... GREEN = 2... BLUE = 3... 成员值可以为任意类型: int, str 等等。 如果具体的值不重要，你可以使用 auto 实例，将为你选择适当的值。 但如果你混用 auto 与其他值则需要小心谨慎。 虽然我们使用 class 语法来创建 Enum，但 Enum 并不是普通的 Python 类。 更多细节请参阅 How are Enums different 命名 类 Color 是一个 枚举 (或称 enum) 属性 Color.RED, Color.GREEN 等等是 枚举成员 (或称 enum 成员) 并且被用作常量。 枚举成员具有 名称 和 值 (Color.RED 的名称为 RED，Color.BLUE 的值为 3 等等。) 枚举成员具有适合人类阅读的表示形式: 12&gt;&gt;&gt; print(Color.RED)Color.RED .而它们的 repr 包含更多信息: 12&gt;&gt;&gt; print(repr(Color.RED))&lt;Color.RED: 1&gt; 一个枚举成员的 type 就是它所从属的枚举: 12345&gt;&gt;&gt; type(Color.RED)&lt;enum 'Color'&gt;&gt;&gt;&gt; isinstance(Color.GREEN, Color)True&gt;&gt;&gt; Enum 的成员还有一个包含其条目名称的特征属性: 12&gt;&gt;&gt; print(Color.RED.name)RED 枚举支持按照定义顺序进行迭代: 12345678910111213&gt;&gt;&gt; class Shake(Enum):... VANILLA = 7... CHOCOLATE = 4... COOKIES = 9... MINT = 3...&gt;&gt;&gt; for shake in Shake:... print(shake)...Shake.VANILLAShake.CHOCOLATEShake.COOKIESShake.MINT 枚举成员是可哈希的，因此它们可在字典和集合中可用: 12345&gt;&gt;&gt; apples = &#123;&#125;&gt;&gt;&gt; apples[Color.RED] = 'red delicious'&gt;&gt;&gt; apples[Color.GREEN] = 'granny smith'&gt;&gt;&gt; apples == &#123;Color.RED: 'red delicious', Color.GREEN: 'granny smith'&#125;True 对枚举成员及其属性的程序化访问 有时对枚举中的成员进行程序化访问是很有用的（例如在某些场合不能使用 Color.RED 因为在编程时并不知道要指定的确切颜色）。 Enum 允许这样的访问: 1234&gt;&gt;&gt; Color(1)&lt;Color.RED: 1&gt;&gt;&gt;&gt; Color(3)&lt;Color.BLUE: 3&gt; 如果你希望通过 name 来访问枚举成员，可使用条目访问: 1234&gt;&gt;&gt; Color['RED']&lt;Color.RED: 1&gt;&gt;&gt;&gt; Color['GREEN']&lt;Color.GREEN: 2&gt; 如果你有一个枚举成员并且需要它的 name 或 value: 12345&gt;&gt;&gt; member = Color.RED&gt;&gt;&gt; member.name'RED'&gt;&gt;&gt; member.value1 复制枚举成员和值 不允许有同名的枚举成员: 1234567&gt;&gt;&gt; class Shape(Enum):... SQUARE = 2... SQUARE = 3...Traceback (most recent call last):...TypeError: Attempted to reuse key: 'SQUARE' 但是，允许两个枚举成员有相同的值。 假定两个成员 A 和 B 有相同的值（且 A 先被定义），则 B 就是 A 的一个别名。 按值查找 A 和 B 的值将返回 A。 按名称查找 B 也将返回 A: 123456789101112&gt;&gt;&gt; class Shape(Enum):... SQUARE = 2... DIAMOND = 1... CIRCLE = 3... ALIAS_FOR_SQUARE = 2...&gt;&gt;&gt; Shape.SQUARE&lt;Shape.SQUARE: 2&gt;&gt;&gt;&gt; Shape.ALIAS_FOR_SQUARE&lt;Shape.SQUARE: 2&gt;&gt;&gt;&gt; Shape(2)&lt;Shape.SQUARE: 2&gt; 试图创建具有与某个已定义的属性（另一个成员或方法等）相同名称的成员或者试图创建具有相同名称的属性也是不允许的 确保唯一的枚举值 默认情况下，枚举允许有多个名称作为某个相同值的别名。 如果不想要这样的行为，可以使用以下装饰器来确保每个值在枚举中只被使用一次: `@enum.unique` 专用于枚举的 class 装饰器。 它会搜索一个枚举的 __members__ 并收集所找到的任何别名；只要找到任何别名就会引发 ValueError 并附带相关细节信息: 1234567891011&gt;&gt;&gt; from enum import Enum, unique&gt;&gt;&gt; @unique... class Mistake(Enum):... ONE = 1... TWO = 2... THREE = 3... FOUR = 3...Traceback (most recent call last):...ValueError: duplicate values found in &lt;enum 'Mistake'&gt;: FOUR -&gt; THREE 使用自动设定的值 如果确切的值不重要，你可以使用 auto: 12345678&gt;&gt;&gt; from enum import Enum, auto&gt;&gt;&gt; class Color(Enum):... RED = auto()... BLUE = auto()... GREEN = auto()...&gt;&gt;&gt; list(Color)[&lt;Color.RED: 1&gt;, &lt;Color.BLUE: 2&gt;, &lt;Color.GREEN: 3&gt;] 值将由 _generate_next_value_() 来选择，该函数可以被重载: 123456789101112&gt;&gt;&gt; class AutoName(Enum):... def _generate_next_value_(name, start, count, last_values):... return name...&gt;&gt;&gt; class Ordinal(AutoName):... NORTH = auto()... SOUTH = auto()... EAST = auto()... WEST = auto()...&gt;&gt;&gt; list(Ordinal)[&lt;Ordinal.NORTH: 'NORTH'&gt;, &lt;Ordinal.SOUTH: 'SOUTH'&gt;, &lt;Ordinal.EAST: 'EAST'&gt;, &lt;Ordinal.WEST: 'WEST'&gt;] 默认 _generate_next_value_() 方法的目标是提供所给出的最后一个 int 所在序列的下一个 int，但这种行为方式属于实现细节并且可能发生改变。 迭代 对枚举成员的迭代不会给出别名: 12&gt;&gt;&gt; list(Shape)[&lt;Shape.SQUARE: 2&gt;, &lt;Shape.DIAMOND: 1&gt;, &lt;Shape.CIRCLE: 3&gt;] 特殊属性 __members__ 是一个从名称到成员的只读有序映射。 它包含枚举中定义的所有名称，包括别名: 1234567&gt;&gt;&gt; for name, member in Shape.__members__.items():... name, member...('SQUARE', &lt;Shape.SQUARE: 2&gt;)('DIAMOND', &lt;Shape.DIAMOND: 1&gt;)('CIRCLE', &lt;Shape.CIRCLE: 3&gt;)('ALIAS_FOR_SQUARE', &lt;Shape.SQUARE: 2&gt;) __members__ 属性可被用于对枚举成员进行详细的程序化访问。 例如，找出所有别名: 12&gt;&gt;&gt; [name for name, member in Shape.__members__.items() if member.name != name]['ALIAS_FOR_SQUARE'] 比较 枚举成员是按标识号进行比较的: 123456&gt;&gt;&gt; Color.RED is Color.REDTrue&gt;&gt;&gt; Color.RED is Color.BLUEFalse&gt;&gt;&gt; Color.RED is not Color.BLUETrue 枚举值之间的排序比较 不被 支持。 Enum 成员不属于整数 (另请参阅下文的 IntEnum): 1234&gt;&gt;&gt; Color.RED &lt; Color.BLUETraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: '&lt;' not supported between instances of 'Color' and 'Color' 相等比较的定义如下: 123456&gt;&gt;&gt; Color.BLUE == Color.REDFalse&gt;&gt;&gt; Color.BLUE != Color.REDTrue&gt;&gt;&gt; Color.BLUE == Color.BLUETrue 与非枚举值的比较将总是不相等（同样地，IntEnum 被显式设计成不同的行为，参见下文）: 12&gt;&gt;&gt; Color.BLUE == 2False 允许的枚举成员和属性以上示例使用整数作为枚举值。 使用整数相当简洁方便（并由 Functional API 默认提供），但并不强制要求使用。 在大部分用例中，开发者都关心枚举的实际值是什么。 但如果值 确实 重要，则枚举可以使用任意的值。 枚举属于 Python 的类，并可具有普通方法和特殊方法。 如果我们有这样一个枚举: 12345678910111213141516&gt;&gt;&gt; class Mood(Enum):... FUNKY = 1... HAPPY = 3...... def describe(self):... # self is the member here... return self.name, self.value...... def __str__(self):... return 'my custom str! &#123;0&#125;'.format(self.value)...... @classmethod... def favorite_mood(cls):... # cls here is the enumeration... return cls.HAPPY... 那么: 123456&gt;&gt;&gt; Mood.favorite_mood()&lt;Mood.HAPPY: 3&gt;&gt;&gt;&gt; Mood.HAPPY.describe()('HAPPY', 3)&gt;&gt;&gt; str(Mood.FUNKY)'my custom str! 1' 对于允许内容的规则如下：以单下划线开头和结尾的名称是由枚举保留而不可使用；在枚举中定义的所有其他属性将成为该枚举的成员，例外项则包括特殊方法成员 (__str__(), __add__() 等)，描述符 (方法也属于描述符) 以及在 _ignore_ 中列出的变量名。 注意：如果你的枚举定义了 __new__() 和/或 __init__() 那么指定给枚举成员的任何值都会被传入这些方法。 请参阅示例 Planet。 受限的 Enum 子类化 一个新的 Enum 类必须基于一个 Enum 类，至多一个实体数据类型以及出于实际需要的任意多个基于 object 的 mixin 类。 这些基类的顺序为: 12class EnumName([mix-in, ...,] [data-type,] base-enum): pass 另外，仅当一个枚举未定义任何成员时才允许子类化该枚举。 因此禁止这样的写法: 123456&gt;&gt;&gt; class MoreColor(Color):... PINK = 17...Traceback (most recent call last):...TypeError: Cannot extend enumerations 但是允许这样的写法: 12345678&gt;&gt;&gt; class Foo(Enum):... def some_behavior(self):... pass...&gt;&gt;&gt; class Bar(Foo):... HAPPY = 1... SAD = 2... 允许子类化定义了成员的枚举将会导致违反类型与实例的某些重要的不可变规则。 在另一方面，允许在一组枚举之间共享某些通用行为也是有意义的。 （请参阅示例 OrderedEnum 。） 封装 枚举可以被封装与解封: 1234&gt;&gt;&gt; from test.test_enum import Fruit&gt;&gt;&gt; from pickle import dumps, loads&gt;&gt;&gt; Fruit.TOMATO is loads(dumps(Fruit.TOMATO))True 封装的常规限制同样适用：可封存枚举必须在模块的最高层级中定义，因为解封操作要求它们可以从该模块导入。 使用 pickle 协议版本 4 可以方便地封存嵌套在其他类中的枚举。 通过在枚举类中定义 __reduce_ex__() 可以对 Enum 成员的封存/解封方式进行修改。 功能性 API Enum 类属于可调用对象，它提供了以下功能性 API: 123456789&gt;&gt;&gt; Animal = Enum('Animal', 'ANT BEE CAT DOG')&gt;&gt;&gt; Animal&lt;enum 'Animal'&gt;&gt;&gt;&gt; Animal.ANT&lt;Animal.ANT: 1&gt;&gt;&gt;&gt; Animal.ANT.value1&gt;&gt;&gt; list(Animal)[&lt;Animal.ANT: 1&gt;, &lt;Animal.BEE: 2&gt;, &lt;Animal.CAT: 3&gt;, &lt;Animal.DOG: 4&gt;] 该 API 的主义类似于 namedtuple。 调用 Enum 的第一个参数是枚举的名称。 第二个参数是枚举成员名称的 来源。 它可以是一个用空格分隔的名称字符串、名称序列、键/值对 2 元组的序列，或者名称到值的映射（例如字典）。 最后两种选项使得可以为枚举任意赋值；其他选项会自动以从 1 开始递增的整数赋值（使用 start 形参可指定不同的起始值）。 返回值是一个派生自 Enum 的新类。 换句话说，以上对 Animal 的赋值就等价于: 123456&gt;&gt;&gt; class Animal(Enum):... ANT = 1... BEE = 2... CAT = 3... DOG = 4... 默认以 1 而以 0 作为起始数值的原因在于 0 的布尔值为 False，但所有枚举成员都应被求值为 True。 对使用功能性 API 创建的枚举执行封存可能会很麻烦，因为要使用帧堆栈的实现细节来尝试并找出枚举是在哪个模块中创建的（例如当你使用了另一个模块中的工具函数就可能失败，在 IronPython 或 Jython 上也可能无效）。 解决办法是显式地指定模块名称，如下所示: 1&gt;&gt;&gt; Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__) 新的 pickle 协议版本 4 在某些情况下同样依赖于 __qualname__ 被设为特定位置以便 pickle 能够找到相应的类。 例如，类是否存在于全局作用域的 SomeData 类中: 1&gt;&gt;&gt; Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal') 完整的签名为: 1Enum(value='NewEnumName', names=&lt;...&gt;, *, module='...', qualname='...', type=&lt;mixed-in class&gt;, start=1) 派生的枚举IntEnum 所提供的第一个变种 Enum 同时也是 int 的一个子类。 IntEnum 的成员可与整数进行比较；通过扩展，不同类型的整数枚举也可以相互进行比较: 123456789101112131415&gt;&gt;&gt; from enum import IntEnum&gt;&gt;&gt; class Shape(IntEnum):... CIRCLE = 1... SQUARE = 2...&gt;&gt;&gt; class Request(IntEnum):... POST = 1... GET = 2...&gt;&gt;&gt; Shape == 1False&gt;&gt;&gt; Shape.CIRCLE == 1True&gt;&gt;&gt; Shape.CIRCLE == Request.POSTTrue 不过，它们仍然不可与标准 Enum 枚举进行比较: 12345678910&gt;&gt;&gt; class Shape(IntEnum):... CIRCLE = 1... SQUARE = 2...&gt;&gt;&gt; class Color(Enum):... RED = 1... GREEN = 2...&gt;&gt;&gt; Shape.CIRCLE == Color.REDFalse IntEnum 值在其他方面的行为都如你预期的一样类似于整数: 123456&gt;&gt;&gt; int(Shape.CIRCLE)1&gt;&gt;&gt; ['a', 'b', 'c'][Shape.CIRCLE]'b'&gt;&gt;&gt; [i for i in range(Shape.SQUARE)][0, 1] IntFlag 所提供的下一个 Enum 的变种 IntFlag 同样是基于 int 的，不同之处在于 IntFlag 成员可使用按位运算符 (&amp;, |, ^, ~) 进行组合且结果仍然为 IntFlag 成员。 如果，正如名称所表明的，IntFlag 成员同时也是 int 的子类，并能在任何使用 int 的场合被使用。 IntFlag 成员进行除按位运算以外的其他运算都将导致失去 IntFlag 成员资格。 示例 IntFlag 类: 12345678910111213&gt;&gt;&gt; from enum import IntFlag&gt;&gt;&gt; class Perm(IntFlag):... R = 4... W = 2... X = 1...&gt;&gt;&gt; Perm.R | Perm.W&lt;Perm.R|W: 6&gt;&gt;&gt;&gt; Perm.R + Perm.W6&gt;&gt;&gt; RW = Perm.R | Perm.W&gt;&gt;&gt; Perm.R in RWTrue 对于组合同样可以进行命名: 123456789&gt;&gt;&gt; class Perm(IntFlag):... R = 4... W = 2... X = 1... RWX = 7&gt;&gt;&gt; Perm.RWX&lt;Perm.RWX: 7&gt;&gt;&gt;&gt; ~Perm.RWX&lt;Perm.-8: -8&gt; IntFlag 和 Enum 的另一个重要区别在于如果没有设置任何旗标（值为 0），则其布尔值为 False: 1234&gt;&gt;&gt; Perm.R &amp; Perm.X&lt;Perm.0: 0&gt;&gt;&gt;&gt; bool(Perm.R &amp; Perm.X)False 由于 IntFlag 成员同时也是 int 的子类，因此它们可以相互组合: 12&gt;&gt;&gt; Perm.X | 8&lt;Perm.8|X: 9&gt; Flag 最后一个变种是 Flag。 与 IntFlag 类似，Flag 成员可使用按位运算符 (&amp;, |, ^, ~) 进行组合，与 IntFlag 不同的是它们不可与任何其它 Flag 枚举或 int 进行组合或比较。 虽然可以直接指定值，但推荐使用 auto 作为值以便让 Flag 选择适当的值。 与 IntFlag 类似，如果 Flag 成员的某种组合导致没有设置任何旗标，则其布尔值为 False: 12345678910&gt;&gt;&gt; from enum import Flag, auto&gt;&gt;&gt; class Color(Flag):... RED = auto()... BLUE = auto()... GREEN = auto()...&gt;&gt;&gt; Color.RED &amp; Color.GREEN&lt;Color.0: 0&gt;&gt;&gt;&gt; bool(Color.RED &amp; Color.GREEN)False 单个旗标的值应当为二的乘方 (1, 2, 4, 8, …)，旗标的组合则无此限制: 12345678&gt;&gt;&gt; class Color(Flag):... RED = auto()... BLUE = auto()... GREEN = auto()... WHITE = RED | BLUE | GREEN...&gt;&gt;&gt; Color.WHITE&lt;Color.WHITE: 7&gt; 对 “no flags set” 条件指定一个名称并不会改变其布尔值: 12345678910&gt;&gt;&gt; class Color(Flag):... BLACK = 0... RED = auto()... BLUE = auto()... GREEN = auto()...&gt;&gt;&gt; Color.BLACK&lt;Color.BLACK: 0&gt;&gt;&gt;&gt; bool(Color.BLACK)False 对于大多数新代码，强烈推荐使用 Enum 和 Flag，因为 IntEnum 和 IntFlag 打破了枚举的某些语义约定（例如可以同整数进行比较，并因而导致此行为被传递给其他无关的枚举）。 IntEnum 和 IntFlag 的使用应当仅限于 Enum 和 Flag 无法使用的场合；例如，当使用枚举替代整数常量时，或是与其他系统进行交互操作时。 其他事项 虽然 IntEnum 是 enum 模块的一部分，但要独立实现也应该相当容易: 12class IntEnum(int, Enum): pass 这里演示了如何定义类似的派生枚举；例如一个混合了 str 而不是 int 的 StrEnum。 几条规则： 当子类化 Enum 时，在基类序列中的混合类型必须出现于 Enum 本身之前，如以上 IntEnum 的例子所示。 虽然 Enum 可以拥有任意类型的成员，不过一旦你混合了附加类型，则所有成员必须为相应类型的值，如在上面的例子中即为 int。 此限制不适用于仅添加方法而未指定另一数据类型如 int 或 str 的混合类。 当混合了另一数据类型时，value 属性会 不同于 枚举成员自身，但它们仍保持等价且比较结果也相等。 %-style formatting: %s 和 %r 会分别调用 Enum 类的 __str__() 和 __repr__()；其他代码 (例如表示 IntEnum 的 %i 或 %h) 会将枚举成员视为对应的混合类型。 格式化字符串字面值, str.format() 和 format() 将使用混合类型的 __format__()。 如果需要 Enum 类的 str() 或 repr()，请使用 !s 或 !r 格式代码。 何时使用 __init__与__new__当你想要定制 Enum 成员的实际值时必须使用 __new__()。 任何其他修改可以用 __new__() 也可以用 __init__()，应优先使用 __init__()。 举例来说，如果你要向构造器传入多个条目，但只希望将其中一个作为值: 123456789101112131415161718192021&gt;&gt;&gt; class Coordinate(bytes, Enum):... """... Coordinate with binary codes that can be indexed by the int code.... """... def __new__(cls, value, label, unit):... obj = bytes.__new__(cls, [value])... obj._value_ = value... obj.label = label... obj.unit = unit... return obj... PX = (0, 'P.X', 'km')... PY = (1, 'P.Y', 'km')... VX = (2, 'V.X', 'km/s')... VY = (3, 'V.Y', 'km/s')...&gt;&gt;&gt; print(Coordinate['PY'])Coordinate.PY&gt;&gt;&gt; print(Coordinate(3))Coordinate.VY 有趣的示例 虽然 Enum, IntEnum, IntFlag 和 Flag 预期可覆盖大多数应用场景，但它们无法覆盖全部。 这里有一些不同类型枚举的方案，它们可以被直接使用，或是作为自行创建的参考示例。 省略值在许多应用场景中人们都不关心枚举的实际值是什么。 有几个方式可以定义此种类型的简单枚举： 使用 auto 的实例作为值 使用 object 的实例作为值 使用描述性的字符串作为值 使用元组作为值并用自定义的 __new__() 以一个 int 值来替代该元组 使用以上任何一种方法均可向用户指明值并不重要，并且使人能够添加、移除或重排序成员而不必改变其余成员的数值。 无论你选择何种方法，你都应当提供一个 repr() 并且它也需要隐藏（不重要的）值: 1234&gt;&gt;&gt; class NoValue(Enum):... def __repr__(self):... return '&lt;%s.%s&gt;' % (self.__class__.__name__, self.name)... 使用auto使用 auto 的形式如下: 1234567&gt;&gt;&gt; class Color(NoValue):... RED = auto()... BLUE = auto()... GREEN = auto()...&gt;&gt;&gt; Color.GREEN&lt;Color.GREEN&gt; 使用 object使用 object 的形式如下: 1234567&gt;&gt;&gt; class Color(NoValue):... RED = object()... GREEN = object()... BLUE = object()...&gt;&gt;&gt; Color.GREEN&lt;Color.GREEN&gt; 使用描述性字符串使用字符串作为值的形式如下: 123456789&gt;&gt;&gt; class Color(NoValue):... RED = 'stop'... GREEN = 'go'... BLUE = 'too fast!'...&gt;&gt;&gt; Color.GREEN&lt;Color.GREEN&gt;&gt;&gt;&gt; Color.GREEN.value'go' 使用自定义的__new__使用自动编号 __new__() 的形式如下: 12345678910111213141516&gt;&gt;&gt; class AutoNumber(NoValue):... def __new__(cls):... value = len(cls.__members__) + 1... obj = object.__new__(cls)... obj._value_ = value... return obj...&gt;&gt;&gt; class Color(AutoNumber):... RED = () ... GREEN = ()... BLUE = ()...&gt;&gt;&gt; Color.GREEN&lt;Color.GREEN&gt;&gt;&gt;&gt; Color.GREEN.value2 如果定义了 __new__() 则它会在创建 Enum 成员期间被使用；随后它将被 Enum 的 __new__() 所替换，该方法会在类创建后被用来查找现有成员 OrderedEnum 一个有序枚举，它不是基于 IntEnum，因此保持了正常的 Enum 不变特性（例如不可与其他枚举进行比较）: 123456789101112131415161718192021222324252627&gt;&gt;&gt; class OrderedEnum(Enum):... def __ge__(self, other):... if self.__class__ is other.__class__:... return self.value &gt;= other.value... return NotImplemented... def __gt__(self, other):... if self.__class__ is other.__class__:... return self.value &gt; other.value... return NotImplemented... def __le__(self, other):... if self.__class__ is other.__class__:... return self.value &lt;= other.value... return NotImplemented... def __lt__(self, other):... if self.__class__ is other.__class__:... return self.value &lt; other.value... return NotImplemented...&gt;&gt;&gt; class Grade(OrderedEnum):... A = 5... B = 4... C = 3... D = 2... F = 1...&gt;&gt;&gt; Grade.C &lt; Grade.ATrue DuplicateFreeEnum 如果发现重复的成员名称则将引发错误而不是创建别名: 12345678910111213141516171819&gt;&gt;&gt; class DuplicateFreeEnum(Enum):... def __init__(self, *args):... cls = self.__class__... if any(self.value == e.value for e in cls):... a = self.name... e = cls(self.value).name... raise ValueError(... "aliases not allowed in DuplicateFreeEnum: %r --&gt; %r"... % (a, e))...&gt;&gt;&gt; class Color(DuplicateFreeEnum):... RED = 1... GREEN = 2... BLUE = 3... GRENE = 2...Traceback (most recent call last):...ValueError: aliases not allowed in DuplicateFreeEnum: 'GRENE' --&gt; 'GREEN' Planet如果定义了 __new__() 或 __init__() 则枚举成员的值将被传给这些方法: 12345678910111213141516171819202122&gt;&gt;&gt; class Planet(Enum):... MERCURY = (3.303e+23, 2.4397e6)... VENUS = (4.869e+24, 6.0518e6)... EARTH = (5.976e+24, 6.37814e6)... MARS = (6.421e+23, 3.3972e6)... JUPITER = (1.9e+27, 7.1492e7)... SATURN = (5.688e+26, 6.0268e7)... URANUS = (8.686e+25, 2.5559e7)... NEPTUNE = (1.024e+26, 2.4746e7)... def __init__(self, mass, radius):... self.mass = mass # in kilograms... self.radius = radius # in meters... @property... def surface_gravity(self):... # universal gravitational constant (m3 kg-1 s-2)... G = 6.67300E-11... return G * self.mass / (self.radius * self.radius)...&gt;&gt;&gt; Planet.EARTH.value(5.976e+24, 6378140.0)&gt;&gt;&gt; Planet.EARTH.surface_gravity9.802652743337129 TimePeriod 一个演示如何使用 _ignore_ 属性的例子: 123456789101112&gt;&gt;&gt; from datetime import timedelta&gt;&gt;&gt; class Period(timedelta, Enum):... "different lengths of time"... _ignore_ = 'Period i'... Period = vars()... for i in range(367):... Period['day_%d' % i] = i...&gt;&gt;&gt; list(Period)[:2][&lt;Period.day_0: datetime.timedelta(0)&gt;, &lt;Period.day_1: datetime.timedelta(days=1)&gt;]&gt;&gt;&gt; list(Period)[-2:][&lt;Period.day_365: datetime.timedelta(days=365)&gt;, &lt;Period.day_366: datetime.timedelta(days=366)&gt;] 各种枚举有何区别？ 枚举具有自定义的元类，它会影响所派生枚举类及其实例（成员）的各个方面。 枚举类 EnumMeta 元类负责提供 __contains__(), __dir__(), __iter__() 及其他方法以允许用户通过 Enum 类来完成一般类做不到的事情，例如 list(Color) 或 some_enum_var in Color。 EnumMeta 会负责确保最终 Enum 类中的各种其他方法是正确的 (例如 __new__(), __getnewargs__(), __str__() 和 __repr__())。 枚举成员（即实例） 有关枚举成员最有趣的特点是它们都是单例对象。 EnumMeta 会在创建 Enum 类本身时将它们全部创建完成，然后准备好一个自定义的 __new__()，通过只返回现有的成员实例来确保不会再实例化新的对象。 细节要点支持的 __dunder__ 名称__members__ 是一个 member_name:member 条目的只读有序映射。 它只在类上可用。 如果指定了 __new__()，它必须创建并返回枚举成员；相应地设定成员的 _value_ 也是一个很好的主意。 一旦所有成员都创建完成它就不会再被使用。 支持的 _sunder_ 名称 _name_ – 成员的名称 _value_ – 成员的值；可以在 __new__ 中设置 / 修改 _missing_ – 当未发现某个值时所使用的查找函数；可被重载 _ignore_ – 一个名称列表，可以为 list() 或 str()，它将不会被转化为成员，并会从最终类中被移除 _order_ – 用于 Python 2/3 代码以确保成员顺序一致（类属性，在类创建期间会被移除） _generate_next_value_ – 用于 Functional API 并通过 auto 为枚举成员获取适当的值；可被重载 用来帮助 Python 2 / Python 3 代码保持同步提供 _order_ 属性。 它将与枚举的实际顺序进行对照检查，如果两者不匹配则会引发错误: 123456789&gt;&gt;&gt; class Color(Enum):... _order_ = 'RED GREEN BLUE'... RED = 1... BLUE = 3... GREEN = 2...Traceback (most recent call last):...TypeError: member order does not match _order_ Enum 成员类型 Enum 成员是其 Enum 类的实例，一般通过 EnumClass.member 的形式来访问。 在特定情况下它们也可通过 EnumClass.member.member 的形式来访问，但你绝对不应这样做，因为查找可能失败，或者更糟糕地返回你所查找的 Enum 成员以外的对象（这也是成员应使用全大写名称的另一个好理由）: 123456789&gt;&gt;&gt; class FieldTypes(Enum):... name = 0... value = 1... size = 2...&gt;&gt;&gt; FieldTypes.value.size&lt;FieldTypes.size: 2&gt;&gt;&gt;&gt; FieldTypes.size.value2 Enum 类和成员的布尔值混合了非 Enum 类型（例如 int, str 等）的 Enum 成员会按所混合类型的规则被求值；在其他情况下，所有成员都将被求值为 True。 要使你的自定义 Enum 的布尔值取决于成员的值，请在你的类中添加以下代码: 12def __bool__(self): return bool(self.value) Enum 类总是会被求值为 True。 带有方法的 Enum 类如果你为你的 Enum 子类添加了额外的方法，如同上述的 Planet 类一样，这些方法将在对成员执行 dir() 时显示出来，但对类执行时则不会显示: 1234&gt;&gt;&gt; dir(Planet)['EARTH', 'JUPITER', 'MARS', 'MERCURY', 'NEPTUNE', 'SATURN', 'URANUS', 'VENUS', '__class__', '__doc__', '__members__', '__module__']&gt;&gt;&gt; dir(Planet.EARTH)['__class__', '__doc__', '__module__', 'name', 'surface_gravity', 'value'] 组合 Flag 的成员 如果 Flag 成员的某种组合未被命名，则 repr() 将包含所有已命名的旗标和值中所有已命名的旗标组合: 123456789101112&gt;&gt;&gt; class Color(Flag):... RED = auto()... GREEN = auto()... BLUE = auto()... MAGENTA = RED | BLUE... YELLOW = RED | GREEN... CYAN = GREEN | BLUE...&gt;&gt;&gt; Color(3) # named combination&lt;Color.YELLOW: 3&gt;&gt;&gt;&gt; Color(7) # not named combination&lt;Color.CYAN|MAGENTA|BLUE|YELLOW|GREEN|RED: 7&gt;]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library pprint]]></title>
    <url>%2F2020%2F01%2F27%2Fpython-standard-library-pprint%2F</url>
    <content type="text"><![CDATA[python 标准库 pprint 今天凌晨,突闻噩耗, 「黑曼巴」 Kobe Bryant（科比） 永远离开了我们,永远的24号,最伟大的nba球员,没有之一,R.I.P。 源码 源代码： Lib/pprint.py 主要类和函数,节选自源码 12__all__ = ["pprint","pformat","isreadable","isrecursive","saferepr", "PrettyPrinter", "pp"] pprint 模块提供了“美化打印”任意 Python 数据结构的功能，这种美化形式可用作对解释器的输入。 如果经格式化的结构包含非基本 Python 类型的对象，则其美化形式可能无法被加载。 包含文件、套接字或类对象，以及许多其他不能用 Python 字面值来表示的对象都有可能导致这样的结果。 格式化后的形式会在可能的情况下以单行来表示对象，并在无法在允许宽度内容纳对象的情况下将其分为多行。 如果你需要调整宽度限制则应显式地构造 PrettyPrinter 对象。 字典在计算其显示形式前会先根据键来排序。 类 pprint 模块定义了一个类： class pprint.PrettyPrinter(indent=1, width=80, depth=None, stream=None, **, compact=False, sort_dicts=True*) 构造一个 PrettyPrinter 实例。 此构造器接受几个关键字形参。 使用 stream 关键字可设置输出流；流对象使用的唯一方法是文件协议的 write() 方法。 如果未指定此关键字，则 PrettyPrinter 会选择 sys.stdout。 每个递归层次的缩进量由 indent 指定；默认值为一。 其他值可导致输出看起来有些怪异，，但可使得嵌套结构更易区分。 可被打印的层级数量由 depth 控制；如果数据结构的层级被打印得过深，其所包含的下一层级会被替换为 ...。 在默认情况下，对被格式化对象的层级深度没有限制。 希望的输出宽度可使用 width 形参来限制；默认值为 80 个字符。 如果一个结构无法在限定宽度内被格式化，则将做到尽可能接近。 如果 compact 为假值（默认）则长序列的每一项将被格式化为单独的行。 如果 compact 为真值，则将在 width 可容纳的的情况下把尽可能多的项放入每个输出行。 如果 sort_dicts 为真值（默认），字典将被格式化为按键排序，否则将按插入顺序显示。 在 3.8 版更改: 增加了 sort_dicts 形参。 12345678910111213141516171819202122&gt;&gt;&gt; import pprint&gt;&gt;&gt; stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']&gt;&gt;&gt; stuff.insert(0, stuff[:])&gt;&gt;&gt; pp = pprint.PrettyPrinter(indent=4)&gt;&gt;&gt; pp.pprint(stuff)[ ['spam', 'eggs', 'lumberjack', 'knights', 'ni'], 'spam', 'eggs', 'lumberjack', 'knights', 'ni']&gt;&gt;&gt; pp = pprint.PrettyPrinter(width=41, compact=True)&gt;&gt;&gt; pp.pprint(stuff)[['spam', 'eggs', 'lumberjack', 'knights', 'ni'], 'spam', 'eggs', 'lumberjack', 'knights', 'ni']&gt;&gt;&gt; tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',... ('parrot', ('fresh fruit',))))))))&gt;&gt;&gt; pp = pprint.PrettyPrinter(depth=6)&gt;&gt;&gt; pp.pprint(tup)('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...))))))) 函数 pprint 模块还提供了一些快捷函数： pprint.pformat(object, indent=1, width=80, depth=None, **, compact=False, sort_dicts=True*) object 的格式化表示作为字符串返回。 indent, width, depth, compact 和 sort_dicts 将作为格式化形参被传入 PrettyPrinter 构造器。在 3.4 版更改: 增加了 compact 形参。在 3.8 版更改: 增加了 sort_dicts 形参。 pprint.pp(object, args, sort_dicts=False, kwargs*) 打印 object 的格式化表示并附带一个换行符。 如果 sort_dicts 为假值（默认），字典将按键的插入顺序显示，否则将按字典键排序。 args 和 kwargs 将作为格式化形参被传给 pprint()。3.8 新版功能. pprint.pprint(object, stream=None, indent=1, width=80, depth=None, **, compact=False, sort_dicts=True*) 在 stream 上打打印 object 的格式化表示，并附带一个换行符。 如果 stream 为 None，则使用 sys.stdout。 这可以替代 print() 函数在交互式解释器中使用以查看值（你甚至可以执行重新赋值 print = pprint.pprint 以在特定作用域中使用）。 indent, width, depth, compact 和 sort_dicts 将作为格式化形参被传给 PrettyPrinter 构造器。 在 3.8 版更改: 增加了 sort_dicts 形参。 12345678910&gt;&gt;&gt; import pprint&gt;&gt;&gt; stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']&gt;&gt;&gt; stuff.insert(0, stuff)&gt;&gt;&gt; pprint.pprint(stuff)[&lt;Recursion on list with id=...&gt;, 'spam', 'eggs', 'lumberjack', 'knights', 'ni'] PrettyPrinter 对象PrettyPrinter 的实例具有下列方法： PrettyPrinter.pformat(object) 返回 object 格式化表示。 这会将传给 PrettyPrinter 构造器的选项纳入考虑。 PrettyPrinter.pprint(object) 在所配置的流上打印 object 的格式化表示，并附加一个换行符。 下列方法提供了与同名函数相对应的实现。 在实例上使用这些方法效率会更高一些，因为不需要创建新的 PrettyPrinter 对象。 PrettyPrinter.isreadable(object) 确定对象的格式化表示是否“可读”，或者是否可使用 eval() 重建对象值。 请注意此方法对于递归对象将返回 False。 如果设置了 PrettyPrinter 的 depth 形参并且对象深度超出允许范围，此方法将返回 False。 PrettyPrinter.isrecursive(object) 确定对象是否需要递归表示。 此方法作为一个钩子提供，允许子类修改将对象转换为字符串的方式。 默认实现使用 saferepr() 实现的内部方式。 PrettyPrinter.format(object, context, maxlevels, level) 返回三个值：字符串形式的 object 已格式化版本，指明结果是否可读的旗标，以及指明是否检测到递归的旗标。 第一个参数是要表示的对象。 第二个是以对象 id() 为键的字典，这些对象是当前表示上下文的一部分（影响 object 表示的直接和间接容器）；如果需要呈现一个已经在 context 中表示的对象，则第三个返回值应当为 True。 对 format() 方法的递归调用应当将容器的附加条目添加到此字典中。 第三个参数 maxlevels 给出了对递归的请求限制；如果没有请求限制则其值将为 0。 此参数应当不加修改地传给递归调用。 第四个参数 level 给出于当前层级；传给递归调用的参数值应当小于当前调用的值。 示例为了演示 pprint() 函数及其形参的几种用法，让我们从 PyPI 获取关于某个项目的信息: 12345&gt;&gt;&gt; import json&gt;&gt;&gt; import pprint&gt;&gt;&gt; from urllib.request import urlopen&gt;&gt;&gt; with urlopen('https://pypi.org/pypi/sampleproject/json') as resp:... project_info = json.load(resp)['info'] pprint() 以其基本形式显示了整个对象: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&gt;&gt;&gt; pprint.pprint(project_info)&#123;'author': 'The Python Packaging Authority', 'author_email': 'pypa-dev@googlegroups.com', 'bugtrack_url': None, 'classifiers': ['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 2', 'Programming Language :: Python :: 2.6', 'Programming Language :: Python :: 2.7', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.2', 'Programming Language :: Python :: 3.3', 'Programming Language :: Python :: 3.4', 'Topic :: Software Development :: Build Tools'], 'description': 'A sample Python project\n' '=======================\n' '\n' 'This is the description file for the project.\n' '\n' 'The file should use UTF-8 encoding and be written using ' 'ReStructured Text. It\n' 'will be used to generate the project webpage on PyPI, and ' 'should be written for\n' 'that purpose.\n' '\n' 'Typical contents for this file would include an overview of ' 'the project, basic\n' 'usage examples, etc. Generally, including the project ' 'changelog in here is not\n' 'a good idea, although a simple "What\'s New" section for the ' 'most recent version\n' 'may be appropriate.', 'description_content_type': None, 'docs_url': None, 'download_url': 'UNKNOWN', 'downloads': &#123;'last_day': -1, 'last_month': -1, 'last_week': -1&#125;, 'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development', 'license': 'MIT', 'maintainer': None, 'maintainer_email': None, 'name': 'sampleproject', 'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN', 'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': &#123;'Download': 'UNKNOWN', 'Homepage': 'https://github.com/pypa/sampleproject'&#125;, 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None, 'requires_python': None, 'summary': 'A sample Python project', 'version': '1.2.0'&#125; 结果可以被限制到特定的 depth (更深层的内容将使用省略号): 123456789101112131415161718192021222324252627282930313233343536373839404142&gt;&gt;&gt; pprint.pprint(project_info, depth=1)&#123;'author': 'The Python Packaging Authority', 'author_email': 'pypa-dev@googlegroups.com', 'bugtrack_url': None, 'classifiers': [...], 'description': 'A sample Python project\n' '=======================\n' '\n' 'This is the description file for the project.\n' '\n' 'The file should use UTF-8 encoding and be written using ' 'ReStructured Text. It\n' 'will be used to generate the project webpage on PyPI, and ' 'should be written for\n' 'that purpose.\n' '\n' 'Typical contents for this file would include an overview of ' 'the project, basic\n' 'usage examples, etc. Generally, including the project ' 'changelog in here is not\n' 'a good idea, although a simple "What\'s New" section for the ' 'most recent version\n' 'may be appropriate.', 'description_content_type': None, 'docs_url': None, 'download_url': 'UNKNOWN', 'downloads': &#123;...&#125;, 'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development', 'license': 'MIT', 'maintainer': None, 'maintainer_email': None, 'name': 'sampleproject', 'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN', 'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': &#123;...&#125;, 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None, 'requires_python': None, 'summary': 'A sample Python project', 'version': '1.2.0'&#125; 此外，还可以设置建议的最大字符 width。 如果一个对象无法被拆分，则将超出指定宽度: 123456789101112131415161718192021222324252627282930313233343536373839404142434445&gt;&gt;&gt; pprint.pprint(project_info, depth=1, width=60)&#123;'author': 'The Python Packaging Authority', 'author_email': 'pypa-dev@googlegroups.com', 'bugtrack_url': None, 'classifiers': [...], 'description': 'A sample Python project\n' '=======================\n' '\n' 'This is the description file for the ' 'project.\n' '\n' 'The file should use UTF-8 encoding and be ' 'written using ReStructured Text. It\n' 'will be used to generate the project ' 'webpage on PyPI, and should be written ' 'for\n' 'that purpose.\n' '\n' 'Typical contents for this file would ' 'include an overview of the project, ' 'basic\n' 'usage examples, etc. Generally, including ' 'the project changelog in here is not\n' 'a good idea, although a simple "What\'s ' 'New" section for the most recent version\n' 'may be appropriate.', 'description_content_type': None, 'docs_url': None, 'download_url': 'UNKNOWN', 'downloads': &#123;...&#125;, 'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development', 'license': 'MIT', 'maintainer': None, 'maintainer_email': None, 'name': 'sampleproject', 'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN', 'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': &#123;...&#125;, 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None, 'requires_python': None, 'summary': 'A sample Python project', 'version': '1.2.0'&#125; 小结1. 常用格式化12345678910111213&gt;&gt;&gt; import pprint&gt;&gt;&gt; data = [(1,&#123;'a':'A','b':'B','c':'C','d':'D'&#125;),(2,&#123;'e':'E','f':'F','g':'G','h':'H','i':'I','j':'J','k':'K','l':'L'&#125;),]&gt;&gt;&gt; pprint.pprint(data)[(1, &#123;'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'&#125;), (2, &#123;'e': 'E', 'f': 'F', 'g': 'G', 'h': 'H', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L'&#125;)] 2. 格式化序列12345678910111213141516&gt;&gt;&gt; data = [(1,&#123;'a':'A','b':'B','c':'C','d':'D'&#125;),(2,&#123;'e':'E','f':'F','g':'G','h':'H','i':'I','j':'J','k':'K','l':'L'&#125;),]&gt;&gt;&gt; result=pprint.pformat(data)&gt;&gt;&gt; for key in result.splitlines(): print(key) [(1, &#123;'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'&#125;), (2, &#123;'e': 'E', 'f': 'F', 'g': 'G', 'h': 'H', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L'&#125;)] 3. 复杂的格式化,用于调试代码123456789101112131415161718192021222324252627282930313233import pprint;import re; def pprintDemo(): varsList = [ [1, 2, 3], ["ab", "c", "def"], re.compile("\w+"), ("123", "abc"), &#123; "key1":"value1", "key2":"value2", &#125;, ]; for value in varsList: print(value); print("-"*80) pp = pprint.PrettyPrinter(indent=4); for value in varsList: pp.pprint(value); print("-"*80) stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']; stuff.insert(0, stuff[:]) print stuff; print("-"*80) pp.pprint(stuff) if __name__ == '__main__': pprintDemo(); 1234567891011121314151617181920[1, 2, 3]['ab', 'c', 'def']&lt;_sre.SRE_Pattern object at 0x00000000030DD378&gt;('123', 'abc')&#123;'key2': 'value2', 'key1': 'value1'&#125;--------------------------------------------------------------------------------[1, 2, 3]['ab', 'c', 'def']&lt;_sre.SRE_Pattern object at 0x00000000030DD378&gt;('123', 'abc')&#123; 'key1': 'value1', 'key2': 'value2'&#125;================================================================================[['spam', 'eggs', 'lumberjack', 'knights', 'ni'], 'spam', 'eggs', 'lumberjack', 'knights', 'ni']--------------------------------------------------------------------------------[ ['spam', 'eggs', 'lumberjack', 'knights', 'ni'], 'spam', 'eggs', 'lumberjack', 'knights', 'ni']]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>pprint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library reprlib]]></title>
    <url>%2F2020%2F01%2F26%2Fpython-standard-library-reprlib%2F</url>
    <content type="text"><![CDATA[python 标准库 reprlib 武汉挺住！！！ reprlib 模块提供了一种对象表示的产生方式，它会对结果字符串的大小进行限制。 该方式被用于 Python 调试器，也适用于某些其他场景。 此模块提供了一个类、一个实例和一个函数： class reprlib.Repr 该类提供了格式化服务 适用于实现与内置 repr() 相似的方法；其中附加了针对不同对象类型的大小限制，以避免生成超长的表示。 reprlib.aRepr 这是 Repr 的一个实例，用于提供如下所述的 repr() 函数。 改变此对象的属性将会影响 repr() 和 Python 调试器所使用的大小限制。 reprlib.repr(obj) 这是 aRepr 的 repr() 方法。 它会返回与同名内置函数所返回字符串相似的字符串，区别在于附带了对多数类型的大小限制。 在大小限制工具以外，此模块还提供了一个装饰器，用于检测对 __repr__() 的递归调用并改用一个占位符来替换。 `@reprlib.recursive_repr`(fillvalue=”…”) 用于为 __repr__() 方法检测同一线程内部递归调用的装饰器。 如果执行了递归调用，则会返回 fillvalue，否则执行正常的 __repr__() 调用。 例如： 1234567891011&gt;&gt;&gt; from reprlib import recursive_repr&gt;&gt;&gt; class MyList(list):--- @recursive_repr()--- def __repr__(self):--- return '&lt;' + '|'.join(map(repr, self)) + '&gt;'---&gt;&gt;&gt; m = MyList('abc')&gt;&gt;&gt; m.append(m)&gt;&gt;&gt; m.append('x')&gt;&gt;&gt; print(m)&lt;'a'|'b'|'c'|...|'x'&gt; Repr 对象 Repr 实例对象包含一些属性可以用于为不同对象类型的表示提供大小限制，还包含一些方法可以格式化特定的对象类型。 Repr.maxlevel 创建递归表示形式的深度限制。 默认为 6。 Repr.maxdict Repr.maxlist 12345import reprlib a = [1,2,3,[4,5],6,7] reprlib.aRepr.maxlist = 2 print(reprlib.repr(a)) &gt;&gt;&gt; [1, 2, ...] Repr.maxtuple Repr.maxset Repr.maxfrozenset Repr.maxdeque Repr.maxarray 代表命名对象类型的条目数量限制。 对于 maxdict 的默认值为 4，对于 maxarray 为 5，对于其他则为 6。 Repr.maxlong 表示整数的最大字符数量。 数码会从中间被丢弃。 默认值为 40。 Repr.maxstring 表示字符串的字符数量限制。 请注意字符源会使用字符串的“正常”表示形式：如果表示中需要用到转义序列，在缩短表示时它们可能会被破坏。 默认值为 30。 Repr.maxother 此限制用于控制在 Repr 对象上没有特定的格式化方法可用的对象类型的大小。 它会以类似 maxstring 的方式被应用。 默认值为 20。 12345import reprliba = [1,2,3,[4,5],6,7]reprlib.aRepr.maxlevel = 1print(reprlib.repr(a))&gt;&gt;&gt; [1,2,3,[...],6,7] Repr.repr(obj) 内置 repr() 的等价形式，它使用实例专属的格式化。 Repr.repr1(obj, level) 供 repr() 使用的递归实现。 此方法使用 obj 的类型来确定要调用哪个格式化方法，并传入 obj 和 level。 类型专属的方法应当调用 repr1() 来执行递归格式化，在递归调用中使用 level - 1 作为 level 的值。 Repr.repr_TYPE(obj, level) 特定类型的格式化方法会被实现为基于类型名称来命名的方法。 在方法名称中，TYPE 会被替换为 &#39;_&#39;.join(type(obj).__name__.split())。 对这些方法的分派会由 repr1() 来处理。 需要对值进行递归格式化的类型专属方法应当调用 self.repr1(subobj, level - 1)。 子类化 Repr 对象 通过 Repr.repr1() 使用动态分派允许 Repr 的子类添加对额外内置对象类型的支持，或是修改对已支持类型的处理。 这个例子演示了如何添加对文件对象的特殊支持: 123456789101112import reprlibimport sysclass MyRepr(reprlib.Repr): def repr_TextIOWrapper(self, obj, level): if obj.name in &#123;'&lt;stdin&gt;', '&lt;stdout&gt;', '&lt;stderr&gt;'&#125;: return obj.name return repr(obj)aRepr = MyRepr()print(aRepr.repr(sys.stdin)) # prints '&lt;stdin&gt;']]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>reprlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library dataclasses]]></title>
    <url>%2F2020%2F01%2F25%2Fpython-standard-library-dataclasses%2F</url>
    <content type="text"><![CDATA[python 标准库 dataclasses 源码 源码： Lib/dataclasses.py 主要类结构层次,节选自源码 ) 123456789101112131415161718192021222324__all__ = ['dataclass', 'field', 'Field', 'FrozenInstanceError', 'InitVar', 'MISSING', # Helper functions. 'fields', 'asdict', 'astuple', 'make_dataclass', 'replace', 'is_dataclass', ]class _DataclassParams: __slots__ = ('init', 'repr', 'eq', 'order', 'unsafe_hash', 'frozen', ) 这个模块提供了一个装饰器和一些函数，用于自动添加生成的 special methods ，例如 __init__() 和 __repr__() 到用户定义的类。 它最初描述于 PEP 557 。 在这些生成的方法中使用的成员变量使用 PEP 526 类型注释定义。例如这段代码: 123456789@dataclassclass InventoryItem: '''Class for keeping track of an item in inventory.''' name: str unit_price: float quantity_on_hand: int = 0 def total_cost(self) -&gt; float: return self.unit_price * self.quantity_on_hand 除其他事情外，将添加 __init__() ，其看起来像: 1234def __init__(self, name: str, unit_price: float, quantity_on_hand: int=0): self.name = name self.unit_price = unit_price self.quantity_on_hand = quantity_on_hand 请注意，此方法会自动添加到类中：它不会在上面显示的 InventoryItem 定义中直接指定。 模块级装饰器、类和函数 `@dataclasses.dataclass`(**, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False*) 这个函数是 decorator ，用于将生成的 special method 添加到类中，如下所述。 dataclass() 装饰器检查类以找到 field。 field 被定义为具有 类型标注 的类变量。除了下面描述的两个例外，在 dataclass() 中没有任何内容检查变量标注中指定的类型。 所有生成的方法中的字段顺序是它们在类定义中出现的顺序。 dataclass() 装饰器将向类中添加各种“dunder”方法，如下所述。如果类中已存在任何添加的方法，则行为取决于参数，如下所述。装饰器返回被调用的同一个类；没有创建新类。 如果 dataclass() 仅用作没有参数的简单装饰器，它就像它具有此签名中记录的默认值一样。也就是说，这三种 dataclass() 用法是等价的: 1234567891011@dataclassclass C: ...@dataclass()class C: ...@dataclass(init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)class C: ... dataclass() 的参数有： init: 如果为真值（默认），将生成一个 __ init__() 方法。 如果类已定义 __ init__() ，则忽略此参数。 repr ：如果为真值（默认），将生成一个 __repr__() 方法。 生成的 repr 字符串将具有类名以及每个字段的名称和 repr ，按照它们在类中定义的顺序。不包括标记为从 repr 中排除的字段。 例如：InventoryItem(name=&#39;widget&#39;, unit_price=3.0, quantity_on_hand=10)。 如果类已定义 __repr__() ，则忽略此参数。 eq ：如果为true（默认值），将生成 __eq__() 方法。此方法将类作为其字段的元组按顺序比较。比较中的两个实例必须是相同的类型。 如果类已定义 __eq__() ，则忽略此参数。 order ：如果为真值（默认为 False ），则 __lt__() 、 __ le__() 、 __gt__() 和 __ge__() 方法将生成。 这将类作为其字段的元组按顺序比较。比较中的两个实例必须是相同的类型。如果 order 为真值并且 eq 为假值 ，则引发 ValueError 。 如果类已经定义了 __lt__() 、 __le__() 、 __gt__() 或者 __ge__() 中的任意一个，将引发 TypeError 。 unsafe_hash ：如果为 False （默认值），则根据 eq 和 frozen 的设置方式生成 __hash__() 方法。 __hash__() 由内置的 hash() 使用，当对象被添加到散列集合（如字典和集合）时。有一个 __hash__() 意味着类的实例是不可变的。可变性是一个复杂的属性，取决于程序员的意图， __eq__() 的存在性和行为，以及 dataclass() 装饰器中 eq 和 frozen 标志的值。 默认情况下， dataclass() 不会隐式添加 __hash__() 方法，除非这样做是安全的。 它也不会添加或更改现有的明确定义的 __hash__() 方法。 设置类属性 __hash__ = None 对 Python 具有特定含义，如 __hash__() 文档中所述。 如果 __hash__() 没有显式定义，或者它被设置为 None ，那么 dataclass() 可以 添加一个隐式 __hash__() 方法。虽然不推荐，但你可以强制 dataclass() 用 unsafe_hash=True 创建一个 __hash__() 方法。 如果你的类在逻辑上是不可变的但实际仍然可变，则可能就是这种情况。这是一个特殊的用例，应该仔细考虑。 以下是隐式创建 __hash__() 方法的规则。请注意，你不能在数据类中都使用显式的 __hash__() 方法并设置 unsafe_hash=True ；这将导致 TypeError 。 如果 eq 和 frozen 都是 true，默认情况下 dataclass() 将为你生成一个 __hash__() 方法。如果 eq 为 true 且 frozen 为 false ，则 __hash__() 将被设置为 None ，标记它不可用（因为它是可变的）。如果 eq 为 false ，则 __hash__() 将保持不变，这意味着将使用超类的 __hash__() 方法（如果超类是 object ，这意味着它将回到基于id的hash）。 frozen: 如为真值 (默认值为 False)，则对字段赋值将会产生异常。 这模拟了只读的冻结实例。 如果在类中定义了 __setattr__() 或 __delattr__() 则将会引发 TypeError。 参见下文的讨论。 fields 可以选择使用普通的 Python 语法指定默认值: 1234@dataclassclass C: a: int # 'a' has no default value b: int = 0 # assign a default value for 'b' 在这个例子中， a 和 b 都将包含在添加的 __init__() 方法中，它们将被定义为: 1def __init__(self, a: int, b: int = 0): 如果没有默认值的字段跟在具有默认值的字段后，将引发 TypeError 。当这发生在单个类中时，或者作为类继承的结果时，都是如此。 dataclasses.field(**, default=MISSING, default_factory=MISSING, repr=True, hash=None, init=True, compare=True, metadata=None*) 对于常见和简单的用例，不需要其他功能。但是，有些数据类功能需要额外的每字段信息。为了满足这种对附加信息的需求，你可以通过调用提供的 field() 函数来替换默认字段值。例如: 123456@dataclassclass C: mylist: List[int] = field(default_factory=list)c = C()c.mylist += [1, 2, 3] 如上所示， MISSING 值是一个 sentinel 对象，用于检测是否提供了 default 和 default_factory 参数。 使用此 sentinel 是因为 None 是 default 的有效值。没有代码应该直接使用 MISSING 值。 field() 参数有： default ：如果提供，这将是该字段的默认值。这是必需的，因为 field() 调用本身会替换一般的默认值。 default_factory ：如果提供，它必须是一个零参数可调用对象，当该字段需要一个默认值时，它将被调用。除了其他目的之外，这可以用于指定具有可变默认值的字段，如下所述。 同时指定 default 和 default_factory 将产生错误。 init ：如果为true（默认值），则该字段作为参数包含在生成的 __init__() 方法中。 repr ：如果为true（默认值），则该字段包含在生成的 __repr__() 方法返回的字符串中。 compare ：如果为true（默认值），则该字段包含在生成的相等性和比较方法中（ __eq__() ， __gt__() 等等）。 hash ：这可以是布尔值或 None 。如果为true，则此字段包含在生成的 __hash__() 方法中。如果为 None （默认值），请使用 compare 的值，这通常是预期的行为。如果字段用于比较，则应在 hash 中考虑该字段。不鼓励将此值设置为 None 以外的任何值。 设置 hash=False 但 compare=True 的一个可能原因是，如果一个计算 hash 的代价很高的字段是检验等价性需要的，但还有其他字段可以计算类型的 hash 。 即使从 hash 中排除某个字段，它仍将用于比较。 metadata ：这可以是映射或 None 。 None 被视为一个空的字典。这个值包含在 MappingProxyType() 中，使其成为只读，并暴露在 Field 对象上。数据类根本不使用它，它是作为第三方扩展机制提供的。多个第三方可以各自拥有自己的键值，以用作元数据中的命名空间。 如果通过调用 field() 指定字段的默认值，则该字段的类属性将替换为指定的 default 值。如果没有提供 default ，那么将删除类属性。目的是在 dataclass() 装饰器运行之后，类属性将包含字段的默认值，就像指定了默认值一样。例如，之后: 123456@dataclassclass C: x: int y: int = field(repr=False) z: int = field(repr=False, default=10) t: int = 20 类属性 C.z 将是 10 ，类属性 C.t 将是 20，类属性 C.x 和 C.y 将不设置。 class dataclasses.Field Field 对象描述每个定义的字段。这些对象在内部创建，并由 fields() 模块级方法返回（见下文）。用户永远不应该直接实例化 Field 对象。 其有文档的属性是： name ：字段的名字。 type ：字段的类型。 default 、 default_factory 、 init 、 repr 、 hash 、 compare 以及 metadata 与具有和 field() 声明中相同的意义和值。 可能存在其他属性，但它们是私有的，不能被审查或依赖。 dataclasses.fields(class_or_instance) 返回 Field 对象的元组，用于定义此数据类的字段。 接受数据类或数据类的实例。如果没有传递一个数据类或实例将引发 TypeError 。 不返回 ClassVar 或 InitVar 的伪字段。 dataclasses.asdict(instance, **, dict_factory=dict*) 将数据类 instance 转换为字典（使用工厂函数 dict_factory ）。每个数据类都转换为其字段的字典，如 name: value 对。数据类、字典、列表和元组被递归。例如: 1234567891011121314@dataclassclass Point: x: int y: int@dataclassclass C: mylist: List[Point]p = Point(10, 20)assert asdict(p) == &#123;'x': 10, 'y': 20&#125;c = C([Point(0, 0), Point(10, 4)])assert asdict(c) == &#123;'mylist': [&#123;'x': 0, 'y': 0&#125;, &#123;'x': 10, 'y': 4&#125;]&#125; 引发 TypeError 如果 instance 不是数据类实例。 dataclasses.astuple(instance, **, tuple_factory=tuple*) 将数据类 instance 转换为元组（通过使用工厂函数 tuple_factory ）。每个数据类都转换为其字段值的元组。数据类、字典、列表和元组被递归。 继续前一个例子: 12assert astuple(p) == (10, 20)assert astuple(c) == ([(0, 0), (10, 4)],) 引发 TypeError 如果 instance 不是数据类实例。 dataclasses.make_dataclass(cls_name, fields, **, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False*) 创建一个名为 cls_name 的新数据类，字段为 fields 中定义的字段，基类为 bases 中给出的基类，并使用 namespace 中给出的命名空间进行初始化。 fields 是一个可迭代的元素，每个元素都是 name 、 (name, type) 或 (name, type, Field) 。 如果只提供name ， type 为 typing.Any 。 init 、 repr 、 eq 、 order 、 unsafe_hash 和 frozen 的值与它们在 dataclass() 中的含义相同。 此函数不是严格要求的，因为用于任何创建带有 __annotations__ 的新类的 Python 机制都可以应用 dataclass() 函数将该类转换为数据类。提供此功能是为了方便。例如: 12345C = make_dataclass('C', [('x', int), 'y', ('z', int, field(default=5))], namespace=&#123;'add_one': lambda self: self.x + 1&#125;) 等价于 12345678@dataclassclass C: x: int y: 'typing.Any' z: int = 5 def add_one(self): return self.x + 1 dataclasses.replace(instance, **changes) 创建一个 instance 相同类型的新对象，用 changes 中的值替换字段。如果 instance 不是数据类，则引发 TypeError 。如果 changes 中的值没有指定字段，则引发 TypeError 。 新返回的对象通过调用数据类的 __init__() 方法创建。这确保了如果存在 __post_init__() ，其也被调用。 如果存在没有默认值的仅初始化变量，必须在调用 replace() 时指定，以便它们可以传递给 __init__() 和 __post_init__() 。 changes 包含任何定义为 init=False 的字段是错误的。在这种情况下会引发 ValueError 。 提前提醒 init=False 字段在调用 replace() 时的工作方式。如果它们完全被初始化的话，它们不是从源对象复制的，而是在 __post_init__() 中初始化。估计 init=False 字段很少能被正确地使用。如果使用它们，那么使用备用类构造函数或者可能是处理实例复制的自定义 replace() （或类似命名的）方法可能是明智的。 dataclasses.is_dataclass(class_or_instance) 如果其形参为 dataclass 或其实例则返回 True，否则返回 False。 如果你需要知道一个类是否是一个数据类的实例（而不是一个数据类本身），那么再添加一个 not isinstance(obj, type) 检查: 12def is_dataclass_instance(obj): return is_dataclass(obj) and not isinstance(obj, type) 初始化后处理生成的 __init__() 代码将调用一个名为 __post_init__() 的方法，如果在类上已经定义了 __post_init__() 。它通常被称为 self.__post_init__() 。但是，如果定义了任何 InitVar 字段，它们也将按照它们在类中定义的顺序传递给 __post_init__() 。 如果没有 __ init__() 方法生成，那么 __post_init__() 将不会被自动调用。 在其他用途中，这允许初始化依赖于一个或多个其他字段的字段值。例如: 12345678@dataclassclass C: a: float b: float c: float = field(init=False) def __post_init__(self): self.c = self.a + self.b 有关将参数传递给 __post_init__() 的方法，请参阅下面有关仅初始化变量的段落。另请参阅关于 replace() 处理 init=False 字段的警告。 类变量 两个地方 dataclass() 实际检查字段类型的之一是确定字段是否是如 PEP 526 所定义的类变量。它通过检查字段的类型是否为 typing.ClassVar 来完成此操作。如果一个字段是一个 ClassVar ，它将被排除在考虑范围之外，并被数据类机制忽略。这样的 ClassVar 伪字段不会由模块级的 fields() 函数返回。 仅初始化变量另一个 dataclass() 检查类型注解地方是为了确定一个字段是否是一个仅初始化变量。它通过查看字段的类型是否为 dataclasses.InitVar 类型来实现。如果一个字段是一个 InitVar ，它被认为是一个称为仅初始化字段的伪字段。因为它不是一个真正的字段，所以它不会被模块级的 fields() 函数返回。仅初始化字段作为参数添加到生成的 __init__() 方法中，并传递给可选的 __post_init__() 方法。数据类不会使用它们。 例如，假设一个字段将从数据库初始化，如果在创建类时未提供其值: 1234567891011@dataclassclass C: i: int j: int = None database: InitVar[DatabaseType] = None def __post_init__(self, database): if self.j is None and database is not None: self.j = database.lookup('j')c = C(10, database=my_database) 在这种情况下， fields() 将返回 i 和 j 的 Field 对象，但不包括 database 。 冻结的实例无法创建真正不可变的 Python 对象。但是，通过将 frozen=True 传递给 dataclass() 装饰器，你可以模拟不变性。在这种情况下，数据类将向类添加 __setattr__() 和 __delattr__() 方法。 些方法在调用时会引发 FrozenInstanceError 。 使用 frozen=True 时会有很小的性能损失： __ init__() 不能使用简单的赋值来初始化字段，并必须使用 object.__ setattr__() 。 继承 当数组由 dataclass() 装饰器创建时，它会查看反向 MRO 中的所有类的基类（即从 object 开始 ），并且对于它找到的每个数据类， 将该基类中的字段添加到字段的有序映射中。添加完所有基类字段后，它会将自己的字段添加到有序映射中。所有生成的方法都将使用这种组合的，计算的有序字段映射。由于字段是按插入顺序排列的，因此派生类会重载基类。一个例子: 123456789@dataclassclass Base: x: Any = 15.0 y: int = 0@dataclassclass C(Base): z: int = 10 x: int = 15 最后的字段列表依次是 x 、 y 、 z 。 x 的最终类型是 int ，如类 C 中所指定的那样。 为 C 生成的 __init__() 方法看起来像: 1def __init__(self, x: int = 15, y: int = 0, z: int = 10): 默认工厂函数 如果一个 field() 指定了一个 default_factory ，当需要该字段的默认值时，将使用零参数调用它。例如，要创建列表的新实例，请使用: 1mylist: list = field(default_factory=list) 如果一个字段被排除在 __init__() 之外（使用 init=False ）并且字段也指定 default_factory ，则默认的工厂函数将始终从生成的 __ init__() 函数调用。发生这种情况是因为没有其他方法可以为字段提供初始值。 可变的默认值 Python 在类属性中存储默认成员变量值。思考这个例子，不使用数据类: 1234567891011class C: x = [] def add(self, element): self.x.append(element)o1 = C()o2 = C()o1.add(1)o2.add(2)assert o1.x == [1, 2]assert o1.x is o2.x 请注意，类 C 的两个实例共享相同的类变量 x ，如预期的那样。 使用数据类， 如果 此代码有效: 12345@dataclassclass D: x: List = [] def add(self, element): self.x += element 它生成的代码类似于: 12345678class D: x = [] def __init__(self, x=x): self.x = x def add(self, element): self.x += elementassert D().x is D().x 这与使用类 C 的原始示例具有相同的问题。也就是说，在创建类实例时没有为 x 指定值的类 D 的两个实例将共享相同的 x 副本。由于数据类只使用普通的 Python 类创建，因此它们也会共享此行为。数据类没有通用的方法来检测这种情况。相反，如果数据类检测到类型为 list 、 dict 或 set 的默认参数，则会引发 TypeError 。这是一个部分解决方案，但它可以防止许多常见错误。 使用默认工厂函数是一种创建可变类型新实例的方法，并将其作为字段的默认值: 12345@dataclassclass D: x: list = field(default_factory=list)assert D().x is not D().x 异常 exception dataclasses.FrozenInstanceError 在使用 frozen=True 定义的数据类上调用隐式定义的 __setattr__() 或 __delattr__() 时引发。 总结我们经常会遇到这样的情况: 比如我们设计一个商品类: 123456789101112class Product(object): def __init__(self, id=None, author_id=None, category_id=None, brand_id=None, spu_id=None, title=None, item_id=None, n_comments=None, creation_time=None, update_time=None, source='', parent_id=0, ancestor_id=0): self.id = id self.author_id = author_id self.category_id = category_id self.brand_id = brand_id self.spu_id = spu_id self.title = title self.item_id = item_id ... __init__方法包含了众多参数, 应用一我们在打印的时候不希望打印所有的参数 通常的做法是,重写__repr__方法 12345678def __repr__(self): return '&#123;&#125;(id=&#123;&#125;, author_id=&#123;&#125;, category_id=&#123;&#125;, brand_id=&#123;&#125;)'.format( self.__class__.__name__, self.id, self.author_id, self.category_id, self.brand_id)#对象打印p = Product()print(p) &gt;&gt;&gt; Product(id=1, author_id=100001, category_id=2003, brand_id=20) 问题来了,我需要在每个类里重写这个方法,那该怎么处理？ 应用二 对象比较，有时候需要判断2个对象是否相等甚至大小（例如用于展示顺序） 通常的做法是 重写对应的__eq__,__lt__方法 12345678910def __eq__(self, other): if not isinstance(other, self.__class__): return NotImplemented return (self.id, self.author_id, self.category_id, self.brand_id) == ( other.id, other.author_id, other.category_id, other.brand_id)def __lt__(self, other): if not isinstance(other, self.__class__): return NotImplemented return (self.id, self.author_id, self.category_id, self.brand_id) &lt; ( other.id, other.author_id, other.category_id, other.brand_id) 应用三对象去重,重写__hash__方法 12def __hash__(self): return hash((self.id, self.author_id, self.category_id, self.brand_id)) 应用四导出字典格式 1234567def to_dict(self): return &#123; 'id': self.id, 'author_id': self.author_id, 'category_id': self.category_id, ... &#125; 但是我并不想打印所有的属性,于是有下面的做法 123def to_dict(self): self._a = 1 return vars(self) 等等,python难道没有解决方案。 答案是肯定的,当然有,那就是dataclasses 用dataclasses解决上面的问题123456789101112131415161718192021222324252627282930313233343536from datetime import datetimefrom dataclasses import dataclass, field@dataclass(unsafe_hash=True, order=True)class Product(object): id: int author_id: int brand_id: int spu_id: int title: str = field(hash=False, repr=False, compare=False) item_id: int = field(hash=False, repr=False, compare=False) n_comments: int = field(hash=False, repr=False, compare=False) creation_time: datetime = field(default=None, repr=False, compare=False,hash=False) update_time: datetime = field(default=None, repr=False, compare=False, hash=False) source: str = field(default='', repr=False, compare=False, hash=False) parent_id: int = field(default=0, repr=False, compare=False, hash=False) ancestor_id: int = field(default=0, repr=False, compare=False, hash=False)p1 = Product(1, 100001, 2003, 20, 1002393002, '这是一个测试商品1', 2000001, 100, None, 1)p2 = Product(1, 100001, 2003, 20, 1002393002, '这是一个测试商品2', 2000001, 100, None, 2)p3 = Product(3, 100001, 2003, 20, 1002393002, '这是一个测试商品3', 2000001, 100, None, 3)print(p1)print(p1 == p2)print(p1 &gt; p2)print(&#123;p1, p2, p3&#125;)from dataclasses import asdictasdict(p1) 想了解更多的使用方法,强烈建议阅读源码。 最后,希望武汉的兄弟们能保护好自己,健康才是最重要的。加油!!!]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>dataclasses</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library bisect]]></title>
    <url>%2F2020%2F01%2F24%2Fpython-standard-library-bisect%2F</url>
    <content type="text"><![CDATA[python 标准库 bisect 二分查找 何谓二分查找 对比顺序查找 通常我们实现二分查找是酱紫的: 123456789101112131415161718def binary_search(li,find): low = 0 high = len(li)-1 ## 需要减一否则会下标越界 while low &lt;= high: middle = (low + high) /2 if li[middle] == find : return middle elif li[middle] &gt; find: high = middle - 1 elif li[middle] &lt; find: low = middle + 1 return -1 if __name__ == '__main__': li = [x for x in xrange(1,101)] for x in xrange(102): print binary_search(li,x) python标准库中已经实现了二分查找。 源代码 源代码： Lib/bisect.py 这个模块对有序列表提供了支持，使得他们可以在插入新数据仍然保持有序。对于长列表，如果其包含元素的比较操作十分昂贵的话，这可以是对更常见方法的改进。这个模块叫做 bisect 因为其使用了基本的二分（bisection）算法。源代码也可以作为很棒的算法示例（边界判断也做好啦！） 函数 bisect.bisect_left(a, x, lo=0, hi=len(a)) 在 a 中找到 x 合适的插入点以维持有序。参数 lo 和 hi 可以被用于确定需要考虑的子集；默认情况下整个列表都会被使用。如果 x 已经在 a 里存在，那么插入点会在已存在元素之前（也就是左边）。如果 a 是列表（list）的话，返回值是可以被放在 list.insert() 的第一个参数的。 返回的插入点 i 可以将数组 a 分成两部分。左侧是 all(val &lt; x for val in a[lo:i]) ，右侧是 all(val &gt;= x for val in a[i:hi]) 。 bisect.bisect_right(a, x, lo=0, hi=len(a)) bisect.bisect(a, x, lo=0, hi=len(a)) 类似于 bisect_left()，但是返回的插入点是 a 中已存在元素 x 的右侧。 返回的插入点 i 可以将数组 a 分成两部分。左侧是 all(val &lt;= x for val in a[lo:i])，右侧是 all(val &gt; x for val in a[i:hi]) for the right side。 bisect.insort_left(a, x, lo=0, hi=len(a)) 将 x 插入到一个有序序列 a 里，并维持其有序。如果 a 有序的话，这相当于 a.insert(bisect.bisect_left(a, x, lo, hi), x)。要注意搜索是 O(log n) 的，插入却是 O(n) 的。 bisect.insort_right(a, x, lo=0, hi=len(a)) bisect.insort(a, x, lo=0, hi=len(a)) 类似于 insort_left()，但是把 x 插入到 a 中已存在元素 x 的右侧。 SortedCollection recipe 使用 bisect 构造了一个功能完整的集合类，提供了直接的搜索方法和对用于搜索的 key 方法的支持。所有用于搜索的键都是预先计算的，以避免在搜索时对 key 方法的不必要调用。 搜索有序列表 上面的 bisect() 函数对于找到插入点是有用的，但在一般的搜索任务中可能会有点尴尬。下面 5 个函数展示了如何将其转变成有序列表中的标准查找函数 12345678910111213141516171819202122232425262728293031323334def index(a, x): 'Locate the leftmost value exactly equal to x' i = bisect_left(a, x) if i != len(a) and a[i] == x: return i raise ValueErrordef find_lt(a, x): 'Find rightmost value less than x' i = bisect_left(a, x) if i: return a[i-1] raise ValueErrordef find_le(a, x): 'Find rightmost value less than or equal to x' i = bisect_right(a, x) if i: return a[i-1] raise ValueErrordef find_gt(a, x): 'Find leftmost value greater than x' i = bisect_right(a, x) if i != len(a): return a[i] raise ValueErrordef find_ge(a, x): 'Find leftmost item greater than or equal to x' i = bisect_left(a, x) if i != len(a): return a[i] raise ValueError 其他示例 函数 bisect() 还可以用于数字表查询。这个例子是使用 bisect() 从一个给定的考试成绩集合里，通过一个有序数字表，查出其对应的字母等级：90 分及以上是 ‘A’，80 到 89 是 ‘B’，以此类推 123456&gt;&gt;&gt; def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):... i = bisect(breakpoints, score)... return grades[i]...&gt;&gt;&gt; [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]['F', 'A', 'C', 'C', 'B', 'A', 'A'] 与 sorted() 函数不同，对于 bisect() 函数来说，key 或者 reversed 参数并没有什么意义。因为这会导致设计效率低下（连续调用 bisect 函数时，是不会 “记住” 过去查找过的键的）。 正相反，最好去搜索预先计算好的键列表，来查找相关记录的索引。 1234567891011&gt;&gt;&gt; data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)]&gt;&gt;&gt; data.sort(key=lambda r: r[1])&gt;&gt;&gt; keys = [r[1] for r in data] # precomputed list of keys&gt;&gt;&gt; data[bisect_left(keys, 0)]('black', 0)&gt;&gt;&gt; data[bisect_left(keys, 1)]('blue', 1)&gt;&gt;&gt; data[bisect_left(keys, 5)]('red', 5)&gt;&gt;&gt; data[bisect_left(keys, 8)]('yellow', 8)]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>bisect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library timeit]]></title>
    <url>%2F2020%2F01%2F23%2Fpython-standard-library-timeit%2F</url>
    <content type="text"><![CDATA[python 标准库 timeit每日一词: Pneumonia n 肺炎 2019 Novel coronavirus (2019-nCoV)， 世界卫生组织定义, 又名武汉冠状病毒（Wuhan coronavirus）、武汉肺炎（Wuhan pneumonia） 冠状病毒属的病毒是具外套膜（envelope） 例句: The doctor diagnosed the illness as pneumonia .医生诊断这病为肺炎。 The doctor has cured her of pneumonia .大夫把她的肺炎看好了。 Fatalities usually come from pneumonia .通常肺炎可引起死亡。 源码 源码： Lib/timeit.py 该模块提供了一种简单的方法来计算一小段 Python 代码的耗时。它有 命令行界面 以及一个 可调用 方法。它避免了许多用于测量执行时间的常见陷阱。另见 Tim Peters 对 O’Reilly 出版的 Python Cookbook 中“算法”章节的介绍。 基本实例 以下示例显示了如何使用 命令行界面 来比较三个不同的表达式： 123456$ python3 -m timeit '"-".join(str(n) for n in range(100))'10000 loops, best of 5: 30.2 usec per loop$ python3 -m timeit '"-".join([str(n) for n in range(100)])'10000 loops, best of 5: 27.5 usec per loop$ python3 -m timeit '"-".join(map(str, range(100)))'10000 loops, best of 5: 23.2 usec per loop 这可以通过 Python 接口 实现 1234567&gt;&gt;&gt; import timeit&gt;&gt;&gt; timeit.timeit('"-".join(str(n) for n in range(100))', number=10000)0.3018611848820001&gt;&gt;&gt; timeit.timeit('"-".join([str(n) for n in range(100)])', number=10000)0.2727368790656328&gt;&gt;&gt; timeit.timeit('"-".join(map(str, range(100)))', number=10000)0.23702679807320237 从 Python 接口 还可以传出一个可调用对象: 12&gt;&gt;&gt; timeit.timeit(lambda: "-".join(map(str, range(100))), number=10000)0.19665591977536678 但请注意 timeit() 仅在使用命令行界面时会自动确定重复次数。 在 示例 一节你可以找到更多的进阶示例。 python接口 该模块定义了三个便利函数和一个公共类： timeit.timeit(stmt=’pass’, setup=’pass’, timer=, number=1000000, globals=None) timeit.repeat(stmt=’pass’, setup=’pass’, timer=, repeat=5, number=1000000, globals=None) timeit.default_timer() class timeit.Timer(stmt=’pass’, setup=’pass’, timer=, globals=None) timeit(number=1000000) autorange(callback=None) repeat(repeat=5, number=1000000) print_exc(file=None) 命令行界面 从命令行调用程序时，使用以下表单: 1python -m timeit [-n N] [-r N] [-u U] [-s S] [-h] [statement ...] 如果了解以下选项： -n N, --number=N 执行 ‘语句’ 多少次 -r N, --repeat=N 重复计时器的次数（默认为5） -s S, --setup=S 最初要执行一次的语句（默认为 pass ） `-p, –process12345678 测量进程时间，而不是 wallclock 时间，使用 [`time.process_time()`](https://docs.python.org/zh-cn/3.8/library/time.html#time.process_time) 而不是 [`time.perf_counter()`](https://docs.python.org/zh-cn/3.8/library/time.html#time.perf_counter) ，这是默认值*3.3 新版功能.*- `-u````, ``--unit``=U` 指定定时器输出的时间单位；可以选择 nsec，usec，msec或sec*3.5 新版功能.*- `-v````, ``--verbose 打印原始计时结果；重复更多位数精度 -h```, --help` 打印一条简短的使用信息并退出 可以通过将每一行指定为单独的语句参数来给出多行语句；通过在引号中包含参数并使用前导空格可以缩进行。多个 -s 选项的处理方式相似。 如果 -n 未给出，则通过尝试10的连续幂次来计算合适数量的循环，直到总时间至少为 0.2 秒。 default_timer() 测量可能受到在同一台机器上运行的其他程序的影响，因此在需要精确计时时最好的做法是重复几次计时并使用最佳时间。 -r 选项对此有利；在大多数情况下，默认的 5 次重复可能就足够了。 你可以使用 time.process_time() 来测量CPU时间。 执行 pass 语句会产生一定的基线开销。这里的代码不会试图隐藏它，但你应该知道它。可以通过不带参数调用程序来测量基线开销，并且Python版本之间可能会有所不同。 实例 可以提供一个在开头只执行一次的 setup 语句： 1234$ python -m timeit -s 'text = "sample string"; char = "g"' 'char in text'5000000 loops, best of 5: 0.0877 usec per loop$ python -m timeit -s 'text = "sample string"; char = "g"' 'text.find(char)'1000000 loops, best of 5: 0.342 usec per loop 12345&gt;&gt;&gt; import timeit&gt;&gt;&gt; timeit.timeit('char in text', setup='text = "sample string"; char = "g"')0.41440500499993504&gt;&gt;&gt; timeit.timeit('text.find(char)', setup='text = "sample string"; char = "g"')1.7246671520006203 使用 Timer 类及其方法可以完成同样的操作: 123456&gt;&gt;&gt; import timeit&gt;&gt;&gt; t = timeit.Timer('char in text', setup='text = "sample string"; char = "g"')&gt;&gt;&gt; t.timeit()0.3955516149999312&gt;&gt;&gt; t.repeat()[0.40183617287970225, 0.37027556854118704, 0.38344867356679524, 0.3712595970846668, 0.37866875250654886] 以下示例显示如何计算包含多行的表达式。 在这里我们对比使用 hasattr() 与 try/except 的开销来测试缺失与提供对象属性: 123456789$ python -m timeit 'try:' ' str.__bool__' 'except AttributeError:' ' pass'20000 loops, best of 5: 15.7 usec per loop$ python -m timeit 'if hasattr(str, "__bool__"): pass'50000 loops, best of 5: 4.26 usec per loop$ python -m timeit 'try:' ' int.__bool__' 'except AttributeError:' ' pass'200000 loops, best of 5: 1.43 usec per loop$ python -m timeit 'if hasattr(int, "__bool__"): pass'100000 loops, best of 5: 2.23 usec per loop 1234567891011121314151617181920212223242526&gt;&gt;&gt; import timeit&gt;&gt;&gt; # attribute is missing&gt;&gt;&gt; s = """\... try:... str.__bool__... except AttributeError:... pass... """&gt;&gt;&gt; timeit.timeit(stmt=s, number=100000)0.9138244460009446&gt;&gt;&gt; s = "if hasattr(str, '__bool__'): pass"&gt;&gt;&gt; timeit.timeit(stmt=s, number=100000)0.5829014980008651&gt;&gt;&gt;&gt;&gt;&gt; # attribute is present&gt;&gt;&gt; s = """\... try:... int.__bool__... except AttributeError:... pass... """&gt;&gt;&gt; timeit.timeit(stmt=s, number=100000)0.04215312199994514&gt;&gt;&gt; s = "if hasattr(int, '__bool__'): pass"&gt;&gt;&gt; timeit.timeit(stmt=s, number=100000)0.08588060699912603 要让 timeit 模块访问你定义的函数，你可以传递一个包含 import 语句的 setup 参数: 1234567def test(): """Stupid test function""" L = [i for i in range(100)]if __name__ == '__main__': import timeit print(timeit.timeit("test()", setup="from __main__ import test")) 另一种选择是将 globals() 传递给 globals 参数，这将导致代码在当前的全局命名空间中执行。这比单独指定 import 更方便 123456789def f(x): return x**2def g(x): return x**4def h(x): return x**8import timeitprint(timeit.timeit('[func(42) for func in (f,g,h)]', globals=globals()))]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>timeit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library filecmp]]></title>
    <url>%2F2020%2F01%2F22%2Fpython-standard-library-filecmp%2F</url>
    <content type="text"><![CDATA[python 标准库 filecmp每日一词: 病毒 germs、bacteria 還是 viruses Germ: 微生物Bacterium: 這是「細菌」的意思，它是微小且單細胞的有機體。注意喔這個字的單數是 bacterium，複數要寫作 bacteriaVirus:病菌 茲卡病毒（Zika virus）、諾羅病毒（Norovirus）、愛滋病毒（Human Immunodeficiency Virus，縮寫即是 HIV）、輪狀病毒（Rotavirus）等。 继续学习关于文件操作的模块 filecmp 源代码 源代码: Lib/filecmp.py filecmp 模块定义了用于比较文件及目录的函数，并且可以选取多种关于时间和准确性的折衷方案。对于文件的比较，另见 difflib 模块。 函数 filecmp 模块定义了如下函数： filecmp.`cmp`(f1, f2, shallow=True) filecmp.`cmpfiles`(dir1, dir2, common, shallow=True) filecmp.`clear_cache`() dircmp 类 class filecmp.`dircmp`(a, b, ignore=None, hide=None) 创建一个用于比较目录 a 和 b 的新的目录比较对象。 ignore 是需要忽略的文件名列表，且默认为 filecmp.DEFAULT_IGNORES 。 hide 是需要隐藏的文件名列表，且默认为 [os.curdir, os.pardir] 。 dircmp 类如 filecmp.cmp() 中所描述的那样对文件进行 shallow 比较。 dircmp 类提供以下方法： report() 将 a 与 b 之间的比较打印（到 sys.stdout ）。 report_partial_closure() 打印 a 与 b 及共同直接子目录的比较结果。 report_full_closure() 打印 a 与 b 及共同子目录比较结果（递归地）。 dircmp 类提供了一些有趣的属性，用以得到关于参与比较的目录树的各种信息。 需要注意，通过 __getattr__() 钩子，所有的属性将会惰性求值，因此如果只使用那些计算简便的属性，将不会有速度损失。 left 目录 a 。 right 目录 b 。 left_list 经 hide 和 ignore 过滤，目录 a 中的文件与子目录。 right_list 经 hide 和 ignore 过滤，目录 b 中的文件与子目录。 common 同时存在于目录 a 和 b 中的文件和子目录。 left_only 仅在目录 a 中的文件和子目录。 right_only 仅在目录 b 中的文件和子目录。 common_dirs 同时存在于目录 a 和 b 中的子目录。 common_files 同时存在于目录 a 和 b 中的文件。 common_funny 在目录 a 和 b 中类型不同的名字，或者那些 os.stat() 报告错误的名字。 same_files 在目录 a 和 b 中使用类的文件比较操作符相等的文件。 diff_files 在目录 a 和 b 中，根据类的文件比较操作符判定内容不等的文件。 funny_files 在目录 a 和 b 中无法比较的文件。 subdirs 一个将 common_dirs 中名称映射为 dircmp 对象的字典。 filecmp.`DEFAULT_IGNORES` 下面是一个简单的例子，使用 subdirs 属性递归搜索两个目录以显示公共差异文件： 12345678910&gt;&gt;&gt; from filecmp import dircmp&gt;&gt;&gt; def print_diff_files(dcmp):... for name in dcmp.diff_files:... print("diff_file %s found in %s and %s" % (name, dcmp.left,... dcmp.right))... for sub_dcmp in dcmp.subdirs.values():... print_diff_files(sub_dcmp)...&gt;&gt;&gt; dcmp = dircmp('dir1', 'dir2') &gt;&gt;&gt; print_diff_files(dcmp) 例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#!/usr/bin/python3#coding:utf-8import os,sysimport filecmpimport reimport shutil''' 校验源与备份目录的差异''' holderlist = []def compareme(dir1,dir2): #递归获取更新项函数 dircomp = filecmp.dircmp(dir1,dir2) only_in_one = dircomp.left_only #源目录新文件或目录 diff_in_one = dircomp.diff_files #不匹配文件，源目录文件已发生变化 dirpath = os.path.abspath(dir1) #定义源目录绝对路径 #将更新文件或目录追加到holderlist [ holderlist.append(os.path.abspath(os.path.join(dir1,x))) for x in only_in_one ] [ holderlist.append(os.path.abspath(os.path.join(dir1,x))) for x in diff_in_one ] if len(dircomp.common_dirs) &gt; 0: #判断是否存在相同子目录，以便递归 for item in dircomp.common_dirs: #递归子目录 compareme(os.path.abspath(os.path.join(dir1,item)),os.path.abspath(os.path.join(dir2,item))) return holderlist def main(): if len(sys.argv) &gt; 2: #输入源目录与备份目录 dir1 = sys.argv[1] dir2 = sys.argv[2] else : print('Usage:',sys.argv[0],'datadir backdir') sys.exit() source_files = compareme(dir1,dir2) #对比源目录与备份目录 dir1 = os.path.abspath(dir1) #取绝对路径后，后面不会自动加上'/' if not dir2.endswith('/'): dir2 = dir2+'/' #备份目录路径加'/' dir2 = os.path.abspath(dir2) destination_files = [] createdir_bool = False for item in source_files: #遍历返回的差异文件或目录清单 destination_dir = re.sub(dir1,dir2,item) #将源目录差异路径清单对应替换成备份目录,即需要在dir2中创建的差异目录和文件 destination_files.append(destination_dir) if os.path.isdir(item): #如果差异路径为目录且不存在，则在备份目录中创建 if not os.path.exists(destination_dir): os.makedirs(destination_dir) createdir_bool = True #再次调用copareme函数标记 if createdir_bool : #重新调用compareme函数，重新遍历新创建目录的内容 destination_files = [] source_files = [] source_files = compareme(dir1,dir2) #调用compareme函数 for item in source_files: #获取源目录差异路径清单，对应替换成备份目录 destination_dir = re.sub(dir1,dir2,item) destination_files.append(destination_dir) print('update item:') print(source_files) #输出更新项列表清单 copy_pair = zip(source_files,destination_files) #将源目录与备份目录文件清单拆分成元组 for item in copy_pair: if os.path.isfile(item[0]): #判断是否为文件，是则进行复制操作 shutil.copyfile(item[0],item[1]) if __name__ == '__main__' : main()]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>filecmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library difflib]]></title>
    <url>%2F2020%2F01%2F21%2Fpython-standard-library-difflib%2F</url>
    <content type="text"><![CDATA[python 标准库学习 difflib每日一词: wink US[wɪŋk] UK[wɪŋk] n.眼色；眨一只眼；眨眼示意 v.闪烁；眨眼示意（尤指使眼色或表示开玩笑）；明灭 网络瞬间；眨眼睛；你眨了眨眼 推荐一个电影： 记忆碎片👴 又是诺兰的大作,强烈推荐 推荐指数： 🌟🌟🌟🌟🌟 马上就要过年了,尽量少去人流密集场所吧。 源代码源代码: Lib/difflib.py 此模块提供用于比较序列的类和函数。 例如，它可以用于比较文件，并可以产生各种格式的不同信息，包括 HTML 和上下文以及统一格式的差异点。 有关目录和文件的比较，请参见 filecmp 模块。 类class difflib.SequenceMatcher 这是一个灵活的类，可用于比较任何类型的序列对，只要序列元素为 hashable 对象。 其基本算法要早于由 Ratcliff 和 Obershelp 于 1980 年代末期发表并以“格式塔模式匹配”的夸张名称命名的算法，并且更加有趣一些。 其思路是找到不包含“垃圾”元素的最长连续匹配子序列；所谓“垃圾”元素是指其在某种意义上没有价值，例如空白行或空白符。 （处理垃圾元素是对 Ratcliff 和 Obershelp 算法的一个扩展。） 然后同样的思路将递归地应用于匹配序列的左右序列片段。 这并不能产生最小编辑序列，但确实能产生在人们看来“正确”的匹配。 耗时: 基本 Ratcliff-Obershelp 算法在最坏情况下为立方时间而在一般情况下为平方时间。 SequenceMatcher 在最坏情况下为平方时间而在一般情况下的行为受到序列中有多少相同元素这一因素的微妙影响；在最佳情况下则为线性时间。 自动垃圾启发式计算: SequenceMatcher 支持使用启发式计算来自动将特定序列项视为垃圾。 这种启发式计算会统计每个单独项在序列中出现的次数。 如果某一项（在第一项之后）的重复次数超过序列长度的 1% 并且序列长度至少有 200 项，该项会被标记为“热门”并被视为序列匹配中的垃圾。 这种启发式计算可以通过在创建 SequenceMatcher 时将 autojunk 参数设为 False 来关闭。 class difflib.Differ 这个类的作用是比较由文本行组成的序列，并产生可供人阅读的差异或增量信息。 Differ 统一使用 SequenceMatcher 来完成行序列的比较以及相似（接近匹配）行内部字符序列的比较。 Differ 增量的每一行均以双字母代码打头： 双字母代码 意义 &#39;- &#39; 行为序列 1 所独有 &#39;+ &#39; 行为序列 2 所独有 &#39; &#39; 行在两序列中相同 &#39;? &#39; 行不存在于任一输入序列 以 ‘?‘ 打头的行尝试将视线引至行以外而不存在于任一输入序列的差异。 如果序列包含制表符则这些行可能会令人感到迷惑。 class difflib.HtmlDiff 这个类可用于创建 HTML 表格（或包含表格的完整 HTML 文件）以并排地逐行显示文本比较，行间与行外的更改将突出显示。 此表格可以基于完全或上下文差异模式来生成。 这个类的构造函数： __init__(tabsize=8, wrapcolumn=None, linejunk=None, charjunk=IS_CHARACTER_JUNK) 初始化 HtmlDiff 的实例。 tabsize 是一个可选关键字参数，指定制表位的间隔，默认值为 8。 wrapcolumn 是一个可选关键字参数，指定行文本自动打断并换行的列位置，默认值为 None 表示不自动换行。 linejunk 和 charjunk 均是可选关键字参数，会传入 ndiff() (被 HtmlDiff 用来生成并排显示的 HTML 差异)。 请参阅 ndiff() 文档了解参数默认值及其说明。 make_file(fromlines, tolines, fromdesc=’’, todesc=’’, context=False, numlines=5, **, charset=’utf-8’*) 比较 fromlines 和 tolines (字符串列表) 并返回一个字符串，表示一个完整 HTML 文件，其中包含各行差异的表格，行间与行外的更改将突出显示。 fromdesc 和 todesc 均是可选关键字参数，指定来源/目标文件的列标题字符串（默认均为空白字符串）。 context 和 numlines 均是可选关键字参数。 当只要显示上下文差异时就将 context 设为 True，否则默认值 False 为显示完整文件。 numlines 默认为 5。 当 context 为 True 时 numlines 将控制围绕突出显示差异部分的上下文行数。 当 context 为 False 时 numlines 将控制在使用 “next” 超链接时突出显示差异部分之前所显示的行数（设为零则会导致 “next” 超链接将下一个突出显示差异部分放在浏览器顶端，不添加任何前导上下文）。 fromdesc 和 todesc 会被当作未转义的 HTML 来解读，当接收不可信来源的输入时应该适当地进行转义。 make_table(fromlines, tolines, fromdesc=’’, todesc=’’, context=False, numlines=5) 比较 fromlines 和 tolines (字符串列表) 并返回一个字符串，表示一个包含各行差异的完整 HTML 表格，行间与行外的更改将突出显示。 此方法的参数与 make_file() 方法的相同。 Tools/scripts/diff.py 是这个类的命令行前端，其中包含一个很好的使用示例。 函数difflib.context_diff(a, b, fromfile=’’, tofile=’’, fromfiledate=’’, tofiledate=’’, n=3, lineterm=’\n’) 比较 a 和 b (字符串列表)；返回上下文差异格式的增量信息 (一个产生增量行的 generator)。 所谓上下文差异是一种只显示有更改的行再加几个上下文行的紧凑形式。 更改被显示为之前/之后的样式。 上下文行数由 n 设定，默认为三行。 默认情况下，差异控制行（以 *** or --- 表示）是通过末尾换行符来创建的。 这样做的好处是从 io.IOBase.readlines() 创建的输入将得到适用于 io.IOBase.writelines() 的差异信息，因为输入和输出都带有末尾换行符。 对于没有末尾换行符的输入，应将 lineterm 参数设为 &quot;&quot;，这样输出内容将统一不带换行符。 上下文差异格式通常带有一个记录文件名和修改时间的标头。 这些信息的部分或全部可以使用字符串 fromfile, tofile, fromfiledate 和 tofiledate 来指定。 修改时间通常以 ISO 8601 格式表示。 如果未指定，这些字符串默认为空。 12345678910111213141516&gt;&gt;&gt; s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']&gt;&gt;&gt; s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']&gt;&gt;&gt; sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py',tofile='after.py'))*** before.py--- after.py****************** 1,4 ****! bacon! eggs! ham guido--- 1,4 ----! python! eggy! hamster guido difflib.get_close_matches(word, possibilities, n=3, cutoff=0.6) 返回由最佳“近似”匹配构成的列表。 word 为一个指定目标近似匹配的序列（通常为字符串），possibilities 为一个由用于匹配 word 的序列构成的列表（通常为字符串列表）。 可选参数 n (默认为 3) 指定最多返回多少个近似匹配； n 必须大于 0. 可选参数 cutoff (默认为 0.6) 是一个 [0, 1] 范围内的浮点数。 与 word 相似度得分未达到该值的候选匹配将被忽略。 候选匹配中（不超过 n 个）的最佳匹配将以列表形式返回，按相似度得分排序，最相似的排在最前面。 123456789&gt;&gt;&gt; get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])['apple', 'ape']&gt;&gt;&gt;import keyword&gt;&gt;&gt; get_close_matches('wheel', keyword.kwlist)['while']&gt;&gt;&gt; get_close_matches('pineapple', keyword.kwlist)[]&gt;&gt;&gt; get_close_matches('accept', keyword.kwlist)['except'] difflib.ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK) 比较 a 和 b (字符串列表)；返回 Differ 形式的增量信息 (一个产生增量行的 generator)。 可选关键字形参 linejunk 和 charjunk 均为过滤函数 (或为 None)： linejunk: 此函数接受单个字符串参数，如果其为垃圾字符串则返回真值，否则返回假值。 默认为 None。 此外还有一个模块层级的函数 IS_LINE_JUNK()，它会过滤掉没有可见字符的行，除非该行添加了至多一个井号符 (&#39;#&#39;) – 但是下层的 SequenceMatcher 类会动态分析哪些行的重复频繁到足以形成噪音，这通常会比使用此函数的效果更好。 charjunk: 此函数接受一个字符（长度为 1 的字符串)，如果其为垃圾字符则返回真值，否则返回假值。 默认为模块层级的函数 IS_CHARACTER_JUNK()，它会过滤掉空白字符（空格符或制表符；但包含换行符可不是个好主意！）。 Tools/scripts/ndiff.py 是这个函数的命令行前端。 123456789101112&gt;&gt;&gt; diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),... 'ore\ntree\nemu\n'.splitlines(keepends=True))&gt;&gt;&gt; print(''.join(diff), end="")- one? ^+ ore? ^- two- three? -+ tree+ emu difflib.restore(sequence, which) 返回两个序列中产生增量的那一个。 给出一个由 Differ.compare() 或 ndiff() 产生的 序列，提取出来自文件 1 或 2 (which 形参) 的行，去除行前缀。 示例: 1234567891011&gt;&gt;&gt; diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),... 'ore\ntree\nemu\n'.splitlines(keepends=True))&gt;&gt;&gt; diff = list(diff) # materialize the generated delta into a list&gt;&gt;&gt; print(''.join(restore(diff, 1)), end="")onetwothree&gt;&gt;&gt; print(''.join(restore(diff, 2)), end="")oretreeemu difflib.unified_diff(a, b, fromfile=’’, tofile=’’, fromfiledate=’’, tofiledate=’’, n=3, lineterm=’\n’) 比较 a 和 b (字符串列表)；返回统一差异格式的增量信息 (一个产生增量行的 generator)。 所以统一差异是一种只显示有更改的行再加几个上下文行的紧凑形式。 更改被显示为内联的样式（而不是分开的之前/之后文本块）。 上下文行数由 n 设定，默认为三行。 默认情况下，差异控制行 (以 ---, +++ 或 @@ 表示) 是通过末尾换行符来创建的。 这样做的好处是从 io.IOBase.readlines() 创建的输入将得到适用于 io.IOBase.writelines() 的差异信息，因为输入和输出都带有末尾换行符。 对于没有末尾换行符的输入，应将 lineterm 参数设为 &quot;&quot;，这样输出内容将统一不带换行符。 上下文差异格式通常带有一个记录文件名和修改时间的标头。 这些信息的部分或全部可以使用字符串 fromfile, tofile, fromfiledate 和 tofiledate 来指定。 修改时间通常以 ISO 8601 格式表示。 如果未指定，这些字符串默认为空。 12345678910111213&gt;&gt;&gt; s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']&gt;&gt;&gt; s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']&gt;&gt;&gt; sys.stdout.writelines(unified_diff(s1, s2, fromfile='before.py',tofile='after.py'))--- before.py+++ after.py@@ -1,4 +1,4 @@-bacon-eggs-ham+python+eggy+hamster guido difflib.diff_bytes(dfunc, a, b, fromfile=b’’, tofile=b’’, fromfiledate=b’’, tofiledate=b’’, n=3, lineterm=b’\n’) 使用 dfunc 比较 a 和 b (字节串对象列表)；产生以 dfunc 所返回格式表示的差异行列表（也是字节串）。 dfunc 必须是可调用对象，通常为 unified_diff() 或 context_diff()。 允许你比较编码未知或不一致的数据。 除 n 之外的所有输入都必须为字节串对象而非字符串。 作用方式为无损地将所有输入 (除 n 之外) 转换为字符串，并调用 dfunc(a, b, fromfile, tofile, fromfiledate, tofiledate, n, lineterm)。 dfunc 的输出会被随即转换回字节串，这样你所得到的增量行将具有与 a 和 b 相同的未知/不一致编码。 difflib.IS_LINE_JUNK(line) 对于可忽略的行返回 True。 如果 line 为空行或只包含单个 &#39;#&#39; 则 line 行就是可忽略的，否则就是不可忽略的。 此函数被用作较旧版本 ndiff() 中 linejunk 形参的默认值。 difflib.IS_CHARACTER_JUNK 对于可忽略的字符返回 True。 字符 ch 如果为空格符或制表符则 ch 就是可忽略的，否则就是不可忽略的。 此函数被用作 ndiff() 中 charjunk 形参的默认值。 SequenceMatcher 对象SequenceMatcher 类具有这样的构造器： class difflib.SequenceMatcher(isjunk=None, a=’’, b=’’, autojunk=True) 可选参数 isjunk 必须为 None (默认值) 或为接受一个序列元素并当且仅当其为应忽略的“垃圾”元素时返回真值的单参数函数。 传入 None 作为 isjunk 的值就相当于传入 lambda x: False；也就是说不忽略任何值。 例如，传入: 1lambda x: x in " \t" 如果你以字符序列的形式对行进行比较，并且不希望区分空格符或硬制表符。 可选参数 a 和 b 为要比较的序列；两者默认为空字符串。 两个序列的元素都必须为 hashable。 可选参数 autojunk 可用于启用自动垃圾启发式计算。 SequenceMatcher 对象接受三个数据属性: bjunk 是 b 当中 isjunk 为 True 的元素集合；bpopular 是被启发式计算（如果其未被禁用）视为热门候选的非垃圾元素集合；b2j 是将 b 当中剩余元素映射到一个它们出现位置列表的字典。 所有三个数据属性将在 b 通过 set_seqs() 或 set_seq2() 重置时被重置。 方法 set_seqs(a, b) 设置要比较的两个序列。 SequenceMatcher 计算并缓存有关第二个序列的详细信息，这样如果你想要将一个序列与多个序列进行比较，可使用 set_seq2() 一次性地设置该常用序列并重复地对每个其他序列各调用一次 set_seq1()。 set_seq1(a) 设置要比较的第一个序列。 要比较的第二个序列不会改变。 set_seq2(b) 设置要比较的第二个序列。 要比较的第一个序列不会改变。 find_longest_match(alo, ahi, blo, bhi) 找出 a[alo:ahi] 和 b[blo:bhi] 中的最长匹配块。 如果 isjunk 被省略或为 None，find_longest_match() 将返回 (i, j, k) 使得 a[i:i+k] 等于 b[j:j+k]，其中 alo &lt;= i &lt;= i+k &lt;= ahi 并且 blo &lt;= j &lt;= j+k &lt;= bhi。 对于所有满足这些条件的 (i&#39;, j&#39;, k&#39;)，如果 i == i&#39;, j &lt;= j&#39; 也被满足，则附加条件 k &gt;= k&#39;, i &lt;= i&#39;。 换句话说，对于所有最长匹配块，返回在 a 当中最先出现的一个，而对于在 a 当中最先出现的所有最长匹配块，则返回在 b 当中最先出现的一个。 123&gt;&gt;&gt; s = SequenceMatcher(None, " abcd", "abcd abcd")&gt;&gt;&gt; s.find_longest_match(0, 5, 0, 9)Match(a=0, b=4, size=5) 如果提供了 isjunk，将按上述规则确定第一个最长匹配块，但额外附加不允许块内出现垃圾元素的限制。 然后将通过（仅）匹配两边的垃圾元素来尽可能地扩展该块。 这样结果块绝对不会匹配垃圾元素，除非同样的垃圾元素正好与有意义的匹配相邻。 这是与之前相同的例子，但是将空格符视为垃圾。 这将防止 &#39; abcd&#39; 直接与第二个序列末尾的 &#39; abcd&#39; 相匹配。 而只可以匹配 &#39;abcd&#39;，并且是匹配第二个序列最左边的 &#39;abcd&#39;： 123&gt;&gt;&gt; s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")&gt;&gt;&gt; s.find_longest_match(0, 5, 0, 9)Match(a=1, b=0, size=4) 如果未找到匹配块，此方法将返回 (alo, blo, 0)。 此方法将返回一个 named tuple Match(a, b, size)。 get_matching_blocks() 返回描述非重叠匹配子序列的三元组列表。 每个三元组的形式为 (i, j, n)，其含义为 a[i:i+n] == b[j:j+n]。 这些三元组按 i 和 j 单调递增排列。 最后一个三元组用于占位，其值为 (len(a), len(b), 0)。 它是唯一 n == 0 的三元组。 如果 (i, j, n) 和 (i&#39;, j&#39;, n&#39;) 是在列表中相邻的三元组，且后者不是列表中的最后一个三元组，则 i+n &lt; i&#39; 或 j+n &lt; j&#39;；换句话说，相邻的三元组总是描述非相邻的相等块。 123&gt;&gt;&gt; s = SequenceMatcher(None, "abxcd", "abcd")&gt;&gt;&gt; s.get_matching_blocks()[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() 返回描述如何将 a 变为 b 的 5 元组列表，每个元组的形式为 (tag, i1, i2, j1, j2)。 在第一个元组中 i1 == j1 == 0，而在其余的元组中 i1 等于前一个元组的 i2，并且 j1 也等于前一个元组的 j2。 tag 值为字符串，其含义如下： 值 意义 &#39;replace&#39; a[i1:i2] 应由 b[j1:j2] 替换。 &#39;delete&#39; a[i1:i2] 应被删除。 请注意在此情况下 j1 == j2。 &#39;insert&#39; b[j1:j2] 应插入到 a[i1:i1]。 请注意在此情况下 i1 == i2。 &#39;equal&#39; a[i1:i2] == b[j1:j2] (两个子序列相同)。 例如： 1234567891011&gt;&gt;&gt; a = "qabxcd"&gt;&gt;&gt; b = "abycdf"&gt;&gt;&gt; s = SequenceMatcher(None, a, b)&gt;&gt;&gt; for tag, i1, i2, j1, j2 in s.get_opcodes():... print('&#123;:7&#125; a[&#123;&#125;:&#123;&#125;] --&gt; b[&#123;&#125;:&#123;&#125;] &#123;!r:&gt;8&#125; --&gt; &#123;!r&#125;'.format(... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))delete a[0:1] --&gt; b[0:0] 'q' --&gt; ''equal a[1:3] --&gt; b[0:2] 'ab' --&gt; 'ab'replace a[3:4] --&gt; b[2:3] 'x' --&gt; 'y'equal a[4:6] --&gt; b[3:5] 'cd' --&gt; 'cd'insert a[6:6] --&gt; b[5:6] '' --&gt; 'f' get_grouped_opcodes(n=3) 返回一个带有最多 n 行上下文的分组的 generator。从 get_opcodes() 所返回的组开始，此方法会拆分出较小的更改簇并消除没有更改的间隔区域。这些分组以与 get_opcodes() 相同的格式返回。 ratio() 返回一个取值范围 [0, 1] 的浮点数作为序列相似性度量。其中 T 是两个序列中元素的总数量，M 是匹配的数量，即 2.0*M / T。 请注意如果两个序列完全相同则该值为 1.0，如果两者完全不同则为 0.0。如果 get_matching_blocks() 或 get_opcodes() 尚未被调用则此方法运算消耗较大，在此情况下你可能需要先调用 quick_ratio() 或 real_quick_ratio() 来获取一个上界。 注意: ratio() 调用的结果可能会取决于参数的顺序。 例如: 12345&gt; &gt;&gt;&gt; SequenceMatcher(None, 'tide', 'diet').ratio()&gt; 0.25&gt; &gt;&gt;&gt; SequenceMatcher(None, 'diet', 'tide').ratio()&gt; 0.5&gt; quick_ratio() 相对快速地返回一个 ratio() 的上界。 real_quick_ratio() 非常快速地返回一个 ratio() 的上界。 这三个返回匹配部分占字符总数的比率的方法可能由于不同的近似级别而给出不一样的结果，但是 quick_ratio() 和 real_quick_ratio() 总是会至少与 ratio() 一样大： 1234567&gt;&gt;&gt; s = SequenceMatcher(None, "abcd", "bcde")s.ratio()0.75&gt;&gt;&gt; s.quick_ratio()0.75&gt;&gt;&gt; s.real_quick_ratio()1.0 SequenceMatcher 的示例以下示例比较两个字符串，并将空格视为“垃圾”： 123&gt;&gt;&gt; s = SequenceMatcher(lambda x: x == " ",... "private Thread currentThread;",... "private volatile Thread currentThread;") ratio() 返回一个 [0, 1] 范围内的整数作为两个序列相似性的度量。 根据经验，ratio() 值超过 0.6 就意味着两个序列是近似匹配的： 12&gt;&gt;&gt; print(round(s.ratio(), 3))0.866 如果你只对两个序列相匹配的位置感兴趣，则 get_matching_blocks() 就很方便： 12345&gt;&gt;&gt; for block in s.get_matching_blocks():... print("a[%d] and b[%d] match for %d elements" % block)a[0] and b[0] match for 8 elementsa[8] and b[17] match for 21 elementsa[29] and b[38] match for 0 elements 请注意 get_matching_blocks() 返回的最后一个元组总是只用于占位的 (len(a), len(b), 0)，这也是元组末尾元素（匹配的元素数量）为 0 的唯一情况。 如果你想要知道如何将第一个序列转成第二个序列，可以使用 get_opcodes(): 12345&gt;&gt;&gt;for opcode in s.get_opcodes():... print("%6s a[%d:%d] b[%d:%d]" % opcode) equal a[0:8] b[0:8]insert a[8:8] b[8:17] equal a[8:29] b[17:38] Differ 对象请注意 Differ 所生成的增量并不保证是 最小 差异。 相反，最小差异往往是违反直觉的，因为它们会同步任何可能的地方，有时甚至意外产生相距 100 页的匹配。 将同步点限制为连续匹配保留了一些局部性概念，这偶尔会带来产生更长差异的代价。 Differ 类具有这样的构造器： class difflib.Differ(linejunk=None, charjunk=None) 可选关键字形参 linejunk 和 charjunk 均为过滤函数 (或为 None)： linejunk: 接受单个字符串作为参数的函数，如果其为垃圾字符串则返回真值。 默认值为 None，意味着没有任何行会被视为垃圾行。 charjunk: 接受单个字符（长度为 1 的字符串）作为参数的函数，如果其为垃圾字符则返回真值。 默认值为 None，意味着没有任何字符会被视为垃圾字符。 这些垃圾过滤函数可加快查找差异的匹配速度，并且不会导致任何差异行或字符被忽略。 请阅读 find_longest_match() 方法的 isjunk 形参的描述了解详情。 Differ 对象是通过一个单独方法来使用（生成增量）的： compare(a, b) 比较两个由行组成的序列，并生成增量（一个由行组成的序列）。每个序列必须包含一个以换行符结尾的单行字符串。 这样的序列可以通过文件类对象的 readlines() 方法来获取。 所生成的增量同样由以换行符结尾的字符串构成，可以通过文件类对象的 writelines() 方法原样打印出来。 Differ 示例此示例比较两段文本。 首先我们设置文本为以换行符结尾的单行字符串构成的序列（这样的序列也可以通过文件类对象的 readlines() 方法来获取）： 1234567891011121314&gt;&gt;&gt; text1 = ''' 1. Beautiful is better than ugly.... 2. Explicit is better than implicit.... 3. Simple is better than complex.... 4. Complex is better than complicated.... '''.splitlines(keepends=True)&gt;&gt;&gt; len(text1)4&gt;&gt;&gt; text1[0][-1]'\n'&gt;&gt;&gt; text2 = ''' 1. Beautiful is better than ugly.... 3. Simple is better than complex.... 4. Complicated is better than complex.... 5. Flat is better than nested.... '''.splitlines(keepends=True) 接下来我们实例化一个 Differ 对象： 1&gt;&gt;&gt; d = Differ() 请注意在实例化 Differ 对象时我们可以传入函数来过滤掉“垃圾”行和字符。 详情参见 Differ() 构造器说明。 最后，我们比较两个序列： 1&gt;&gt;&gt; result = list(d.compare result 是一个字符串列表，让我们将其美化打印出来： 123456789101112&gt;&gt;&gt; from pprint import pprint&gt;&gt;&gt; pprint(result)[' 1. Beautiful is better than ugly.\n', '- 2. Explicit is better than implicit.\n', '- 3. Simple is better than complex.\n', '+ 3. Simple is better than complex.\n', '? ++\n', '- 4. Complex is better than complicated.\n', '? ^ ---- ^\n', '+ 4. Complicated is better than complex.\n', '? ++++ ^ ^\n', '+ 5. Flat is better than nested.\n'] 作为单独的多行字符串显示出来则是这样： 123456789101112&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.stdout.writelines(result) 1. Beautiful is better than ugly.- 2. Explicit is better than implicit.- 3. Simple is better than complex.+ 3. Simple is better than complex.? ++- 4. Complex is better than complicated.? ^ ---- ^+ 4. Complicated is better than complex.? ++++ ^ ^+ 5. Flat is better than nested. difflib 的命令行接口这个实例演示了如何使用 difflib 来创建一个类似于 diff 的工具。 它同样包含在 Python 源码发布包中，文件名为 Tools/scripts/diff.py。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/usr/bin/env python3""" Command line interface to difflib.py providing diffs in four formats:* ndiff: lists every line and highlights interline changes.* context: highlights clusters of changes in a before/after format.* unified: highlights clusters of changes in an inline format.* html: generates side by side comparison with change highlights."""import sys, os, difflib, argparsefrom datetime import datetime, timezonedef file_mtime(path): t = datetime.fromtimestamp(os.stat(path).st_mtime, timezone.utc) return t.astimezone().isoformat()def main(): parser = argparse.ArgumentParser() parser.add_argument('-c', action='store_true', default=False, help='Produce a context format diff (default)') parser.add_argument('-u', action='store_true', default=False, help='Produce a unified format diff') parser.add_argument('-m', action='store_true', default=False, help='Produce HTML side by side diff ' '(can use -c and -l in conjunction)') parser.add_argument('-n', action='store_true', default=False, help='Produce a ndiff format diff') parser.add_argument('-l', '--lines', type=int, default=3, help='Set number of context lines (default 3)') parser.add_argument('fromfile') parser.add_argument('tofile') options = parser.parse_args() n = options.lines fromfile = options.fromfile tofile = options.tofile fromdate = file_mtime(fromfile) todate = file_mtime(tofile) with open(fromfile) as ff: fromlines = ff.readlines() with open(tofile) as tf: tolines = tf.readlines() if options.u: diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n) elif options.n: diff = difflib.ndiff(fromlines, tolines) elif options.m: diff = difflib.HtmlDiff().make_file(fromlines,tolines,fromfile,tofile,context=options.c,numlines=n) else: diff = difflib.context_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n) sys.stdout.writelines(diff)if __name__ == '__main__': main() 补充关于HtmlDiff类用法结合webbrowser创建差异比较页面 123456789101112import difflibimport webbrowserdef check_diff(self, index, wrapcolumn): file1, file2 = self.differing[index] with open(file1, 'r') as f: content1 = f.read().splitlines() with open(file2, 'r') as f: content2 = f.read().splitlines() htmlDiff = HtmlDiff(tabsize=2,wrapcolumn=wrapcolumn) with open('tmp.html', 'w') as f: f.write(htmlDiff.make_file(content1, content2, fromdesc=self.dir1, todesc=self.dir2)) webbrowser.open('tmp.html') 对比Nginx配置文件差异脚本 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python3# -*- coding:utf-8 -*- import difflibimport stringimport sys try: textfile1 = sys.argv[1] textfile2 = sys.argv[2]except Exception: print("Error:" + str(e)) print("Usage: xxxx.py filename1 filename2") sys.exit()def readfile(filename): try: fileHandle = open(filename,'r') text = fileHandle.read().splitlines() fileHandle.close() return text except IOError as error: print('Read file Error:' + str(error)) sys.exit() if textfile1 == "" or textfile2 == "": print("Usage:test.py filename1 filename2") sys.exit() text1_lines = readfile(textfile1)text2_lines = readfile(textfile2) d = difflib.HtmlDiff()print(d.make_file(text1_lines,text2_lines))]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>difflib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library sqlite3]]></title>
    <url>%2F2020%2F01%2F20%2Fpython-standard-library-sqlite3%2F</url>
    <content type="text"><![CDATA[python 标准库 sqlite3今天是二十四节气的大寒 大寒，是二十四节气中的最后一个节气。斗指丑；太阳黄经为300°；公历1月20－21日交节。同小寒一样，大寒也是表示天气寒冷程度的节气。在我国部分地区，大寒不如小寒冷，但在某些年份和沿海少数地方，全年最低气温仍然会出现在大寒节气内。小寒、大寒是一年中雨水最少的时段。 兹大寒一过，新一年的节气就又轮回来了，正所谓冬去春来。大寒虽然寒冷，但因为已近春天，所以不会像大雪到冬至期间那样酷寒。这时节，人们开始忙着除旧饰新、腌制年肴、准备年货和各种祭祀供品、扫尘洁物，因为中国人最重要的节日——春节就要到了。 每日一词： Cold adj 冷,寒冷 例句： It is the last one in January 20th of each year twenty-four solar term solar term, before and after the sun reaches 300 degrees for it”. It is cold weather, meaning extreme. 大寒是二十四节气中最后一个节气，每年1月20日前后太阳到达黄经300°时为”大寒”。大寒，是天气寒冷到极点的意思。 源码源代码： Lib/sqlite3/ SQLite 是一个C语言库，它可以提供一种轻量级的基于磁盘的数据库，这种数据库不需要独立的服务器进程，也允许需要使用一种非标准的 SQL 查询语言来访问它。一些应用程序可以使用 SQLite 作为内部数据存储。可以用它来创建一个应用程序原型，然后再迁移到更大的数据库，比如 PostgreSQL 或 Oracle。 sqlite3 模块由 Gerhard Häring 编写。它提供了符合 DB-API 2.0 规范的接口，这个规范是 PEP 249。 要使用这个模块，必须先创建一个 Connection 对象，它代表数据库。下面例子中，数据将存储在 example.db 文件中： 12import sqlite3conn = sqlite3.connect('example.db') 你也可以使用 :memory: 来创建一个内存中的数据库 当有了 Connection 对象后，你可以创建一个 Cursor 游标对象，然后调用它的 execute() 方法来执行 SQL 语句： 123456789101112131415c = conn.cursor()# Create tablec.execute(&apos;&apos;&apos;CREATE TABLE stocks (date text, trans text, symbol text, qty real, price real)&apos;&apos;&apos;)# Insert a row of datac.execute(&quot;INSERT INTO stocks VALUES (&apos;2006-01-05&apos;,&apos;BUY&apos;,&apos;RHAT&apos;,100,35.14)&quot;)# Save (commit) the changesconn.commit()# We can also close the connection if we are done with it.# Just be sure any changes have been committed or they will be lost.conn.close() 这些数据被持久化保存了，而且可以在之后的会话中使用它们： 123import sqlite3conn = sqlite3.connect('example.db')c = conn.cursor() 通常你的 SQL 操作需要使用一些 Python 变量的值。你不应该使用 Python 的字符串操作来创建你的查询语句，因为那样做不安全；它会使你的程序容易受到 SQL 注入攻击（在 https://xkcd.com/327/ 上有一个搞笑的例子，看看有什么后果） 推荐另外一种方法：使用 DB-API 的参数替换。在你的 SQL 语句中，使用 ? 占位符来代替值，然后把对应的值组成的元组做为 execute() 方法的第二个参数。（其他数据库可能会使用不同的占位符，比如 %s 或者 :1）例如： 123456789101112131415# Never do this -- insecure!symbol = 'RHAT'c.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)# Do this insteadt = ('RHAT',)c.execute('SELECT * FROM stocks WHERE symbol=?', t)print(c.fetchone())# Larger example that inserts many records at a timepurchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00), ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00), ('2006-04-06', 'SELL', 'IBM', 500, 53.00), ]c.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases) 要在执行 SELECT 语句后获取数据，你可以把游标作为 iterator，然后调用它的 fetchone() 方法来获取一条匹配的行，也可以调用 fetchall() 来得到包含多个匹配行的列表。 下面是一个使用迭代器形式的例子： 1234567&gt;&gt;&gt; for row in c.execute('SELECT * FROM stocks ORDER BY price'): print(row)('2006-01-05', 'BUY', 'RHAT', 100, 35.14)('2006-03-28', 'BUY', 'IBM', 1000, 45.0)('2006-04-06', 'SELL', 'IBM', 500, 53.0)('2006-04-05', 'BUY', 'MSFT', 1000, 72.0) 模块函数和常量 sqlite3.version ​ 这个模块的版本号，是一个字符串。不是 SQLite 库的版本号。 sqlite3.version_info 这个模块的版本号，是一个由整数组成的元组。不是 SQLite 库的版本号。 sqlite3.sqlite_version 使用中的 SQLite 库的版本号，是一个字符串。 sqlite3.sqlite_version_info 使用中的 SQLite 库的版本号，是一个整数组成的元组。 sqlite3.PARSE_DECLTYPES 这个常量可以作为 connect() 函数的 detect_types 参数。 设置这个参数后，sqlite3 模块将解析它返回的每一列申明的类型。它会申明的类型的第一个单词，比如“integer primary key”，它会解析出“integer”，再比如“number(10)”，它会解析出“number”。然后，它会在转换器字典里查找那个类型注册的转换器函数，并调用它。 sqlite3.PARSE_COLNAMES sqlite3.connect(database[, timeout, detect_types, isolation_level, check_same_thread, factory, cached_statements, uri]) 连接 SQLite 数据库 database。默认返回 Connection 对象，除非使用了自定义的 factory 参数。 database 是准备打开的数据库文件的路径（绝对路径或相对于当前目录的相对路径），它是 path-like object。你也可以用 &quot;:memory:&quot; 在内存中打开一个数据库。 当一个数据库被多个连接访问的时候，如果其中一个进程修改这个数据库，在这个事务提交之前，这个 SQLite 数据库将会被一直锁定。timeout 参数指定了这个连接等待锁释放的超时时间，超时之后会引发一个异常。这个超时时间默认是 5.0（5秒）。 isolation_level 参数，请查看 Connection 对象的 isolation_level 属性。 SQLite 原生只支持5种类型：TEXT，INTEGER，REAL，BLOB 和 NULL。如果你想用其它类型，你必须自己添加相应的支持。使用 detect_types 参数和模块级别的 register_converter() 函数注册转换器 可以简单的实现。 detect_types 默认为0（即关闭，没有类型检测）。你也可以组合 PARSE_DECLTYPES 和 PARSE_COLNAMES 来开启类型检测。 默认情况下，check_same_thread 为 True，只有当前的线程可以使用该连接。 如果设置为 False，则多个线程可以共享返回的连接。 当多个线程使用同一个连接的时候，用户应该把写操作进行序列化，以避免数据损坏。 默认情况下，当调用 connect 方法的时候，sqlite3 模块使用了它的 Connection 类。当然，你也可以创建 Connection 类的子类，然后创建提供了 factory 参数的 connect() 方法。 详情请查阅当前手册的 SQLite 与 Python 类型 部分。 sqlite3 模块在内部使用语句缓存来避免 SQL 解析开销。 如果要显式设置当前连接可以缓存的语句数，可以设置 cached_statements 参数。 当前实现的默认值是缓存100条语句。 如果 uri 为真，则 database 被解释为 URI。 它允许您指定选项。 例如，以只读模式打开数据库： 1db = sqlite3.connect('file:path/to/database?mode=ro', uri=True) 有关此功能的更多信息，包括已知选项的列表，可以在 SQLite URI 文档 &lt;&lt;https://www.sqlite.org/uri.html&gt;&gt;_ 中找到。 sqlite3.register_converter(typename, callable) 注册一个回调对象 callable, 用来转换数据库中的字节串为自定的 Python 类型。所有类型为 typename 的数据库的值在转换时，都会调用这个回调对象。通过指定 connect() 函数的 detect-types 参数来设置类型检测的方式。注意，typename 与查询语句中的类型名进行匹配时不区分大小写。 sqlite3.register_adapter(type, callable) 注册一个回调对象 callable，用来转换自定义Python类型为一个 SQLite 支持的类型。 这个回调对象 callable 仅接受一个 Python 值作为参数，而且必须返回以下某个类型的值：int，float，str 或 bytes。 sqlite3.complete_statement(sql) 如果字符串 sql 包含一个或多个完整的 SQL 语句（以分号结束）则返回 True。它不会验证 SQL 语法是否正确，仅会验证字符串字面上是否完整，以及是否以分号结束。 它可以用来构建一个 SQLite shell，下面是一个例子： 123456789101112131415161718192021222324252627282930# A minimal SQLite shell for experimentsimport sqlite3con = sqlite3.connect(":memory:")con.isolation_level = Nonecur = con.cursor()buffer = ""print("Enter your SQL commands to execute in sqlite3.")print("Enter a blank line to exit.")while True: line = input() if line == "": break buffer += line if sqlite3.complete_statement(buffer): try: buffer = buffer.strip() cur.execute(buffer) if buffer.lstrip().upper().startswith("SELECT"): print(cur.fetchall()) except sqlite3.Error as e: print("An error occurred:", e.args[0]) buffer = ""con.close() sqlite3.enable_callback_tracebacks(flag) 默认情况下，您不会获得任何用户定义函数中的回溯消息，比如聚合，转换器，授权器回调等。如果要调试它们，可以设置 flag 参数为 True 并调用此函数。 之后，回调中的回溯信息将会输出到 sys.stderr。 再次使用 False 来禁用该功能。 连接对象（Connection） class sqlite3.Connection SQLite 数据库连接对象有如下的属性和方法： isolation_level 获取或设置当前默认的隔离级别。 表示自动提交模式的 None 以及 “DEFERRED”, “IMMEDIATE” 或 “EXCLUSIVE” 其中之一。 详细描述请参阅 控制事务。 in_transaction 如果是在活动事务中（还没有提交改变），返回 True，否则，返回 False。它是一个只读属性。3.2 新版功能. cursor(factory=Cursor) 这个方法接受一个可选参数 factory，如果要指定这个参数，它必须是一个可调用对象，而且必须返回 Cursor 类的一个实例或者子类。 commit() 这个方法提交当前事务。如果没有调用这个方法，那么从上一次提交 commit() 以来所有的变化在其他数据库连接上都是不可见的。如果你往数据库里写了数据，但是又查询不到，请检查是否忘记了调用这个方法。 rollback() 这个方法回滚从上一次调用 commit() 以来所有数据库的改变。 close() 关闭数据库连接。注意，它不会自动调用 commit() 方法。如果在关闭数据库连接之前没有调用 commit()，那么你的修改将会丢失！ execute(sql[, parameters]) 这是一个非标准的快捷方法，它会调用 cursor() 方法来创建一个游标对象，并使用给定的 parameters 参数来调用游标对象的 execute() 方法，最后返回这个游标对象。 executemany(sql[, parameters]) 这是一个非标准的快捷方法，它会调用 cursor() 方法来创建一个游标对象，并使用给定的 parameters 参数来调用游标对象的 executemany() 方法，最后返回这个游标对象。 executescript(sql_script) 这是一个非标准的快捷方法，它会调用 cursor() 方法来创建一个游标对象，并使用给定的 sql_script 参数来调用游标对象的 executescript() 方法，最后返回这个游标对象。 create_function(name, num_params, func, **, deterministic=False*) 创建一个可以在 SQL 语句中使用的用户自定义函数，函数名为 name。 num_params 为该函数所接受的形参个数（如果 num_params 为 -1，则该函数可接受任意数量的参数）， func 是一个 Python 可调用对象，它将作为 SQL 函数被调用。 如果 deterministic 为真值，则所创建的函数将被标记为 deterministic，这允许 SQLite 执行额外的优化。 此旗标在 SQLite 3.8.3 或更高版本中受到支持，如果在旧版本中使用将引发 NotSupportedError。此函数可返回任何 SQLite 所支持的类型: bytes, str, int, float 和 None。在 3.8 版更改: 增加了 deterministic 形参。示例: 12345678910111213import sqlite3import hashlibdef md5sum(t): return hashlib.md5(t).hexdigest()con = sqlite3.connect(":memory:")con.create_function("md5", 1, md5sum)cur = con.cursor()cur.execute("select md5(?)", (b"foo",))print(cur.fetchone()[0])con.close() create_aggregate(name, num_params, aggregate_class) 创建一个自定义的聚合函数。 参数中 aggregate_class 类必须实现两个方法：step 和 finalize。step 方法接受 num_params 个参数（如果 num_params 为 -1，那么这个函数可以接受任意数量的参数）；finalize 方法返回最终的聚合结果。 finalize 方法可以返回任何 SQLite 支持的类型：bytes，str，int，float 和 None。 示例: 12345678910111213141516171819202122import sqlite3class MySum: def __init__(self): self.count = 0 def step(self, value): self.count += value def finalize(self): return self.countcon = sqlite3.connect(":memory:")con.create_aggregate("mysum", 1, MySum)cur = con.cursor()cur.execute("create table test(i)")cur.execute("insert into test(i) values (1)")cur.execute("insert into test(i) values (2)")cur.execute("select mysum(i) from test")print(cur.fetchone()[0])con.close() create_collation(name, callable) 使用 name 和 callable 创建排序规则。这个 callable 接受两个字符串对象，如果第一个小于第二个则返回 -1， 如果两个相等则返回 0，如果第一个大于第二个则返回 1。注意，这是用来控制排序的（SQL 中的 ORDER BY），所以它不会影响其它的 SQL 操作。 注意，这个 callable 可调用对象会把它的参数作为 Python 字节串，通常会以 UTF-8 编码格式对它进行编码。 以下示例显示了使用“错误方式”进行排序的自定义排序规则： 1234567891011121314151617181920import sqlite3def collate_reverse(string1, string2): if string1 == string2: return 0 elif string1 &lt; string2: return 1 else: return -1con = sqlite3.connect(":memory:")con.create_collation("reverse", collate_reverse)cur = con.cursor()cur.execute("create table test(x)")cur.executemany("insert into test(x) values (?)", [("a",), ("b",)])cur.execute("select x from test order by x collate reverse")for row in cur: print(row)con.close() 要移除一个排序规则，需要调用 create_collation 并设置 callable 参数为 None。 1con.create_collation("reverse", None) interrupt() 可以从不同的线程调用这个方法来终止所有查询操作，这些查询操作可能正在连接上执行。此方法调用之后， 查询将会终止，而且查询的调用者会获得一个异常。 set_authorizer(authorizer_callback) 此方法注册一个授权回调对象。每次在访问数据库中某个表的某一列的时候，这个回调对象将会被调用。如果要允许访问，则返回 SQLITE_OK，如果要终止整个 SQL 语句，则返回 SQLITE_DENY，如果这一列需要当做 NULL 值处理，则返回 SQLITE_IGNORE。这些常量可以在 sqlite3 模块中找到。回调的第一个参数表示要授权的操作类型。 第二个和第三个参数将是参数或 None，具体取决于第一个参数的值。 第 4 个参数是数据库的名称（“main”，“temp”等），如果需要的话。 第 5 个参数是负责访问尝试的最内层触发器或视图的名称，或者如果此访问尝试直接来自输入 SQL 代码，则为 None。请参阅 SQLite 文档，了解第一个参数的可能值以及第二个和第三个参数的含义，具体取决于第一个参数。 所有必需的常量都可以在 sqlite3 模块中找到。 set_progress_handler(handler, n) 此例程注册回调。 对SQLite虚拟机的每个多指令调用回调。 如果要在长时间运行的操作期间从SQLite调用（例如更新用户界面），这非常有用。如果要清除以前安装的任何进度处理程序，调用该方法时请将 handler 参数设置为 None。从处理函数返回非零值将终止当前正在执行的查询并导致它引发 OperationalError 异常。 set_trace_callback(trace_callback) 为每个 SQLite 后端实际执行的 SQL 语句注册要调用的 trace_callback。传递给回调的唯一参数是正在执行的语句（作为字符串）。 回调的返回值将被忽略。 请注意，后端不仅运行传递给 Cursor.execute() 方法的语句。 其他来源包括 Python 模块的事务管理和当前数据库中定义的触发器的执行。将传入的 trace_callback 设为 None 将禁用跟踪回调。 enable_load_extension(enabled) 此例程允许/禁止SQLite引擎从共享库加载SQLite扩展。 SQLite扩展可以定义新功能，聚合或全新的虚拟表实现。 一个众所周知的扩展是与SQLite一起分发的全文搜索扩展。 默认情况下禁用可加载扩展。 12345678910111213141516171819202122232425262728import sqlite3con = sqlite3.connect(":memory:")# enable extension loadingcon.enable_load_extension(True)# Load the fulltext search extensioncon.execute("select load_extension('./fts3.so')")# alternatively you can load the extension using an API call:# con.load_extension("./fts3.so")# disable extension loading againcon.enable_load_extension(False)# example from SQLite wikicon.execute("create virtual table recipe using fts3(name, ingredients)")con.executescript(""" insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes'); insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery'); insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour'); insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter'); """)for row in con.execute("select rowid, name, ingredients from recipe where name match 'pie'"): print(row)con.close() load_extension(path) 此例程从共享库加载SQLite扩展。 在使用此例程之前，必须使用 enable_load_extension() 启用扩展加载。 默认情况下禁用可加载扩展。 row_factory您可以将此属性更改为可接受游标和原始行作为元组的可调用对象，并将返回实际结果行。 这样，您可以实现更高级的返回结果的方法，例如返回一个可以按名称访问列的对象。示例: 1234567891011121314def dict_factory(cursor, row): d = &#123;&#125; for idx, col in enumerate(cursor.description): d[col[0]] = row[idx] return dcon = sqlite3.connect(":memory:")con.row_factory = dict_factorycur = con.cursor()cur.execute("select 1 as a")print(cur.fetchone()["a"]) con.close() 如果返回一个元组是不够的，并且你想要对列进行基于名称的访问，你应该考虑将 row_factory 设置为高度优化的 sqlite3.Row 类型。 Row 提供基于索引和不区分大小写的基于名称的访问，几乎没有内存开销。 它可能比您自己的基于字典的自定义方法甚至基于 db_row 的解决方案更好。 text_factory 使用此属性可以控制为 TEXT 数据类型返回的对象。 默认情况下，此属性设置为 str 和 sqlite3 模块将返回 TEXT 的 Unicode 对象。 如果要返回字节串，可以将其设置为 bytes。 您还可以将其设置为接受单个 bytestring 参数的任何其他可调用对象，并返回结果对象。 请参阅以下示例代码以进行说明： 1234567891011121314151617181920212223242526272829import sqlite3con = sqlite3.connect(":memory:")cur = con.cursor()AUSTRIA = "\xd6sterreich"# by default, rows are returned as Unicodecur.execute("select ?", (AUSTRIA,))row = cur.fetchone()assert row[0] == AUSTRIA# but we can make sqlite3 always return bytestrings ...con.text_factory = bytescur.execute("select ?", (AUSTRIA,))row = cur.fetchone()assert type(row[0]) is bytes# the bytestrings will be encoded in UTF-8, unless you stored garbage in the# database ...assert row[0] == AUSTRIA.encode("utf-8")# we can also implement a custom text_factory ...# here we implement one that appends "foo" to all stringscon.text_factory = lambda x: x.decode("utf-8") + "foo"cur.execute("select ?", ("bar",))row = cur.fetchone()assert row[0] == "barfoo"con.close() total_changes 返回自打开数据库连接以来已修改，插入或删除的数据库行的总数。 iterdump() 返回以SQL文本格式转储数据库的迭代器。 保存内存数据库以便以后恢复时很有用。 此函数提供与 sqlite3 shell 中的 .dump 命令相同的功能。 示例: 12345678# Convert file existing_db.db to SQL dump file dump.sqlimport sqlite3con = sqlite3.connect('existing_db.db')with open('dump.sql', 'w') as f: for line in con.iterdump(): f.write('%s\n' % line)con.close() backup(target, **, pages=0, progress=None, name=”main”, sleep=0.250*) 即使在 SQLite 数据库被其他客户端访问时，或者同时由同一连接访问，该方法也会对其进行备份。 该副本将写入强制参数 target，该参数必须是另一个 Connection 实例。 默认情况下，或者当 pages 为 0 或负整数时，整个数据库将在一个步骤中复制；否则该方法一次循环复制 pages 规定数量的页面。 示例一，将现有数据库复制到另一个数据库中： 1234567891011import sqlite3def progress(status, remaining, total): print(f'Copied &#123;total-remaining&#125; of &#123;total&#125; pages...')con = sqlite3.connect('existing_db.db')bck = sqlite3.connect('backup.db')with bck: con.backup(bck, pages=1, progress=progress)bck.close()con.close() 示例二，将现有数据库复制到临时副本中： 12345import sqlite3source = sqlite3.connect('existing_db.db')dest = sqlite3.connect(':memory:')source.backup(dest) 可用性：SQLite 3.6.11 或以上版本 Cursor 对象 class sqlite3.Cursor Cursor 游标实例具有以下属性和方法。 execute(sql[, parameters]) 执行SQL语句。 可以是参数化 SQL 语句（即，在 SQL 语句中使用占位符）。sqlite3 模块支持两种占位符：问号（qmark风格）和命名占位符（命名风格）。以下是两种风格的示例： 123456789101112131415161718import sqlite3con = sqlite3.connect(":memory:")cur = con.cursor()cur.execute("create table people (name_last, age)")who = "Yeltsin"age = 72# This is the qmark style:cur.execute("insert into people values (?, ?)", (who, age))# And this is the named style:cur.execute("select * from people where name_last=:who and age=:age", &#123;"who": who, "age": age&#125;)print(cur.fetchone())con.close() execute() will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a Warning. Use executescript() if you want to execute multiple SQL statements with one call. executemany(sql, seq_of_parameters) 通过所有参数序列或者映射参数 执行SQL 命令,同时支持使用iterator(可迭代对象) yield类型生成参数代替序列。 1234567891011121314151617181920212223242526import sqlite3class IterChars: def __init__(self): self.count = ord('a') def __iter__(self): return self def __next__(self): if self.count &gt; ord('z'): raise StopIteration self.count += 1 return (chr(self.count - 1),) # this is a 1-tuplecon = sqlite3.connect(":memory:")cur = con.cursor()cur.execute("create table characters(c)")theIter = IterChars()cur.executemany("insert into characters(c) values (?)", theIter)cur.execute("select c from characters")print(cur.fetchall())con.close() 这是一个使用生成器 generator 的简短示例： 1234567891011121314151617import sqlite3import stringdef char_generator(): for c in string.ascii_lowercase: yield (c,)con = sqlite3.connect(":memory:")cur = con.cursor()cur.execute("create table characters(c)")cur.executemany("insert into characters(c) values (?)", char_generator())cur.execute("select c from characters")print(cur.fetchall())con.close() executescript(sql_script) 这是一个非标准方式执行sql语句的方法,它首先执行COMMIT语句,然后执行作为参数传递而来的SQL语句。 12345678910111213141516171819202122232425import sqlite3con = sqlite3.connect(":memory:")cur = con.cursor()cur.executescript(""" create table person( firstname, lastname, age ); create table book( title, author, published ); insert into book(title, author, published) values ( 'Dirk Gently''s Holistic Detective Agency', 'Douglas Adams', 1987 ); """)con.close() fetchone() 获取查询语句结果中的一条记录集,返回一个单独的序列,当没有数据时返回None。 fetchmany(size=cursor.arraysize) 提取查询结果的下一组行，返回列表。当没有更多行可用时，将返回一个空列表。每个调用要提取的行数由 [size] 参数指定。如果未提供，则游标的数组大小确定要提取的行数。该方法应尝试提取大小参数指示的行数。如果由于指定的行数不可用而无法这样做，则返回的行数可能更少。请注意，[size] 参数涉及性能注意事项。为了获得最佳性能，通常最好使用数组大小属性。如果使用 [size] 参数，则最好将其保留从fetchmany() 方法调用到下一个相同的值。 ​ 返回list类型存储的所有结果的行。如果没有记录返回,返回一个空的list。 close() 立即关闭游标(无论__del__方法是否被调用)。当前游标无法再获取上下文对象,如果尝试访问该游标,则会引发ProgrammingError 异常。 rowcount 对于 executemany() 语句，修改次数汇总为 rowcount.根据 Python DB API 规范的要求，rowcount 属性在游标上未执行executeXX()或最后一个操作的行计数无法由接口决定的情况下为 -1。这包括SELECT语句，因为我们无法确定在提取所有行之前生成的查询的行数。 lastrowid 这是一个只读属性取得最后一条修改记录的rowid。仅当使用 execute() 方法执行INSERT or a REPLACE 语句时设置该属性。或者 当执行executemany() 方法时,该属性设置为None。如果INSERT 或 REPLACE 语句执行失败时,则返回最近一次成功执行的rowid。 arraysize 该属性可读写,主要控制 fetchmany()方法返回的记录数量。默认值是1意味着返回一行结果。 description 此只读属性提供最后一次查询的列名称。为了保持与 Python DB API 的兼容，它为每个列返回一个 7 元组，其中每个元组的最后六个项为 None. connection 此只读属性提供SQLite数据库的 Connection 使用的游标对象。 行对象class sqlite3.Row keys() 该方法返回列名构成的列表。查询后,在 Cursor.description 中元组数据的第一个元素. 接下来我们在上面的例子中初始化一个table： 123456789conn = sqlite3.connect(":memory:")c = conn.cursor()c.execute('''create table stocks(date text, trans text, symbol text, qty real, price real)''')c.execute("""insert into stocks values ('2006-01-05','BUY','RHAT',100,35.14)""")conn.commit()c.close() 我们使用Row 12345678910111213141516171819202122232425&gt;&gt;&gt; conn.row_factory = sqlite3.Row&gt;&gt;&gt; c = conn.cursor()&gt;&gt;&gt; c.execute('select * from stocks')&lt;sqlite3.Cursor object at 0x7f4e7dd8fa80&gt;&gt;&gt;&gt; r = c.fetchone()&gt;&gt;&gt; type(r)&lt;class 'sqlite3.Row'&gt;&gt;&gt;&gt; tuple(r)('2006-01-05', 'BUY', 'RHAT', 100.0, 35.14)&gt;&gt;&gt; len(r)5&gt;&gt;&gt; r[2]'RHAT'&gt;&gt;&gt; r.keys()['date', 'trans', 'symbol', 'qty', 'price']&gt;&gt;&gt; r['qty']100.0&gt;&gt;&gt; for member in r:... print(member)...2006-01-05BUYRHAT100.035.14 异常 exception sqlite3.Warning Exception 的一个子类。 exception sqlite3.Error 此模块中其他异常的基类。 它是 Exception 的一个子类。 exception sqlite3.DatabaseError 抛出和数据库有关异常。 exception sqlite3.IntegrityError 抛出和关联标识符有关异常,例如外键检查失败,是DatabaseError的一个子类。 exception sqlite3.ProgrammingError 抛出和程序有关的异常,例如：table未找到,或已经存在,SQL 语句异常,参数不正确, 是DatabaseError的一个子类。 exception sqlite3.OperationalError 抛出和程序无法控制的数据库操作的异常,例如: 不可预料的数据库连接错误,数据源名字未找到,事务没有被执行,是DatabaseError的一个子类。 exception sqlite3.NotSupportedError 抛出当一个方法对当前数据库不支持的异常,例如:调用 rollback()时,数据库事务不支持或者事务被关闭。是DatabaseError的一个子类 SQLite 与 Python 类型概述SQLite 原生支持如下的类型： NULL，INTEGER，REAL，TEXT，BLOB。 Python 类型 SQLite 类型 None NULL int INTEGER float REAL str TEXT bytes BLOB 这是SQLite类型默认转换为Python类型的方式： SQLite 类型 Python 类型 NULL None INTEGER int REAL float TEXT 取决于 text_factory , 默认为 str BLOB bytes sqlite3 中数据类型的扩展有两种途径: 一种是使用SQLite对象适配器扩展附加的Python数据类型；另一种是使用Python类型转换函数转换SQLite类型。 使用适配器在SQLite中存储附加的python数据类型正如之前描述的转换方法中说明的,SQLite只支持有限的几种数据类型。如果想在SQLite中使用Python的相关数据类型,你必须通过适配器,让SQLite的模块让SQLite支持诸如: one of NoneType, int, float, str, bytes等类型。请看下面的例子: 让对象自行调整如果自己编写类，这是一种很好的方法。假设有这样的类：： 123class Point: def __init__(self, x, y): self.x, self.y = x, y 我们想在SQLite中存储,首先选择何种数据类型存储这个Point类。 接下来使用类方法 __conform__返回转换后的值, 参数是 PrepareProtocol类型的protocol。 123456789101112131415161718import sqlite3class Point: def __init__(self, x, y): self.x, self.y = x, y def __conform__(self, protocol): if protocol is sqlite3.PrepareProtocol: return "%f;%f" % (self.x, self.y)con = sqlite3.connect(":memory:")cur = con.cursor()p = Point(4.0, -3.2)cur.execute("select ?", (p,))print(cur.fetchone()[0])con.close() 注册可调用的适配器另一个可行的方法时创建一个可以转换string和其他类型的函数,使用register_adapter(). 12345678910111213141516171819import sqlite3class Point: def __init__(self, x, y): self.x, self.y = x, ydef adapt_point(point): return "%f;%f" % (point.x, point.y)sqlite3.register_adapter(Point, adapt_point)con = sqlite3.connect(":memory:")cur = con.cursor()p = Point(4.0, -3.2)cur.execute("select ?", (p,))print(cur.fetchone()[0])con.close() 对于Python中的内置数据类型 datetime.date 和 datetime.datetime ,我们可以存储 datetime.datetime 使用ISO 实现而非 Unix 时间戳。请参考下面的例子: 1234567891011121314151617import sqlite3import datetimeimport timedef adapt_datetime(ts): return time.mktime(ts.timetuple())sqlite3.register_adapter(datetime.datetime, adapt_datetime)con = sqlite3.connect(":memory:")cur = con.cursor()now = datetime.datetime.now()cur.execute("select ?", (now,))print(cur.fetchone()[0])con.close() 将SQLite 值转换为自定义Python 类型让我们回到刚才定义的Point 类,在SQLite中存储x,y字符串类型参数。 首先我们定义一个转换函数,接收字符串类型的参数,转换为Point类的对象。 转换函数通常处理的是byte类型对象,无论你传入的是什么类型 数据。 123def convert_point(s): x, y = map(float, s.split(b";")) return Point(x, y) 现在我们需要让 sqlite3 模块知道你查询的是一个point对象，有两种方式实现: 隐式的声明类型 显式的通过列名 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import sqlite3class Point: def __init__(self, x, y): self.x, self.y = x, y def __repr__(self): return "(%f;%f)" % (self.x, self.y)def adapt_point(point): return ("%f;%f" % (point.x, point.y)).encode('ascii')def convert_point(s): x, y = list(map(float, s.split(b";"))) return Point(x, y)# Register the adaptersqlite3.register_adapter(Point, adapt_point)# Register the convertersqlite3.register_converter("point", convert_point)p = Point(4.0, -3.2)########################## 1) Using declared typescon = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)cur = con.cursor()cur.execute("create table test(p point)")cur.execute("insert into test(p) values (?)", (p,))cur.execute("select p from test")print("with declared types:", cur.fetchone()[0])cur.close()con.close()######################## 1) Using column namescon = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)cur = con.cursor()cur.execute("create table test(p)")cur.execute("insert into test(p) values (?)", (p,))cur.execute('select p as "p [point]" from test')print("with column names:", cur.fetchone()[0])cur.close()con.close() 默认适配器和转换器对于时间和 日期时间类型, sqlite模块已经做了自动转换。 下面的示例演示了这一点。 12345678910111213141516171819202122import sqlite3import datetimecon = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)cur = con.cursor()cur.execute("create table test(d date, ts timestamp)")today = datetime.date.today()now = datetime.datetime.now()cur.execute("insert into test(d, ts) values (?, ?)", (today, now))cur.execute("select d, ts from test")row = cur.fetchone()print(today, "=&gt;", row[0], type(row[0]))print(now, "=&gt;", row[1], type(row[1]))cur.execute('select current_date as "d [date]", current_timestamp as "ts [timestamp]"')row = cur.fetchone()print("current_date", row[0], type(row[0]))print("current_timestamp", row[1], type(row[1]))con.close() 控制事务默认sqlite3中对于autocommit 默认是开启的,但是Python中的sqlite3模块默认并没有开启。 autocommit 模式意味着当修改数据库时对数据库影响立即生效。一个BEGIN 和 SAVEPOINT的语句禁止automode,如果是COMMIT，ROLLBACK 或RELASE 语句执行后,autocommit模式才设置成启用。 Python sqlite3 默认在DDL 语句( (例如: INSERT/UPDATE/DELETE/REPLACE).)执行前执行BEGIN 语句。 你可以通过控制 BEGIN 语句,隐式执行connect()方法的 isolation_level 参数,或是connections的 isolation_level 属性来实现。如果你没有声明 isolation_level,那么使用的就是普通的BEGIN使用,和DEFERRED是一样的。其他可能的值还有IMMEDIATE 和 EXCLUSIVE。 你可以在代码中通过禁止 sqlite3 模块中设定 control the transaction state 的值为BEGIN, ROLLBACK, SAVEPOINT, and RELEASE 语句实现事务处理。 有效使用 sqlite3使用快捷方式使用 Connection 对象的非标准 execute(), executemany() 和 executescript() 方法，可以更简洁地编写代码，因为不必显式创建（通常是多余的） Cursor 对象。相反， Cursor 对象是隐式创建的，这些快捷方法返回游标对象。这样，只需对 Connection 对象调用一次，就能直接执行 SELECT 语句并遍历对象。 123456789101112131415161718192021222324import sqlite3persons = [ ("Hugo", "Boss"), ("Calvin", "Klein") ]con = sqlite3.connect(":memory:")# Create the tablecon.execute("create table person(firstname, lastname)")# Fill the tablecon.executemany("insert into person(firstname, lastname) values (?, ?)", persons)# Print the table contentsfor row in con.execute("select firstname, lastname from person"): print(row)print("I just deleted", con.execute("delete from person").rowcount, "rows")# close is not a shortcut method and it's not called automatically,# so the connection object should be closed manuallycon.close() 通过名称而不是索引访问索引sqlite3 模块的一个有用功能是内置的 sqlite3.Row 类，该类旨在用作行工厂。 该类的行装饰器可以用索引（如元组）和不区分大小写的名称访问： 1234567891011121314import sqlite3con = sqlite3.connect(":memory:")con.row_factory = sqlite3.Rowcur = con.cursor()cur.execute("select 'John' as name, 42 as age")for row in cur: assert row[0] == row["name"] assert row["name"] == row["nAmE"] assert row[1] == row["age"] assert row[1] == row["AgE"]con.close() 使用连接作为上下文管理器连接对象可以用来作为上下文管理器，它可以自动提交或者回滚事务。如果出现异常，事务会被回滚；否则，事务会被提交。 1234567891011121314151617181920import sqlite3con = sqlite3.connect(":memory:")con.execute("create table person (id integer primary key, firstname varchar unique)")# Successful, con.commit() is called automatically afterwardswith con: con.execute("insert into person(firstname) values (?)", ("Joe",))# con.rollback() is called after the with block finishes with an exception, the# exception is still raised and must be caughttry: with con: con.execute("insert into person(firstname) values (?)", ("Joe",))except sqlite3.IntegrityError: print("couldn't add Joe twice")# Connection object used as context manager only commits or rollbacks transactions,# so the connection object should be closed manuallycon.close() 常见问题多线程较老版本的 SQLite 在共享线程之间存在连接问题。这就是Python模块不允许线程之间共享连接和游标的原因。如果仍然尝试这样做，则在运行时会出现异常。 唯一的例外是调用 interrupt() 方法，该方法仅在从其他线程进行调用时才有意义。 关于事务的补充说明isolation_level 到底控制的是什么,下图摘自SQLite官网。 下面是一个在connect()中不传入 isolation_level的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#!/usr/bin/env python# -*- coding:utf-8 -*-'''sqlite3事务总结:在connect()中不传入 isolation_level事务处理: 使用connection.commit()分析: 智能commit状态: 生成方式: 在connect()中不传入 isolation_level, 此时isolation_level=='' 在进行 执行Data Modification Language (DML) 操作(INSERT/UPDATE/DELETE/REPLACE)时, 会自动打开一个事务, 在执行 非DML, 非query (非 SELECT 和上面提到的)语句时, 会隐式执行commit 可以使用 connection.commit()方法来进行提交 注意: 不能和cur.execute("COMMIT")共用 自动commit状态: 生成方式: 在connect()中传入 isolation_level=None 这样,在任何DML操作时,都会自动提交 事务处理 connection.execute("BEGIN TRANSACTION") connection.execute("COMMIT") 如果不使用事务, 批量添加数据非常缓慢数据对比: 两种方式, 事务耗时差别不大 count = 100000 智能commit即时提交耗时: 0.621 自动commit耗时: 0.601 智能commit即时提交耗时: 0.588 自动commit耗时: 0.581 智能commit即时提交耗时: 0.598 自动commit耗时: 0.588 智能commit即时提交耗时: 0.589 自动commit耗时: 0.602 智能commit即时提交耗时: 0.588 自动commit耗时: 0.622'''import sysimport timeclass Elapse_time(object): '''耗时统计工具''' def __init__(self, prompt=''): self.prompt = prompt self.start = time.time() def __del__(self): print('%s耗时: %.3f' % (self.prompt, time.time() - self.start))CElapseTime = Elapse_timeimport sqlite3# -------------------------------------------------------------------------------# 测试#filename = 'e:/temp/a.db'def prepare(isolation_level = ''): connection = sqlite3.connect(filename, isolation_level = isolation_level) connection.execute("create table IF NOT EXISTS people (num, age)") connection.execute('delete from people') connection.commit() return connection, connection.cursor()def db_insert_values(cursor, count): num = 1 age = 2 * num while num &lt;= count: cursor.execute("insert into people values (?, ?)", (num, age)) num += 1 age = 2 * num def study_case1_intelligent_commit(count): ''' 在智能commit状态下, 不能和cur.execute("COMMIT")共用 ''' connection, cursor = prepare() elapse_time = Elapse_time(' 智能commit') db_insert_values(cursor, count) #cursor.execute("COMMIT") #产生异常 cursor.execute("select count(*) from people") print (cursor.fetchone()) def study_case2_autocommit(count): connection, cursor = prepare(isolation_level = None) elapse_time = Elapse_time(' 自动commit') db_insert_values(cursor, count) cursor.execute("select count(*) from people") print (cursor.fetchone())def study_case3_intelligent_commit_manual(count): connection, cursor = prepare() elapse_time = Elapse_time(' 智能commit即时提交') db_insert_values(cursor, count) connection.commit() cursor.execute("select count(*) from people") print (cursor.fetchone())def study_case4_autocommit_transaction(count): connection, cursor = prepare(isolation_level = None) elapse_time = Elapse_time(' 自动commit') connection.execute("BEGIN TRANSACTION;") # 关键点 db_insert_values(cursor, count) connection.execute("COMMIT;") #关键点 cursor.execute("select count(*) from people;") print (cursor.fetchone())if __name__ == '__main__': count = 10000 prepare() for i in range(5): #study_case1_intelligent_commit(count) #不提交数据 #study_case2_autocommit(count) #非常缓慢 study_case3_intelligent_commit_manual(count) study_case4_autocommit_transaction(count) 参考文档python sqlite3 事务控制 python sqlite3 事务总结]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>sqlite3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Understand Python GIL]]></title>
    <url>%2F2020%2F01%2F19%2FUnderstand-Python-GIL%2F</url>
    <content type="text"><![CDATA[python 标准库 threading每日一词: US[‘weðər] UK[‘weðə(r)] n.天气；气象；气象预报 v.变形；经受住 气候；天气预报；风化 给大家推荐一部电影: 气象先生 This shit life,we must chuck some things 源代码源代码: Lib/threading.py 核心函数 threading.active_count() 返回当前存活的线程类 Thread 对象。返回的计数等于 enumerate() 返回的列表长度。 threading.current_thread() 返回当前对应调用者的控制线程的 Thread 对象。如果调用者的控制线程不是利用 threading 创建，会返回一个功能受限的虚拟线程对象。 threading.excepthook(args, /) 参数可以是下面任意一种类型 exc_type: 异常类型 exc_value: 异常值，可以是 None. exc_traceback: 异常回溯，可以是 None. thread: 线程跑出的异常 可以是None. threading.get_ident() 返回当前线程的 “线程标识符”。它是一个非零的整数。它的值没有直接含义，主要是用作 magic cookie，比如作为含有线程相关数据的字典的索引。线程标识符可能会在线程退出，新线程创建时被复用。3.3 新版功能. threading.get_native_id() 返回内核分配给当前线程的原生集成线程 ID。 这是一个非负整数。 它的值可被用来在整个系统中唯一地标识这个特定线程（直到线程终结，在那之后该值可能会被 OS 回收再利用）。可用性: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX。3.8 新版功能. threading.enumerate() 以列表形式返回当前所有存活的 Thread 对象。 该列表包含守护线程，current_thread() 创建的虚拟线程对象和主线程。它不包含已终结的线程和尚未开始的线程。 threading.main_thread() 返回主 Thread 对象。一般情况下，主线程是Python解释器开始时创建的线程。3.4 新版功能. threading.settrace(func) 为所有 threading 模块开始的线程设置追踪函数。在每个线程的 run() 方法被调用前，func 会被传递给 sys.settrace() 。 threading.setprofile(func) 为所有 threading 模块开始的线程设置性能测试函数。在每个线程的 run() 方法被调用前，func 会被传递给 sys.setprofile() 。 threading.stack_size([size]) 返回创建线程时用的堆栈大小。可选参数 size 指定之后新建的线程的堆栈大小，而且一定要是0（根据平台或者默认配置）或者最小是32,768(32KiB)的一个正整数。如果 size 没有指定，默认是0。如果不支持改变线程堆栈大小，会抛出 RuntimeError 错误。如果指定的堆栈大小不合法，会抛出 ValueError 错误并且不会修改堆栈大小。32KiB是当前最小的能保证解释器有足够堆栈空间的堆栈大小。需要注意的是部分平台对于堆栈大小会有特定的限制，例如要求大于32KiB的堆栈大小或者需要根据系统内存页面的整数倍进行分配 - 应当查阅平台文档有关详细信息（4KiB页面比较普遍，在没有更具体信息的情况下，建议的方法是使用4096的倍数作为堆栈大小）。适用于: Windows，具有 POSIX 线程的系统。 常量threading.TIMEOUT_MAX¶ 阻塞函数（ Lock.acquire(), RLock.acquire(), Condition.wait(), …）中形参 timeout 允许的最大值。传入超过这个值的 timeout 会抛出 OverflowError 异常。 常用函数线程本地数据线程本地数据是特定线程的数据。管理线程本地数据，只需要创建一个 local （或者一个子类型）的实例并在实例中储存属性： 12mydata = threading.local()mydata.x = 1 在不同的线程中，实例的值会不同。 class threading.local 一个代表线程本地数据的类。更多相关细节和大量示例，参见 _threading_local 模块的文档。 线程对象当线程对象一但被创建，其活动一定会因调用线程的 start() 方法开始。这会在独立的控制线程调用 run() 方法。 一旦线程活动开始，该线程会被认为是 ‘存活的’ 。当它的 run() 方法终结了（不管是正常的还是抛出未被处理的异常），就不是’存活的’。 is_alive() 方法用于检查线程是否存活。 其他线程可以调用一个线程的 join() 方法。这会阻塞调用该方法的线程，直到被调用 join() 方法的线程终结。 线程有名字。名字可以传递给构造函数，也可以通过 name 属性读取或者修改。 如果运行线程中的 run()抛出了异常, threading.excepthook()` 方法就会被调用,默认情况下,忽略 SystemExit. 一个线程可以被标记成一个“守护线程”。 这个标志的意义是，当剩下的线程都是守护线程时，整个 Python 程序将会退出。 初始值继承于创建线程。 这个标志可以通过 daemon 特征属性或者 daemon 构造器参数来设置。 守护线程在程序关闭时会突然关闭。他们的资源（例如已经打开的文档，数据库事务等等）可能没有被正确释放。如果你想你的线程正常停止，设置他们成为非守护模式并且使用合适的信号机制，例如： Event。 有个 “主线程” 对象；这对应Python程序里面初始的控制线程。它不是一个守护线程。 “虚拟线程对象” 是可以被创建的。这些是对应于“外部线程”的线程对象，它们是在线程模块外部启动的控制线程，例如直接来自C代码。虚拟线程对象功能受限；他们总是被认为是存活的和守护模式，不能被 join() 。因为无法检测外来线程的终结，它们永远不会被删除。 class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, **, daemon=None*) 调用这个构造函数时，必需带有关键字参数。参数如下： group 应该为 None；为了日后扩展 ThreadGroup 类实现而保留。 target 是用于 run() 方法调用的可调用对象。默认是 None，表示不需要调用任何方法。 name 是线程名称。默认情况下，由 “Thread-N“ 格式构成一个唯一的名称，其中 N 是小的十进制数。 args 是用于调用目标函数的参数元组。默认是 ()。 kwargs 是用于调用目标函数的关键字参数字典。默认是 {}。 start() 开始线程活动。它在一个线程里最多只能被调用一次。它安排对象的 run() 方法在一个独立的控制进程中调用。如果同一个线程对象中调用这个方法的次数大于一次，会抛出 RuntimeError 。 run() 代表线程活动的方法。你可以在子类型里重载这个方法。 标准的 run() 方法会对作为 target 参数传递给该对象构造器的可调用对象（如果存在）发起调用，并附带从 args 和 kwargs 参数分别获取的位置和关键字参数。 join(timeout=None) 等待，直到线程终结。这会阻塞调用这个方法的线程，直到被调用 join() 的线程终结 – 不管是正常终结还是抛出未处理异常 – 或者直到发生超时，超时选项是可选的。当 timeout 参数存在而且不是 None 时，它应该是一个用于指定操作超时的以秒为单位的浮点数（或者分数）。因为 join() 总是返回 None ，所以你一定要在 join() 后调用 is_alive() 才能判断是否发生超时 – 如果线程仍然存货，则 join() 超时。当 timeout 参数不存在或者是 None ，这个操作会阻塞直到线程终结。一个线程可以被 join() 很多次。如果尝试加入当前线程会导致死锁， join() 会引起 RuntimeError 异常。如果尝试 join() 一个尚未开始的线程，也会抛出相同的异常。 name 只用于识别的字符串。它没有语义。多个线程可以赋予相同的名称。 初始名称由构造函数设置。 getName() setName() 旧的 name 取值/设值 API；直接当做特征属性使用它。 ident 这个线程的 ‘线程标识符’，如果线程尚未开始则为 None 。这是个非零整数。参见 get_ident() 函数。当一个线程退出而另外一个线程被创建，线程标识符会被复用。即使线程退出后，仍可得到标识符。 native_id 内部生成的线程id,一个非负的整数,如果为None意味着线程还没有启动。 is_alive() 返回线程是否存活。当 run() 方法刚开始直到 run() 方法刚结束，这个方法返回 True 。模块函数 enumerate() 返回包含所有存活线程的列表。 daemon 一个表示这个线程是（True）否（False）守护线程的布尔值。一定要在调用 start() 前设置好，不然会抛出 RuntimeError 。初始值继承于创建线程；主线程不是守护线程，因此主线程创建的所有线程默认都是 daemon = False。当没有存活的非守护线程时，整个Python程序才会退出。 isDaemon() setDaemon() 旧的 name 取值/设值 API；建议直接当做特征属性使用它。 CPython implementation detail: CPython下，因为 Global Interpreter Lock，一个时刻只有一个线程可以执行Python代码（尽管如此，某些性能导向的库可能会克服这个限制）。如果你想让你的应用更好的利用多核计算机的计算性能，推荐你使用 multiprocessing 或者 concurrent.futures.ProcessPoolExecutor 。但是如果你想同时运行多个I/O绑定任务，线程仍然是一个合适的模型。 锁对象原始锁是一个在锁定时不属于特定线程的同步基元组件。在Python中，它是能用的最低级的同步基元组件，由 _thread 扩展模块直接实现。 原始锁处于 “锁定” 或者 “非锁定” 两种状态之一。它被创建时为非锁定状态。它有两个基本方法， acquire() 和 release() 。当状态为非锁定时， acquire() 将状态改为 锁定 并立即返回。当状态是锁定时， acquire() 将阻塞至其他线程调用 release() 将其改为非锁定状态，然后 acquire() 调用重置其为锁定状态并返回。 release() 只在锁定状态下调用； 它将状态改为非锁定并立即返回。如果尝试释放一个非锁定的锁，则会引发 RuntimeError 异常。 锁同样支持 上下文管理协议。 当多个线程在 acquire() 等待状态转变为未锁定被阻塞，然后 release() 重置状态为未锁定时，只有一个线程能继续执行；至于哪个等待线程继续执行没有定义，并且会根据实现而不同。 所有方法的执行都是原子性的。 class threading.Lock 实现原始锁对象的类。一旦一个线程获得一个锁，会阻塞随后尝试获得锁的线程，直到它被释放；任何线程都可以释放它。 需要注意的是 Lock 其实是一个工厂函数，返回平台支持的具体锁类中最有效的版本的实例。 acquire(blocking=True, timeout=-1) 可以阻塞或非阻塞地获得锁。当调用时参数 blocking 设置为 True （缺省值），阻塞直到锁被释放，然后将锁锁定并返回 True 。在参数 blocking 被设置为 False 的情况下调用，将不会发生阻塞。如果调用时 blocking 设为 True 会阻塞，并立即返回 False ；否则，将锁锁定并返回 True。当浮点型 timeout 参数被设置为正值调用时，只要无法获得锁，将最多阻塞 timeout 设定的秒数。timeout 参数被设置为 -1 时将无限等待。当 blocking 为 false 时，timeout 指定的值将被忽略。如果成功获得锁，则返回 True，否则返回 False (例如发生 超时 的时候)。在 3.2 版更改: 新的 timeout 形参。在 3.2 版更改: 现在如果底层线程实现支持，则可以通过POSIX上的信号中断锁的获取。 release() 释放一个锁。这个方法可以在任何线程中调用，不单指获得锁的线程。当锁被锁定，将它重置为未锁定，并返回。如果其他线程正在等待这个锁解锁而被阻塞，只允许其中一个允许。在未锁定的锁调用时，会引发 RuntimeError 异常。没有返回值。 locked() Return true if the lock is acquired. 递归锁重入锁是一个可以被同一个线程多次获取的同步基元组件。在内部，它在基元锁的锁定/非锁定状态上附加了 “所属线程” 和 “递归等级” 的概念。在锁定状态下，某些线程拥有锁 ； 在非锁定状态下， 没有线程拥有它。 若要锁定锁，线程调用其 acquire() 方法；一旦线程拥有了锁，方法将返回。若要解锁，线程调用 release() 方法。 acquire()/release() 对可以嵌套；只有最终 release() (最外面一对的 release() ) 将锁解开，才能让其他线程继续处理 acquire() 阻塞。 递归锁也支持 上下文管理协议。 class threading.RLock 此类实现了重入锁对象。重入锁必须由获取它的线程释放。一旦线程获得了重入锁，同一个线程再次获取它将不阻塞；线程必须在每次获取它时释放一次。需要注意的是 RLock 其实是一个工厂函数，返回平台支持的具体递归锁类中最有效的版本的实例。 acquire(blocking=True, timeout=-1) 可以阻塞或非阻塞地获得锁。 当无参数调用时： 如果这个线程已经拥有锁，递归级别增加一，并立即返回。否则，如果其他线程拥有该锁，则阻塞至该锁解锁。一旦锁被解锁(不属于任何线程)，则抢夺所有权，设置递归等级为一，并返回。如果多个线程被阻塞，等待锁被解锁，一次只有一个线程能抢到锁的所有权。在这种情况下，没有返回值。 当发起调用时将 blocking 参数设为真值，则执行与无参数调用时一样的操作，然后返回 True。 当发起调用时将 blocking 参数设为假值，则不进行阻塞。 如果一个无参数调用将要阻塞，则立即返回 False；在其他情况下，执行与无参数调用时一样的操作，然后返回 True。 当发起调用时将浮点数的 timeout 参数设为正值时，只要无法获得锁，将最多阻塞 timeout 所指定的秒数。 如果已经获得锁则返回 True，如果超时则返回假值。 release() 释放锁，自减递归等级。如果减到零，则将锁重置为非锁定状态(不被任何线程拥有)，并且，如果其他线程正被阻塞着等待锁被解锁，则仅允许其中一个线程继续。如果自减后，递归等级仍然不是零，则锁保持锁定，仍由调用线程拥有。 只有当前线程拥有锁才能调用这个方法。如果锁被释放后调用这个方法，会引起 RuntimeError 异常。 没有返回值。 条件对象条件变量总是与某种类型的锁对象相关联，锁对象可以通过传入获得，或者在缺省的情况下自动创建。当多个条件变量需要共享同一个锁时，传入一个锁很有用。锁是条件对象的一部分，你不必单独地跟踪它。 条件变量服从 上下文管理协议：使用 with 语句会在它包围的代码块内获取关联的锁。 acquire() 和 release() 方法也能调用关联锁的相关方法。 其它方法必须在持有关联的锁的情况下调用。 wait() 方法释放锁，然后阻塞直到其它线程调用 notify() 方法或 notify_all() 方法唤醒它。一旦被唤醒， wait() 方法重新获取锁并返回。它也可以指定超时时间。 The notify() method wakes up one of the threads waiting for the condition variable, if any are waiting. The notify_all() method wakes up all threads waiting for the condition variable. 注意： notify() 方法和 notify_all() 方法并不会释放锁，这意味着被唤醒的线程不会立即从它们的 wait() 方法调用中返回，而是会在调用了 notify() 方法或 notify_all() 方法的线程最终放弃了锁的所有权后返回。 使用条件变量的典型编程风格是将锁用于同步某些共享状态的权限，那些对状态的某些特定改变感兴趣的线程，它们重复调用 wait() 方法，直到看到所期望的改变发生；而对于修改状态的线程，它们将当前状态改变为可能是等待者所期待的新状态后，调用 notify() 方法或者 notify_all() 方法。例如，下面的代码是一个通用的无限缓冲区容量的生产者-消费者情形： 12345678910# Consume one itemwith cv: while not an_item_is_available(): cv.wait() get_an_available_item()# Produce one itemwith cv: make_an_item_available() cv.notify() 使用 while 循环检查所要求的条件成立与否是有必要的，因为 wait() 方法可能要经过不确定长度的时间后才会返回，而此时导致 notify() 方法调用的那个条件可能已经不再成立。这是多线程编程所固有的问题。 wait_for() 方法可自动化条件检查，并简化超时计算。 1234# Consume an itemwith cv: cv.wait_for(an_item_is_available) get_an_available_item() 选择 notify() 还是 notify_all() ，取决于一次状态改变是只能被一个还是能被多个等待线程所用。例如在一个典型的生产者-消费者情形中，添加一个项目到缓冲区只需唤醒一个消费者线程。 class threading.Condition(lock=None) 实现条件变量对象的类。一个条件变量对象允许一个或多个线程在被其它线程所通知之前进行等待。 如果给出了非 None 的 lock 参数，则它必须为 Lock 或者 RLock 对象，并且它将被用作底层锁。否则，将会创建新的 RLock 对象，并将其用作底层锁。 在 3.3 版更改: 从工厂函数变为类。 acquire(*args) 请求底层锁。此方法调用底层锁的相应方法，返回值是底层锁相应方法的返回值。 release() 释放底层锁。此方法调用底层锁的相应方法。没有返回值。 wait(timeout=None) 等待直到被通知或发生超时。如果线程在调用此方法时没有获得锁，将会引发 RuntimeError 异常。这个方法释放底层锁，然后阻塞，直到在另外一个线程中调用同一个条件变量的 notify() 或 notify_all() 唤醒它，或者直到可选的超时发生。一旦被唤醒或者超时，它重新获得锁并返回。当提供了 timeout 参数且不是 None 时，它应该是一个浮点数，代表操作的超时时间，以秒为单位（可以为小数）。当底层锁是个 RLock ，不会使用它的 release() 方法释放锁，因为当它被递归多次获取时，实际上可能无法解锁。相反，使用了 RLock 类的内部接口，即使多次递归获取它也能解锁它。 然后，在重新获取锁时，使用另一个内部接口来恢复递归级别。返回 True ，除非提供的 timeout 过期，这种情况下返回 False。在 3.2 版更改: 很明显，方法总是返回 None。 wait_for(predicate, timeout=None) 等待，直到条件计算为真。 predicate 应该是一个可调用对象而且它的返回值可被解释为一个布尔值。可以提供 timeout 参数给出最大等待时间。这个实用方法会重复地调用 wait() 直到满足判断式或者发生超时。返回值是判断式最后一个返回值，而且如果方法发生超时会返回 False 。忽略超时功能，调用此方法大致相当于编写:while not predicate(): cv.wait()因此，规则同样适用于 wait() ：锁必须在被调用时保持获取，并在返回时重新获取。 随着锁定执行判断式。3.2 新版功能. notify(n=1) 默认唤醒一个等待这个条件的线程。如果调用线程在没有获得锁的情况下调用这个方法，会引发 RuntimeError 异常。这个方法唤醒最多 n 个正在等待这个条件变量的线程；如果没有线程在等待，这是一个空操作。当前实现中，如果至少有 n 个线程正在等待，准确唤醒 n 个线程。但是依赖这个行为并不安全。未来，优化的实现有时会唤醒超过 n 个线程。注意：被唤醒的线程实际上不会返回它调用的 wait() ，直到它可以重新获得锁。因为 notify() 不会释放锁，只有它的调用者应该这样做。 notify_all() 唤醒所有正在等待这个条件的线程。这个方法行为与 notify() 相似，但并不只唤醒单一线程，而是唤醒所有等待线程。如果调用线程在调用这个方法时没有获得锁，会引发 RuntimeError 异常。 信号量对象这是计算机科学史上最古老的同步原语之一，早期的荷兰科学家 Edsger W. Dijkstra 发明了它。（他使用名称 P() 和 V() 而不是 acquire() 和 release() ）。 一个信号量管理一个内部计数器，该计数器因 acquire() 方法的调用而递减，因 release() 方法的调用而递增。 计数器的值永远不会小于零；当 acquire() 方法发现计数器为零时，将会阻塞，直到其它线程调用 release() 方法。 信号量对象也支持 上下文管理协议 。 class threading.Semaphore(value=1) 该类实现信号量对象。信号量对象管理一个原子性的计数器，代表 release() 方法的调用次数减去 acquire() 的调用次数再加上一个初始值。如果需要， acquire() 方法将会阻塞直到可以返回而不会使得计数器变成负数。在没有显式给出 value 的值时，默认为1。 可选参数 value 赋予内部计数器初始值，默认值为 1 。如果 value 被赋予小于0的值，将会引发 ValueError 异常。 acquire(blocking=True, timeout=None) 获取一个信号量。在不带参数的情况下调用时：如果在进入时内部计数器的值大于零，则将其减一并立即返回 True.如果在进入时内部计数器的值为零，则将会阻塞直到被对 release() 的调用唤醒。 一旦被唤醒（并且计数器的值大于 0），则将计数器减 1 并返回 True。 每次对 release() 的调用将只唤醒一个线程。 线程被唤醒的次序是不可确定的。当发起调用时将 blocking 设为假值，则不进行阻塞。 如果一个无参数调用将要阻塞，则立即返回 False；在其他情况下，执行与无参数调用时一样的操作，然后返回 True。当发起调用时如果 timeout 不为 None，则它将阻塞最多 timeout 秒。 请求在此时段时未能成功完成获取则将返回 False。 在其他情况下返回 True。在 3.2 版更改: 新的 timeout 形参。 release() 释放一个信号量，将内部计数器的值增加1。当计数器原先的值为0且有其它线程正在等待它再次大于0时，唤醒正在等待的线程。 class threading.BoundedSemaphore(value=1) 该类实现有界信号量。有界信号量通过检查以确保它当前的值不会超过初始值。如果超过了初始值，将会引发 ValueError 异常。在大多情况下，信号量用于保护数量有限的资源。如果信号量被释放的次数过多，则表明出现了错误。没有指定时， value 的值默认为1。在 3.3 版更改: 从工厂函数变为类。 Semaphore例子信号量通常用于保护数量有限的资源，例如数据库服务器。在资源数量固定的任何情况下，都应该使用有界信号量。在生成任何工作线程前，应该在主线程中初始化信号量。 123maxconnections = 5# ...pool_sema = BoundedSemaphore(value=maxconnections) 工作线程生成后，当需要连接服务器时，这些线程将调用信号量的 acquire 和 release 方法： 12345conn = connectdb()try: # ... use connection ...finally: conn.close() 使用有界信号量能减少这种编程错误：信号量的释放次数多于其请求次数。 事件对象这是线程之间通信的最简单机制之一：一个线程发出事件信号，而其他线程等待该信号。 一个事件对象管理一个内部标志，调用 set() 方法可将其设置为true，调用 clear() 方法可将其设置为false，调用 wait() 方法将进入阻塞直到标志为true。 class threading.Event 实现事件对象的类。事件对象管理一个内部标志，调用 set() 方法可将其设置为true。调用 clear() 方法可将其设置为false。调用 wait() 方法将进入阻塞直到标志为true。这个标志初始时为false。在 3.3 版更改: 从工厂函数变为类。is_set()当且仅当内部旗标为时返回 True。set()将内部标志设置为true。所有正在等待这个事件的线程将被唤醒。当标志为true时，调用 wait() 方法的线程不会被被阻塞。clear()将内部标志设置为false。之后调用 wait() 方法的线程将会被阻塞，直到调用 set() 方法将内部标志再次设置为true。wait(timeout=None)阻塞线程直到内部变量为true。如果调用时内部标志为true，将立即返回。否则将阻塞线程，直到调用 set() 方法将标志设置为true或者发生可选的超时。当提供了timeout参数且不是 None 时，它应该是一个浮点数，代表操作的超时时间，以秒为单位（可以为小数）。当且仅当内部旗标在等待调用之前或者等待开始之后被设为真值时此方法将返回 True，也就是说，它将总是返回 True 除非设定了超时且操作发生了超时。 定时器对象此类表示一个操作应该在等待一定的时间之后运行 — 相当于一个定时器。 Timer 类是 Thread 类的子类，因此可以像一个自定义线程一样工作。 与线程一样，通过调用 start() 方法启动定时器。而 cancel() 方法可以停止计时器（在计时结束前）， 定时器在执行其操作之前等待的时间间隔可能与用户指定的时间间隔不完全相同。 例如: 12345def hello(): print("hello, world")t = Timer(30.0, hello)t.start() # after 30 seconds, "hello, world" will be printed class threading.Timer(interval, function, args=None, kwargs=None) 创建一个定时器，在经过 interval 秒的间隔事件后，将会用参数 args 和关键字参数 kwargs 调用 function。如果 args 为 None （默认值），则会使用一个空列表。如果 kwargs 为 None （默认值），则会使用一个空字典。 cancel()¶ 停止定时器并取消执行计时器将要执行的操作。仅当计时器仍处于等待状态时有效。 栅栏对象栅栏类提供一个简单的同步原语，用于应对固定数量的线程需要彼此相互等待的情况。线程调用 wait() 方法后将阻塞，直到所有线程都调用了 wait() 方法。此时所有线程将被同时释放。 栅栏对象可以被多次使用，但进程的数量不能改变。 这是一个使用简便的方法实现客户端进程与服务端进程同步的例子： 1234567891011121314b = Barrier(2, timeout=5)def server(): start_server() b.wait() while True: connection = accept_connection() process_server_connection(connection)def client(): b.wait() while True: connection = make_connection() process_client_connection(connection) class threading.Barrier(parties, action=None, timeout=None) 创建一个需要 parties 个线程的栅栏对象。如果提供了可调用的 action 参数，它会在所有线程被释放时在其中一个线程中自动调用。 timeout 是默认的超时时间，如果没有在 wait() 方法中指定超时时间的话。 wait(timeout=None) 冲出栅栏。当栅栏中所有线程都已经调用了这个函数，它们将同时被释放。如果提供了 timeout 参数，这里的 timeout 参数优先于创建栅栏对象时提供的 timeout 参数。函数返回值是一个整数，取值范围在0到 parties – 1，在每个线程中的返回值不相同。可用于从所有线程中选择唯一的一个线程执行一些特别的工作。例如： 1234i = barrier.wait()if i == 0: # Only one thread needs to print this print("passed the barrier") 如果创建栅栏对象时在构造函数中提供了 action 参数，它将在其中一个线程释放前被调用。如果此调用引发了异常，栅栏对象将进入损坏态。 如果发生了超时，栅栏对象将进入破损态。 如果栅栏对象进入破损态，或重置栅栏时仍有线程等待释放，将会引发 BrokenBarrierError 异常。 reset() 重置栅栏为默认的初始态。如果栅栏中仍有线程等待释放，这些线程将会收到 BrokenBarrierError 异常。 abort() Put the barrier into a broken state. This causes any active or future calls to wait() to fail with the BrokenBarrierError. Use this for example if one of the threads needs to abort, to avoid deadlocking the application.更好的方式是：创建栅栏时提供一个合理的超时时间，来自动避免某个线程出错。 parties 冲出栅栏所需要的线程数量。 n_waiting 当前时刻正在栅栏中阻塞的线程数量。 broken 一个布尔值，值为 True 表明栅栏为破损态。 exception threading.BrokenBarrierError 异常类，是 RuntimeError 异常的子类，在 Barrier 对象重置时仍有线程阻塞时和对象进入破损态时被引发。 在 with 语句中使用锁、条件和信号量这个模块提供的带有 acquire() 和 release() 方法的对象，可以被用作 with 语句的上下文管理器。当进入语句块时 acquire() 方法会被调用，退出语句块时 release() 会被调用。因此，以下片段: 12with some_lock: # do something... 相当于: 12345some_lock.acquire()try: # do something...finally: some_lock.release() 小结GIL 原理参考 stackoverflow上 大神的解释 Python’s GIL is intended to serialize access to interpreter internals from different threads. On multi-core systems, it means that multiple threads can’t effectively make use of multiple cores. (If the GIL didn’t lead to this problem, most people wouldn’t care about the GIL - it’s only being raised as an issue because of the increasing prevalence of multi-core systems.) If you want to understand it in detail, you can view this video or look at this set of slides. It might be too much information, but then you did ask for details :-) Note that Python’s GIL is only really an issue for CPython, the reference implementation. Jython and IronPython don’t have a GIL. As a Python developer, you don’t generally come across the GIL unless you’re writing a C extension. C extension writers need to release the GIL when their extensions do blocking I/O, so that other threads in the Python process get a chance to run. 简单说 所谓的全局线程锁,就是同步线程间信号的一种处理方式。 在多线程系统中,并不能充分利用多线程,来提高整体的性能。所以才有了 GIL。 根据我的理解,GIL的一个应用场景是在同一时刻只能跑一个线程，这样在跑多线程的情况下，只有当线程获取到全局解释器锁后才能运行，而全局解释器锁只有一个，因此即使在多核的情况下也只能发挥出单核的功能。 如下图所示: GIL仅仅对cpython实现和扩展的模块起作用,jython或者ironpython没有GIL的概念。 到底是并行还是多线程,在很多场景中都有争论。 GIL 对线程执行的影响：首先理解什么是interval时间,和操作系统绑定: 1234&gt;&gt;&gt; import sys&gt;&gt;&gt; # The interval is set to 100 instructions:&gt;&gt;&gt; sys.getcheckinterval()100 多线程环境中，python虚拟机按照以下方式执行： 设置GIL 切换到一个线程去执行 运行代码，这里有两种机制： q 指定数量的字节码指令（100个） 固定时间15ms线程主动让出控制 把线程设置为睡眠状态 解锁GIL 再次重复以上步骤 一个栗子Code 1: CPU bound program that perform simple countdown 123456789101112131415import time from threading import Thread COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 start = time.time() countdown(COUNT) end = time.time() print('Time taken in seconds -', end - start) &gt;&gt;&gt; Time taken in seconds - 2.5236213207244873 Code 2: Two threads running parallel 123456789101112131415161718192021import time from threading import Thread COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 t1 = Thread(target = countdown, args =(COUNT//2, )) t2 = Thread(target = countdown, args =(COUNT//2, )) start = time.time() t1.start() t2.start() t1.join() t2.join() end = time.time() print('Time taken in seconds -', end - start) &gt;&gt;&gt; Time taken in seconds - 2.183610439300537 python的解决方案 123456789101112131415161718192021222324252627import multiprocessing import time COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 if __name__ == "__main__": # creating processes start = time.time() p1 = multiprocessing.Process(target = countdown, args =(COUNT//2, )) p2 = multiprocessing.Process(target = countdown, args =(COUNT//2, )) # starting process 1 p1.start() # starting process 2 p2.start() # wait until process 1 is finished p1.join() # wait until process 2 is finished p2.join() end = time.time() print('Time taken in seconds -', end - start) &gt;&gt;&gt; Time taken in seconds - 2.5148496627807617 参考文档UnderstandingGIL understanding-python-gil what is the python interpreter lock gil]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>thread</tag>
        <tag>GIL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library numbers]]></title>
    <url>%2F2020%2F01%2F18%2Fpython-standard-library-numbers%2F</url>
    <content type="text"><![CDATA[python 标准库数字的抽象基类 numbers昨天深夜 红薯 一篇博文 悼 @宏哥 ,让我久久不能平静。 时间定格在了2020年1月16号。 还依稀记得几年前和宏哥聊天,听说他去创业了。 还记得那时意气风发,舌战群儒,没想到如今阴阳两隔。 创业这条路,真的不好走。 愿天堂没有代码。 大家都好好活着吧。 源代码源代码： Lib/numbers.py numbers 模块 (PEP 3141) 定义了数字 抽象基类 的层次结构，其中逐级定义了更多操作。 此模块中所定义的类型都不可被实例化。 核心类class numbers.Number 数字的层次结构的基础。如果你只想确认参数 x 是不是数字而不关心其类型，则使用isinstance(x, Number)。 数字的层次 class numbers.Complex 内置在类型 complex 里的子类描述了复数和它的运算操作。这些操作有：转化至 complex 和 bool， real、 imag、+、-、*、/、 abs()、 conjugate()、 == 和 !=。 所有的异常，- 和 != ，都是抽象的。real抽象的。得到该数字的实数部分。imag抽象的。得到该数字的虚数部分。abstractmethod conjugate()抽象的。返回共轭复数。例如 (1+3j).conjugate() == (1-3j)。 class numbers.Real 相对于 Complex，Real 加入了只有实数才能进行的操作。简单的说，它们是：转化至 float，math.trunc()、 round()、 math.floor()、 math.ceil()、 divmod()、 //、 %、 &lt;、 &lt;=、 &gt;、 和 &gt;=。实数同样默认支持 complex()、 real、 imag 和 conjugate()。 class numbers.Rational 子类型 Real 并加入 numerator 和 denominator 两种属性，这两种属性应该属于最低的级别。加入后，这默认支持 float()。numerator摘要。denominator摘要。 class numbers.Integral 子类型 Rational 加上转化至 int。 默认支持 float()、 numerator 和 denominator。 在 ** 中加入抽象方法和比特字符串的操作： &lt;&lt;、 &gt;&gt;、 &amp;、 ^、 |、 ~。 类型接口注解实现者需要注意使相等的数字相等并拥有同样的值。当这两个数使用不同的扩展模块时，这其中的差异是很微妙的。例如，用 fractions.Fraction 实现 hash() 如下: 1234567891011def __hash__(self): if self.denominator == 1: # Get integers right. return hash(self.numerator) # Expensive check, but definitely correct. if self == float(self): return hash(float(self)) else: # Use tuple's hash to avoid a high collision rate on # simple fractions. return hash((self.numerator, self.denominator)) 添加更多数字的ABC(创造自定义的数字子类)当然，这里有更多支持数字的ABC，如果不加入这些，就将缺少层次感。你可以用如下方法在 Complex 和 Real 中加入MyFoo： 123class MyFoo(Complex): passMyFoo.register(Real) 实现算数运算我们希望实现计算，因此，混合模式操作要么调用一个作者知道参数类型的实现，要么转变成为最接近的内置类型并对这个执行操作。对于子类 Integral，这意味着 __add__() 和 __radd__() 必须用如下方式定义： 1234567891011121314151617181920212223class MyIntegral(Integral): def __add__(self, other): if isinstance(other, MyIntegral): return do_my_adding_stuff(self, other) elif isinstance(other, OtherTypeIKnowAbout): return do_my_other_adding_stuff(self, other) else: return NotImplemented def __radd__(self, other): if isinstance(other, MyIntegral): return do_my_adding_stuff(other, self) elif isinstance(other, OtherTypeIKnowAbout): return do_my_other_adding_stuff(other, self) elif isinstance(other, Integral): return int(other) + int(self) elif isinstance(other, Real): return float(other) + float(self) elif isinstance(other, Complex): return complex(other) + complex(self) else: return NotImplemented 复数的子类上的混合操作有五种情况。前述的代码中除去MyIntegral和OtherTypeIKnow的文本将作为下面描述的样板。a是A的实例，并且使复数的子类（a：A&lt;：Complex），b是B的实例，也是复数的子类。我们以a+b做如下讨论： 如果 A 被定义成一个承认b 的 __add__()，一切都没有问题。 如果 A 转回成“模板”失败，它将返回一个属于 __add__() 的值，我们需要避免 B 定义了一个更加智能的 __radd__()，因此模板需要返回一个属于 __add__() 的 NotImplemented 。（或者 A 可能完全不实现 __add__() 。） 接着看 B 的 __radd__() 。如果它接受a ，一切都将完美。 如果没有成功回退到模板，就没有更多的方法可以去尝试，因此这里将使用默认的实现。 如果 B &lt;: A ， Python 在 A.__add__ 之前尝试 B.__radd__ 。 这是可行的，是通过对 A 的认识实现的，因此这可以在交给 Complex 处理之前处理这些实例。 如果 A &lt;: Complex 和 B &lt;: Real 没有共享任何资源，那么适当的共享操作涉及内置的 complex ，并且分别获得 __radd__() ，因此 a+b == b+a。 由于对任何一直类型的大部分操作是十分相似的，可以定义一个帮助函数，即一个生成后续或相反的实例的生成器。例如，使用 fractions.Fraction 如下： 12345678910111213141516171819202122232425262728293031323334353637def _operator_fallbacks(monomorphic_operator, fallback_operator): def forward(a, b): if isinstance(b, (int, Fraction)): return monomorphic_operator(a, b) elif isinstance(b, float): return fallback_operator(float(a), b) elif isinstance(b, complex): return fallback_operator(complex(a), b) else: return NotImplemented forward.__name__ = '__' + fallback_operator.__name__ + '__' forward.__doc__ = monomorphic_operator.__doc__ def reverse(b, a): if isinstance(a, Rational): # Includes ints. return monomorphic_operator(a, b) elif isinstance(a, numbers.Real): return fallback_operator(float(a), float(b)) elif isinstance(a, numbers.Complex): return fallback_operator(complex(a), complex(b)) else: return NotImplemented reverse.__name__ = '__r' + fallback_operator.__name__ + '__' reverse.__doc__ = monomorphic_operator.__doc__ return forward, reversedef _add(a, b): """a + b""" return Fraction(a.numerator * b.denominator + b.numerator * a.denominator, a.denominator * b.denominator)__add__, __radd__ = _operator_fallbacks(_add, operator.add)# ...]]></content>
      <categories>
        <category>python</category>
        <category>standard_library</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard libary heapq]]></title>
    <url>%2F2020%2F01%2F17%2Fpython-standard-library-heapq%2F</url>
    <content type="text"><![CDATA[python 标准库 堆队列算法 heapq每日一词: Pollen n 花粉 例句: Good news for all you hay fever and asthma sufferers对于花粉症和哮喘病患者是个好消息 今天是小年,祝大家心想事成 源码源码：Lib/heapq.py 主要模块和方法： 12__all__ = ['heappush', 'heappop', 'heapify', 'heapreplace', 'merge', 'nlargest', 'nsmallest', 'heappushpop'] 这个模块提供了堆队列算法的实现，也称为优先队列算法。 堆是一个二叉树，它的每个父节点的值都只会小于或大于所有孩子节点（的值）。它使用了数组来实现：从零开始计数，对于所有的 k ，都有 heap[k] &lt;= heap[2*k+1] 和 heap[k] &lt;= heap[2*k+2]。 为了便于比较，不存在的元素被认为是无限大。 堆最有趣的特性在于最小的元素总是在根结点：heap[0]。 这个API与教材的堆算法实现有所不同，具体区别有两方面：（a）我们使用了从零开始的索引。这使得节点和其孩子节点索引之间的关系不太直观但更加适合，因为 Python 使用从零开始的索引。 （b）我们的 pop 方法返回最小的项而不是最大的项（这在教材中称为“最小堆”；而“最大堆”在教材中更为常见，因为它更适用于原地排序）。 基于这两方面，把堆看作原生的Python list也没什么奇怪的： heap[0] 表示最小的元素，同时 heap.sort() 维护了堆的不变性！ 要创建一个堆，可以使用list来初始化为 [] ，或者你可以通过一个函数 heapify() ，来把一个list转换成堆。 定义了以下函数： heapq.heappush(heap, item) 将 item 的值加入 heap 中，保持堆的不变性。 heapq.heappop(heap) 弹出并返回 heap 的最小的元素，保持堆的不变性。如果堆为空，抛出 IndexError 。使用 heap[0] ，可以只访问最小的元素而不弹出它。 heapq.heappushpop(heap, item) 将 item 放入堆中，然后弹出并返回 heap 的最小元素。该组合操作比先调用 heappush() 再调用 heappop() 运行起来更有效率。 heapq.heapify(x) 将list x 转换成堆，原地，线性时间内。 heapq.heapreplace(heap, item) 弹出并返回 heap 中最小的一项，同时推入新的 item。 堆的大小不变。 如果堆为空则引发 IndexError。这个单步骤操作比 heappop() 加 heappush() 更高效，并且在使用固定大小的堆时更为适宜。 pop/push 组合总是会从堆中返回一个元素并将其替换为 item。返回的值可能会比添加的 item 更大。 如果不希望如此，可考虑改用 heappushpop()。 它的 push/pop 组合会返回两个值中较小的一个，将较大的值留在堆中。 该模块还提供了三个基于堆的通用功能函数。 heapq.merge(*iterables, key=None, reverse=False) 将多个已排序的输入合并为一个已排序的输出（例如，合并来自多个日志文件的带时间戳的条目）。 返回已排序值的 iterator。类似于 sorted(itertools.chain(*iterables)) 但返回一个可迭代对象，不会一次性地将数据全部放入内存，并假定每个输入流都是已排序的（从小到大）。具有两个可选参数，它们都必须指定为关键字参数。key 指定带有单个参数的 key function，用于从每个输入元素中提取比较键。 默认值为 None (直接比较元素)。reverse 为一个布尔值。 如果设为 True，则输入元素将按比较结果逆序进行合并。 要达成与 sorted(itertools.chain(*iterables), reverse=True) 类似的行为，所有可迭代对象必须是已从大到小排序的。在 3.5 版更改: 添加了可选的 key 和 reverse 形参。 heapq.nlargest(n, iterable, key=None) 从 iterable 所定义的数据集中返回前 n 个最大元素组成的列表。 如果提供了 key 则其应指定一个单参数的函数，用于从 iterable 的每个元素中提取比较键 (例如 key=str.lower)。 等价于: sorted(iterable, key=key, reverse=True)[:n]。 heapq.nsmallest(n, iterable, key=None) 从 iterable 所定义的数据集中返回前 n 个最小元素组成的列表。 如果提供了 key 则其应指定一个单参数的函数，用于从 iterable 的每个元素中提取比较键 (例如 key=str.lower)。 等价于: sorted(iterable, key=key)[:n]。 后两个函数在 n 值较小时性能最好。 对于更大的值，使用 sorted() 函数会更有效率。 此外，当 n==1 时，使用内置的 min() 和 max() 函数会更有效率。 如果需要重复使用这些函数，请考虑将可迭代对象转为真正的堆。 基本实例堆排序 可以通过将所有值推入堆中然后每次弹出一个最小值项来实现。 12345678&gt;&gt;&gt; def heapsort(iterable):... h = []... for value in iterable:... heappush(h, value)... return [heappop(h) for i in range(len(h))]...&gt;&gt;&gt; heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 这类似于 sorted(iterable)，但与 sorted() 不同的是这个实现是不稳定的。 堆元素可以为元组。 这适用于将比较值（例如任务优先级）与跟踪的主记录进行赋值的场合: 1234567&gt;&gt;&gt; h = []&gt;&gt;&gt; heappush(h, (5, 'write code'))&gt;&gt;&gt; heappush(h, (7, 'release product'))&gt;&gt;&gt; heappush(h, (1, 'write spec'))&gt;&gt;&gt; heappush(h, (3, 'create tests'))&gt;&gt;&gt; heappop(h)(1, 'write spec') 优先队列实现说明优先队列 是堆的常用场合，并且它的实现包含了多个挑战： 排序稳定性：你该如何令相同优先级的两个任务按它们最初被加入时的顺序返回？ 如果优先级相同且任务没有默认比较顺序，则 (priority, task) 对的元组比较将会中断。 如果任务优先级发生改变，你该如何将其移至堆中的新位置？ 或者如果一个挂起的任务需要被删除，你该如何找到它并将其移出队列？ 针对前两项挑战的一种解决方案是将条目保存为包含优先级、条目计数和任务对象 3 个元素的列表。 条目计数可用来打破平局，这样具有相同优先级的任务将按它们的添加顺序返回。 并且由于没有哪两个条目计数是相同的，元组比较将永远不会直接比较两个任务。 不可比较任务问题的另一种解决方案是创建一个忽略任务条目并且只比较优先级字段的包装器类: 1234567from dataclasses import dataclass, fieldfrom typing import Any@dataclass(order=True)class PrioritizedItem: priority: int item: Any=field(compare=False) 其余的挑战主要包括找到挂起的任务并修改其优先级或将其完全移除。 找到一个任务可使用一个指向队列中条目的字典来实现。 移除条目或改变其优先级的操作实现起来更为困难，因为它会破坏堆结构不变量。 因此，一种可能的解决方案是将条目标记为已移除，再添加一个改变了优先级的新条目: 123456789101112131415161718192021222324252627pq = [] # list of entries arranged in a heapentry_finder = &#123;&#125; # mapping of tasks to entriesREMOVED = '&lt;removed-task&gt;' # placeholder for a removed taskcounter = itertools.count() # unique sequence countdef add_task(task, priority=0): 'Add a new task or update the priority of an existing task' if task in entry_finder: remove_task(task) count = next(counter) entry = [priority, count, task] entry_finder[task] = entry heappush(pq, entry)def remove_task(task): 'Mark an existing task as REMOVED. Raise KeyError if not found.' entry = entry_finder.pop(task) entry[-1] = REMOVEDdef pop_task(): 'Remove and return the lowest priority task. Raise KeyError if empty.' while pq: priority, count, task = heappop(pq) if task is not REMOVED: del entry_finder[task] return task raise KeyError('pop from an empty priority queue') 理论堆是通过数组来实现的，其中的元素从 0 开始计数，对于所有的 k 都有 a[k] &lt;= a[2*k+1] 且 a[k] &lt;= a[2*k+2]。 为了便于比较，不存在的元素被视为无穷大。 堆最有趣的特性在于 a[0] 总是其中最小的元素。 上面的特殊不变量是用来作为一场锦标赛的高效内存表示。 下面的数字是 k 而不是 a[k]: 123456789 0 1 2 3 4 5 6 7 8 9 10 11 12 13 1415 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 在上面的树中，每个 k 单元都位于 2*k+1 和 2*k+2 之上。 体育运动中我们经常见到二元锦标赛模式，每个胜者单元都位于另两个单元之上，并且我们可以沿着树形图向下追溯胜者所遇到的所有对手。 但是，在许多采用这种锦标赛模式的计算机应用程序中，我们并不需要追溯胜者的历史。 为了获得更高的内存利用效率，当一个胜者晋级时，我们会用较低层级的另一条目来替代它，因此规则变为一个单元和它之下的两个单元包含三个不同条目，上方单元“胜过”了两个下方单元。 如果此堆的不变量始终受到保护，则序号 0 显然是最后的赢家。 删除它并找出“下一个”赢家的最简单算法方式是家某个输家（让我们假定是上图中的 30 号单元）移至 0 号位置，然后将这个新的 0 号沿树下行，不断进行值的交换，直到不变量重新建立。 这显然会是树中条目总数的对数。 通过迭代所有条目，你将得到一个 O(n log n) 复杂度的排序。 此排序有一个很好的特性就是你可以在排序进行期间高效地插入新条目，前提是插入的条目不比你最近取出的 0 号元素“更好”。 这在模拟上下文时特别有用，在这种情况下树保存的是所有传入事件，“胜出”条件是最小调度时间。 当一个事件将其他事件排入执行计划时，它们的调试时间向未来方向延长，这样它们可方便地入堆。 因此，堆结构很适宜用来实现调度器，我的 MIDI 音序器就是用的这个 :-)。 用于实现调度器的各种结构都得到了充分的研究，堆是非常适宜的一种，因为它们的速度相当快，并且几乎是恒定的，最坏的情况与平均情况没有太大差别。 虽然还存在其他总体而言更高效的实现方式，但其最坏的情况却可能非常糟糕。 堆在大磁盘排序中也非常有用。 你应该已经了解大规模排序会有多个“运行轮次”（即预排序的序列，其大小通常与 CPU 内存容量相关），随后这些轮次会进入合并通道，轮次合并的组织往往非常巧妙 1。 非常重要的一点是初始排序应产生尽可能长的运行轮次。 锦标赛模式是达成此目标的好办法。 如果你使用全部有用内存来进行锦标赛，替换和安排恰好适合当前运行轮次的条目，你将可以对于随机输入生成两倍于内存大小的运行轮次，对于模糊排序的输入还会有更好的效果。 另外，如果你输出磁盘上的第 0 个条目并获得一个可能不适合当前锦标赛的输入（因为其值要“胜过”上一个输出值），它无法被放入堆中，因此堆的尺寸将缩小。 被释放的内存可以被巧妙地立即重用以逐步构建第二个堆，其增长速度与第一个堆的缩减速度正好相同。 当第一个堆完全消失时，你可以切换新堆并启动新的运行轮次。 这样做既聪明又高效！ 总之，堆是值得了解的有用内存结构。 我在一些应用中用到了它们，并且认为保留一个 ‘heap’ 模块是很有意义的。 :-) 堆排序图例]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>heapq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library calendar]]></title>
    <url>%2F2020%2F01%2F16%2Fpython-standard-library-calendar%2F</url>
    <content type="text"><![CDATA[python 标准库 calendar每日一词: calendar 英 [ˈkælɪndə(r)] 美 [ˈkælɪndər] n. 日历；[天] 历法；日程表 vt. 将…列入表中；将…排入日程表 短语 chinese calendar 中国传统历法 ; 阴历 ; 中国农历 lunar calendar 阴历 ; 夏历 ; 来自日月星辰的力量 ; 太阴历 solar calendar 太阳历 ; 公历 ; 阳历与阴历 还有几天就过年了,2020年充满了期待,你呢？ 今天我们学习python 标准库 calendar 。 输出像 Unix cal 那样的日历，它还提供了其它与日历相关的实用函数。 默认情况下，这些日历把星期一当作一周的第一天，星期天为一周的最后一天（按照欧洲惯例）。 可以使用 setfirstweekday() 方法设置一周的第一天为星期天 (6) 或者其它任意一天。 使用整数作为指定日期的参数。 更多相关的函数，参见 datetime 和 time 模块。 在这个模块中定义的函数和类都基于一个理想化的日历，现行公历向过去和未来两个方向无限扩展。这与 Dershowitz 和 Reingold 的书 “历法计算” 中所有计算的基本日历 – “proleptic Gregorian” 日历的定义相符合。 ISO 8601标准还规定了 0 和 负数年份。0年指公元前1年， -1年指公元前2年，依此类推 . 源代码 源代码： Lib/calendar.py 主要类和方法,节选自源码 123456__all__ = ["IllegalMonthError", "IllegalWeekdayError", "setfirstweekday", "firstweekday", "isleap", "leapdays", "weekday", "monthrange", "monthcalendar", "prmonth", "month", "prcal", "calendar", "timegm", "month_name", "month_abbr", "day_name", "day_abbr", "Calendar", "TextCalendar", "HTMLCalendar", "LocaleTextCalendar", "LocaleHTMLCalendar", "weekheader"] 类class calendar.Calendar(firstweekday=0)¶创建一个 Calendar 对象。 firstweekday 是一个整数，用于指定一周的第一天。 0 是星期一（默认值），6 是星期天。 Calendar 对象提供了一些可被用于准备日历数据格式化的方法。 这个类本身不执行任何格式化操作。 这部分任务应由子类来完成。 Calendar 类的实例有下列方法： iterweekdays() 返回一个迭代器，迭代器的内容为一星期的数字。迭代器的第一个值与 firstweekday 属性的值一至。 itermonthdates(year, month) 返回一个迭代器，迭代器的内容为 year 年 month 月(1-12)的日期。这个迭代器返回当月的所有日期 ( datetime.date 对象)，日期包含了本月头尾用于组成完整一周的日期。 itermonthdays(year, month) 返回一个迭代器，迭代器的内容与 itermonthdates() 类似，为 year 年 month 月的日期，但不受 datetime.date 范围限制。返回的日期为当月每一天的日期对应的天数。对于不在当月的日期，显示为 0。 itermonthdays2(year, month) 返回一个迭代器，迭代器的内容与 itermonthdates() 类似为 year 年 month 月的日期，但不受 datetime.date 范围的限制。迭代器中的元素为一个由日期和代表星期几的数字组成的的元组。 itermonthdays3(year, month) 返回一个迭代器，迭代器的内容与 itermonthdates() 类似为 year 年 month 月的日期，但不受 datetime.date 范围的限制。迭代器的元素为一个由年，月，日组成的元组。3.7 新版功能. itermonthdays4(year, month) 返回一个迭代器，迭代器的内容与 itermonthdates() 类似为 year 年 month 月的日期，但不受 datetime.date 范围的限制。迭代器的元素为一个由年，月，日和代表星期几的数字组成的元组。3.7 新版功能. monthdatescalendar(year, month) 返回一个表示指定年月的周列表。周列表由七个 datetime.date 对象组成。 monthdays2calendar(year, month) 返回一个表示指定年月的周列表。周列表由七个代表日期的数字和代表周几的数字组成的二元元组。 monthdayscalendar(year, month) 返回一个表示指定年月的周列表。周列表由七个代表日期的数字组成。 yeardatescalendar(year, width=3) 返回可以用来格式化的指定年月的数据。返回的值是一个列表，列表是月份组成的行。每一行包含了最多 width 个月(默认为3)。每个月包含了4到6周，每周包含1–7天。每一天使用 datetime.date 对象。 yeardays2calendar(year, width=3) 返回可以用来模式化的指定年月的数据(与 yeardatescalendar() 类似)。周列表的元素是由表示日期的数字和表示星期几的数字组成的元组。不在这个月的日子为0。 yeardayscalendar(year, width=3) 返回可以用来模式化的指定年月的数据(与 yeardatescalendar() 类似)。周列表的元素是表示日期的数字。不在这个月的日子为0。 class calendar.TextCalendar(firstweekday=0)可以使用这个类生成纯文本日历。 TextCalendar 实例有以下方法： formatmonth(theyear, themonth, w=0, l=0) 返回一个多行字符串来表示指定年月的日历。w 为日期的宽度，但始终保持日期居中。l 指定了每星期占用的行数。以上这些还依赖于构造器或者 setfirstweekday() 方法指定的周的第一天是哪一天。 prmonth(theyear, themonth, w=0, l=0) 与 formatmonth() 方法一样，返回一个月的日历。 formatyear(theyear, w=2, l=1, c=6, m=3) 返回一个多行字符串，这个字符串为一个 m 列日历。可选参数 w, l, 和 c 分别表示日期列数， 周的行数， 和月之间的间隔。同样，以上这些还依赖于构造器或者 setfirstweekday() 指定哪一天为一周的第一天。日历的第一年由平台依赖于使用的平台。 pryear(theyear, w=2, l=1, c=6, m=3) 与 formatyear() 方法一样，返回一整年的日历。 class calendar.HTMLCalendar(firstweekday=0)可以使用这个类生成 HTML 日历。HTMLCalendar 实例有以下方法：formatmonth(theyear, themonth, withyear=True)返回一个 HTML 表格作为指定年月的日历。 withyear 为真，则年份将会包含在表头，否则只显示月份。formatyear(theyear, width=3)返回一个 HTML 表格作为指定年份的日历。 width (默认为3) 用于规定每一行显示月份的数量。formatyearpage(theyear, width=3, css=’calendar.css’, encoding=None)返回一个完整的 HTML 页面作为指定年份的日历。 width\(默认为3) 用于规定每一行显示的月份数量。 *css 为层叠样式表的名字。如果不使用任何层叠样式表，可以使用 None 。 encoding* 为输出页面的编码 (默认为系统的默认编码)。HTMLCalendar 有以下属性，你可以重载它们来自定义应用日历的样式。 cssclasses一个对应星期一到星期天的 CSS class 列表。默认列表为 1cssclasses = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"] 可以向每天加入其它样式 1cssclasses = ["mon text-bold", "tue", "wed", "thu", "fri", "sat", "sun red"] 需要注意的是，列表的长度必须为7。 cssclass_noday 工作日的 CSS 类在上个月或下个月发生。 cssclasses_weekday_head 用于标题行中的工作日名称的 CSS 类 列表。默认值与 cssclasses 相同。3.7 新版功能. cssclass_month_head 月份的头 CSS 类（由 formatmonthname() 使用）。默认值为 &quot;month&quot; 。3.7 新版功能. cssclass_month 某个月的月历的 CSS 类（由 formatmonth() 使用）。默认值为 &quot;month&quot; 。3.7 新版功能. cssclass_year 某年的年历的 CSS 类（由 formatyear() 使用）。默认值为 &quot;year&quot; 。3.7 新版功能. cssclass_year_head 年历的·表头 CSS 类（由 formatyear() 使用）。默认值为 &quot;year&quot; 。3.7 新版功能. 需要注意的是，尽管上面命名的样式类都是单独出现的(如： cssclass_month cssclass_noday), 但我们可以使用空格将样式类列表中的多个元素分隔开，例如： 1"text-bold text-red" 下面是一个如何自定义 HTMLCalendar 的示例 123456class CustomHTMLCal(calendar.HTMLCalendar): cssclasses = [style + " text-nowrap" for style in calendar.HTMLCalendar.cssclasses] cssclass_month_head = "text-center month-head" cssclass_month = "text-center month" cssclass_year = "text-italic lead" class calendar.LocaleTextCalendar(firstweekday=0, locale=None)这个子类 TextCalendar 可以在构造函数中传递一个语言环境名称，并且返回月份和星期几的名称在特定语言环境中。如果此语言环境包含编码，则包含月份和工作日名称的所有字符串将作为 unicode 返回。 class calendar.LocaleHTMLCalendar(firstweekday=0, locale=None) calendar.setfirstweekday(weekday) 设置每一周的开始(0 表示星期一，6 表示星期天)。calendar还提供了 MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY 和 SUNDAY 几个常量方便使用。例如，设置每周的第一天为星期天 12import calendarcalendar.setfirstweekday(calendar.SUNDAY) calendar.firstweekday() 返回当前设置的每星期的第一天的数值。 calendar.isleap(year) 如果 year 是闰年则返回 True ,否则返回 False。 calendar.leapdays(y1, y2) 返回在范围 y1 至 y2 （包含 y1 和 y2 ）之间的闰年的年数，其中 y1 和 y2 是年份。此函数适用于跨越一个世纪变化的范围。 calendar.weekday(year, month, day) 返回某年（ 1970 – …），某月（ 1 – 12 ），某日（ 1 – 31 ）是星期几（ 0 是星期一）。 calendar.weekheader(n) 返回一个包含星期几的缩写名的头。 n 指定星期几缩写的字符宽度。 calendar.monthrange(year, month) 返回指定 年份 的指定 月份 的第一天是星期几和这个月的天数。 calendar.monthcalendar(year, month) 返回表示一个月的日历的矩阵。每一行代表一周；此月份外的日子由零表示。除非由 setfirstweekday() 设置，否则每周以周一为始。 calendar.prmonth(theyear, themonth, w=0, l=0) 打印由 month() 返回的一个月的日历。 calendar.month(theyear, themonth, w=0, l=0) 使用 TextCalendar 类的 formatmonth() 以多行字符串形式返回月份日历。 calendar.prcal(year, w=0, l=0, c=6, m=3) 打印由 calendar() 返回的整年的日历。 calendar.calendar(year, w=2, l=1, c=6, m=3) 使用 TextCalendar 类的 formatyear() 返回整年的3列的日历以多行字符串的形式。 calendar.timegm(tuple) 一个不相关但很好用的函数，它接受一个时间元组例如 time 模块中的 gmtime() 函数的返回并返回相应的 Unix 时间戳值，假定 1970 年开始计数， POSIX 编码。实际上， time.gmtime() 和 timegm() 是彼此相反的。 属性 calendar.day_name 在当前语言环境下表示星期几的数组。 calendar.day_abbr 在当前语言环境下表示星期几缩写的数组。 calendar.month_name 在当前语言环境下表示一年中月份的数组。这遵循一月的月号为 1 的通常惯例，所以它的长度为 13 且 month_name[0] 是空字符串。 calendar.month_abbr 在当前语言环境下表示月份简写的数组。这遵循一月的月号为 1 的通常惯例，所以它的长度为 13 且 month_abbr[0] 是空字符串。 例子 小结 默认情况下，这些日历将星期一作为一周的第一天，将星期日作为一周的最后一天(欧洲惯例)。不过，我们可以使用setfirstweekday()方法来设置一周的第一天为星期日或h者其他工作日，指定的日期以整数形式给出。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>calendar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library iterator and generator]]></title>
    <url>%2F2020%2F01%2F15%2Fpython-standard-library-iterator-and-generator%2F</url>
    <content type="text"><![CDATA[python 标准库 类型： 迭代器 和 生成器每日英语: miracle n [英] [ˈmɪrəkl] [美] [ ˈmɪrəkəl ] 奇迹，圣迹，神迹； 令人惊奇的人（或事） 推荐一个老电影： 每个人终将都会踏上自己的绿色旅程,善恶就在一念之间。愿世界美好,温情以待。 先看一张图: 1，迭代器协议：对象需要提供next()方法，它要么返回迭代中的下一项，要么就引起一个StopIteration异常，以终止迭代。 2，可迭代对象：实现了迭代器协议对象。list、tuple、dict都是Iterable（可迭代对象），但不是Iterator（迭代器对象）。但可以使用内建函数iter()，把这些都变成Iterable（可迭代器对象）。 3，for item in Iterable 循环的本质就是先通过iter()函数获取可迭代对象Iterable的迭代器，然后对获取到的迭代器不断调用next()方法来获取下一个值并将其赋值给item，当遇到StopIteration的异常后循环结束 迭代器类型Python 支持在容器中进行迭代的概念。 这是通过使用两个单独方法来实现的；它们被用于允许用户自定义类对迭代的支持。 将在下文中详细描述的序列总是支持迭代方法。 容器对象要提供迭代支持，必须定义一个方法: container.__iter__() 返回一个迭代器对象。 该对象需要支持下文所述的迭代器协议。 如果容器支持不同的迭代类型，则可以提供额外的方法来专门地请求不同迭代类型的迭代器。 （支持多种迭代形式的对象的例子有同时支持广度优先和深度优先遍历的树结构。） 此方法对应于 Python/C API 中 Python 对象类型结构体的 tp_iter 槽位。 迭代器对象自身需要支持以下两个方法，它们共同组成了 迭代器协议: iterator.__iter__() 返回迭代器对象本身。 这是同时允许容器和迭代器配合 for 和 in 语句使用所必须的。 此方法对应于 Python/C API 中 Python 对象类型结构体的 tp_iter 槽位。 iterator.__next__() 从容器中返回下一项。 如果已经没有项可返回，则会引发 StopIteration 异常。 此方法对应于 Python/C API 中 Python 对象类型结构体的 tp_iternext 槽位。 Python 定义了几种迭代器对象以支持对一般和特定序列类型、字典和其他更特别的形式进行迭代。 除了迭代器协议的实现，特定类型的其他性质对迭代操作来说都不重要。 一旦迭代器的 __next__() 方法引发了 StopIteration，它必须一直对后续调用引发同样的异常。 不遵循此行为特性的实现将无法正常使用。 迭代器使用实例 123456789101112131415161718# 随便定义一个listlistArray=[1,2,3]# 使用iter()函数iterName=iter(listArray)print(iterName)# 结果如下：是一个列表list的迭代器# &lt;list_iterator object at 0x0000017B0D984278&gt;print(next(iterName))print(next(iterName))print(next(iterName))print(next(iterName))#没有迭代到下一个元素，直接抛出异常# 1# 2# 3# Traceback (most recent call last):# File "python_iterator.py", line 32, in &lt;module&gt;# StopIteration 自定义迭代器实例 123456789101112131415161718192021222324252627class Fib(object): def __init__(self, max): super(Fib, self).__init__() self.max = max def __iter__(self): self.a = 0 self.b = 1 return self def __next__(self): fib = self.a if fib &gt; self.max: raise StopIteration self.a, self.b = self.b, self.a + self.b return fib# 定义一个main函数，循环遍历每一个菲波那切数def main(): # 20以内的数 fib = Fib(20) for i in fib: print(i)# 测试if __name__ == '__main__': main() 生成器类型Python 的 generator 提供了一种实现迭代器协议的便捷方式。 如果容器对象 __iter__() 方法被实现为一个生成器，它将自动返回一个迭代器对象（从技术上说是一个生成器对象），该对象提供 __iter__() 和 __next__() 方法。 有关生成器的更多信息可以参阅 yield 表达式的文档。 生成器函数123456789101112131415161718# 菲波那切数列def Fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return '亲！没有数据了...'# 调用方法，生成出10个数来f=Fib(10)# 使用一个循环捕获最后return 返回的值，保存在异常StopIteration的value中while True: try: x=next(f) print("f:",x) except StopIteration as e: print("生成器最后的返回值是：",e.value) break 生成器表达式1234567891011121314151617181920212223242526272829# 一个列表xiaoke=[2,3,4,5]# 生成器generator，类似于list，但是是把[]改为()gen=(a for a in xiaoke)for i in gen: print(i)#结果是：2345# 为什么要使用生成器？因为效率。# 使用生成器表达式取代列表推导式可以同时节省 cpu 和 内存(RAM)。# 如果你构造一个列表(list)的目的仅仅是传递给别的函数,# 比如 传递给tuple()或者set(), 那就用生成器表达式替代吧!# 本案例是直接把列表转化为元组kk=tuple(a for a in xiaoke)print(kk)#结果是：(2, 3, 4, 5)# python内置的一些函数，可以识别这是生成器表达式，外面有一对小括号，就是生成器result1=sum(a for a in range(3))print(result1)# 列表推导式result2=sum([a for a in range(3)])print(result2) yield关键字使用yield关键字实现生成器函数 12345def fib(max): a, b = 1, 1 while a &lt; max: yield a #这时a,b值分别为1,1，当然，程序也在执行到这时，返回 a, b = b, a+b 使用yield关键字实现自定义生成器 123456789101112131415161718class Fib: def __init__(self, max): self.max = max def __iter__(self): self.a = 0 self.b = 1 return self def next(self): fib = self.a if fib &gt; self.max: raise StopIteration self.a, self.b = self.b, self.a + self.b return fib if __name__ == '__main__': for f in Fib(6): print f]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>iterator</tag>
        <tag>generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library pickle]]></title>
    <url>%2F2020%2F01%2F14%2Fpython-standard-library-pickle%2F</url>
    <content type="text"><![CDATA[python 标准库 pickle快过年了,准备了一些过节用的英语 传统中国节日：traditional Chinese festival 农历：lunar calendar 腊八节：Laba Festival 小年：Little New Year 除夕：Lunar New Year’s Eve 春节：the Spring Festival 正月初一：the lunar New Year’s Day 元宵节：the Lantern Festival 正月：the first month of the lunar year 二月二：Dragon Heads-raising Day 时间过得好快,又是一年过去了。 python 标准库学习之 pickle常用的文本处理 除了文件,数据库,json,xml 以外,python还提供了一种存储方案,这就是pickle。 模块 pickle 实现了对一个 Python 对象结构的二进制序列化和反序列化。“pickling” 是将 Python 对象及其所拥有的层次结构转化为一个字节流的过程，而 “unpickling” 是相反的操作，会将（来自一个 binary file 或者 bytes-like object 的）字节流转化回一个对象层次结构。 pickling（和 unpickling）也被称为“序列化”, “编组” 或者 “平面化”。而为了避免混乱，此处采用术语 “封存 (pickling)” 和 “解封 (unpickling)”。 警告 : pickle 模块并不安全。你只应该对你信任的数据进行unpickle操作。构建恶意的 pickle 数据来在解封时执行任意代码是可能的。绝对不要对不信任来源的数据和可能被篡改过的数据进行解封。请考虑使用 hmac 来对数据进行签名，确保数据没有被篡改。在你处理不信任数据时，更安全的序列化格式如 json 可能更为适合。参见 与 json 模块的比较 源代码： Lib/pickle.py本节内容比较多,先看下类层次结构,有一个大体的概念(节选自源码)： 123456789101112131415Classes: Pickler UnpicklerFunctions: dump(object, file) dumps(object) -&gt; string load(file) -&gt; object loads(string) -&gt; objectMisc variables: __version__ format_version compatible_formats __all__ = ["PickleError", "PicklingError", "UnpicklingError", "Pickler", "Unpickler", "dump", "dumps", "load", "loads"] 数据流格式pickletools 模块包含了相应的工具用于分析 pickle 生成的数据流。pickletools 源码中包含了对 pickle 协议使用的操作码的大量注释。 当前共有 6 种不同的协议可用于封存操作。 使用的协议版本越高，读取所生成 pickle 对象所需的 Python 版本就要越新。 v0 版协议是原始的“人类可读”协议，并且向后兼容早期版本的 Python。 v1 版协议是较早的二进制格式，它也与早期版本的 Python 兼容。 v2 版协议是在 Python 2.3 中引入的。它为存储 new-style class 提供了更高效的机制。欲了解有关第 2 版协议带来的改进，请参阅 PEP 307。 v3 版协议是在 Python 3.0 中引入的。 它显式地支持 bytes 字节对象，不能使用 Python 2.x 解封。这是 Python 3.0-3.7 的默认协议。 v4 版协议添加于 Python 3.4。它支持存储非常大的对象，能存储更多种类的对象，还包括一些针对数据格式的优化。它是Python 3.8使用的默认协议。有关第 4 版协议带来改进的信息，请参阅 PEP 3154。 第 5 版协议是在 Python 3.8 中加入的。 它增加了对带外数据的支持，并可加速带内数据处理。 请参阅 PEP 574 了解第 5 版协议所带来的改进的详情。 模块接口要序列化某个包含层次结构的对象，只需调用 dumps() 函数即可。同样，要反序列化数据流，可以调用 loads() 函数。但是，如果要对序列化和反序列化加以更多的控制，可以分别创建 Pickler 或 Unpickler 对象。 pickle 模块包含了以下常量： pickle.HIGHEST_PROTOCOL 整数，可用的最高 协议版本。此值可以作为 协议 值传递给 dump() 和 dumps() 函数，以及 Pickler 的构造函数。 pickle.DEFAULT_PROTOCOL 整数，用于 pickle 数据的默认 协议版本。它可能小于 HIGHEST_PROTOCOL。当前默认协议是 v4，它在 Python 3.4 中首次引入，与之前的版本不兼容。在 3.8 版更改: 默认协议版本还是 4。 模块方法 pickle.dump(obj, file, protocol=None, **, fix_imports=True, buffer_callback=None*) 将对象 obj 封存以后的对象写入已打开的 file object file。它等同于 Pickler(file, protocol).dump(obj)。参数 file、protocol、fix_imports 和 buffer_callback 的含义与它们在 Pickler 的构造函数中的含义相同。在 3.8 版更改: 加入了 buffer_callback 参数。 pickle.dumps(obj, protocol=None, **, fix_imports=True, buffer_callback=None*) 将 obj 封存以后的对象作为 bytes 类型直接返回，而不是将其写入到文件。参数 protocol、fix_imports 和 buffer_callback 的含义与它们在 Pickler 的构造函数中的含义相同。在 3.8 版更改: 加入了 buffer_callback 参数。 pickle.load(file, **, fix_imports=True, encoding=”ASCII”, errors=”strict”, buffers=None*) 从已打开的 file object 文件 中读取封存后的对象，重建其中特定对象的层次结构并返回。它相当于 Unpickler(file).load()。Pickle 协议版本是自动检测出来的，所以不需要参数来指定协议。封存对象以外的其他字节将被忽略。参数 file、fix_imports、encoding、errors、strict 和 buffers 的含义与它们在 Unpickler 的构造函数中的含义相同。在 3.8 版更改: 加入了 buffers 参数。 pickle.loads(bytes_object, **, fix_imports=True, encoding=”ASCII”, errors=”strict”, buffers=None*) 对于封存生成的对象 bytes_object，还原出原对象的结构并返回。Pickle 协议版本是自动检测出来的，所以不需要参数来指定协议。封存对象以外的其他字节将被忽略。参数 file、fix_imports、encoding、errors、strict 和 buffers 的含义与它们在 Unpickler 的构造函数中的含义相同。 异常处理pickle 模块定义了以下 3 个异常： exception pickle.PickleError 其他 pickle 异常的基类。它是 Exception 的一个子类。 exception pickle.PicklingError 当 Pickler 遇到无法解封的对象时抛出此错误。它是 PickleError 的子类。参考 可以被封存/解封的对象 来了解哪些对象可以被封存。 exception pickle.UnpicklingError 当解封出错时抛出此异常，例如数据损坏或对象不安全。它是 PickleError 的子类。注意，解封时可能还会抛出其他异常，包括（但不限于） AttributeError、EOFError、ImportError 和 IndexError。 模块中的类pickle 模块包含了 3 个类，Pickler、Unpickler 和 PickleBuffer： Picklerclass pickle.Pickler(file, protocol=None, **, fix_imports=True, buffer_callback=None*) 它接受一个二进制文件用于写入 pickle 数据流。 可选参数 protocol 是一个整数，告知 pickler 使用指定的协议，可选择的协议范围从 0 到 HIGHEST_PROTOCOL。如果没有指定，这一参数默认值为 DEFAULT_PROTOCOL。指定一个负数就相当于指定 HIGHEST_PROTOCOL。 参数 file 必须有一个 write() 方法，该 write() 方法要能接收字节作为其唯一参数。因此，它可以是一个打开的磁盘文件（用于写入二进制内容），也可以是一个 io.BytesIO 实例，也可以是满足这一接口的其他任何自定义对象。 如果 fix_imports 为 True 且 protocol 小于 3，pickle 将尝试将 Python 3 中的新名称映射到 Python 2 中的旧模块名称，因此 Python 2 也可以读取封存的数据流。 如果 buffer_callback 为 None（默认情况），缓冲区视图（buffer view）将会作为 pickle 流的一部分被序列化到 file 中。 如果 buffer_callback 不为 None，那它可以用缓冲区视图调用任意次。如果某次调用返回了 False 值（例如 None），则给定的缓冲区是 带外的，否则缓冲区是带内的（例如保存在了 pickle 流里面）。 如果 buffer_callback 不是 None 且 protocol 是 None 或小于 5，就会出错。 在 3.8 版更改: 加入了 buffer_callback 参数。 dump(obj) 将 obj 封存后的内容写入已打开的文件对象，该文件对象已经在构造函数中指定。 persistent_id(obj) 默认无动作，子类继承重载时使用。如果 persistent_id() 返回 None，obj 会被照常 pickle。如果返回其他值，Pickler 会将这个函数的返回值作为 obj 的持久化 ID（Pickler 本应得到序列化数据流并将其写入文件，若此函数有返回值，则得到此函数的返回值并写入文件）。这个持久化 ID 的解释应当定义在 Unpickler.persistent_load() 中（该方法定义还原对象的过程，并返回得到的对象）。注意，persistent_id() 的返回值本身不能拥有持久化 ID。参阅 持久化外部对象 获取详情和使用示例。 dispatch_table Pickler 对象的 dispatch 表是 copyreg.pickle() 中用到的 reduction 函数 的注册。dispatch 表本身是一个 class 到其 reduction 函数的映射键值对。一个 reduction 函数只接受一个参数，就是其关联的 class，函数行为应当遵守 __reduce__() 接口规范。Pickler 对象默认并没有 dispatch_table 属性，该对象默认使用 copyreg 模块中定义的全局 dispatch 表。如果要为特定 Pickler 对象自定义序列化过程，可以将 dispatch_table 属性设置为类字典对象（dict-like object）。另外，如果 Pickler 的子类设置了 dispatch_table 属性，则该子类的实例会使用这个表作为默认的 dispatch 表。参阅 Dispatch 表 获取使用示例。3.3 新版功能. reducer_override(self, obj) 可以在 Pickler 的子类中定义的特殊 reducer。此方法的优先级高于 dispatch_table 中的任何 reducer。它应该与 __reduce__() 方法遵循相同的接口，它也可以返回 NotImplemented，这将使用 dispatch_table 里注册的 reducer 来封存 obj。 Unpicklerclass pickle.Unpickler(file, **, fix_imports=True, encoding=”ASCII”, errors=”strict”, buffers=None*) 它接受一个二进制文件用于读取 pickle 数据流。 Pickle 协议版本是自动检测出来的，所以不需要参数来指定协议。 参数 file 必须有三个方法，read() 方法接受一个整数参数，readinto() 方法接受一个缓冲区作为参数，readline() 方法不需要参数，这与 io.BufferedIOBase 里定义的接口是相同的。因此 file 可以是一个磁盘上用于二进制读取的文件，也可以是一个 io.BytesIO 实例，也可以是满足这一接口的其他任何自定义对象。 可选的参数是 fix_imports, encoding 和 errors，用于控制由Python 2 生成的 pickle 流的兼容性。如果 fix_imports 为 True，则 pickle 将尝试将旧的 Python 2 名称映射到 Python 3 中对应的新名称。encoding 和 errors 参数告诉 pickle 如何解码 Python 2 存储的 8 位字符串实例；这两个参数默认分别为 ‘ASCII’ 和 ‘strict’。encoding 参数可置为 ‘bytes’ 来将这些 8 位字符串实例读取为字节对象。读取 NumPy array 和 Python 2 存储的 datetime、date 和 time 实例时，请使用 encoding=&#39;latin1&#39;。 如果 buffers 为 None（默认值），则反序列化所需的所有数据都必须包含在 pickle 流中。这意味着在实例化 Pickler 时（或调用 dump() 或 dumps() 时），参数 buffer_callback 为 None。 如果 buffers 不为 None，则每次 pickle 流引用 带外 缓冲区视图时，消耗的对象都应该是可迭代的启用缓冲区的对象。这样的缓冲区应该按顺序地提供给 Pickler 对象的 buffer_callback 方法。 在 3.8 版更改: 加入了 buffers 参数。 load() 从构造函数中指定的文件对象里读取封存好的对象，重建其中特定对象的层次结构并返回。封存对象以外的其他字节将被忽略。 persistent_load(pid) 默认抛出 UnpicklingError 异常。如果定义了此方法，persistent_load() 应当返回持久化 ID pid 所指定的对象。 如果遇到无效的持久化 ID，则应当引发 UnpicklingError。参阅 持久化外部对象 获取详情和使用示例。 find_class(module, name) 如有必要，导入 module 模块并返回其中名叫 name 的对象，其中 module 和 name 参数都是 str 对象。注意，不要被这个函数的名字迷惑， find_class() 同样可以用来导入函数。子类可以重载此方法，来控制加载对象的类型和加载对象的方式，从而尽可能降低安全风险。参阅 限制全局变量 获取更详细的信息。引发一个 审核事件 pickle.find_class 附带参数 module、name。 PickleBufferclass pickle.PickleBuffer(buffer) 缓冲区的包装器 (wrapper)，缓冲区中包含着可封存的数据。buffer 必须是一个 buffer-providing 对象，比如 bytes-like object 或多维数组。 PickleBuffer 本身就可以生成缓冲区对象，因此可以将其传递给需要缓冲区生成器的其他 API，比如 memoryview。 PickleBuffer 对象只能用 pickle 版本 5 及以上协议进行序列化。它们符合 带外序列化 的条件。 3.8 新版功能. raw() 返回该缓冲区底层内存区域的 memoryview。 返回的对象是一维的、C 连续布局的 memoryview，格式为 B (无符号字节)。 如果缓冲区既不是 C 连续布局也不是 Fortran 连续布局的，则抛出 BufferError 异常。 release() 释放由 PickleBuffer 占用的底层缓冲区。 可以被封存/解封的对象下列类型可以被封存： None、True 和 False 整数、浮点数、复数 str、byte、bytearray 只包含可封存对象的集合，包括 tuple、list、set 和 dict 定义在模块最外层的函数（使用 def 定义，lambda 函数则不可以） 定义在模块最外层的内置函数 定义在模块最外层的类 某些类实例，这些类的 __dict__ 属性值或 __getstate__() 函数的返回值可以被封存（详情参阅 封存类实例 这一段）。 尝试封存不能被封存的对象会抛出 PicklingError 异常，异常发生时，可能有部分字节已经被写入指定文件中。尝试封存递归层级很深的对象时，可能会超出最大递归层级限制，此时会抛出 RecursionError 异常，可以通过 sys.setrecursionlimit() 调整递归层级，不过请谨慎使用这个函数，因为可能会导致解释器崩溃。 注意 函数封存 函数（内置函数或用户自定义函数）在被封存时，引用的是函数全名。2 这意味着只有函数所在的模块名，与函数名会被封存，函数体及其属性不会被封存。因此，在解封的环境中，函数所属的模块必须是可以被导入的，而且模块必须包含这个函数被封存时的名称，否则会抛出异常。 类封存 类也只封存名称，所以在解封环境中也有和函数相同的限制。注意，类体及其数据不会被封存，所以在下面的例子中类属性 attr 不会存在于解封后的环境中： 1234class Foo: attr = 'A class attribute'picklestring = pickle.dumps(Foo) 类的实例封存 在封存类的实例时，其类体和类数据不会跟着实例一起被封存，只有实例数据会被封存。这样设计是有目的的，在将来修复类中的错误、给类增加方法之后，仍然可以载入原来版本类实例的封存数据来还原该实例。如果你准备长期使用一个对象，可能会同时存在较多版本的类体，可以为对象添加版本号，这样就可以通过类的 __setstate__() 方法将老版本转换成新版本 封存类实例 通常，使一个实例可被封存不需要附加任何代码。Pickle 默认会通过 Python 的内省机制获得实例的类及属性。而当实例解封时，它的 __init__() 方法通常 不会 被调用。其默认动作是：先创建一个未初始化的实例，然后还原其属性，下面的代码展示了这种行为的实现机制： 1234567def save(obj): return (obj.__class__, obj.__dict__)def load(cls, attributes): obj = cls.__new__(cls) obj.__dict__.update(attributes) return obj 类可以改变默认行为，只需定义以下一种或几种特殊方法： object.__getnewargs_ex__() 对于使用第 2 版或更高版协议的 pickle，实现了 __getnewargs_ex__() 方法的类可以控制在解封时传给 __new__() 方法的参数。本方法必须返回一对 (args, kwargs) 用于构建对象，其中 args 是表示位置参数的 tuple，而 kwargs 是表示命名参数的 dict。它们会在解封时传递给 __new__() 方法。如果类的 __new__() 方法只接受关键字参数，则应当实现这个方法。否则，为了兼容性，更推荐实现 __getnewargs__() 方法。在 3.6 版更改: __getnewargs_ex__() 现在可用于第 2 和第 3 版协议。 object.__getnewargs__() 这个方法与上一个 __getnewargs_ex__() 方法类似，但仅支持位置参数。它要求返回一个 tuple 类型的 args，用于解封时传递给 __new__() 方法。如果定义了 __getnewargs_ex__()，那么 __getnewargs__() 就不会被调用。在 3.6 版更改: 在 Python 3.6 前，第 2、3 版协议会调用 __getnewargs__()，更高版本协议会调用 __getnewargs_ex__()。 object.__getstate__() 类还可以进一步控制其实例的封存过程。如果类定义了 __getstate__()，它就会被调用，其返回的对象是被当做实例内容来封存的，否则封存的是实例的 dict。如果 __getstate__() 未定义，实例的 __dict__ 会被照常封存。 object.__setstate__(state) 当解封时，如果类定义了 __setstate__()，就会在已解封状态下调用它。此时不要求实例的 state 对象必须是 dict。没有定义此方法的话，先前封存的 state 对象必须是 dict，且该 dict 内容会在解封时赋给新实例的 dict。 ==备注==： 如果 __getstate__() 返回 False，那么在解封时就不会调用 __setstate__() 方法。 object.__reduce__() 该接口当前定义如下。__reduce__() 方法不带任何参数，并且应返回字符串或最好返回一个元组（返回的对象通常称为“reduce 值”）。如果返回字符串，该字符串会被当做一个全局变量的名称。它应该是对象相对于其模块的本地名称，pickle 模块会搜索模块命名空间来确定对象所属的模块。这种行为常在单例模式使用。如果返回的是元组，则应当包含 2 到 6 个元素，可选元素可以省略或设置为 None。每个元素代表的意义如下：一个可调用对象，该对象会在创建对象的最初版本时调用。可调用对象的参数，是一个元组。如果可调用对象不接受参数，必须提供一个空元组。可选元素，用于表示对象的状态，将被传给前述的 __setstate__() 方法。 如果对象没有此方法，则这个元素必须是字典类型，并会被添加至 __dict__ 属性中。可选元素，一个返回连续项的迭代器（而不是序列）。这些项会被 obj.append(item) 逐个加入对象，或被 obj.extend(list_of_items) 批量加入对象。这个元素主要用于 list 的子类，也可以用于那些正确实现了 append() 和 extend() 方法的类。（具体是使用 append() 还是 extend() 取决于 pickle 协议版本以及待插入元素的项数，所以这两个方法必须同时被类支持。）可选元素，一个返回连续键值对的迭代器（而不是序列）。这些键值对将会以 obj[key] = value 的方式存储于对象中。该元素主要用于 dict 子类，也可以用于那些实现了 __setitem__() 的类。可选元素，一个带有 (obj, state) 签名的可调用对象。该可调用对象允许用户以编程方式控制特定对象的状态更新行为，而不是使用 obj 的静态 __setstate__() 方法。如果此处不是 None，则此可调用对象的优先级高于 obj 的 __setstate__()。3.8 新版功能: 新增了元组的第 6 项，可选元素 (obj, state)。 object.__reduce_ex__(protocol) 作为替代选项，也可以实现 __reduce_ex__() 方法。 此方法的唯一不同之处在于它应接受一个整型参数用于指定协议版本。 如果定义了这个函数，则会覆盖 __reduce__() 的行为。 此外，__reduce__() 方法会自动成为扩展版方法的同义词。 这个函数主要用于为以前的 Python 版本提供向后兼容的 reduce 值。 持久化外部对象为了获取对象持久化的利益， pickle 模块支持引用已封存数据流之外的对象。 这样的对象是通过一个持久化 ID 来引用的，它应当是一个由字母数字类字符组成的字符串 (对于第 0 版协议) 5 或是一个任意对象 (用于任意新版协议)。 pickle 模块不提供对持久化 ID 的解析工作，它将解析工作分配给用户定义的方法，分别是 pickler 中的 persistent_id() 方法和 unpickler 中的 persistent_load() 方法。 要通过持久化 ID 将外部对象封存，必须在 pickler 中实现 persistent_id() 方法，该方法接受需要被封存的对象作为参数，返回一个 None 或返回该对象的持久化 ID。如果返回 None，该对象会被按照默认方式封存为数据流。如果返回字符串形式的持久化 ID，则会封存这个字符串并加上一个标记，这样 unpickler 才能将其识别为持久化 ID。 要解封外部对象，Unpickler 必须实现 persistent_load() 方法，接受一个持久化 ID 对象作为参数并返回一个引用的对象。 下面是一个全面的例子，展示了如何使用持久化 ID 来封存外部对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# Simple example presenting how persistent ID can be used to pickle# external objects by reference.import pickleimport sqlite3from collections import namedtuple# Simple class representing a record in our database.MemoRecord = namedtuple("MemoRecord", "key, task")class DBPickler(pickle.Pickler): def persistent_id(self, obj): # Instead of pickling MemoRecord as a regular class instance, we emit a # persistent ID. if isinstance(obj, MemoRecord): # Here, our persistent ID is simply a tuple, containing a tag and a # key, which refers to a specific record in the database. return ("MemoRecord", obj.key) else: # If obj does not have a persistent ID, return None. This means obj # needs to be pickled as usual. return Noneclass DBUnpickler(pickle.Unpickler): def __init__(self, file, connection): super().__init__(file) self.connection = connection def persistent_load(self, pid): # This method is invoked whenever a persistent ID is encountered. # Here, pid is the tuple returned by DBPickler. cursor = self.connection.cursor() type_tag, key_id = pid if type_tag == "MemoRecord": # Fetch the referenced record from the database and return it. cursor.execute("SELECT * FROM memos WHERE key=?", (str(key_id),)) key, task = cursor.fetchone() return MemoRecord(key, task) else: # Always raises an error if you cannot return the correct object. # Otherwise, the unpickler will think None is the object referenced # by the persistent ID. raise pickle.UnpicklingError("unsupported persistent object")def main(): import io import pprint # Initialize and populate our database. conn = sqlite3.connect(":memory:") cursor = conn.cursor() cursor.execute("CREATE TABLE memos(key INTEGER PRIMARY KEY, task TEXT)") tasks = ( 'give food to fish', 'prepare group meeting', 'fight with a zebra', ) for task in tasks: cursor.execute("INSERT INTO memos VALUES(NULL, ?)", (task,)) # Fetch the records to be pickled. cursor.execute("SELECT * FROM memos") memos = [MemoRecord(key, task) for key, task in cursor] # Save the records using our custom DBPickler. file = io.BytesIO() DBPickler(file).dump(memos) print("Pickled records:") pprint.pprint(memos) # Update a record, just for good measure. cursor.execute("UPDATE memos SET task='learn italian' WHERE key=1") # Load the records from the pickle data stream. file.seek(0) memos = DBUnpickler(file, conn).load() print("Unpickled records:") pprint.pprint(memos)if __name__ == '__main__': main() 自定义封存 Dispatch 表如果想对某些类进行自定义封存，而又不想在类中增加用于封存的代码，就可以创建带有特殊 dispatch 表的 pickler。 在 copyreg 模块的 copyreg.dispatch_table 中定义了全局 dispatch 表。因此，可以使用 copyreg.dispatch_table 修改后的副本作为自有 dispatch 表。 例如 1234f = io.BytesIO()p = pickle.Pickler(f)p.dispatch_table = copyreg.dispatch_table.copy()p.dispatch_table[SomeClass] = reduce_SomeClass 创建了一个带有自有 dispatch 表的 pickle.Pickler 实例，它可以对 SomeClass 类进行特殊处理。另外，下列代码 12345class MyPickler(pickle.Pickler): dispatch_table = copyreg.dispatch_table.copy() dispatch_table[SomeClass] = reduce_SomeClassf = io.BytesIO()p = MyPickler(f) 完成了相同的操作，但所有 MyPickler 的实例都会共用同一份 dispatch 表。使用 copyreg 模块实现的等效代码是 123copyreg.pickle(SomeClass, reduce_SomeClass)f = io.BytesIO()p = pickle.Pickler(f) 处理有状态的对象 下面的示例展示了如何修改类在封存时的行为。其中 TextReader 类打开了一个文本文件，每次调用其 readline() 方法则返回行号和该行的字符。 在封存这个 TextReader 的实例时，除了 文件对象，其他属性都会被保存。 当解封实例时，需要重新打开文件，然后从上次的位置开始继续读取。实现这些功能需要实现 __setstate__() 和 __getstate__() 方法。 123456789101112131415161718192021222324252627282930313233343536class TextReader: """Print and number lines in a text file.""" def __init__(self, filename): self.filename = filename self.file = open(filename) self.lineno = 0 def readline(self): self.lineno += 1 line = self.file.readline() if not line: return None if line.endswith('\n'): line = line[:-1] return "%i: %s" % (self.lineno, line) def __getstate__(self): # Copy the object's state from self.__dict__ which contains # all our instance attributes. Always use the dict.copy() # method to avoid modifying the original state. state = self.__dict__.copy() # Remove the unpicklable entries. del state['file'] return state def __setstate__(self, state): # Restore instance attributes (i.e., filename and lineno). self.__dict__.update(state) # Restore the previously opened file's state. To do so, we need to # reopen it and read from it until the line count is restored. file = open(self.filename) for _ in range(self.lineno): file.readline() # Finally, save the file. self.file = file 使用方法如下所示： 12345678&gt;&gt;&gt; reader = TextReader("hello.txt")&gt;&gt;&gt; reader.readline()'1: Hello world!'&gt;&gt;&gt; reader.readline()'2: I am line number two.'&gt;&gt;&gt; new_reader = pickle.loads(pickle.dumps(reader))&gt;&gt;&gt; new_reader.readline()'3: Goodbye!' 除了Dispatcher,类型和函数及其他对象自定义规约 有时，dispatch_table 可能不够灵活。 特别是当我们想要基于对象类型以外的其他规则来对封存进行定制，或是当我们想要对函数和类的封存进行定制的时候。 对于那些情况，可能要基于 Pickler 类进行子类化并实现 reducer_override() 方法。 此方法可返回任意的归约元组 (参见 __reduce__())。 它也可以选择返回 NotImplemented 来回退到传统行为。 如果同时定义了 dispatch_table 和 reducer_override()，则 reducer_override() 方法具有优先权。 注解：出于性能理由，可能不会为以下对象调用 reducer_override(): None, True, False, 以及 int, float, bytes, str, dict, set, frozenset, list 和 tuple 的具体实例。 以下是一个简单的例子，其中我们允许封存并重新构建一个给定的类: 123456789101112131415161718192021222324252627import ioimport pickleclass MyClass: my_attribute = 1class MyPickler(pickle.Pickler): def reducer_override(self, obj): """Custom reducer for MyClass.""" if getattr(obj, "__name__", None) == "MyClass": return type, (obj.__name__, obj.__bases__, &#123;'my_attribute': obj.my_attribute&#125;) else: # For any other object, fallback to usual reduction return NotImplementedf = io.BytesIO()p = MyPickler(f)p.dump(MyClass)del MyClassunpickled_class = pickle.loads(f.getvalue())assert isinstance(unpickled_class, type)assert unpickled_class.__name__ == "MyClass"assert unpickled_class.my_attribute == 1 外部缓冲区在某些场景中，pickle 模块会被用来传输海量的数据。 因此，最小化内存复制次数以保证性能和节省资源是很重要的。 但是 pickle 模块的正常运作会将图类对象结构转换为字节序列流，因此在本质上就要从封存流中来回复制数据。 如果 provider (待传输对象类型的实现) 和 consumer (通信系统的实现) 都支持 pickle 第 5 版或更高版本所提供的外部传输功能，则此约束可以被撤销。 提供方API大的待封存数据对象必须实现协议 5 及以上版本专属的 __reduce_ex__() 方法，该方法将为任意大的数据返回一个 PickleBuffer 实例（而不是 bytes 对象等）。 PickleBuffer 对象会 表明 底层缓冲区可被用于外部数据传输。 那些对象仍将保持与 pickle 模块的正常用法兼容。 但是，使用方也可以选择告知 pickle 它们将自行处理那些缓冲区。 使用方API当序列化一个对象图时，通信系统可以启用对所生成 PickleBuffer 对象的定制处理。 发送端需要传递 buffer_callback 参数到 Pickler (或是到 dump() 或 dumps() 函数)，该回调函数将在封存对象图时附带每个所生成的 PickleBuffer 被调用。 由 buffer_callback 所累积的缓冲区的数据将不会被拷贝到 pickle 流，而是仅插入一个简单的标记。 接收端需要传递 buffers 参数到 Unpickler (或是到 load() 或 loads() 函数)，其值是一个由缓冲区组成的可迭代对象，它会被传递给 buffer_callback。 该可迭代对象应当按其被传递给 buffer_callback 时的顺序产生缓冲区。 这些缓冲区将提供对象重构造器所期望的数据，对这些数据的封存产生了原本的 PickleBuffer 对象。 在发送端和接受端之间，通信系统可以自由地实现它自己用于外部缓冲区的传输机制。 潜在的优化包括使用共享内存或基于特定数据类型的压缩等。 实例:下面是一个小例子，在其中我们实现了一个 bytearray 的子类，能够用于外部缓冲区封存: 1234567891011121314151617181920class ZeroCopyByteArray(bytearray): def __reduce_ex__(self, protocol): if protocol &gt;= 5: return type(self)._reconstruct, (PickleBuffer(self),), None else: # PickleBuffer is forbidden with pickle protocols &lt;= 4. return type(self)._reconstruct, (bytearray(self),) @classmethod def _reconstruct(cls, obj): with memoryview(obj) as m: # Get a handle over the original buffer object obj = m.obj if type(obj) is cls: # Original buffer object is a ZeroCopyByteArray, return it # as-is. return obj else: return cls(obj) 重构造器 (_reconstruct 类方法) 会在缓冲区的提供对象具有正确类型时返回该对象。 在此小示例中这是模拟零拷贝行为的便捷方式。 在使用方，我们可以按通常方式封存那些对象，它们在反序列化时将提供原始对象的一个副本: 12345b = ZeroCopyByteArray(b"abc")data = pickle.dumps(b, protocol=5)new_b = pickle.loads(data)print(b == new_b) # Trueprint(b is new_b) # False: a copy was made 但是如果我们传入 buffer_callback 然后在反序列化时给回累积的缓冲区，我们就能够取回原始对象: 123456b = ZeroCopyByteArray(b"abc")buffers = []data = pickle.dumps(b, protocol=5, buffer_callback=buffers.append)new_b = pickle.loads(data, buffers=buffers)print(b == new_b) # Trueprint(b is new_b) # True: no copy was made 这个例子受限于 bytearray 会自行分配内存这一事实：你无法基于另一个对象的内存创建 bytearray 的实例。 但是，第三方数据类型例如 NumPy 数组则没有这种限制，允许在单独进程或系统间传输时使用零拷贝的封存（或是尽可能少地拷贝） 。 参见：PEP 574 – 带有外部数据缓冲区的 pickle 协议 5 限制全局变量默认情况下，解封将会导入在 pickle 数据中找到的任何类或函数。 对于许多应用来说，此行为是不可接受的，因为它会允许解封器导入并发起调用任意代码。 只须考虑当这个手工构建的 pickle 数据流被加载时会做什么: 1234&gt;&gt;&gt; import pickle&gt;&gt;&gt; pickle.loads(b"cos\nsystem\n(S'echo hello world'\ntR.")hello world0 在这个例子里，解封器导入 os.system() 函数然后应用字符串参数 “echo hello world”。 虽然这个例子不具攻击性，但是不难想象别人能够通过此方式对你的系统造成损害。 出于这样的理由，你可能会希望通过定制 Unpickler.find_class() 来控制要解封的对象。 与其名称所提示的不同，Unpickler.find_class() 会在执行对任何全局对象（例如一个类或一个函数）的请求时被调用。 因此可以完全禁止全局对象或是将它们限制在一个安全的子集中。 下面的例子是一个解封器，它只允许某一些安全的来自 builtins 模块的类被加载: 12345678910111213141516171819202122232425import builtinsimport ioimport picklesafe_builtins = &#123; 'range', 'complex', 'set', 'frozenset', 'slice',&#125;class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): # Only allow safe classes from builtins. if module == "builtins" and name in safe_builtins: return getattr(builtins, name) # Forbid everything else. raise pickle.UnpicklingError("global '%s.%s' is forbidden" % (module, name))def restricted_loads(s): """Helper function analogous to pickle.loads().""" return RestrictedUnpickler(io.BytesIO(s)).load() 我们这个解封器的一个示例用法所达成的目标: 123456789101112&gt;&gt;&gt; restricted_loads(pickle.dumps([1, 2, range(15)]))[1, 2, range(0, 15)]&gt;&gt;&gt; restricted_loads(b"cos\nsystem\n(S'echo hello world'\ntR.")Traceback (most recent call last): ...pickle.UnpicklingError: global 'os.system' is forbidden&gt;&gt;&gt; restricted_loads(b'cbuiltins\neval\n'... b'(S\'getattr(__import__("os"), "system")'... b'("echo hello world")\'\ntR.')Traceback (most recent call last): ...pickle.UnpicklingError: global 'builtins.eval' is forbidden 正如我们这个例子所显示的，对于允许解封的对象你必须要保持谨慎。 因此如果要保证安全，你可以考虑其他选择例如 xmlrpc.client 中的编组 API 或是第三方解决方案。 性能较新版本的 pickle 协议（第 2 版或更高）具有针对某些常见特性和内置类型的高效二进制编码格式。 此外，pickle 模块还拥有一个以 C 编写的透明优化器。 实例 对于最简单的代码，请使用 dump() 和 load() 函数。 123456789101112import pickle# An arbitrary collection of objects supported by pickle.data = &#123; 'a': [1, 2.0, 3, 4+6j], 'b': ("character string", b"byte string"), 'c': &#123;None, True, False&#125;&#125;with open('data.pickle', 'wb') as f: # Pickle the 'data' dictionary using the highest protocol available. pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) 以下示例读取之前封存的数据。 123456import picklewith open('data.pickle', 'rb') as f: # The protocol version used is detected automatically, so we do not # have to specify it. data = pickle.load(f)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>pickle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library array type]]></title>
    <url>%2F2020%2F01%2F13%2Fpython-standard-library-array-type%2F</url>
    <content type="text"><![CDATA[每日一词: underdog 英 [ˈʌndədɒg] 美 [ˈʌndərdɔg] n.失败者； 退居下风的人； 受压迫者； 打败了的选手 复数： underdogs 这个词来自1887年出现，原指在斗狗比赛中战败的狗。后来词义引申至人，指的是各类竞赛和对碰中不被看好的一方，或是指处在逆境中的人和团体。 被看好的一方，即Topdog，从来不缺喝彩和支持。而Underdog的路则注定孤独许多。不被人看好，较少人支持。 所幸的是，正如倪匡先生感言：太多的时候，孤独最好。 若能与孤独为师,又何须担心underdog呢？ python 标准库学习 array此模块定义了一种对象类型，可以紧凑地表示基本类型值的数组：字符、整数、浮点数等。 数组属于序列类型，其行为与列表非常相似，不同之处在于其中存储的对象类型是受限的。 类型在对象创建时使用单个字符的 类型码 来指定。 已定义的类型码如下： 类型码 C 类型 Python 类型 以字节表示的最小尺寸 注释 &#39;b&#39; signed char int 1 &#39;B&#39; unsigned char int 1 &#39;u&#39; Py_UNICODE Unicode 字符 2 (1) &#39;h&#39; signed short int 2 &#39;H&#39; unsigned short int 2 &#39;i&#39; signed int int 2 &#39;I&#39; 无符号整型 int 2 &#39;l&#39; signed long int 4 &#39;L&#39; 无符号长整型 int 4 &#39;q&#39; signed long long int 8 &#39;Q&#39; 无符号 long long int 8 &#39;f&#39; float float 4 &#39;d&#39; double float 8 ==注释== ‘u’类型码在python3已经被废除,默认python的字符串就是unicode字符 类 class array.array(typecode[, initializer]) 一个包含由 typecode 限制类型的条目的新数组，并由可选的 initializer 值进行初始化，该值必须为一个列表、bytes-like object 或包含正确类型元素的可迭代对象。如果给定一个列表或字符串，该 initializer 会被传给新数组的 fromlist(), frombytes() 或 fromunicode() 方法（见下文）以将初始条目添加到数组中。 否则会将可迭代对象作为 initializer 传给 extend() 方法。引发一个 审核事件 array.__new__ 附带参数 typecode, initializer。 属性 array.typecodes 包含所有可用类型码的字符串。 123&gt;&gt;&gt; import array&gt;&gt;&gt; array.typecodes&apos;bBuhHiIlLqQfd&apos; 数组对象支持普通的序列操作如索引、切片、拼接和重复等。 当使用切片赋值时，所赋的值必须为具有相同类型码的数组对象；所有其他情况都将引发 TypeError。 数组对象也实现了缓冲区接口，可以用于所有支持 字节类对象 的场合。 函数以下数据项和方法也受到支持： array.typecode 用于创建数组的类型码字符。 array.itemsize 在内部表示中一个数组项的字节长度。 array.append(x) 添加一个值为 x 的新项到数组末尾。 array.buffer_info() 返回一个元组 (address, length) 以给出用于存放数组内容的缓冲区元素的当前内存地址和长度。 以字节表示的内存缓冲区大小可通过 array.buffer_info()[1] * array.itemsize 来计算。 这在使用需要内存地址的低层级（因此不够安全） I/O 接口时会很有用，例如某些 ioctl() 操作。 只要数组存在并且没有应用改变长度的操作，返回数值就是有效的。注解 当在 C 或 C++ 编写的代码中使用数组对象时（这是有效使用此类信息的唯一方式），使用数组对象所支持的缓冲区接口更为适宜。 此方法仅保留用作向下兼容，应避免在新代码中使用。 缓冲区接口的文档参见 缓冲协议。 array.byteswap() “字节对调”所有数组项。 此方法只支持大小为 1, 2, 4 或 8 字节的值；对于其他值类型将引发 RuntimeError。 它适用于从不同字节序机器所生成的文件中读取数据的情况。 array.count(x) 返回 x 在数组中的出现次数。 array.extend(iterable) 将来自 iterable 的项添加到数组末尾。 如果 iterable 是另一个数组，它必须具有 完全 相同的类型码；否则将引发 TypeError。 如果 iterable 不是一个数组，则它必须为可迭代对象并且其元素必须为可添加到数组的适当类型。 array.frombytes(s) 添加来自字符串的项，将字符串解读为机器值的数组（相当于使用 fromfile() 方法从文件中读取数据）。3.2 新版功能: fromstring() 重命名为 frombytes() 以使其含义更清晰。 array.fromfile(f, n) 从 file object f 中读取 n 项（解读为机器值）并将它们添加到数组末尾。 如果可读取数据少于 n 项则将引发 EOFError，但有效的项仍然会被插入数组。 f 必须为一个真实的内置文件对象；不支持带有 read() 方法的其它对象。 array.fromlist(list) 添加来自 list 的项。 这等价于 for x in list: a.append(x)，区别在于如果发生类型错误，数组将不会被改变。 array.fromstring() frombytes() 的已弃用别名。Deprecated since version 3.2, will be removed in version 3.9. array.fromunicode(s) 使用来自给定 Unicode 字符串的数组扩展数组。 数组必须是类型为 &#39;u&#39; 的数组；否则将引发 ValueError。 请使用 array.frombytes(unicodestring.encode(enc)) 来将 Unicode 数据添加到其他类型的数组。 array.index(x) 返回最小的 i 使得 i 为 x 在数组中首次出现的序号。 array.insert(i, x) 将值 x 作为新项插入数组的 i 位置之前。 负值将被视为相对于数组末尾的位置。 array.pop([i]) 从数组中移除序号为 i 的项并将其返回。 可选参数值默认为 -1，因此默认将移除并返回末尾项。 array.remove(x) 从数组中移除首次出现的 x。 array.reverse() 反转数组中各项的顺序。 array.tobytes() 将数组转换为一个机器值数组并返回其字节表示（即相当与通过 tofile() 方法写入到文件的字节序列。）3.2 新版功能: tostring() 被重命名为 tobytes() 以使其含义更清晰。 array.tofile(f) 将所有项（作为机器值）写入到 file object f。 array.tolist() 将数组转换为包含相同项的普通列表。 array.tostring() tobytes() 的已弃用别名。Deprecated since version 3.2, will be removed in version 3.9. array.tounicode() 将数组转换为一个 Unicode 字符串。 数组必须是类型为 &#39;u&#39; 的数组；否则将引发 ValueError。 请使用 array.tobytes().decode(enc) 来从其他类型的数组生成 Unicode 字符串。 当一个数组对象被打印或转换为字符串时，它会表示为 array(typecode, initializer)。 如果数组为空则 initializer 会被省略，否则如果 typecode 为 &#39;u&#39; 则它是一个字符串，否则它是一个数字列表。 使用 eval() 保证能将字符串转换回具有相同类型和值的数组，只要 array 类已通过 from array import array 被引入。 例如: 12345from array import arrayarray('l')array('u', 'hello \u2641')array('l', [1, 2, 3, 4, 5])array('d', [1.0, 2.0, 3.14]) 更高效数组处理的可以详见 numpy 库 总结原来python标准库里就有专门操作array对象的方法,这里我理解array和list的区别在于,list里包含的元素可以是任意数据类型,处理数据的时候不是很方便,而array里的数据类型是一致的,这样处理数据效率更高。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library collections.abc]]></title>
    <url>%2F2020%2F01%2F12%2Fpython-standard-library-collections-abc%2F</url>
    <content type="text"><![CDATA[python 标准库 之 collections.abc每日一词: wrong adj. 不道德的, 不正当的, 不义的 不确实的, 不正确的, 错误的 不合要求的, 不适合的, 并非合意的 有故障, 有毛病 adv. 方式或方向错误地; 错误地; 结果错误地 n. 罪过, 过失, 罪恶 不义的行为, 不公正的事 时 态: wronged, wronging, wrongs名 词: wronger副 词: wrongly名 词: wrongness 词语： confound right and wrong 混淆是非，黑白不分 get one wrong 误会某人；误会 right or wrongadv. 不管如何 something wrong with …出了毛病；…有问题；…不对头 python 标准库学习之 抽象基类 collection.abc众所周知,python3中所有类默认继承自object类,意味着父类中所有的方法,子类都继承了。 我个人理解,抽象基类是无法被实例化的,只能子类实现 参考文档 源代码： Lib/_collections_abc.py 该模块定义了一些 抽象基类，它们可用于判断一个具体类是否具有某一特定的接口；例如，这个类是否可哈希，或其是否为映射类。 模块里方法一览,摘自源码 12345678910__all__ = ["Awaitable", "Coroutine", "AsyncIterable", "AsyncIterator", "AsyncGenerator", "Hashable", "Iterable", "Iterator", "Generator", "Reversible", "Sized", "Container", "Callable", "Collection", "Set", "MutableSet", "Mapping", "MutableMapping", "MappingView", "KeysView", "ItemsView", "ValuesView", "Sequence", "MutableSequence", "ByteString", ] 容器抽象基类 这个容器模块提供了以下 ABCs: 抽象基类 继承自 抽象方法 Mixin 方法 Container __contains__ Hashable __hash__ Iterable __iter__ Iterator Iterable __next__ __iter__ Reversible Iterable __reversed__ Generator Iterator send, throw close, __iter__, __next__ Sized __len__ Callable __call__ Collection Sized, Iterable, Container __contains__, __iter__, __len__ Sequence Reversible, Collection __getitem__, __len__ __contains__, __iter__, __reversed__, index, and count MutableSequence Sequence __getitem__, __setitem__, __delitem__, __len__, insert 继承自 Sequence 的方法，以及 append, reverse, extend, pop, remove，和 __iadd__ ByteString Sequence __getitem__, __len__ 继承自 Sequence 的方法 Set Collection __contains__, __iter__, __len__ __le__, __lt__, __eq__, __ne__, __gt__, __ge__, __and__, __or__, __sub__, __xor__, and isdisjoint MutableSet Set __contains__, __iter__, __len__, add, discard 继承自 Set 的方法以及 clear, pop, remove, __ior__, __iand__, __ixor__，和 __isub__ Mapping Collection __getitem__, __iter__, __len__ __contains__, keys, items, values, get, __eq__, and __ne__ MutableMapping Mapping __getitem__, __setitem__, __delitem__, __iter__, __len__ 继承自 Mapping 的方法以及 pop, popitem, clear, update，和 setdefault MappingView Sized __len__ ItemsView MappingView, Set __contains__, __iter__ KeysView MappingView, Set __contains__, __iter__ ValuesView MappingView, Collection __contains__, __iter__ Awaitable __await__ Coroutine Awaitable send, throw close AsyncIterable __aiter__ AsyncIterator AsyncIterable __anext__ __aiter__ AsyncGenerator AsyncIterator asend, athrow aclose, __aiter__, __anext__ 类 class collections.abc.Container class collections.abc.Hashable class collections.abc.Sized class collections.abc.Callable 分别提供了 __contains__(), __hash__(), __len__() 和 __call__() 方法的抽象基类。 class collections.abc.Iterable 提供了 __iter__() 方法的抽象基类。使用 isinstance(obj, Iterable) 可以检测一个类是否已经注册到了 Iterable 或者实现了 __iter__() 函数，但是无法检测这个类是否能够使用 __getitem__() 方法进行迭代。检测一个对象是否是 iterable 的唯一可信赖的方法是调用 iter(obj)。 class collections.abc.Collection 集合了 Sized 和 Iterable 类的抽象基类。 class collections.abc.Iterator 提供了 __iter__() 和 __next__() 方法的抽象基类。参见 iterator 的定义。 class collections.abc.Reversible 为可迭代类提供了 __reversed__() 方法的抽象基类。3.6 新版功能. class collections.abc.Generator 生成器类，实现了 PEP 342 中定义的协议，继承并扩展了迭代器，提供了 send(), throw() 和 close() 方法。参见 generator 的定义。3.5 新版功能. class collections.abc.Sequence class collections.abc.MutableSequence class collections.abc.ByteString 只读且可变的序列 sequences 的抽象基类。实现笔记：一些混入（Maxin）方法比如 __iter__(), __reversed__() 和 index() 会重复调用底层的 __getitem__() 方法。因此，如果实现的 __getitem__() 是常数级访问速度，那么相应的混入方法会有一个线性的表现；然而，如果底层方法是线性实现（例如链表），那么混入方法将会是平方级的表现，这也许就需要被重构了。在 3.5 版更改: index() 方法支持 stop 和 start 参数。 class collections.abc.Set class collections.abc.MutableSet 只读且可变的集合的抽象基类。 class collections.abc.Mapping class collections.abc.MutableMapping 只读且可变的映射 mappings 的抽象基类。 class collections.abc.MappingView class collections.abc.ItemsView class collections.abc.KeysView class collections.abc.ValuesView 映射及其键和值的视图 views 的抽象基类。 class collections.abc.Awaitable 为可等待对象 awaitable 提供的类，可以被用于 await 表达式中。习惯上必须实现 __await__() 方法。协程对象 Coroutine 和 Coroutine 抽象基类的实例都是这个抽象基类的实例。 class collections.abc.Coroutine 用于协程兼容类的抽象基类。实现了如下定义在 协程对象: 里的方法： send()，throw() 和 close()。通常的实现里还需要实现 __await__() 方法。所有的 Coroutine 实例都必须是 Awaitable 实例。参见 coroutine 的定义。注解 在 CPython 里，基于生成器的协程（使用 types.coroutine() 或 asyncio.coroutine() 包装的生成器）都是 可等待对象，即使他们不含有 __await__() 方法。使用 isinstance(gencoro, Coroutine) 来检测他们会返回 False。要使用 inspect.isawaitable() 来检测他们。 class collections.abc.AsyncIterable 提供了 __aiter__ 方法的抽象基类。参见 asynchronous iterable 的定义。3.5 新版功能. class collections.abc.AsyncIterator 提供了 __aiter__ 和 __anext__ 方法的抽象基类。参见 asynchronous iterator 的定义。3.5 新版功能. class collections.abc.AsyncGenerator 为异步生成器类提供的抽象基类，这些类实现了定义在 PEP 525 和 PEP 492 里的协议。 这些抽象基类让我们可以确定类和示例拥有某些特定的函数，例如： 123size = Noneif isinstance(myvar, collections.abc.Sized): size = len(myvar) 有些抽象基类也可以用作混入类（mixin），这可以更容易地开发支持容器 API 的类。例如，要写一个支持完整 Set API 的类，只需要提供下面这三个方法： __contains__(), __iter__() 和 __len__()。抽象基类会补充上其余的方法，比如 __and__() 和 isdisjoint(): 123456789101112131415161718192021class ListBasedSet(collections.abc.Set): ''' Alternate set implementation favoring space over speed and not requiring the set elements to be hashable. ''' def __init__(self, iterable): self.elements = lst = [] for value in iterable: if value not in lst: lst.append(value) def __iter__(self): return iter(self.elements) def __contains__(self, value): return value in self.elements def __len__(self): return len(self.elements)s1 = ListBasedSet('abcdef')s2 = ListBasedSet('defghi')overlap = s1 &amp; s2 # The __and__() method is supported automatically 当把 Set 和 MutableSet 用作混入类时需注意： 由于某些集合操作会创建新集合，默认的混入方法需要一种从可迭代对象里创建新实例的方法。假如其类构造函数签名形如 ClassName(iterable) ，则其会调用一个内部的类方法 _from_iterable()，其中调用了 cls(iterable) 来生成一个新集合。如果这个 Set 混入类在类中被使用，但其构造函数的签名却是不同的形式，那么你就需要重载 _from_iterable() 方法，将其编写成一个类方法，并且它能够从可迭代对象参数中构造一个新实例。 重载比较符时时（想必是为了速度，因为其语义都是固定的），只需要重定义 __le__() 和 __ge__() 函数，然后其他的操作会自动跟进。 混入集合类 Set 提供了一个 _hash() 方法为集合计算哈希值，然而， __hash__() 函数却没有被定义，因为并不是所有集合都是可哈希并且不可变的。为了使用混入类为集合添加哈希能力，可以同时继承 Set() 和 Hashable() 类，然后定义 __hash__ = Set._hash。 总结我看了官方文档的描述,一头雾水。下面就我个人理解谈谈这个模块。 abc模块应用的场景 1. 判定某个对象的类型 2. 强制子类实现某些父类方法]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>collections.abc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library context-manager-types]]></title>
    <url>%2F2020%2F01%2F11%2Fpython-standard-library-context-manager-types%2F</url>
    <content type="text"><![CDATA[python 标准库 上下文管理类型每日一词: intresting : US [‘ɪntrəstɪŋ] UK [‘ɪntrəstɪŋ] adj.有趣的；有吸引力的 v.“interest”的现在分词 Web有意思的；令人感兴趣的；引人入胜的 比较级：more interesting最高级：most interesting 大部分时候,你都是一个人在默默努力,这样,距离成功才会更进一步。 ​ – 凭海临风语录 python 标准库学习 上下文管理什么是上下文管理器？上下文管理器就是一个用装饰器实现上下文协议管理的对象。主要用于保存和恢复各种全局状态,例如关闭文件等。下面我们来了解具体的内容。 函数 contextmanager.__enter__() 进入运行时上下文并返回此对象或关联到该运行时上下文的其他对象。 此方法的返回值会绑定到使用此上下文管理器的 with 语句的 as 子句中的标识符。一个返回其自身的上下文管理器的例子是 file object。 文件对象会从 enter() 返回其自身，以允许 open() 被用作 with 语句中的上下文表达式。一个返回关联对象的上下文管理器的例子是 decimal.localcontext() 所返回的对象。 此种管理器会将活动的 decimal 上下文设为原始 decimal 上下文的一个副本并返回该副本。 这允许对 with 语句的语句体中的当前 decimal 上下文进行更改，而不会影响 with 语句以外的代码。 contextmanager.__exit__(*exc_type*, *exc_val*, *exc_tb*) 退出运行时上下文并返回一个布尔值旗标来表明所发生的任何异常是否应当被屏蔽。 如果在执行 with 语句的语句体期间发生了异常，则参数会包含异常的类型、值以及回溯信息。 在其他情况下三个参数均为 None。自此方法返回一个真值将导致 with 语句屏蔽异常并继续执行紧随在 with 语句之后的语句。 否则异常将在此方法结束执行后继续传播。 在此方法执行期间发生的异常将会取代 with 语句的语句体中发生的任何异常。传入的异常绝对不应当被显式地重新引发 —— 相反地，此方法应当返回一个假值以表明方法已成功完成并且不希望屏蔽被引发的异常。 这允许上下文管理代码方便地检测 __exit__() 方法是否确实已失败。 一个文件操作实例1234&gt;&gt;&gt; with open("/etc/hosts", "r") as file:... dir(file)... ['__class__', '__delattr__', '__doc__', '__enter__', '__exit__', '__format__', '__getattribute__', '__hash__', '__init__', '__iter__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'close', 'closed', 'encoding', 'errors', 'fileno', 'flush', 'isatty', 'mode', 'name', 'newlines', 'next', 'read', 'readinto', 'readline', 'readlines', 'seek', 'softspace', 'tell', 'truncate', 'write', 'writelines', 'xreadlines'] 此时的open返回的对象file,就实现了管理打开文件、关闭文件的上下文管理协议。 with 语句上下文管理器上下文管理器 是一个对象，它定义了在执行 with 语句时要建立的运行时上下文。 上下文管理器处理进入和退出所需运行时上下文以执行代码块。 通常使用 with 语句（在 with 语句 中描述），但是也可以通过直接调用它们的方法来使用。 上下文管理器的典型用法包括保存和恢复各种全局状态，锁定和解锁资源，关闭打开的文件等等。 要了解上下文管理器的更多信息，请参阅 上下文管理器类型。 object.__enter__(self) 进入与此对象相关的运行时上下文。 with 语句将会绑定这个方法的返回值到 as 子句中指定的目标，如果有的话。 object.__exit__(self, exc_type, exc_value, traceback) 退出关联到此对象的运行时上下文。 各个参数描述了导致上下文退出的异常。 如果上下文是无异常地退出的，三个参数都将为 None。如果提供了异常，并且希望方法屏蔽此异常（即避免其被传播），则应当返回真值。 否则的话，异常将在退出此方法时按正常流程处理。请注意 __exit__() 方法不应该重新引发被传入的异常，这是调用者的责任。 可以参考 PEP 343 - “with” 语句 Python with 语句的规范描述、背景和示例。 自定义上下文管理实现__enter__ 和 __exit__ 方法就是一个实现了上下文管理的类。 12345678910111213141516171819class ContextManager(object): def __init__(self): print '__init__()' def __enter__(self): print '__enter__()' return self def __exit__(self, exc_type, exc_val, exc_tb): print "__exit__()"with ContextManager(): print "OK, we can do something here~~" #输出__init__()__enter__()OK, we can do something here~~__exit__() 另一个不返回当前类的上下文管理器的例子： 123456789101112131415161718192021222324252627282930313233class InnerContext(object): def __init__(self, obj): print 'InnerContext.__init__(%s)' % obj def do_something(self): print 'InnerContext.do_something()' def __del__(self): print 'InnerContext.__del__()'class ContextManager(object): def __init__(self): print 'ContextManager.__init__()' def __enter__(self): print 'ContextManager.__enter__()' return InnerContext(self) def __exit__(self, exc_type, exc_val, exc_tb): print "ContextManager.__exit__()"with ContextManager() as obj: obj.do_something() print "OK, we can do something here~~" #输出ContextManager.__init__()ContextManager.__enter__()InnerContext.__init__(&lt;__main__.ContextManager object at 0x1012f95d0&gt;)InnerContext.do_something()OK, we can do something here~~ContextManager.__exit__()InnerContext.__del__() 异常处理的例子 ： 1234567891011121314151617181920212223242526272829303132class ContextManager(object): def __init__(self, flag): print 'ContextManager.__init__(%s)' % flag self.flag = flag def __enter__(self): print 'ContextManager.__enter__()' return self def __exit__(self, exc_type, exc_val, exc_tb): print 'ContextManager.__exit__(%s, %s, %s)' % (exc_type, exc_val, exc_tb) return self.flagwith ContextManager(True): raise RuntimeError('error message handled')printwith ContextManager(False): raise RuntimeError('error message propagated')#输出ContextManager.__init__(True)ContextManager.__enter__()ContextManager.__exit__(&lt;type 'exceptions.RuntimeError'&gt;, error message handled, &lt;traceback object at 0x10d69dbd8&gt;)ContextManager.__init__(False)ContextManager.__enter__()ContextManager.__exit__(&lt;type 'exceptions.RuntimeError'&gt;, error message propagated, &lt;traceback object at 0x109e0fbd8&gt;)Traceback (most recent call last): File "ContextManager.py", line 19, in &lt;module&gt; raise RuntimeError('error message propagated')RuntimeError: error message propagated contextlib 模块参考文档 源代码 Lib/contextlib.py 这个内置模块实现了上下文管理,使用with关键字。 主要方法如下(节选自源码): 1234__all__ = ["asynccontextmanager", "contextmanager", "closing", "nullcontext", "AbstractContextManager", "AbstractAsyncContextManager", "AsyncExitStack", "ContextDecorator", "ExitStack", "redirect_stdout", "redirect_stderr", "suppress"] 核心类class contextlib.AbstractContextManager 同步的上下文管理类 class contextlib.AbstractAsyncContextManager 异步的上下文管理类 装饰器 `@contextlib.contextmanager` 一个实现了上下文资源管理的例子: 123456789101112131415from contextlib import contextmanager@contextmanagerdef managed_resource(*args, **kwds): # Code to acquire resource, e.g.: resource = acquire_resource(*args, **kwds) try: yield resource finally: # Code to release resource, e.g.: release_resource(resource)&gt;&gt;&gt; with managed_resource(timeout=3600) as resource:... # Resource is released at the end of this block,... # even if code in the block raises an exception ==tips== : 注意这里 返回的是generator对象，每次迭代器只会yield一个对象出来,这个值会用在with语句中,绑定到as 后的对象上。 @contextlib.asynccontextmanager` 下面是一个实现了异步上下文管理器的实例,关于操作数据库对象 12345678910111213from contextlib import asynccontextmanager@asynccontextmanagerasync def get_connection(): conn = await acquire_db_connection() try: yield conn finally: await release_db_connection(conn)async def get_all_users(): async with get_connection() as conn: return conn.query('SELECT ...') 其他方法 contextlib.closing(thing) 返回一个上下文管理对象,在语句结束之前被调用 相当于下面的实现 12345678from contextlib import contextmanager@contextmanagerdef closing(thing): try: yield thing finally: thing.close() 也可以这样实现 123456from contextlib import closingfrom urllib.request import urlopenwith closing(urlopen('http://www.python.org')) as page: for line in page: print(line) contextlib.nullcontext 返回一个上下文管理对象( 实现了__enter__方法) 一个例子 123456789def myfunction(arg, ignore_exceptions=False): if ignore_exceptions: # Use suppress to ignore all exceptions. cm = contextlib.suppress(Exception) else: # Do not ignore any exceptions, cm has no effect. cm = contextlib.nullcontext() with cm: # Do something 另一个例子 12345678910def process_file(file_or_path): if isinstance(file_or_path, str): # If string, open file cm = open(file_or_path) else: # Caller is responsible for closing file cm = nullcontext(file_or_path) with cm as file: # Perform processing on the file contextlib.suppress 返回一个声明的异常对象的上下文管理 一个例子： 1234567from contextlib import suppresswith suppress(FileNotFoundError): os.remove('somefile.tmp')with suppress(FileNotFoundError): os.remove('someotherfile.tmp') 和下面的代码等价 123456789try: os.remove('somefile.tmp')except FileNotFoundError: passtry: os.remove('someotherfile.tmp')except FileNotFoundError: pass contextlib.redirect_stdout 临时输出标准输出的上下文管理器 contextlib.redirect_stderr 临时输出标准错误的上下文管理器 class contextlib.ContextDecorator 允许一个类像装饰器那样使用,ContextDecorator 正好实现了__enter__ and __exit__ 方法。 使用contextlib就自动调用这个装饰器。 一个实例 1234567891011121314151617181920212223242526from contextlib import ContextDecoratorclass mycontext(ContextDecorator): def __enter__(self): print('Starting') return self def __exit__(self, *exc): print('Finishing') return False&gt;&gt;&gt; @mycontext()... def function():... print('The bit in the middle')...&gt;&gt;&gt; function()StartingThe bit in the middleFinishing&gt;&gt;&gt; with mycontext():... print('The bit in the middle')...StartingThe bit in the middleFinishing 其实本质上就是实现了语法糖 例如： 123def f(): with cm(): # Do stuff ContextDecorator 允许你这样使用: 123@cm()def f(): # Do stuff 允许你通过继承ContextBaseClass和ContextDecorator,实现Mixin class(我也不知道该如何翻译,姑且翻译成混合继承吧) 12345678from contextlib import ContextDecoratorclass mycontext(ContextBaseClass, ContextDecorator): def __enter__(self): return self def __exit__(self, *exc): return False class contextlib.ExitStack 一个上下文管理器可以被设计成自动合并其他上下文管理器,清除方法(栈),尤其是那些需要输入数据的功能实现。 这里我看了源码,通过一个栈结构管理上下文管理， 其实就是实现了一个上下文管理器栈 下面是一个例子: 12345with ExitStack() as stack: files = [stack.enter_context(open(fname)) for fname in filenames] # All opened files will automatically be closed at the end of # the with statement, even if attempts to open files later # in the list raise an exception 个人理解这是一个低级的api,内部实现了,你无需关心何时该调用该方法,由python内部去处理。 小结 最近恰好看flask的源码,flask的生命周期管理也是使用上下文管理装饰器实现。 等有空再更新一篇吧。 今天就到这里,祝大家周末愉快！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>context-manager-types</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard_library operator]]></title>
    <url>%2F2020%2F01%2F10%2Fpython-standard-library-operator%2F</url>
    <content type="text"><![CDATA[python 标准库 operator今天的关键词: trouble trouble [英] [ˈtrʌbl] [美] [ˈtrʌbəl] n.麻烦； 烦恼； 故障； 动乱； vi.费心； 烦恼； vt.麻烦； 使烦恼； 折磨； python 标准库学习 operatoroperator 模块提供了一套与Python的内置运算符对应的高效率函数。例如，operator.add(x, y) 与表达式 x+y 相同。 许多函数名与特殊方法名相同，只是没有双下划线。为了向后兼容性，也保留了许多包含双下划线的函数。为了表述清楚，建议使用没有双下划线的函数。 函数包含的种类有：对象的比较运算、逻辑运算、数学运算以及序列运算。 对象比较函数适用于所有的对象，函数名根据它们对应的比较运算符命名。 比较运算operator.lt(*a*, *b*) operator.le(*a*, *b*) operator.eq(*a*, *b*) operator.ne*a*, *b*) operator.ge*a*, *b*) operator.gt*a*, *b*) operator.__lt__*a*, *b*) operator.__le__*a*, *b*) operator.__eq__*a*, *b*) operator.__ne__*a*, *b*) operator.__ge__*a*, *b*) operator.__gt__*a*, *b*) 逻辑运算 operator.not_(*obj*)` operator.__not__(*obj*) 返回 not*obj* 的结果。 （请注意对象实例并没有 [not()](https://docs.python.org/zh-cn/3.8/library/operator.html#operator.__not__) 方法；只有解释器核心可定义此操作。 结果会受 [bool()](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__bool__) 和 [len()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__len__) 方法影响。） `operator.truth(obj) 如果 obj 为真值则返回 True，否则返回 False。 这等价于使用 bool 构造器。 operator.is_(*a*, *b*) 返回 a is b。 检测对象标识。 operator.is_not(*a*, *b*) 返回 a is not b。 检测对象标识。 数学运算和位运算 operator.abs(*obj*) operator.__abs__(*obj*) 返回 obj 的绝对值。 operator.add(*a*, *b*) operator.__add__(*a*, *b*) 对于数字 a 和 b，返回 a + b。 operator.and_(*a*, *b*) operator.__and__(*a*, *b*) 返回 x 和 y 按位与的结果。 operator.floordiv(*a*, *b*) operator.__floordiv__(*a*, *b*) 返回 a // b。 operator.index(*a*) operator.__index__(*a*) 返回 a 转换为整数的结果。 等价于 a.__index__()`。 operator.inv(*obj*) operator.invert(*obj*) operator.__inv__(*obj*) operator.__invert__(*obj*) 返回数字 obj 按位取反的结果。 这等价于 ~obj。 operator.lshift(*a*, *b*) operator.__lshift__(*a*, *b*) 返回 a 左移 b 位的结果。 operator.mod(*a*, *b*) operator.__mod__(*a*, *b*) 返回 a % b。 operator.mul(*a*, *b*) operator.__mul__(*a*, *b*) 对于数字 a 和 b，返回 a * b。 operator.matmul(*a*, *b*) operator.__matmul__(*a*, *b*) 返回 a @ b。 operator.neg(*obj*) operator.__neg__(*obj*) 返回 obj 取负的结果 (-obj)`。 operator.or_(*a*, *b*) operator.__or__(*a*, *b*) 返回 a 和 b 按位或的结果。 operator.pos(*obj*) operator.__pos__(*obj*) 返回 obj 取正的结果 (+obj)`。 operator.pow(*a*, *b*) operator.__pow__(*a*, *b*) 对于数字 a 和 b，返回 a ** b。 operator.rshift(*a*, *b*) operator.__rshift__(*a*, *b*) 返回 a 右移 b 位的结果。 operator.sub(*a*, *b*) operator.__sub__(*a*, *b*) 返回 a - b。 operator.truediv(*a*, *b*) operator.__truediv__(*a*, *b*) 返回 a / b 例如 2/3 将等于 .66 而不是 0。 这也被称为“真”除法。 operator.xor(*a*, *b*) operator.__xor__(*a*, *b*) 返回 a 和 b 按位异或的结果。 适用于序列的操作（其中一些也适用于映射）包括： operator.concat(*a*, *b*) operator.__concat__(*a*, *b*) 对于序列 a 和 b，返回 a + b。 operator.contains(*a*, *b*) operator.__contains__(*a*, *b*) 返回 b in a 检测的结果。 请注意操作数是反序的。 operator.countOf(*a*, *b*) 返回 b 在 a 中的出现次数。 operator.delitem(*a*, *b*) operator.__delitem__(*a*, *b*) 移除索引号 b 上的值 a。 operator.getitem(*a*, *b*) operator.__getitem__(*a*, *b*) 返回索引号 b 上的值 a。 operator.indexOf(*a*, *b*) 返回 b 在 a 中首次出现所在的索引号。 operator.setitem(*a*, *b*, *c*) operator.__setitem__(*a*, *b*, *c*) 将索引号 b 上的值 a 设为 c。 operator.length_hint(*obj*, *default=0*) 返回对象 o 的估计长度。 首先尝试返回其实际长度，再使用 object.__length_hint__() 得出估计值，最后返回默认值。 工具operator.attrgetter(*attr*) operator.attrgetter(**attrs*) 返回一个可从操作数中获取 attr 的可调用对象。 如果请求了一个以上的属性，则返回一个属性元组。 属性名称还可包含点号。 例如： 在 f = attrgetter(&#39;name&#39;) 之后，调用 f(b) 将返回 b.name。 在 f = attrgetter(&#39;name&#39;, &#39;date&#39;) 之后，调用 f(b) 将返回 (b.name, b.date)`。 在 f = attrgetter(&#39;name.first&#39;, &#39;name.last&#39;) 之后，调用 f(b) 将返回 (b.name.first, b.name.last)`。 `operator.itemgetter(item) `operator.itemgetter(*items) 返回一个使用操作数的 __getitem__() 方法从操作数中获取 item 的可调用对象。 如果指定了多个条目，则返回一个查找值的元组。 例如： 在 f = itemgetter(2) 之后，调用 f(r) 将返回 r[2]。 在 g = itemgetter(2, 5, 3) 之后，调用 g(r) 将返回 (r[2], r[5], r[3])`。 将运算符映射到函数 运算 语法 函数 加法 a + b add(a, b) 字符串拼接 seq1 + seq2 concat(seq1, seq2) 包含测试 obj in seq contains(seq, obj) 除法 a / b truediv(a, b) 除法 a // b floordiv(a, b) 按位与 a &amp; b and_(a, b) 按位异或 a ^ b xor(a, b) 按位取反 ~ a invert(a) 按位或 `a b` or_(a, b) 取幂 a ** b pow(a, b) 标识 a is b is_(a, b) 标识 a is not b is_not(a, b) 索引赋值 obj[k] = v setitem(obj, k, v) 索引删除 del obj[k] delitem(obj, k) 索引取值 obj[k] getitem(obj, k) 左移 a &lt;&lt; b lshift(a, b) 取模 a % b mod(a, b) 乘法 a * b mul(a, b) 矩阵乘法 a @ b matmul(a, b) 取反（算术） - a neg(a) 取反（逻辑） not a not_(a) 正数 + a pos(a) 右移 a &gt;&gt; b rshift(a, b) 切片赋值 seq[i:j] = values setitem(seq, slice(i, j), values) 切片删除 del seq[i:j] delitem(seq, slice(i, j)) 切片取值 seq[i:j] getitem(seq, slice(i, j)) 字符串格式化 s % obj mod(s, obj) 减法 a - b sub(a, b) 真值测试 obj truth(obj) 比较 a &lt; b lt(a, b) 比较 a &lt;= b le(a, b) 相等 a == b eq(a, b) 不等 a != b ne(a, b) 比较 a &gt;= b ge(a, b) 比较 a &gt; b gt(a, b) 原地运算符 operator.iadd(*a*, *b*) operator.__iadd__(*a*, *b*) a = iadd(a, b) 等价于 a += b。 operator.iand(*a*, *b*) operator.__iand__(*a*, *b*) a = iand(a, b) 等价于 a &amp;= b。 operator.iconcat(*a*, *b*) operator.__iconcat__(*a*, *b*) a = iconcat(a, b) 等价于 a += b 其中 a 和 b 为序列。 operator.ifloordiv(*a*, *b*) operator.__ifloordiv__(*a*, *b*) a = ifloordiv(a, b) 等价于 a //= b。 operator.ilshift(*a*, *b*) operator.__ilshift__(*a*, *b*) a = ilshift(a, b) 等价于 a &lt;&lt;= b。 operator.imod(*a*, *b*) operator.__imod__(*a*, *b*) a = imod(a, b) 等价于 a %= b。 operator.imul(*a*, *b*) operator.__imul__(*a*, *b*) a = imul(a, b) 等价于 a *= b。 operator.imatmul(*a*, *b*) operator.__imatmul__(*a*, *b*) a = imatmul(a, b) 等价于 a @= b。3.5 新版功能. operator.ior(*a*, *b*) operator.__ior__(*a*, *b*) a = ior(a, b) 等价于 a |= b。 operator.ipow(*a*, *b*) operator.__ipow__(*a*, *b*) a = ipow(a, b) 等价于 a **= b。 operator.irshift(*a*, *b*) operator.__irshift__(*a*, *b*) a = irshift(a, b) 等价于 a &gt;&gt;= b。 operator.isub(*a*, *b*) operator.__isub__(*a*, *b*) a = isub(a, b) 等价于 a -= b。 operator.itruediv(*a*, *b*) operator.__itruediv__(*a*, *b*) a = itruediv(a, b) 等价于 a /= b。 operator.ixor(*a*, *b*) operator.__ixor__(*a*, *b*) a = ixor(a, b) 等价于 a ^= b。 实例朋友建议我说,别光说标准库的基本使用,最好有一些实际的例子,接下来我会在每一篇博客的最后给大家一些实际应用的例子，欢迎大家批评指正。 稍后我会在对应的文章下面开通gitalk,大家可以及时给我留言。 实现一个简单的计算器,不使用if else 12345678910111213from operator import *def calculator(a, b, k): return &#123; '+': add, '-': sub, '*': mul, '/': truediv, '**': pow &#125;[k](a, b)calculator(1, 2, '+') # 3calculator(3, 4, '**') # 81]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library http.cookies]]></title>
    <url>%2F2020%2F01%2F09%2Fpython-standard-library-http-cookies%2F</url>
    <content type="text"><![CDATA[python 标准库 http.cookies最近需要教孩子自然拼读,所以我想还是每天用一个关键词描述吧。 traffic .n UK /træf.ɪk/ US /ˈtræf.ɪk/ 交通(拥堵) There was heavy/a lot of traffic on the roads this morning.今天早晨道路上车流量很大。 We got stuck in traffic for several hours.我们碰上交通阻塞被堵了好几个小时。 New measures have been introduced to try and ease traffic congestion in the city.这个城市已经采取了新措施，试图缓解交通拥堵。 Five people were injured in a traffic accident (= one involving vehicles).有5人在交通事故中受伤。 US I heard about the accident on the traffic report on the radio this morning.我在今早电台的交通节目中听到了这起事故。 Air traffic has increased 30 percent in the last decade.在过去的10年里，空中交通量增加了30%。 python 标准库学习 http.cookieshttp.cookies 模块定义了类实现了http状态管理机制和cookies概念。不仅支持字符串格式化的cookie值,还支持任何序列化对象的cookie值。 模块的实现完全遵循 RFC 2109 和 RFC 2068 协议规范。但MSIE 3.0x不遵循那些规范中概述的字符规则，并且当涉及Cookie处理时，许多当今的浏览器和服务器已经放宽了解析规则。 Cookie名定义字符集中非法字符囊括在 string.ascii_letters,string.digits 和 !#$%&amp;&#39;*+-.^_|~:`中。 核心类 exception http.cookies.CookieError 违反RFC 2109 规范中的错误,例如:不正确的属性或不正确的Set-Cookies header class http.cookies.BaseCookie([*input*]) 这个类是一个字典类型的对象,键是字符串,值是 Morsel 的实例。 如果设置参数input,实际上是通过load() 方法设置。 class http.cookies.SimpleCookie([*input*]) 这个类是从BaseCookie 继承过来并重写了 value_decode() and value_encode()方法。 SimpleCookies支持字符串格式的cookie values. Cookie对象 BaseCookie.value_decode(val) 以字符串形式返回 一个元组(real_value,coded_value)。其中real_value可以是任意类型。此方法在[BaseCookie]（https://docs.python.org/zh-cn/3.8/library/http.cookies.html#http.cookies.BaseCookie）中不进行解码,---因为已经存在被重写了。 BaseCookie.value_encode(val) 以字符串形式返回 一个元组(real_value,coded_value)。其中val可以是任意类型,coded_value 通常被转换为字符串类型。 BaseCookie.output(*attrs=None*, *header=&#39;Set-Cookie:&#39;*, *sep=&#39;\r\n&#39;*) 返回一个字符串表示的 用来适配 Http请求头,属性的相关方法。分隔符默认使用\r\n（CRLF）。 BaseCookie.js_output(*attrs=None*) 返回一个绑定Javascript脚本的对象,如果运行的浏览器支持Javascript脚本,作为输出和 out_put()的实现一样。 BaseCookie.load(rawdata)` 如果参数rawdata 是字符串,转化为 HTTP_COOKIE对象,并添加值。 如果参数是字典类型,可以这样取值。 12for k, v in rawdata.items(): cookie[k] = v Morsel 对象class http.cookies.Morsel 部分实现了 RFC 2109 规范的键值对抽象类。 Morsels是一个字典类型的对象, 里面的键是一个常量,同RFC 2109 规范,如下面所示: expires path comment domain max-age secure version httponly samesite httponly 属性声明了cookie只能通过HTTP 请求传输,并且包括Javascript脚本。这将会被合并到跨站脚本部分。 samesite 声明了浏览器是否允许发送跨站请求的cookie。这将会避免CSRF 攻击。无效的值包括 “Strict” and “Lax”。 这些键是大小写敏感的.默认值是&#39;&#39;. Morsel.value Cookie的值。 Morsel.coded_value编码后的cookie值。 Morsel.key cookie的名字 Morsel.set(key, value, coded_value) 设置key ,value和 coded_value* attributes 属性。 Morsel.isReservedKey(*K*) 判断 键 知否是 Morsel 里的键的成员。 Morsel.output(*attrs=None*, *header=&#39;Set-Cookie:&#39;*) 返回字符串格式的 Morsel 。默认包括所有的属性,除非指定声明attrs 属性,header 参数默认值是&quot;Set-Cookie:&quot;. Morsel.js_output(*attrs=None*) 返回一个绑定Javascript脚本的对象,如果运行的浏览器支持Javascript脚本,作为输出和 out_put()的实现一样。 Morsel.OutputString(*attrs=None*) 返回一个字符串格式的 Morsel,不包括Http或Javascript。 Morsel.update(*values*) 根据参数值更新Morsel 字典。如果参数不在字典中则引发异常。具体可以参考 RFC 2109 Morsel.copy(*value*) 返回一个 Morsel 对象的浅拷贝。 Morsel.setdefault(*key*, *value=None*) Raise an error if key is not a valid RFC 2109 attribute, otherwise behave the same as dict.setdefault(). 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445&gt;&gt;&gt; from http import cookies&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C["fig"] = "newton"&gt;&gt;&gt; C["sugar"] = "wafer"&gt;&gt;&gt; print(C) # generate HTTP headersSet-Cookie: fig=newtonSet-Cookie: sugar=wafer&gt;&gt;&gt; print(C.output()) # same thingSet-Cookie: fig=newtonSet-Cookie: sugar=wafer&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C["rocky"] = "road"&gt;&gt;&gt; C["rocky"]["path"] = "/cookie"&gt;&gt;&gt; print(C.output(header="Cookie:"))Cookie: rocky=road; Path=/cookie&gt;&gt;&gt; print(C.output(attrs=[], header="Cookie:"))Cookie: rocky=road&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C.load("chips=ahoy; vienna=finger") # load from a string (HTTP header)&gt;&gt;&gt; print(C)Set-Cookie: chips=ahoySet-Cookie: vienna=finger&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C.load('keebler="E=everybody; L=\\"Loves\\"; fudge=\\012;";')&gt;&gt;&gt; print(C)Set-Cookie: keebler="E=everybody; L=\"Loves\"; fudge=\012;"&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C["oreo"] = "doublestuff"&gt;&gt;&gt; C["oreo"]["path"] = "/"&gt;&gt;&gt; print(C)Set-Cookie: oreo=doublestuff; Path=/&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C["twix"] = "none for you"&gt;&gt;&gt; C["twix"].value'none for you'&gt;&gt;&gt; C = cookies.SimpleCookie()&gt;&gt;&gt; C["number"] = 7 # equivalent to C["number"] = str(7)&gt;&gt;&gt; C["string"] = "seven"&gt;&gt;&gt; C["number"].value'7'&gt;&gt;&gt; C["string"].value'seven'&gt;&gt;&gt; print(C)Set-Cookie: number=7Set-Cookie: string=seven 小结顺便了解了下http协议的相关内容,附链接。 RFC 2068 ：http超文本传输协议1.0 RFC 2616 ：http超文本传输协议1.1 RFC 2109: http状态管理机制]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>http</tag>
        <tag>cookies</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library http]]></title>
    <url>%2F2020%2F01%2F08%2Fpython-standard-library-http%2F</url>
    <content type="text"><![CDATA[python 标准库之 http 山雨欲来风满楼,最近不是很太平,希望世界和平吧。 python 标准库学习 之 httphttp 是一个包，它收集了多个用于处理超文本传输协议的模块: 参考文档 http.client 是一个低层级的 HTTP 协议客户端；对于高层级的 URL 访问请使用 urllib.request http.server 包含基于 socketserver 的基本 HTTP 服务类 http.cookies 包含一些有用来实现通过 cookies 进行状态管理的工具 http.cookiejar 提供了 cookies 的持久化 本次只整理 http.client的内容,后面持续更新。 常量class http.HTTPStatus 使用方法： 12345678910111213&gt;&gt;&gt; from http import HTTPStatus&gt;&gt;&gt; HTTPStatus.OK&lt;HTTPStatus.OK: 200&gt;&gt;&gt;&gt; HTTPStatus.OK == 200True&gt;&gt;&gt; HTTPStatus.OK.value200&gt;&gt;&gt; HTTPStatus.OK.phrase'OK'&gt;&gt;&gt; HTTPStatus.OK.description'Request fulfilled, document follows'&gt;&gt;&gt; list(HTTPStatus)[&lt;HTTPStatus.CONTINUE: 100&gt;, &lt;HTTPStatus.SWITCHING_PROTOCOLS: 101&gt;, ...] HTTP状态码 状态码 映射名 详情 100 CONTINUE HTTP/1.1 RFC 7231, 6.2.1 节 101 SWITCHING_PROTOCOLS HTTP/1.1 RFC 7231, 6.2.2 节 102 PROCESSING WebDAV RFC 2518, 10.1 节 200 OK HTTP/1.1 RFC 7231, 6.3.1 节 201 CREATED HTTP/1.1 RFC 7231, 6.3.2 节 202 ACCEPTED HTTP/1.1 RFC 7231, 6.3.3 节 203 NON_AUTHORITATIVE_INFORMATION HTTP/1.1 RFC 7231, 6.3.4 节 204 NO_CONTENT HTTP/1.1 RFC 7231, 6.3.5 节 205 RESET_CONTENT HTTP/1.1 RFC 7231, 6.3.6 节 206 PARTIAL_CONTENT HTTP/1.1 RFC 7233, 4.1 节 207 MULTI_STATUS WebDAV RFC 4918, 11.1 节 208 ALREADY_REPORTED WebDAV Binding Extensions RFC 5842, 7.1 节（实验性） 226 IM_USED Delta Encoding in HTTP RFC 3229, 10.4.1 节 300 MULTIPLE_CHOICES：有多种资源可选择 HTTP/1.1 RFC 7231, 6.4.1 节 301 MOVED_PERMANENTLY：永久移动 HTTP/1.1 RFC 7231, 6.4.2 节 302 FOUND：临时移动 HTTP/1.1 RFC 7231, 6.4.3 节 303 SEE_OTHER：已经移动 HTTP/1.1 RFC 7231, 6.4.4 节 304 NOT_MODIFIED：没有修改 HTTP/1.1 RFC 7232, 4.1 节 305 USE_PROXY：使用代理 HTTP/1.1 RFC 7231, 6.4.5 节 307 TEMPORARY_REDIRECT：临时重定向 HTTP/1.1 RFC 7231, 6.4.7 节 308 PERMANENT_REDIRECT：永久重定向 Permanent Redirect RFC 7238, Section 3 (Experimental) 400 BAD_REQUEST：错误请求 HTTP/1.1 RFC 7231, 6.5.1 节 401 UNAUTHORIZED：未授权 HTTP/1.1 Authentication RFC 7235, 3.1 节 402 PAYMENT_REQUIRED：保留，将来使用 HTTP/1.1 RFC 7231, 6.5.2 节 403 FORBIDDEN：禁止 HTTP/1.1 RFC 7231, 6.5.3 节 404 NOT_FOUND：没有找到 HTTP/1.1 RFC 7231, 6.5.4 节 405 METHOD_NOT_ALLOWED：该请求方法不允许 HTTP/1.1 RFC 7231, 6.5.5 节 406 NOT_ACCEPTABLE：不可接受 HTTP/1.1 RFC 7231, 6.5.6 节 407 PROXY_AUTHENTICATION_REQUIRED：要求使用代理验证身份 HTTP/1.1 Authentication RFC 7235, 3.1 节 408 REQUEST_TIMEOUT：请求超时 HTTP/1.1 RFC 7231, 6.5.7 节 409 CONFLICT：冲突 HTTP/1.1 RFC 7231, 6.5.8 节 410 GONE：已经不在了 HTTP/1.1 RFC 7231, 6.5.9 节 411 LENGTH_REQUIRED：长度要求 HTTP/1.1 RFC 7231, 6.5.10 节 412 PRECONDITION_FAILED：前提条件错误 HTTP/1.1 RFC 7232, 4.2 节 413 REQUEST_ENTITY_TOO_LARGE：请求体太大了 HTTP/1.1 RFC 7231, 6.5.11 节 414 REQUEST_URI_TOO_LONG：请求URI太长了 HTTP/1.1 RFC 7231, 6.5.12 节 415 UNSUPPORTED_MEDIA_TYPE：不支持的媒体格式 HTTP/1.1 RFC 7231, 6.5.13 节 416 REQUESTED_RANGE_NOT_SATISFIABLE HTTP/1.1 Range Requests RFC 7233, 4.4 节 417 EXPECTATION_FAILED：期望失败 HTTP/1.1 RFC 7231, 6.5.14 节 421 MISDIRECTED_REQUEST HTTP/2 RFC 7540, 9.1.2 节 422 UNPROCESSABLE_ENTITY：可加工实体 WebDAV RFC 4918, 11.2 节 423 LOCKED：锁着 WebDAV RFC 4918, 11.3 节 424 FAILED_DEPENDENCY：失败的依赖 WebDAV RFC 4918, 11.4 节 426 UPGRADE_REQUIRED：升级需要 HTTP/1.1 RFC 7231, 6.5.15 节 428 PRECONDITION_REQUIRED：先决条件要求 Additional HTTP Status Codes RFC 6585 429 TOO_MANY_REQUESTS：太多的请求 Additional HTTP Status Codes RFC 6585 431 REQUEST_HEADER_FIELDS_TOO_LARGE：请求头太大 Additional HTTP Status Codes RFC 6585 451 UNAVAILABLE_FOR_LEGAL_REASONS HTTP 状态码用于报告法律障碍 RFC 7725 500 INTERNAL_SERVER_ERROR：内部服务错误 HTTP/1.1 RFC 7231, 6.6.1 节 501 NOT_IMPLEMENTED：不可执行 HTTP/1.1 RFC 7231, 6.6.2 节 502 BAD_GATEWAY：无效网关 HTTP/1.1 RFC 7231, 6.6.3 节 503 SERVICE_UNAVAILABLE：服务不可用 HTTP/1.1 RFC 7231, 6.6.4 节 504 GATEWAY_TIMEOUT：网关超时 HTTP/1.1 RFC 7231, 6.6.5 节 505 HTTP_VERSION_NOT_SUPPORTED：HTTP版本不支持 HTTP/1.1 RFC 7231, 6.6.6 节 506 VARIANT_ALSO_NEGOTIATES：服务器存在内部配置错误 透明内容协商在： HTTP RFC 2295, 8.1 节（实验性） 507 INSUFFICIENT_STORAGE：存储不足 WebDAV RFC 4918, 11.5 节 508 LOOP_DETECTED：循环检测 WebDAV Binding Extensions RFC 5842, 7.2 节（实验性） 510 NOT_EXTENDED：不扩展 WebDAV Binding Extensions RFC 5842, 7.2 节（实验性） 511 NETWORK_AUTHENTICATION_REQUIRED：要求网络身份验证 Additional HTTP Status Codes RFC 6585, 6 节 为了保持向后兼容性，枚举值也以常量形式出现在 http.client 模块中，。 枚举名等于常量名 (例如 http.HTTPStatus.OK 也可以是 http.client.OK)。 http.client 对象这个模块定义了实现 HTTP 和 HTTPS 协议客户端的类。 它通常不直接使用 — 模块 urllib.request 用它来处理使用 HTTP 和 HTTPS 的 URL。 参见 The Requests 是一个高级的实现http协议的http客户端接口库. 注意: HTTPS 支持仅在编译 Python 时启用了 SSL 支持的情况下（通过 ssl 模块）可用。 强烈建议看源代码 Lib/http/client.py 我摘取其中关于http请求状态的描述 12345678910111213141516171819202122232425262728293031323334 (null) | | HTTPConnection() v Idle | | putrequest() v Request-started | | ( putheader() )* endheaders() v Request-sent |\_____________________________ | | getresponse() raises | response = getresponse() | ConnectionError v v Unread-response Idle [Response-headers-read] |\____________________ | | | response.read() | putrequest() v v Idle Req-started-unread-response ______/| / |response.read() | | ( putheader() )* endheaders() v v Request-started Req-sent-unread-response | | response.read() v Request-sent 类 class http.client.HTTPConnection(*host*, *port=None*, [*timeout*, ]*source_address=None*, *blocksize=8192*) HTTPConnection 的实例代表与 HTTP 的一个连接事务。 它的实例化应当传入一个主机和可选的端口号。 如果没有传入端口号，如果主机字符串的形式为 主机:端口 则会从中提取端口，否则将使用默认的 HTTP 端口（80）。 如果给出了可选的 timeout 参数，则阻塞操作（例如连接尝试）将在指定的秒数之后超时（如果未给出，则使用全局默认超时设置）。 可选的 source_address 参数可以为一个 (主机, 端口) 元组，用作进行 HTTP 连接的源地址。 可选的 blocksize 参数可以字节为单位设置缓冲区的大小，用来发送文件类消息体。 举个例子，以下调用都是创建连接到同一主机和端口的服务器的实例： 1234&gt;&gt;&gt; h1 = http.client.HTTPConnection('www.python.org')&gt;&gt;&gt; h2 = http.client.HTTPConnection('www.python.org:80')&gt;&gt;&gt; h3 = http.client.HTTPConnection('www.python.org', 80)&gt;&gt;&gt; h4 = http.client.HTTPConnection('www.python.org', 80, timeout=10) `class http.client.HTTPSConnection(host, port=None, key_file=None, cert_file=None, [timeout, ]source_address=None, **, context=None, check_hostname=None, blocksize=8192*)¶ HTTPConnection 的子类，使用 SSL 与安全服务器进行通信。 默认端口为 443。 如果指定了 context，它必须为一个描述 SSL 各选项的 ssl.SSLContext 实例。 class http.client.`HTTPResponse`(sock, debuglevel=0, method=None, url=None) 在成功连接后返回类的实例，而不是由用户直接实例化。 异常 exception http.client.`HTTPException` 此模块中其他异常的基类。 它是 Exception 的一个子类。 exception http.client.`NotConnected` HTTPException 的一个子类。 exception http.client.`InvalidURL` HTTPException 的一个子类，如果给出了一个非数字或为空值的端口就会被引发。 exception http.client.`UnknownProtocol` HTTPException 的一个子类。 exception http.client.`UnknownTransferEncoding` HTTPException 的一个子类。 exception http.client.`UnimplementedFileMode` HTTPException 的一个子类。 exception http.client.`IncompleteRead` HTTPException 的一个子类。 exception http.client.`ImproperConnectionState` HTTPException 的一个子类。 exception http.client.`CannotSendRequest` ImproperConnectionState 的一个子类。 exception http.client.`CannotSendHeader` ImproperConnectionState 的一个子类。 exception http.client.`ResponseNotReady` ImproperConnectionState 的一个子类。 exception http.client.`BadStatusLine` HTTPException 的一个子类。 如果服务器反馈了一个我们不理解的 HTTP 状态码就会被引发。 exception http.client.`LineTooLong` HTTPException 的一个子类。 如果在 HTTP 协议中从服务器接收到过长的行就会被引发。 exception http.client.`RemoteDisconnected` ConnectionResetError 和 BadStatusLine 的一个子类。 当尝试读取响应时的结果是未从连接读取到数据时由 HTTPConnection.getresponse() 引发，表明远端已关闭连接。 常量 http.client.`HTTP_PORT` HTTP 协议默认的端口号 (总是 80)。 http.client.`HTTPS_PORT` HTTPS 协议默认的端口号 (总是 443)。 http.client.`responses` 这个字典把 HTTP 1.1 状态码映射到 W3C 名称。例如：http.client.responses[http.client.NOT_FOUND] 是 &#39;NOT FOUND （未发现）。 HTTPConnection 对象方法 HTTPConnection.request(method, url, body=None, headers={}, , encode_chunked=False*) 这会使用 HTTP 请求方法 method 和选择器 url 向服务器发送请求。 如果给定 body，那么给定的数据会在信息头完成之后发送。它可能是一个 str 、一个 bytes-like object 、一个打开的 file object，或者 bytes 迭代器。如果 body 是字符串，它会按 HTTP 默认的 ISO-8859-1 编码；如果是一个字节类对象，它会按原样发送；如果是 file object ，文件的内容会被发送，这个文件对象应该支持 read() 方法。如果这个文件对象是一个 io.TextIOBase 实例， read() 方法返回的数据会按 ISO-8859-1 编码，否则 read() 方法返回的数据会按原样发送；如果 body 是一个迭代器，迭代器中的元素会被发送，直到迭代器耗尽。 headers 参数应是额外的随请求发送的 HTTP 信息头的字典。 如果 headers 既不包含 Content-Length 也没有 Transfer-Encoding，但存在请求正文，那么这些头字段中的一个会自动设定。如果 body 是 None，那么对于要求正文的方法 (PUT，POST，和 PATCH)，Content-Length 头会被设为 0。如果 body 是字符串或者类似字节的对象，并且也不是 文件，Content-Length 头会设为正文的长度。任何其他类型的 body （一般是文件或迭代器）会按块编码，这时会自动设定 Transfer-Encoding 头以代替 Content-Length。 在 headers 中指定 Transfer-Encoding 时， encode_chunked 是唯一相关的参数。如果 encode_chunked 为 False，HTTPConnection 对象会假定所有的编码都由调用代码处理。如果为 True，正文会按块编码。 HTTPConnection.`set_debuglevel`(level) 设置调试等级。 默认的调试等级为 0，意味着不会打印调试输出。 任何大于 0 的值将使得所有当前定义的调试输出被打印到 stdout。 debuglevel 会被传给任何新创建的 HTTPResponse 对象。 HTTPConnection.`set_tunnel`(host, port=None, headers=None) 为 HTTP 连接隧道设置主机和端口。 这将允许通过代理服务器运行连接。 host 和 port 参数指明隧道连接的位置（即 CONNECT 请求所包含的地址，而 不是 代理服务器的地址）。 headers 参数应为一个随 CONNECT 请求发送的额外 HTTP 标头的映射。 例如，要通过一个运行于本机 8080 端口的 HTTPS 代理服务器隧道，我们应当向 HTTPSConnection 构造器传入代理的地址，并将我们最终想要访问的主机地址传给 set_tunnel() 方法: 1234&gt;&gt;&gt; import http.client&gt;&gt;&gt; conn = http.client.HTTPSConnection("localhost", 8080)&gt;&gt;&gt; conn.set_tunnel("www.python.org")&gt;&gt;&gt; conn.request("HEAD","/index.html") HTTPConnection.connect() 当对象被创建后连接到指定的服务器。 默认情况下，如果客户端还未建立连接，此函数会在发送请求时自动被调用。 HTTPConnection.close() 关闭到服务器的连接。 HTTPConnection.blocksize 用于发送文件类消息体的缓冲区大小。 HTTPConnection.send(data) 发送数据到服务器 。这个方法直接使用将会在endheaders()方法后和 getresponse() 方法调用之前被调用 HTTPResponse 对象HTTPResponse 对象实例绑定从服务器返回的 Http response 内容。 response是一个可迭代对象,可以使用with上下文语句来管理。 方法 HTTPResponse.read([amt]) 读取并返回response body HTTPResponse.`readinto`(b) 读取从 response body 的b长度的字节放到 buffer b中，并返回这个字节b。 HTTPResponse.getheader(name, default=None) 如果有匹配的header name,则返回 header name的值。如果不止一个header name的名字，则返回所有的值的字符串,通过逗号连接。 HTTPResponse.getheaders() 返回一个包含header和value的元组元素的列表 HTTPResponse.fileno() Return the fileno of the underlying socket. 返回底层套接字的fileno HTTPResponse.msg 一个http.client.HTTPMessage 消息的实例,包含response header。 http.client.HTTPMessage 是 email.message.Message的子类 HTTPResponse.version Http response版本号,例如 HTTP/1.0, 11 for HTTP/1.1. HTTPResponse.`status` 由服务器返回的状态码。 HTTPResponse.reason 从服务器返回的状态码 HTTPResponse.debuglevel 一个 debugging hook. 如果 debuglevel 大于0, 消息将会被打印到控制台。 HTTPResponse.closed 如果stream关闭,返回true 实例:一个使用get请求的实例 12345678910111213141516171819202122&gt;&gt;&gt; import http.client&gt;&gt;&gt; conn = http.client.HTTPSConnection("www.python.org")&gt;&gt;&gt; conn.request("GET", "/")&gt;&gt;&gt; r1 = conn.getresponse()&gt;&gt;&gt; print(r1.status, r1.reason)200 OK&gt;&gt;&gt; data1 = r1.read() # This will return entire content.&gt;&gt;&gt; # The following example demonstrates reading data in chunks.&gt;&gt;&gt; conn.request("GET", "/")&gt;&gt;&gt; r1 = conn.getresponse()&gt;&gt;&gt; while chunk := r1.read(200):... print(repr(chunk))b'&lt;!doctype html&gt;\n&lt;!--[if"......&gt;&gt;&gt; # Example of an invalid request&gt;&gt;&gt; conn = http.client.HTTPSConnection("docs.python.org")&gt;&gt;&gt; conn.request("GET", "/parrot.spam")&gt;&gt;&gt; r2 = conn.getresponse()&gt;&gt;&gt; print(r2.status, r2.reason)404 Not Found&gt;&gt;&gt; data2 = r2.read()&gt;&gt;&gt; conn.close() 一个使用head方法的实例 1234567891011&gt;&gt;&gt; import http.client&gt;&gt;&gt; conn = http.client.HTTPSConnection("www.python.org")&gt;&gt;&gt; conn.request("HEAD", "/")&gt;&gt;&gt; res = conn.getresponse()&gt;&gt;&gt; print(res.status, res.reason)200 OK&gt;&gt;&gt; data = res.read()&gt;&gt;&gt; print(len(data))0&gt;&gt;&gt; data == b''True 一个使用post提交请求的实例 12345678910111213&gt;&gt;&gt; import http.client, urllib.parse&gt;&gt;&gt; params = urllib.parse.urlencode(&#123;'@number': 12524, '@type': 'issue', '@action': 'show'&#125;)&gt;&gt;&gt; headers = &#123;"Content-type": "application/x-www-form-urlencoded",... "Accept": "text/plain"&#125;&gt;&gt;&gt; conn = http.client.HTTPConnection("bugs.python.org")&gt;&gt;&gt; conn.request("POST", "", params, headers)&gt;&gt;&gt; response = conn.getresponse()&gt;&gt;&gt; print(response.status, response.reason)302 Found&gt;&gt;&gt; data = response.read()&gt;&gt;&gt; datab'Redirecting to &lt;a href="http://bugs.python.org/issue12524"&gt;http://bugs.python.org/issue12524&lt;/a&gt;'&gt;&gt;&gt; conn.close() 一个使用HTTP PUT请求的实例 1234567891011&gt;&gt;&gt; # This creates an HTTP message&gt;&gt;&gt; # with the content of BODY as the enclosed representation&gt;&gt;&gt; # for the resource http://localhost:8080/file...&gt;&gt;&gt; import http.client&gt;&gt;&gt; BODY = "***filecontents***"&gt;&gt;&gt; conn = http.client.HTTPConnection("localhost", 8080)&gt;&gt;&gt; conn.request("PUT", "/file", BODY)&gt;&gt;&gt; response = conn.getresponse()&gt;&gt;&gt; print(response.status, response.reason)200, OK HTTPMessage 对象一个 http.client.HTTPMessage的实例包含了http response 请求头. 是 email.message.Message类的具体实现. 总结通过阅读源码加深了对http协议的理解,看python实现的方式受益良多。继续加油!]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library glob]]></title>
    <url>%2F2020%2F01%2F07%2Fpython-standard-library-glob%2F</url>
    <content type="text"><![CDATA[python 标准库之 glob 在严寒的冬季,温暖人的只有笑脸了吧。 今天继续给大家介绍python标准库 glob参考文档 glob 模块可根据 Unix 终端所用规则找出所有匹配特定模式的路径名，但会按不确定的顺序返回结果。支持查找文件只用到三个匹配符：’*’, “?”, “[ ]”，不包括波浪线~,因为这个符号在linux代表当前用户的home目录。 对于波浪号和终端变量扩展，请使用 os.path.expanduser() 和 os.path.expandvars())。 根据阅读代码发现,这个底层使用cpython实现, 有兴趣的童鞋可以移步到源代码: Lib/glob.py 相对于高级面向对象路径查找模块pathlib ,glob更偏向底层实现。 函数 glob.glob(pathname, *, recursive=False) 返回匹配 pathname 的可能为空的路径名列表，其中的元素必须为包含一个路径信息的字符串。 pathname 可以是绝对路径 (如 /usr/src/Python-1.5/Makefile) 或相对路径 (如 ../../Tools/*/*.gif)，并且可包含 shell 风格的通配符。 结果也将包含无效的符号链接 (与在 shell 中一致)。 结果是否排序取决于具体文件系统。 如果 recursive 为真值，则模式 “**“ 将匹配目录中的任何文件以及零个或多个目录、子目录和符号链接。 如果模式加了一个 os.sep 或 os.altsep 则将不匹配文件。 备注：在一个较大的目录树中使用 “**“ 模式可能会消耗非常多的时间。 3.5 版更改: 支持使用 “**“ 的递归 glob glob.iglob(pathname, *, recursive=False) 返回一个 iterator，它会产生与 glob() 相同的结果，但不会实际地同时保存它们。 glob.escape(pathname) 转义所有特殊字符 (&#39;?&#39;, &#39;*&#39; 和 &#39;[&#39;)。 这适用于当你想要匹配可能带有特殊字符的任意字符串字面值的情况。 在 drive/UNC 共享点中的特殊字符不会被转义，例如在 Windows 上 escape(&#39;//?/c:/Quo vadis?.txt&#39;) 将返回 &#39;//?/c:/Quo vadis[?].txt&#39;。 实例123456789101112#例如，考虑一个包含以下内容的目录：文件 1.gif, 2.txt, card.gif 以及一个子目录 sub 其中只包含一个文件 3.txt. glob() 将产生如下结果。 请注意路径的任何开头部分都将被保留。&gt;&gt;&gt; glob.glob('./[0-9].*')['./1.gif', './2.txt']&gt;&gt;&gt; glob.glob('*.gif')['1.gif', 'card.gif']&gt;&gt;&gt; glob.glob('?.gif')['1.gif']&gt;&gt;&gt; glob.glob('**/*.txt', recursive=True)['2.txt', 'sub/3.txt']&gt;&gt;&gt; glob.glob('./**/', recursive=True)['./', './sub/'] 如果目录包含以 . 打头的文件，它们默认将不会被匹配。 例如，考虑一个包含 card.gif 和 .card.gif 的目录: 12345&gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('*.gif')['card.gif']&gt;&gt;&gt; glob.glob('.c*')['.card.gif'] 补充内容 ”*”匹配任意0个或多个字符；”?”匹配任意单个字符；”[ ]”匹配指定范围内的字符，如：[0-9]匹配数字。 如下图所示的文件结构 12345678910111213141516171819import glob# 返回上一级所有目录print(glob.glob(r"../*"))# 返回上本级所有目录print(glob.glob(r"./*"))# 本级所有文件print(glob.glob(r"./*.*"))# 本级所有.py文件print(glob.glob('./*.py'))#两级目录所有的.py文件print(glob.glob('./*/*.py'))# c盘所有文件print(glob.glob(r'c:/*'))#C盘所有包含pr/po/br/bo的目录print(glob.glob('C:/*[PB][RO]*'))#C盘所有包含P_o的目录print(glob.glob('C:/*P?O*'))#C盘两级目录所有的.txt文件print(glob.glob('C:/*/*.txt')) 显示内容如下: 12345['..\\class_demo.py', '..\\excel', '..\\flask_test', '..\\glob', '..\\image', '..\\mymodule', '..\\numpy', '..\\opencv', '..\\opencv_demo', '..\\othermodule', '..\\ppt', '..\\python_enuerate.py', '..\\python速成', '..\\selenium_test', '..\\交换算法.py', '..\\爬虫']['.\\app', '.\\config', '.\\data', '.\\glob_demo.py', '.\\other.py', '.\\readme.md']['.\\glob_demo.py', '.\\other.py', '.\\readme.md']['.\\glob_demo.py', '.\\other.py']['.\\app\\__init__.py', '.\\config\\config.py'] 其他阅读源码中发现 12345678"""Filename globbing utility."""import osimport reimport fnmatchimport sys__all__ = ["glob", "iglob", "escape"] 顺便把__all__用法整理下,算是查漏补缺, __all__问题描述: 在研读pythonmodel源码时,会看到一些.py文件或者init.py中会使用all。对于all具体所其的作用是什么?在此对查取结果进行总结下。2.总结(1)在init.py文件中表示形式:all=[“module_a”,”module_b”]在使用frompackage_nameimport时,表示import该package中的两个module及两个module相关的类、方 表示形式: __all__=[&quot;class_name&quot;,&quot;function_name&quot;] 在使用 from module_name import * 时,表示import 该module中的all中所列出的。 使用注意事项: (1) 在普通的*.py中, 使用all 时,可以使用all列出的 类、函数、变量等,不使用all时会使用module中的所有不以下划线开头的成员。 (2)all只能影响到 from import * 这种import 方式, 对于from import 的 import 方式没有影响。 (3) all 的数据类型:List or Tuple 关联的模块模块 fnmatch Shell 风格文件名（而非路径）扩展]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>glob</tag>
        <tag>__all__</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library textwrap]]></title>
    <url>%2F2020%2F01%2F06%2Fpython-standard-library-textwrap%2F</url>
    <content type="text"><![CDATA[Python 标准库 之 textwrap 今天给大家介绍 python标准库中的 textwrap参考文档 标准库 textwrap 是一个关于文本自动换行和填充的模块。 关于这个模块官网介绍如下: textwrap 模块提供了一些快捷函数，以及可以完成所有工作的类 TextWrapper。 如果你只是要对一两个文本字符串进行自动换行或填充，快捷函数应该就够用了； 否则的话，你应该使用 TextWrapper 的实例来提高效率。 函数 textwrap.wrap(*text*, *width=70*, kwargs) 对 text (字符串) 中的单独段落自动换行以使每行长度最多为 width 个字符。 返回由输出行组成的列表，行尾不带换行符。 textwrap.fill(text, width=70, kwargs) 对 text 中的单独段落自动换行，并返回一个包含被自动换行段落的单独字符串。 fill() 是以下语句的快捷方式 1"\n".join(wrap(text, ...)) textwrap.shorten(text, width, kwargs) 折叠并截短给定的 text 以符合给定的 width。 textwrap.dedent(text)` 移除 text 中每一行的任何相同前缀空白符。 1234567# end first line with \ to avoid the empty line!s = '''\hello world'''print(repr(s)) # prints ' hello\n world\n 'print(repr(dedent(s))) # prints 'hello\n world\n' textwrap.indent(text, prefix, predicate=None)` 将 prefix 添加到 text 中选定行的开头。 通过调用 text.splitlines(True) 来对行进行拆分。 默认情况下，prefix 会被添加到所有不是只由空白符（包括任何行结束符）组成的行。 例如: 123&gt;&gt;&gt; s = 'hello\n\n \nworld'&gt;&gt;&gt; indent(s, ' ')' hello\n\n \n world' 可选的 predicate 参数可用来控制哪些行要缩进。 例如，可以很容易地为空行或只有空白符的行添加 prefix: 12345&gt;&gt;&gt; print(indent(s, '+ ', lambda line: True))+ hello+++ world 实例属性 width (默认: 70) 自动换行的最大行长度。 只要输入文本中没有长于 width 的单个单词，TextWrapper 就能保证没有长于 width 个字符的输出行。 expand_tabs (默认: True) 如果为真值，则 text 中所有的制表符将使用 text 的 expandtabs() 方法扩展为空格符。 tabsize (默认: 8) 如果 expand_tabs 为真值，则 text 中所有的制表符将扩展为零个或多个空格，具体取决于当前列位置和给定的制表宽度。 replace_whitespace (default: True) 如果为真值，在制表符扩展之后、自动换行之前，wrap() 方法将把每个空白字符都替换为单个空格。 会被替换的空白字符如下：制表，换行，垂直制表，进纸和回车 (&#39;\t\n\v\f\r&#39;)。注解 如果 expand_tabs 为假值且 replace_whitespace 为真值，每个制表符将被替换为单个空格，这与制表符扩展是 不 一样的。注解 如果 replace_whitespace 为假值，在一行的中间有可能出现换行符并导致怪异的输出。 因此，文本应当（使用 str.splitlines() 或类似方法）拆分为段落并分别进行自动换行。 drop_whitespace (默认: True) 如果为真值，每一行开头和末尾的空白字符（在包装之后、缩进之前）会被丢弃。 但是段落开头的空白字符如果后面不带任何非空白字符则不会被丢弃。 如果被丢弃的空白字符占据了一个整行，则该整行将被丢弃。 initial_indent (默认: &#39;&#39;) 将被添加到被自动换行输出内容的第一行的字符串。 其长度会被计入第一行的长度。 空字符串不会被缩进。 subsequent_indent (default: &#39;&#39;) 将被添加到被自动换行输出内容除第一行外的所有行的字符串。 其长度会被计入除行一行外的所有行的长度。 fix_sentence_endings (默认: False) 如果为真值，TextWrapper 将尝试检测句子结尾并确保句子间总是以恰好两个空格符分隔。 对于使用等宽字体的文本来说通常都需要这样。 但是，句子检测算法并不完美：它假定句子结尾是一个小写字母加字符 &#39;.&#39;, &#39;!&#39; 或 &#39;?&#39; 中的一个，并可能带有字符 &#39;&quot;&#39; 或 &quot;&#39;&quot;，最后以一个空格结束。 此算法的问题之一是它无法区分以下文本中的 “Dr.”[...] Dr. Frankenstein&#39;s monster [...]和以下文本中的 “Spot.”[...] See Spot. See Spot run [...]fix_sentence_endings 默认为假值。由于句子检测算法依赖于 string.lowercase 来确定“小写字母”，以及约定在句点后使用两个空格来分隔处于同一行的句子，因此只适用于英语文本。 break_long_words (默认: True) 如果为真值，则长度超过 width 的单词将被分开以保证行的长度不会超过 width。 如果为假值，超长单词不会被分开，因而某些行的长度可能会超过 width。 （超长单词将被单独作为一行，以尽量减少超出 width 的情况。） break_on_hyphens (默认: True) 如果为真值，将根据英语的惯例首选在空白符和复合词的连字符之后自动换行。 如果为假值，则只有空白符会被视为合适的潜在断行位置，但如果你确实不希望出现分开的单词则你必须将 break_long_words 设为假值。 之前版本的默认行为总是允许分开带有连字符的单词。 max_lines (默认: None) 如果不为 None，则输出内容将最多包含 max_lines 行，并使 placeholder 出现在输出内容的末尾。 placeholder (默认: &#39; [...]&#39;) 该文本将在输出文本被截短时出现在文本末尾。 公有方法 wrap(text) 对 text (字符串) 中的单独段落自动换行以使每行长度最多为 width 个字符。 所有自动换行选项均获取自 TextWrapper 实例的实例属性。 返回由输出行组成的列表，行尾不带换行符。 如果自动换行输出结果没有任何内容，则返回空列表。 fill(text) 对 text 中的单独段落自动换行并返回包含被自动换行段落的单独字符串。 具体实例比如我想格式化一个文本,每一行要求输出的文字固定字符的长度30,就可以使用textwrap这个模块 1234567891011121314151617&gt;&gt;&gt; from textwrap import wrap&gt;&gt;&gt;&gt;&gt;&gt; string = 'This is python programming language. One of its kind, it is also one of the most popular language in the world.'&gt;&gt;&gt;&gt;&gt;&gt; s = wrap(text = string, width = 30)&gt;&gt;&gt; print s&gt;&gt;&gt; ['This is python programming', 'language. One of its kind, it', 'is also one of the most', 'popular language in the world.']&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; for i in s: print i This is python programminglanguage. One of its kind, itis also one of the mostpopular language in the world.&gt;&gt;&gt;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library http.server]]></title>
    <url>%2F2020%2F01%2F05%2Fpython-standard-library-http-server%2F</url>
    <content type="text"><![CDATA[python 标准库之 http.server 今天下午主要是陪我闺女,组装完成一个桌面足球,很开心的一下午。 孩子的童年只有一次,有时间多陪陪孩子吧。 python 标准库 http.server从python2时代开始 SimpleHttpServer就陪伴我走过那些快乐的时光。可以自己建立一个简单的文件服务器,让同事们通过浏览器就可以访问我电脑上的资源,而不需要http server或者 ftp软件。 到了python3时代,这个模块被合并进了http.server。 参考网址 这个模块定义了实现 HTTP 服务器（ Web 服务器）的类 。 HTTPServer 是 socketserver.TCPServer 的一个子类。它会创建和侦听 HTTP 套接字，并将请求调度给处理程序。用于创建和运行服务器的代码看起来像这样 1234def run(server_class=HTTPServer, handler_class=BaseHTTPRequestHandler): server_address = ('', 8000) httpd = server_class(server_address, handler_class) httpd.serve_forever() 核心类class http.server.HTTPServer(server_address, RequestHandlerClass) 该类基于 TCPServer 类，并会将服务器地址存入名为 server_name 和 server_port 的实例变量中。服务器可被处理程序通过 server 实例变量访问。 class http.server.ThreadingHTTPServer(server_address, RequestHandlerClass) 根据官方说明,这是一个基于 ThreadingMixIn的类,主要功能是使用线程处理请求。 实例变量BaseHTTPRequestHandler has the following instance variables: client_address 包含指向客户地址的元组类型数据(host,port) server 包含Server实例 close_connection 返回一个Boolean类型数据,在handle_one_request() ,表明另一个请求开始,或者当前请求关闭。 requestline 包含http请求行，. 这个属性应该用 handle_one_request()设置. 如果一个不存在的请求被执行,应将其设置成空字符串。 command 包含Http请求类型,例如:’Get’ path 包含请求url路径 request_version 包含请求的版本,例如:’ HTTP/1.0 ‘ headers 包含通过MessageClass 类声明的变量。实例会转化为http请求。http.client 中parse_headers() 方法可以验证一个非法的请求头,参照 RFC 2822 中请求头说明。 rfile 一个io.BufferedIOBase 输入流对象，读取可能输入数据。 wfile 根据客户端请求,返回数据 实例属性 server_version 格式化输出服务器版本信息,例如&#39;BaseHTTP/0.2&#39;. sys_version 包含系统版本,使用version_string 方法和server_version 类变量,例如:&#39;Python/1.4&#39;. error_message_format 声明错误信息 error_content_type 声明错误上下文类型默认值是 &#39;text/html&#39;. protocol_version 声明HTTP协议版本,例如:&#39;HTTP/1.1&#39;, 服务器会保持连接。 MessageClass 声明email.message.Message](https://docs.python.org/zh-cn/3.8/library/email.compat32-message.html#email.message.Message)-like 类处理请求头。通常不用重写,默认指向http.client.HTTPMessage属性。. responses 回应 通常使用send_response_only() 和send_error() 方法实现。 实例方法 handle() 调用handle_one_request() 方法一次(如果保持连接,会调用多次) 来管理http请求。. 此方法不需要重写,除此以外,可以重写 do_*() 等方法实现处理请求。 handle_one_request() 此方法不需要重写,实现处理 do_*()等方法. handle_expect_100() 当 HTTP/1.1 请求时,服务器期望返回 100-continue 并返回 200响应码。如果想拒绝客户端连接,会抛出一个异常。 send_error(code, message=None, explain=None) send_response(code, message=None) send_header(keyword, value) send_response_only(code, message=None) end_headers() flush_headers() log_request(code=’-‘, size=’-‘) log_error(…) log_message(format, …) version_string() date_time_string(timestamp=None) log_date_time_string() address_string() 创建一个简易服务器例如下面的代码: 12345678910import http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer(("", PORT), Handler) as httpd: print("serving at port", PORT) httpd.serve_forever() 当然也可以通过命令行方式创建,例如: 1python -m http.server 8000 默认绑定本机的ip地址。 当然你可以指定一个ip地址,加入--bind参数 1python -m http.server 8000 --bind 127.0.0.1 3.8 新增 支持绑定ipv6地址 3.7 新增支持绑定一个cgi程序,例如 1python -m http.server --cgi 8000 一个具体应用的实例12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python from http.server import BaseHTTPRequestHandler, HTTPServer # HTTPRequestHandler classclass testHTTPServer_RequestHandler(BaseHTTPRequestHandler): # GET def do_GET(self): # Send response status code self.send_response(200) # Send headers self.send_header('Content-type','text/html') self.end_headers() # Send message back to client message = "Hello world!" # Write content as utf-8 data self.wfile.write(bytes(message, "utf8")) return def run(): print('starting server...') # Server settings # Choose port 8080, for port 80, which is normally used for a http server, you need root access server_address = ('127.0.0.1', 8081) httpd = HTTPServer(server_address, testHTTPServer_RequestHandler) print('running server...') httpd.serve_forever() run() 备注: 此处wfile.write方法 需要转成 byte类型, 可以参考stackoverflow上的关于这个问题的讨论:: python-3-x-basehttpserver-or-http-server 小结看完http.server 深有感触,一个简单的服务器学习了这么多http协议实现,看来还得继续深入理解。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>http.server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows jupyter notebook nbextension usage]]></title>
    <url>%2F2020%2F01%2F04%2Fwindows-jupyter-notebook-nbextension-usage%2F</url>
    <content type="text"><![CDATA[windows下jupyter 安装nbextension 插件填坑记 环境 软件和操作系统 版本号 操作系统 win7 64位 sp1 python版本 3.6.2 jupyter core 4.5.0 jupyter notebook 6.0.0 问题描述本来以为给jupyter安装个插件,分分钟搞定的事,结果三天了还是没解决。 我回家用win10的电脑,5分钟搞定。 尝试了各种方式,卸载重装,修改环境变量,换不同的python版本。后来我快要放放弃的时候，我终于搞定了。 问题定位我突然想到,是不是因为我安装了anaconda,于是增加了搜索关键字,终于发现了问题所在。 正确操作步骤 确定是已经安装好anaconda 要在anaconda prompt模式下(重要的事情说三遍,三遍,三遍，此处省略一万字,万马奔腾) pip install jupyter_contrib_nbextensions 配置：jupyter contrib nbextension install --user --skip-running-check 启动jupyter notebook，“Nbextensions”出现在导航栏中，在勾选目录。 查看 jupyter 版本123456789101112(base) C:\Users\Mr.Sui&gt;jupyter --versionjupyter core : 4.5.0jupyter-notebook : 6.0.0qtconsole : 4.5.1ipython : 7.6.1ipykernel : 5.1.1jupyter client : 5.3.1jupyter lab : 1.0.2nbconvert : 5.5.0ipywidgets : 7.5.0nbformat : 4.4.0traitlets : 4.3.2 有用的插件 代码导航功能 Table of Contents 变量检查器 Variable Inspector 显示单元格运行的时间和长度 Excute time 折叠/放下标题 Collapsible Headings 折叠代码 Codefolding 隐藏代码 hide input 隐藏选定代码 hide input all 隐藏所有代码 代码自动补全 Hinterland 通知 Notify Jupyter Notebook 首先你要勾选Notify扩展，其次再点击按钮正式启动。你选择的时间是Jupyter Notebook运行的最短时间，到点后它会向你发送通知 隐藏活动状态栏 zenmode tqdm_notebook 为循环代码显示执行进度条 12# 先安装 tqdm ：pip install tqdm# 使用时导入：from tqdm import tqdm_notebook 脚本自动保存 AutoSaveTime 参考文章官网教程 jupyter notebook的插件拓展—-jupyter_contrib_nbextensions 使用Jupyter Notebook编写技术文档]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>windows</tag>
        <tag>juypter</tag>
        <tag>nbextension</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library webbrowser]]></title>
    <url>%2F2020%2F01%2F03%2Fpython-standard-library-webbrowser%2F</url>
    <content type="text"><![CDATA[python 标准库之 webbrowser没啥前提一张图表示我现在的心情 标准库 webbrowserwebbrowser 模块提供了一个高级接口，允许向用户显示基于Web的文档。 在大多数情况下，只需从该模块调用 open() 函数就可以了。 在 Unix 下，图形浏览器在 X11 下是首选，但如果图形浏览器不可用或 X11 显示不可用，则将使用文本模式浏览器。 如果使用文本模式浏览器，则调用进程将阻塞，直到用户退出浏览器。 如果存在环境变量 BROWSER ，则将其解释为 os.pathsep 分隔的浏览器列表，以便在平台默认值之前尝试。 当列表部分的值包含字符串 ％s 时，它被解释为一个文字浏览器命令行，用于替换 ％s 的参数 URL ；如果该部分不包含 ％s，则它只被解释为要启动的浏览器的名称。 脚本 webbrowser 可以用作模块的命令行界面。它接受一个 URL 作为参数。还接受以下可选参数：-n 如果可能，在新的浏览器窗口中打开 URL ； -t 在新的浏览器页面（“标签”）中打开 URL。这些选择当然是相互排斥的。用法示例: 1python -m webbrowser -t "https://jeffsui.github.io" 异常exception webbrowser.`Error` 发生浏览器控件错误时引发异常。 函数 webbrowser.`open`(url, new=0, autoraise=True) 使用默认浏览器显示 url。 如果 new 为 0，则尽可能在同一浏览器窗口中打开 url。 如果 new 为 1，则尽可能打开新的浏览器窗口。 如果 new 为 2，则尽可能打开新的浏览器页面（“标签”）。 如果 autoraise 为 “True”，则会尽可能置前窗口（请注意，在许多窗口管理器下，无论此变量的设置如何，都会置前窗口）。请注意，在某些平台上，尝试使用此函数打开文件名，可能会起作用并启动操作系统的关联程序。 但是，这种方式不被支持也不可移植。使用 url 参数会引发 auditing event webbrowser.open 。 webbrowser.open_new(url) 如果可能，在默认浏览器的新窗口中打开 url，否则，在唯一的浏览器窗口中打开 url。 webbrowser.open_new_tab(url) 如果可能，在默认浏览器的新页面（“标签”）中打开 url，否则等效于 open_new()。 webbrowser.get(*using=None*) 返回浏览器类型为 using 指定的控制器对象。 如果 using 为 None，则返回适用于调用者环境的默认浏览器的控制器。 webbrowser.register(name, constructor, instance=None, **, preferred=False*) 注册 name 浏览器类型。 注册浏览器类型后， get() 函数可以返回该浏览器类型的控制器。 如果没有提供 instance，或者为 None，constructor 将在没有参数的情况下被调用，以在需要时创建实例。 如果提供了 instance，则永远不会调用 constructor，并且可能是 None。将 preferred 设置为 True 使得这个浏览器成为 get() 不带参数调用的首选结果。 否则，只有在您计划设置 BROWSER 变量，或使用与您声明的处理程序的名称相匹配的非空参数调用 get() 时，此入口点才有用。 浏览器类型预定义了许多浏览器类型。 此表给出了可以传递给 get() 函数的类型名称以及控制器类的相应实例化，这些都在此模块中定义。 类型名 类名 注释 &#39;mozilla&#39; Mozilla(&#39;mozilla&#39;) &#39;firefox&#39; Mozilla(&#39;mozilla&#39;) &#39;netscape&#39; Mozilla(&#39;netscape&#39;) &#39;galeon&#39; Galeon(&#39;galeon&#39;) &#39;epiphany&#39; Galeon(&#39;epiphany&#39;) &#39;skipstone&#39; BackgroundBrowser(&#39;skipstone&#39;) &#39;kfmclient&#39; Konqueror() (1) &#39;konqueror&#39; Konqueror() (1) &#39;kfm&#39; Konqueror() (1) &#39;mosaic&#39; BackgroundBrowser(&#39;mosaic&#39;) &#39;opera&#39; Opera() &#39;grail&#39; Grail() &#39;links&#39; GenericBrowser(&#39;links&#39;) &#39;elinks&#39; Elinks(&#39;elinks&#39;) &#39;lynx&#39; GenericBrowser(&#39;lynx&#39;) &#39;w3m&#39; GenericBrowser(&#39;w3m&#39;) &#39;windows-default&#39; WindowsDefault (2) &#39;macosx&#39; MacOSX(&#39;default&#39;) (3) &#39;safari&#39; MacOSX(&#39;safari&#39;) (3) &#39;google-chrome&#39; Chrome(&#39;google-chrome&#39;) &#39;chrome&#39; Chrome(&#39;chrome&#39;) &#39;chromium&#39; Chromium(&#39;chromium&#39;) &#39;chromium-browser&#39; Chromium(&#39;chromium-browser&#39;) 简单的例子: 1234567url = 'http://docs.python.org/'# Open URL in a new tab, if a browser window is already open.webbrowser.open_new_tab(url)# Open URL in new window, raising the window if possible.webbrowser.open_new(url) 浏览器控制器对象浏览器控制器提供三个与模块级便捷函数相同的方法： controller.open(url, new=0, autoraise=True)` 使用此控制器处理的浏览器显示 url。 如果 new 为 1，则尽可能打开新的浏览器窗口。 如果 new 为 2，则尽可能打开新的浏览器页面（“标签”）。 controller.open_new(url)` 如果可能，在此控制器处理的浏览器的新窗口中打开 url ，否则，在唯一的浏览器窗口中打开 url 。 别名 open_new()。 controller.open_new_tab(url)` 如果可能，在此控制器处理的浏览器的新页面（“标签”）中打开 url，否则等效于 open_new() 总结标准库中的webbrowser只提供了一个简单的操作本地浏览器的接口。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>webbrowser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library csv]]></title>
    <url>%2F2020%2F01%2F02%2Fpython-standard-library-csv%2F</url>
    <content type="text"><![CDATA[python 标准库学习之csv前言2019年立的flag,今年继续,标准库系列文章继续更新。 今天是真冷啊,屋里头才16℃,只能用一张图来表示我的心情。 标准库 csv文档路径python标准库csv CSV 文件格式文件扩展名为.csv,通用的电子表格文件格式,经常使用在数据分析中。 分隔符可能有所差别, python中的csv模块提供了对csv文件的读写操作,非常方便。 csv 常用方法csv.reader(csvfile,dialect=&#39;excel&#39;, ***fmtparams) 返回一个reader对象,该对象遍历csvfile。csv对象可以是任何对象,只要这个对象支持iteratable协议,并在每次调用__next__()方法时都返回字符串即可。如果csvfile是文件对象,则打开它时应使用newline=&#39;&#39;。可选参数dialect是用于不同的csv文件类型,它可以是 Dialect 类的子类的实例，也可以是 list_dialects() 函数返回的字符串之一。完整的解释可以参考csv文件格式参数。 csv文件的每一行都会默认当做字符串列表解析,除非指定了 QUOTE_NONNUMERIC 格式选项（在这种情况下，未加引号的字段会转换为浮点数），否则不会执行自动数据类型转换。 一个读文件例子 1234567&gt;&gt;&gt; import csv&gt;&gt;&gt; with open('eggs.csv', newline='') as csvfile:... spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')... for row in spamreader:... print(', '.join(row))Spam, Spam, Spam, Spam, Spam, Baked BeansSpam, Lovely Spam, Wonderful Spam csv.writer(csvfile, dialect=&#39;excel&#39;, **fmtparams) 返回一个 writer 对象，该对象负责将用户的数据在给定的文件类对象上转换为带分隔符的字符串。csvfile 可以是具有 write() 方法的任何对象。如果 csvfile 是文件对象，则打开它时应使用 newline=&#39;&#39;。 为了尽量简化与数据库 API 模块之间的对接，None 值会写入为空字符串。虽然这个转换是不可逆的，但它让 SQL 空数据值转储到 CSV 文件更容易，而无需预处理从 cursor.fetch* 调用返回的数据。写入前，所有非字符串数据都先用 str() 转化为字符串再写入。 一个写文件例子 123456import csvwith open('eggs.csv', 'w', newline='') as csvfile: spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL) spamwriter.writerow(['Spam'] * 5 + ['Baked Beans']) spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam']) csv.register_dialect(name[, dialect[, **fmtparams]]) 将 name 与 dialect 关联起来。name 必须是字符串。要指定变种 (dialect)，可以给出 Dialect 的子类，或给出 fmtparams 关键字参数，或两者都给出（此时关键字参数会覆盖 dialect 参数）。 有关方言和格式设置参数的完整详细信息，请参见 方言格式参数 部分。 其他方法: csv.unregister_dialect(name) 从变种注册表中删除 name 对应的变种。如果 name 不是已注册的变种名称，则抛出 Error 异常。 csv.get_dialect(name) 返回 name 对应的变种。如果 name 不是已注册的变种名称，则抛出 Error 异常。该函数返回的是不可变的 Dialect 对象。 csv.list_dialects() 返回所有已注册变种的名称。 csv.field_size_limit([new_limit]) 返回解析器当前允许的最大字段大小。如果指定了 new_limit，则它将成为新的最大字段大小。 csv模块定义的类class csv.DictReader(*f*, *fieldnames=None*, *restkey=None*, *restval=None*, *dialect=&#39;excel&#39;*, **args*, ***kwds*) 创建一个对象，该对象在操作上类似于常规 reader，但是将每行中的信息映射到一个 dict，该 dict 的键由 fieldnames 可选参数给出。 fieldnames 参数是一个 sequence。如果省略 fieldnames，则文件 f 第一行中的值将用作字段名。无论字段名是如何确定的，字典都将保留其原始顺序。 如果某一行中的字段多于字段名，则其余字段将放入列表中，字段名由 restkey 指定（默认为 None）。如果非空白行的字段少于字段名，则缺少的值将用 None 填充。 所有其他可选或关键字参数都传递给底层的 reader 实例。 3.8 中,返回的行是 dict 类型。 一个使用DictReader例子 1234567891011&gt;&gt;&gt; import csv&gt;&gt;&gt; with open('names.csv', newline='') as csvfile:... reader = csv.DictReader(csvfile)... for row in reader:... print(row['first_name'], row['last_name'])...Eric IdleJohn Cleese&gt;&gt;&gt; print(row)&#123;'first_name': 'John', 'last_name': 'Cleese'&#125; class csv.DictWriter(f, fieldnames, restval=&#39;&#39;, extrasaction=&#39;raise&#39;, dialect=&#39;excel&#39;, **args, **kwds) 创建一个对象，该对象在操作上类似常规 writer，但会将字典映射到输出行。 fieldnames 参数是由键组成的 序列，它指定字典中值的顺序，这些值会按指定顺序传递给 writerow() 方法并写入文件 f。 如果字典缺少 fieldnames 中的键，则可选参数 restval 用于指定要写入的值。 如果传递给 writerow() 方法的字典的某些键在 fieldnames 中找不到，则可选参数 extrasaction 用于指定要执行的操作。 如果将其设置为默认值 &#39;raise&#39;，则会引发 ValueError。 如果将其设置为 &#39;ignore&#39;，则字典中的其他键值将被忽略。 所有其他可选或关键字参数都传递给底层的 writer 实例。 注意，与 DictReader 类不同，DictWriter 类的 fieldnames 参数不是可选参数 一个使用DictWriter写入文件例子 12345678910import csvwith open('names.csv', 'w', newline='') as csvfile: fieldnames = ['first_name', 'last_name'] writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() writer.writerow(&#123;'first_name': 'Baked', 'last_name': 'Beans'&#125;) writer.writerow(&#123;'first_name': 'Lovely', 'last_name': 'Spam'&#125;) writer.writerow(&#123;'first_name': 'Wonderful', 'last_name': 'Spam'&#125;) 其他方法: class csv.Dialect Dialect 类是主要依赖于其属性的容器类，用于将定义好的参数传递给特定的 reader 或 writer 实例。 class csv.excel excel 类定义了 Excel 生成的 CSV 文件的常规属性。它在变种注册表中的名称是 &#39;excel&#39;。 class csv.excel_tab excel_tab 类定义了 Excel 生成的、制表符分隔的 CSV 文件的常规属性。它在变种注册表中的名称是 &#39;excel-tab&#39;。 class csv.unix_dialect unix_dialect 类定义了在 UNIX 系统上生成的 CSV 文件的常规属性，即使用 &#39;\n&#39; 作为换行符，且所有字段都有引号包围。它在变种注册表中的名称是 &#39;unix&#39;。 class csv.SnifferSniffer 类用于推断 CSV 文件的格式。 Sniffer 类提供了两个方法： sniff(sample, delimiters=None) 分析给定的 sample 并返回一个 Dialect 子类，该子类中包含了分析出的格式参数。如果给出可选的 delimiters 参数，则该参数会被解释为字符串，该字符串包含了可能的有效定界符。 has_header(sample) 分析示例文本（假定为 CSV 格式），如果第一行很可能是一系列列标题，则返回 True。 一个使用Sniffer的例子: 12345ith open('example.csv', newline='') as csvfile: dialect = csv.Sniffer().sniff(csvfile.read(1024)) csvfile.seek(0) reader = csv.reader(csvfile, dialect) # ... process CSV file contents here ... csv 中定义的常量 csv.`QUOTE_ALL` 指示 writer 对象给所有字段加上引号。 csv.`QUOTE_MINIMAL` 指示 writer 对象仅为包含特殊字符（例如 定界符、引号字符 或 行结束符 中的任何字符）的字段加上引号。 csv.`QUOTE_NONNUMERIC` 指示 writer 对象为所有非数字字段加上引号。指示 reader 将所有未用引号引出的字段转换为 float 类型。 csv.`QUOTE_NONE` 指示 writer 对象不使用引号引出字段。当 定界符 出现在输出数据中时，其前面应该有 转义符。如果未设置 转义符，则遇到任何需要转义的字符时，writer 都会抛出 Error 异常。指示 reader 不对引号字符进行特殊处理。 csv模块定义了以下异常： exception csv.`Error` 该异常可能由任何发生错误的函数抛出。 备注如果没有指定 newline=&#39;&#39;，则嵌入引号中的换行符将无法正确解析，并且在写入时，使用 \r\n 换行的平台会有多余的 \r 写入。由于 csv 模块会执行自己的（通用）换行符处理，因此指定 newline=&#39;&#39; 应该总是安全的。 总结csv模块是一个非常实用的处理csv文件的标准库，提供了两个核心类。一个是把csv文件对象当作字符串列表解析csv文件的类，另一个是把csv文件对象当作字典解析的类。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>csv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[using python venv to create virtual environment]]></title>
    <url>%2F2019%2F12%2F26%2F2019-26-using-python-venv-to-create-virtual-environment%2F</url>
    <content type="text"><![CDATA[python env 创建虚拟环境前言又断更了,长此以往,我可能无法完成100天打卡任务了。 红包是刺激自己前进的动力。 python 标准库03之虚拟环境创建参考文档 python目前官方推荐的工具是venv 顺便介绍下目前常用的python虚拟环境工具 virsualenv pyvenv (3.3,3.4中推荐的虚拟环境创建工具,3.6中被弃用) venv(3.6以后推荐的虚拟环境创建工具) 创建虚拟环境使用下面的命令创建一个虚拟环境 1python3 -m venv /path/to/new/virtual/environment windows下使用venv来创建虚拟环境 1c:\&gt;c:\Python35\python -m venv c:\path\to\myenv 使用-h参数可以查看venv命令行的帮助文档 1234567891011121314151617181920212223242526usage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear] [--upgrade] [--without-pip] [--prompt PROMPT] ENV_DIR [ENV_DIR ...]Creates virtual Python environments in one or more target directories.positional arguments: ENV_DIR A directory to create the environment in.optional arguments: -h, --help show this help message and exit --system-site-packages Give the virtual environment access to the system site-packages dir. --symlinks Try to use symlinks rather than copies, when symlinks are not the default for the platform. --copies Try to use copies rather than symlinks, even when symlinks are the default for the platform. --clear Delete the contents of the environment directory if it already exists, before environment creation. --upgrade Upgrade the environment directory to use this version of Python, assuming Python has been upgraded in-place. --without-pip Skips installing or upgrading pip in the virtual environment (pip is bootstrapped by default) --prompt PROMPT Provides an alternative prompt prefix for this environment. 除非你使用了--without-pip 参数,否则 ensurepip 模块会默认安装pip指令到创建好的虚拟环境中。 一旦一个虚拟环境被创建，可以通过下面的命令激活这个虚拟环境。不同平台下的激活方式略有不同,下面总结了各个平台下虚拟环境的激活命令脚本,请参考。 激活虚拟环境 平台 Shell 用于激活虚拟环境的命令 POSIX bash/zsh $ source /bin/activate fish $ . /bin/activate.fish csh/tcsh $ source /bin/activate.csh PowerShell Core $ /bin/Activate.ps1 Windows cmd.exe C:> \Scripts\activate.bat PowerShell PS C:> \Scripts\Activate.ps1 You don’t specifically need to activate an environment; activation just prepends the virtual environment’s binary directory to your path, so that “python” invokes the virtual environment’s Python interpreter and you can run installed scripts without having to use their full path. However, all scripts installed in a virtual environment should be runnable without activating it, and run with the virtual environment’s Python automatically. You can deactivate a virtual environment by typing “deactivate” in your shell. The exact mechanism is platform-specific and is an internal implementation detail (typically a script or shell function will be used). 你无需关心如何激活一个虚拟环境；使用相对于项目当前路径下的可执行方法,python解析器就可以激活虚拟环境。已经激活的虚拟环境, 就可以使用python的命令直接执行脚本或者安装其他软件包到当前的虚拟环境，而不需要关心是否会污染本地python环境的问题。同样，使用deactivate 就可以退出当前的虚拟环境。 API下面展示的是一个使用EnvBuilder 创建一个自定义虚拟环境的脚本。 1class venv.EnvBuilder(system_site_packages=False, clear=False, symlinks=False, upgrade=False, with_pip=False, prompt=None) create(env_dir) system_site_packages – 一个Boolean值,是否将site-packages添加到虚拟环境中 默认是False. clear – 一个Boolean值,如果为真,将会在创建环境之前清除已经存在的目标路径. symlinks – 一个Boolean值,如果为真,将会在创建环境前删除包含内容的目录 upgrade – 一个Boolean值,如果为真, 则将用正在运行的Python升级现有环境 - 用于在Python就地升级（默认为False）时使用。. with_pip – 一个Boolean值,如果为真,pip命令将会安装到虚拟环境中 ,使用 ensurepip 的默认 --default-pip 参数选项. prompt – 在激活虚拟环境后使用的字符串（默认为None表示将使用环境的目录名称）。. 1234567891011def create(self, env_dir): """ Create a virtualized Python environment in a directory. env_dir is the target directory to create an environment in. """ env_dir = os.path.abspath(env_dir) context = self.ensure_directories(env_dir) self.create_configuration(context) self.setup_python(context) self.setup_scripts(context) self.post_setup(context) ensure_directories(env_dir) 创建环境目录和所有必需的目录，并返回一个上下文对象。这只是属性（如路径）的持有者，供其他方法使用。这些目录已被允许存在，只要其中一个clear或被upgrade指定为允许在现有环境目录上进行操作即可。 create_configuration(context) pyvenv.cfg在环境中创建配置文件。 setup_python(context) 在环境中创建Python可执行文件（以及Windows下的DLL）的副本。在POSIX系统中，如果一个特定的可执行文件 python3.x使用，符号链接python和python3将创建指向该可执行文件，除非已存在具有这些名称的文件。 setup_scripts(context) 将适合该平台的激活脚本安装到虚拟环境中。 post_setup(context) 一种占位符方法，可以在第三方实现中重写，以在虚拟环境中预安装包或执行其他后创建步骤。 此外，EnvBuilder提供这种工具方法，可以从被称为setup_scripts()或post_setup()在子类中，以协助安装自定义脚本到虚拟环境中。install_scripts（上下文，路径）路径是应包含子目录“common”，“posix”，“nt”的目录的路径，每个目录都包含指向环境中bin目录的脚本。os.name经过一些文本替换占位符后，“common”的内容和相应的目录被复制： __VENV_DIR__ 被替换为环境目录的绝对路径。 __VENV_NAME__ 被替换为环境名称（环境目录的最终路径段）。 __VENV_PROMPT__ 被提示符替换（环境名称由括号括起来，并带有下面的空格） __VENV_BIN_NAME__被替换为bin目录的名称（bin或者Scripts）。 __VENV_PYTHON__被替换为环境可执行文件的绝对路径。允许目录存在（用于在现有环境正在升级时）。 还有一个模块级的便利功能： 12venv.create（env_dir，system_site_packages = False，clear = False，symlinks =False，with_pip = False ） EnvBuilder用给定的关键字参数创建一个参数，并调用create()并使用env_dir参数。 一个扩展EnvBuilder例子以下脚本展示了如何EnvBuilder通过实现将setuptools和pip安装到创建的虚拟环境中的子类来进行扩展： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214import osimport os.pathfrom subprocess import Popen, PIPEimport sysfrom threading import Threadfrom urllib.parse import urlparsefrom urllib.request import urlretrieveimport venvclass ExtendedEnvBuilder(venv.EnvBuilder): """ This builder installs setuptools and pip so that you can pip or easy_install other packages into the created virtual environment. :param nodist: If true, setuptools and pip are not installed into the created virtual environment. :param nopip: If true, pip is not installed into the created virtual environment. :param progress: If setuptools or pip are installed, the progress of the installation can be monitored by passing a progress callable. If specified, it is called with two arguments: a string indicating some progress, and a context indicating where the string is coming from. The context argument can have one of three values: 'main', indicating that it is called from virtualize() itself, and 'stdout' and 'stderr', which are obtained by reading lines from the output streams of a subprocess which is used to install the app. If a callable is not specified, default progress information is output to sys.stderr. """ def __init__(self, *args, **kwargs): self.nodist = kwargs.pop('nodist', False) self.nopip = kwargs.pop('nopip', False) self.progress = kwargs.pop('progress', None) self.verbose = kwargs.pop('verbose', False) super().__init__(*args, **kwargs) def post_setup(self, context): """ Set up any packages which need to be pre-installed into the virtual environment being created. :param context: The information for the virtual environment creation request being processed. """ os.environ['VIRTUAL_ENV'] = context.env_dir if not self.nodist: self.install_setuptools(context) # Can't install pip without setuptools if not self.nopip and not self.nodist: self.install_pip(context) def reader(self, stream, context): """ Read lines from a subprocess' output stream and either pass to a progress callable (if specified) or write progress information to sys.stderr. """ progress = self.progress while True: s = stream.readline() if not s: break if progress is not None: progress(s, context) else: if not self.verbose: sys.stderr.write('.') else: sys.stderr.write(s.decode('utf-8')) sys.stderr.flush() stream.close() def install_script(self, context, name, url): _, _, path, _, _, _ = urlparse(url) fn = os.path.split(path)[-1] binpath = context.bin_path distpath = os.path.join(binpath, fn) # Download script into the virtual environment's binaries folder urlretrieve(url, distpath) progress = self.progress if self.verbose: term = '\n' else: term = '' if progress is not None: progress('Installing %s ...%s' % (name, term), 'main') else: sys.stderr.write('Installing %s ...%s' % (name, term)) sys.stderr.flush() # Install in the virtual environment args = [context.env_exe, fn] p = Popen(args, stdout=PIPE, stderr=PIPE, cwd=binpath) t1 = Thread(target=self.reader, args=(p.stdout, 'stdout')) t1.start() t2 = Thread(target=self.reader, args=(p.stderr, 'stderr')) t2.start() p.wait() t1.join() t2.join() if progress is not None: progress('done.', 'main') else: sys.stderr.write('done.\n') # Clean up - no longer needed os.unlink(distpath) def install_setuptools(self, context): """ Install setuptools in the virtual environment. :param context: The information for the virtual environment creation request being processed. """ url = 'https://bitbucket.org/pypa/setuptools/downloads/ez_setup.py' self.install_script(context, 'setuptools', url) # clear up the setuptools archive which gets downloaded pred = lambda o: o.startswith('setuptools-') and o.endswith('.tar.gz') files = filter(pred, os.listdir(context.bin_path)) for f in files: f = os.path.join(context.bin_path, f) os.unlink(f) def install_pip(self, context): """ Install pip in the virtual environment. :param context: The information for the virtual environment creation request being processed. """ url = 'https://raw.github.com/pypa/pip/master/contrib/get-pip.py' self.install_script(context, 'pip', url)def main(args=None): compatible = True if sys.version_info &lt; (3, 3): compatible = False elif not hasattr(sys, 'base_prefix'): compatible = False if not compatible: raise ValueError('This script is only for use with ' 'Python 3.3 or later') else: import argparse parser = argparse.ArgumentParser(prog=__name__, description='Creates virtual Python ' 'environments in one or ' 'more target ' 'directories.') parser.add_argument('dirs', metavar='ENV_DIR', nargs='+', help='A directory in which to create the 'virtual environment.') parser.add_argument('--no-setuptools', default=False, action='store_true', dest='nodist', help="Don't install setuptools or pip in the " "virtual environment.") parser.add_argument('--no-pip', default=False, action='store_true', dest='nopip', help="Don't install pip in the virtual " "environment.") parser.add_argument('--system-site-packages', default=False, action='store_true', dest='system_site', help='Give the virtual environment access to the ' 'system site-packages dir.') if os.name == 'nt': use_symlinks = False else: use_symlinks = True parser.add_argument('--symlinks', default=use_symlinks, action='store_true', dest='symlinks', help='Try to use symlinks rather than copies, ' 'when symlinks are not the default for ' 'the platform.') parser.add_argument('--clear', default=False, action='store_true', dest='clear', help='Delete the contents of the ' 'virtual environment ' 'directory if it already ' 'exists, before virtual ' 'environment creation.') parser.add_argument('--upgrade', default=False, action='store_true', dest='upgrade', help='Upgrade the virtual ' 'environment directory to ' 'use this version of ' 'Python, assuming Python ' 'has been upgraded ' 'in-place.') parser.add_argument('--verbose', default=False, action='store_true', dest='verbose', help='Display the output ' 'from the scripts which ' 'install setuptools and pip.') options = parser.parse_args(args) if options.upgrade and options.clear: raise ValueError('you cannot supply --upgrade and --clear together.') builder = ExtendedEnvBuilder(system_site_packages=options.system_site, clear=options.clear, symlinks=options.symlinks, upgrade=options.upgrade, nodist=options.nodist, nopip=options.nopip, verbose=options.verbose) for d in options.dirs: builder.create(d)if __name__ == '__main__': rc = 1 try: main() rc = 0 except Exception as e: print('Error: %s' % e, file=sys.stderr) sys.exit(rc) 实践在windows下vscode中通过venv 创建虚拟环境步骤: powershell下,执行命令 python -m venv .venv 执行激活命令 .\Scripts\activate.ps1 退出虚拟环境 在项目目录下执行deactivate 即可。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[using python venv to create virtual environment]]></title>
    <url>%2F2019%2F12%2F26%2Fusing-python-venv-to-create-virtual-environment%2F</url>
    <content type="text"><![CDATA[python env 创建虚拟环境前言又断更了,长此以往,我可能无法完成100天打卡任务了。 红包是刺激自己前进的动力。 python 标准库03之虚拟环境创建参考文档 python目前官方推荐的工具是venv 顺便介绍下目前常用的python虚拟环境工具 virsualenv pyvenv (3.3,3.4中推荐的虚拟环境创建工具,3.6中被弃用) venv(3.6以后推荐的虚拟环境创建工具) 创建虚拟环境使用下面的命令创建一个虚拟环境 1python3 -m venv /path/to/new/virtual/environment windows下使用venv来创建虚拟环境 1c:\&gt;c:\Python35\python -m venv c:\path\to\myenv 使用-h参数可以查看venv命令行的帮助文档 1234567891011121314151617181920212223242526usage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear] [--upgrade] [--without-pip] [--prompt PROMPT] ENV_DIR [ENV_DIR ...]Creates virtual Python environments in one or more target directories.positional arguments: ENV_DIR A directory to create the environment in.optional arguments: -h, --help show this help message and exit --system-site-packages Give the virtual environment access to the system site-packages dir. --symlinks Try to use symlinks rather than copies, when symlinks are not the default for the platform. --copies Try to use copies rather than symlinks, even when symlinks are the default for the platform. --clear Delete the contents of the environment directory if it already exists, before environment creation. --upgrade Upgrade the environment directory to use this version of Python, assuming Python has been upgraded in-place. --without-pip Skips installing or upgrading pip in the virtual environment (pip is bootstrapped by default) --prompt PROMPT Provides an alternative prompt prefix for this environment. 除非你使用了--without-pip 参数,否则 ensurepip 模块会默认安装pip指令到创建好的虚拟环境中。 一旦一个虚拟环境被创建，可以通过下面的命令激活这个虚拟环境。不同平台下的激活方式略有不同,下面总结了各个平台下虚拟环境的激活命令脚本,请参考。 激活虚拟环境 平台 Shell 用于激活虚拟环境的命令 POSIX bash/zsh $ source /bin/activate fish $ . /bin/activate.fish csh/tcsh $ source /bin/activate.csh PowerShell Core $ /bin/Activate.ps1 Windows cmd.exe C:> \Scripts\activate.bat PowerShell PS C:> \Scripts\Activate.ps1 You don’t specifically need to activate an environment; activation just prepends the virtual environment’s binary directory to your path, so that “python” invokes the virtual environment’s Python interpreter and you can run installed scripts without having to use their full path. However, all scripts installed in a virtual environment should be runnable without activating it, and run with the virtual environment’s Python automatically. You can deactivate a virtual environment by typing “deactivate” in your shell. The exact mechanism is platform-specific and is an internal implementation detail (typically a script or shell function will be used). 你无需关心如何激活一个虚拟环境；使用相对于项目当前路径下的可执行方法,python解析器就可以激活虚拟环境。已经激活的虚拟环境, 就可以使用python的命令直接执行脚本或者安装其他软件包到当前的虚拟环境，而不需要关心是否会污染本地python环境的问题。同样，使用deactivate 就可以退出当前的虚拟环境。 API下面展示的是一个使用EnvBuilder 创建一个自定义虚拟环境的脚本。 1class venv.EnvBuilder(system_site_packages=False, clear=False, symlinks=False, upgrade=False, with_pip=False, prompt=None) create(env_dir) system_site_packages – 一个Boolean值,是否将site-packages添加到虚拟环境中 默认是False. clear – 一个Boolean值,如果为真,将会在创建环境之前清除已经存在的目标路径. symlinks – 一个Boolean值,如果为真,将会在创建环境前删除包含内容的目录 upgrade – 一个Boolean值,如果为真, 则将用正在运行的Python升级现有环境 - 用于在Python就地升级（默认为False）时使用。. with_pip – 一个Boolean值,如果为真,pip命令将会安装到虚拟环境中 ,使用 ensurepip 的默认 --default-pip 参数选项. prompt – 在激活虚拟环境后使用的字符串（默认为None表示将使用环境的目录名称）。. 1234567891011def create(self, env_dir): """ Create a virtualized Python environment in a directory. env_dir is the target directory to create an environment in. """ env_dir = os.path.abspath(env_dir) context = self.ensure_directories(env_dir) self.create_configuration(context) self.setup_python(context) self.setup_scripts(context) self.post_setup(context) ensure_directories(env_dir) 创建环境目录和所有必需的目录，并返回一个上下文对象。这只是属性（如路径）的持有者，供其他方法使用。这些目录已被允许存在，只要其中一个clear或被upgrade指定为允许在现有环境目录上进行操作即可。 create_configuration(context) pyvenv.cfg在环境中创建配置文件。 setup_python(context) 在环境中创建Python可执行文件（以及Windows下的DLL）的副本。在POSIX系统中，如果一个特定的可执行文件 python3.x使用，符号链接python和python3将创建指向该可执行文件，除非已存在具有这些名称的文件。 setup_scripts(context) 将适合该平台的激活脚本安装到虚拟环境中。 post_setup(context) 一种占位符方法，可以在第三方实现中重写，以在虚拟环境中预安装包或执行其他后创建步骤。 此外，EnvBuilder提供这种工具方法，可以从被称为setup_scripts()或post_setup()在子类中，以协助安装自定义脚本到虚拟环境中。install_scripts（上下文，路径）路径是应包含子目录“common”，“posix”，“nt”的目录的路径，每个目录都包含指向环境中bin目录的脚本。os.name经过一些文本替换占位符后，“common”的内容和相应的目录被复制： __VENV_DIR__ 被替换为环境目录的绝对路径。 __VENV_NAME__ 被替换为环境名称（环境目录的最终路径段）。 __VENV_PROMPT__ 被提示符替换（环境名称由括号括起来，并带有下面的空格） __VENV_BIN_NAME__被替换为bin目录的名称（bin或者Scripts）。 __VENV_PYTHON__被替换为环境可执行文件的绝对路径。允许目录存在（用于在现有环境正在升级时）。 还有一个模块级的便利功能： 12venv.create（env_dir，system_site_packages = False，clear = False，symlinks =False，with_pip = False ） EnvBuilder用给定的关键字参数创建一个参数，并调用create()并使用env_dir参数。 一个扩展EnvBuilder例子以下脚本展示了如何EnvBuilder通过实现将setuptools和pip安装到创建的虚拟环境中的子类来进行扩展： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214import osimport os.pathfrom subprocess import Popen, PIPEimport sysfrom threading import Threadfrom urllib.parse import urlparsefrom urllib.request import urlretrieveimport venvclass ExtendedEnvBuilder(venv.EnvBuilder): """ This builder installs setuptools and pip so that you can pip or easy_install other packages into the created virtual environment. :param nodist: If true, setuptools and pip are not installed into the created virtual environment. :param nopip: If true, pip is not installed into the created virtual environment. :param progress: If setuptools or pip are installed, the progress of the installation can be monitored by passing a progress callable. If specified, it is called with two arguments: a string indicating some progress, and a context indicating where the string is coming from. The context argument can have one of three values: 'main', indicating that it is called from virtualize() itself, and 'stdout' and 'stderr', which are obtained by reading lines from the output streams of a subprocess which is used to install the app. If a callable is not specified, default progress information is output to sys.stderr. """ def __init__(self, *args, **kwargs): self.nodist = kwargs.pop('nodist', False) self.nopip = kwargs.pop('nopip', False) self.progress = kwargs.pop('progress', None) self.verbose = kwargs.pop('verbose', False) super().__init__(*args, **kwargs) def post_setup(self, context): """ Set up any packages which need to be pre-installed into the virtual environment being created. :param context: The information for the virtual environment creation request being processed. """ os.environ['VIRTUAL_ENV'] = context.env_dir if not self.nodist: self.install_setuptools(context) # Can't install pip without setuptools if not self.nopip and not self.nodist: self.install_pip(context) def reader(self, stream, context): """ Read lines from a subprocess' output stream and either pass to a progress callable (if specified) or write progress information to sys.stderr. """ progress = self.progress while True: s = stream.readline() if not s: break if progress is not None: progress(s, context) else: if not self.verbose: sys.stderr.write('.') else: sys.stderr.write(s.decode('utf-8')) sys.stderr.flush() stream.close() def install_script(self, context, name, url): _, _, path, _, _, _ = urlparse(url) fn = os.path.split(path)[-1] binpath = context.bin_path distpath = os.path.join(binpath, fn) # Download script into the virtual environment's binaries folder urlretrieve(url, distpath) progress = self.progress if self.verbose: term = '\n' else: term = '' if progress is not None: progress('Installing %s ...%s' % (name, term), 'main') else: sys.stderr.write('Installing %s ...%s' % (name, term)) sys.stderr.flush() # Install in the virtual environment args = [context.env_exe, fn] p = Popen(args, stdout=PIPE, stderr=PIPE, cwd=binpath) t1 = Thread(target=self.reader, args=(p.stdout, 'stdout')) t1.start() t2 = Thread(target=self.reader, args=(p.stderr, 'stderr')) t2.start() p.wait() t1.join() t2.join() if progress is not None: progress('done.', 'main') else: sys.stderr.write('done.\n') # Clean up - no longer needed os.unlink(distpath) def install_setuptools(self, context): """ Install setuptools in the virtual environment. :param context: The information for the virtual environment creation request being processed. """ url = 'https://bitbucket.org/pypa/setuptools/downloads/ez_setup.py' self.install_script(context, 'setuptools', url) # clear up the setuptools archive which gets downloaded pred = lambda o: o.startswith('setuptools-') and o.endswith('.tar.gz') files = filter(pred, os.listdir(context.bin_path)) for f in files: f = os.path.join(context.bin_path, f) os.unlink(f) def install_pip(self, context): """ Install pip in the virtual environment. :param context: The information for the virtual environment creation request being processed. """ url = 'https://raw.github.com/pypa/pip/master/contrib/get-pip.py' self.install_script(context, 'pip', url)def main(args=None): compatible = True if sys.version_info &lt; (3, 3): compatible = False elif not hasattr(sys, 'base_prefix'): compatible = False if not compatible: raise ValueError('This script is only for use with ' 'Python 3.3 or later') else: import argparse parser = argparse.ArgumentParser(prog=__name__, description='Creates virtual Python ' 'environments in one or ' 'more target ' 'directories.') parser.add_argument('dirs', metavar='ENV_DIR', nargs='+', help='A directory in which to create the 'virtual environment.') parser.add_argument('--no-setuptools', default=False, action='store_true', dest='nodist', help="Don't install setuptools or pip in the " "virtual environment.") parser.add_argument('--no-pip', default=False, action='store_true', dest='nopip', help="Don't install pip in the virtual " "environment.") parser.add_argument('--system-site-packages', default=False, action='store_true', dest='system_site', help='Give the virtual environment access to the ' 'system site-packages dir.') if os.name == 'nt': use_symlinks = False else: use_symlinks = True parser.add_argument('--symlinks', default=use_symlinks, action='store_true', dest='symlinks', help='Try to use symlinks rather than copies, ' 'when symlinks are not the default for ' 'the platform.') parser.add_argument('--clear', default=False, action='store_true', dest='clear', help='Delete the contents of the ' 'virtual environment ' 'directory if it already ' 'exists, before virtual ' 'environment creation.') parser.add_argument('--upgrade', default=False, action='store_true', dest='upgrade', help='Upgrade the virtual ' 'environment directory to ' 'use this version of ' 'Python, assuming Python ' 'has been upgraded ' 'in-place.') parser.add_argument('--verbose', default=False, action='store_true', dest='verbose', help='Display the output ' 'from the scripts which ' 'install setuptools and pip.') options = parser.parse_args(args) if options.upgrade and options.clear: raise ValueError('you cannot supply --upgrade and --clear together.') builder = ExtendedEnvBuilder(system_site_packages=options.system_site, clear=options.clear, symlinks=options.symlinks, upgrade=options.upgrade, nodist=options.nodist, nopip=options.nopip, verbose=options.verbose) for d in options.dirs: builder.create(d)if __name__ == '__main__': rc = 1 try: main() rc = 0 except Exception as e: print('Error: %s' % e, file=sys.stderr) sys.exit(rc) 实践在windows下vscode中通过venv 创建虚拟环境步骤: powershell下,执行命令 python -m venv .venv 执行激活命令 .\Scripts\activate.ps1 退出虚拟环境 在项目目录下执行deactivate 即可。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library -2 dictionary]]></title>
    <url>%2F2019%2F12%2F23%2F2019-23-python-standard-library-2-dictionary%2F</url>
    <content type="text"><![CDATA[python 标准库学习笔记 – dictionary0.0 前言家里孩子发烧了,延迟更新标准库学习笔记 折腾了三个晚上,一家三口都累倒了。 人生就好比一个蹒跚学步的孩童,很容易被外界环境影响。 1.0 标准库- 内置函数参考文档: 内置类型-字典 python中主要内置类型包括numbers,sequences,mappings,classes,instance和exception。 1.1 逻辑值检测任何对象都可以进行逻辑值检测,以便在if 或while作为条件或是作为上下文所指返回值是布尔类型的表达式来使用。所以就有下面的用法。 12345L = []if(L): passwhile(L): pass 一个对象在默认情况下被认为是True,除非该对象定义了__boolean__() 方法且返回False 或者定义__len__()方法且返回零。下面三种情况的内置对象都会被认为是逻辑假值。 None 或 False 任何数值类型的零 空的序列和多项集 包括 空字符串、空列表、空集合、空字典、空元组以及空数列(reange(0)) 1.2 布尔运算 – and,or,not 运算 结果 注释 x or y if x is false, then y, else x 短路运算,只有第一个为假的时候才会对第二个求值 x and y if x is false, then x, else y 短路运算,只有第二个为真的时候才会对第二个求值 not x if x is false, then True, else False 逻辑取反 1.3 比较运算 运算 含义 &lt; 严格小于 &lt;= 小于或等于 &gt; 严格大于 &gt;= 大于或等于 == 等于 != 不等于 is 对象标识 is not 否定的对象标识 ==tips== 不同类型的对象之间不能使用比较运算,除非定义了对应的方法，例如__lt__(),__eq__()这样的函数 具有不同标识的类的实例,比较结果为False,除非你自己定义了__eq__()方法 一个类实例不能与相同类或的其他实例或其他类型的对象进行排序,除非定义了对应的方法，包括 __lt__(), __le__(), __gt__() 以及 __ge__() 1.4 数字类型 – int、float、complexpython中存在三种不同的数字类型: 整数, 浮点数 和 复数*。 运算 结果 注释 完整文档 x + y x 和 y 的和 x - y x 和 y 的差 x * y x 和 y 的乘积 x / y x 和 y 的商 x // y x 和 y 的商数 取整 x % y remainder of x / y 不可用于负数 -x x 取反 +x x 不变 abs(x) x 的绝对值或大小 abs() int(x) 将 x 转换为整数 小数会被截断 int() float(x) 将 x 转换为浮点数 (4)(6) float() complex(re, im) 一个带有实部 re 和虚部 im 的复数。im 默认为0。 (6) complex() c.conjugate() 复数 c 的共轭 divmod(x, y) (x // y, x % y) (2) divmod() pow(x, y) x 的 y 次幂 (5) pow() x ** y x 的 y 次幂 (5) 所有的numbers.Real类型（包括int 和 float)还包括以下运算: 运算 结果 math.trunc(x) x 截断为 Integral round(x[, n\]) x 舍入到 n 位小数，半数值会舍入到偶数。 如果省略 n，则默认为 0。 math.floor(x) &lt;= x 的最大 Integral math.ceil(x) &gt;= x 的最小 Integral 1.5 整数类型的附加方法int.bit_length() 返回以二进制表示一个整数锁需要的位数，不包括符号位和前面的零 1.6 浮点数类型的附加方法float.as_integer_ratio() 返回一对整数，其比率正好等于原浮点数并且分母为正数。 无穷大会引发 OverflowError 而 NaN 则会引发 ValueError。 float.is_integer() 如果 float 实例可用有限位整数表示则返回 True，否则返回 False: float.hex() 以十六进制字符串的形式返回一个浮点数表示。 对于有限浮点数，这种表示法将总是包含前导的 0x 和尾随的 p 加指数。 classmethod float.fromhex(s) 返回以十六进制字符串 s 表示的浮点数的类方法。 字符串 s 可以带有前导和尾随的空格。 ==tips==: float.hex() 是实例方法, float.fromhex(s)是类方法 1234&gt;&gt;&gt; float.fromhex('0x3.a7p10')3740.0&gt;&gt;&gt; float.hex(3740.0)'0x1.d380000000000p+11' 1.7 数字类型的哈希运算一个例子说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import sys, mathdef hash_fraction(m, n): """Compute the hash of a rational number m / n. Assumes m and n are integers, with n positive. Equivalent to hash(fractions.Fraction(m, n)). """ P = sys.hash_info.modulus # Remove common factors of P. (Unnecessary if m and n already coprime.) while m % P == n % P == 0: m, n = m // P, n // P if n % P == 0: hash_value = sys.hash_info.inf else: # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P. hash_value = (abs(m) % P) * pow(n, P - 2, P) % P if m &lt; 0: hash_value = -hash_value if hash_value == -1: hash_value = -2 return hash_valuedef hash_float(x): """Compute the hash of a float x.""" if math.isnan(x): return sys.hash_info.nan elif math.isinf(x): return sys.hash_info.inf if x &gt; 0 else -sys.hash_info.inf else: return hash_fraction(*x.as_integer_ratio())def hash_complex(z): """Compute the hash of a complex number z.""" hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag) # do a signed reduction modulo 2**sys.hash_info.width M = 2**(sys.hash_info.width - 1) hash_value = (hash_value &amp; (M - 1)) - (hash_value &amp; M) if hash_value == -1: hash_value = -2 return hash_value 1.8 映射类型 – dictpython中目前只有一种映射类型, 字典,映射属于可变对象。映射类型会将hashtable值映射到任意对象. 字典的键 几乎可以是任意值， 可hash的任意值,也就是包含列表、字典和其他可变类型的值,不可以用来充当字典中的键。 1.创建字典字典可以通过将以逗号分隔的 键: 值 对列表包含于花括号之内来创建，例如: {&#39;jack&#39;: 4098, &#39;sjoerd&#39;: 4127} 或 {4098: &#39;jack&#39;, 4127: &#39;sjoerd&#39;}，也可以通过 dict 构造器来创建。 2.构造函数class dict(**kwarg) class dict(mapping, **kwarg) class dict(iterable, **kwarg) 3. 其他函数 函数名 描述 list(d) 返回字典 d 中使用的所有键的列表。 len(d) 返回字典 d 中的项数。 d[key] 返回 d 中以 key 为键的项。 如果映射中不存在 key 则会引发 KeyError。 [1] d[key] = value 给d[key]的值设为value del d[key] 将 d[key] 从 d 中移除。 如果映射中不存在 key 则会引发 KeyError。 key in d 如果 d 中存在键 key 则返回 True，否则返回 False。 key not in d 等价于 not key in d。 iter(d) 返回以字典的键为元素的迭代器 clear() 移除字典中的所有元素。 copy() 返回原字典的浅拷贝。 classmethod fromkeys(iterable[, value]) 使用来自 iterable 的键创建一个新字典，并将键值设为 value。 get(key[, default]) 如果 key 存在于字典中则返回 key 的值，否则返回 default。 如果 default 未给出则默认为 None，因而此方法绝不会引发 KeyError。 items() 返回由字典项 ((键, 值) 对) 组成的一个新视图。 keys() 返回由字典键组成的一个新视图 pop(key[, default]) 如果 key 存在于字典中则将其移除并返回其值，否则返回 default。 如果 default 未给出且 key 不存在于字典中，则会引发 KeyError。 popitem() 从字典中移除并返回一个 (键, 值) 对。 键值对会按 LIFO 的顺序被返回。 reversed(d) 返回一个逆序获取字典键的迭代器 setdefault(key[, default]) 如果字典存在键 key ，返回它的值。如果不存在，插入值为 default 的键 key ，并返回 default 。 default 默认为 None。 update([other]) 使用来自 other 的键/值对更新字典，覆盖原有的键。 values() 返回由字典值组成的一个新视图 [2] 1234567891011121314#[1] 如果字典的子类定义了方法 __missing__() 并且 key 不存在，则 d[key] 操作将调用该方法并附带键 key 作为参数。 d[key] 随后将返回或引发 __missing__(key) 调用所返回或引发的任何对象或异常。 没有其他操作或方法会发起调用 __missing__()。 如果未定义 __missing__()，则会引发 KeyError。 __missing__() 必须是一个方法；它不能是一个实例变量:&gt;&gt;&gt; class Counter(dict):... def __missing__(self, key):... return 0&gt;&gt;&gt; c = Counter()&gt;&gt;&gt; c['red']0&gt;&gt;&gt; c['red'] += 1&gt;&gt;&gt; c['red']1#[2]两个 dict.values() 视图之间的相等性比较将总是返回 False。 这在 dict.values() 与其自身比较时也同样适用: &gt;&gt;&gt; d = &#123;'a': 1&#125;&gt;&gt;&gt; d.values() == d.values()False 字典比较: 两个字典的比较当且仅当它们具有相同的 (键, 值) 对时才会相等（不考虑顺序）。 排序比较 (‘&lt;’, ‘&lt;=’, ‘&gt;=’, ‘&gt;’) 会引发 TypeError。 字典会保留插入时的顺序。 请注意对键的更新不会影响顺序。 删除并再次添加的键将被插入到末尾。 1234567891011121314&gt;&gt;&gt; d = &#123;"one": 1, "two": 2, "three": 3, "four": 4&#125;&gt;&gt;&gt; d&#123;'one': 1, 'two': 2, 'three': 3, 'four': 4&#125;&gt;&gt;&gt; list(d)['one', 'two', 'three', 'four']&gt;&gt;&gt; list(d.values())[1, 2, 3, 4]&gt;&gt;&gt; d["one"] = 42&gt;&gt;&gt; d&#123;'one': 42, 'two': 2, 'three': 3, 'four': 4&#125;&gt;&gt;&gt; del d["two"]&gt;&gt;&gt; d["two"] = None&gt;&gt;&gt; d&#123;'one': 42, 'three': 3, 'four': 4, 'two': None&#125; 4.字典视图对象由 dict.keys(), dict.values() 和 dict.items() 所返回的对象是 视图对象。 该对象提供字典条目的一个动态视图，这意味着当字典改变时，视图也会相应改变。 字典视图函数 描述 len(dictview) 返回字典中的条目数 iter(dictview) 返回字典中的键、值或项（以 (键, 值) 为元素的元组表示）的迭代器 [1] x in dictview 如果 x 是对应字典中存在的键、值或项（在最后一种情况下 x 应为一个 (键, 值) 元组） 则返回 True reversed(dictview) 返回一个逆序获取字典键、值或项的迭代器。 视图将按与插入时相反的顺序进行迭代。 [2] 1234567891011121314151617181920212223242526272829#键视图类似于集合，因为其条目不重复且可哈希。 如果所有值都是可哈希的，即 (键, 值) 对也是不重复且可哈希的，那么条目视图也会类似于集合。 （值视图则不被视为类似于集合，因其条目通常都是有重复的。） 对于类似于集合的视图，为抽象基类 collections.abc.Set 所定义的全部操作都是有效的 (例如 ==, &lt; 或 ^)。&gt;&gt;&gt; dishes = &#123;'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500&#125;&gt;&gt;&gt; keys = dishes.keys()&gt;&gt;&gt; values = dishes.values()&gt;&gt;&gt; # iteration&gt;&gt;&gt; n = 0&gt;&gt;&gt; for val in values:... n += val&gt;&gt;&gt; print(n)504&gt;&gt;&gt; # keys and values are iterated over in the same order (insertion order)&gt;&gt;&gt; list(keys)['eggs', 'sausage', 'bacon', 'spam']&gt;&gt;&gt; list(values)[2, 1, 1, 500]&gt;&gt;&gt; # view objects are dynamic and reflect dict changes&gt;&gt;&gt; del dishes['eggs']&gt;&gt;&gt; del dishes['sausage']&gt;&gt;&gt; list(keys)['bacon', 'spam']&gt;&gt;&gt; # set operations&gt;&gt;&gt; keys &amp; &#123;'eggs', 'bacon', 'salad'&#125;&#123;'bacon'&#125;&gt;&gt;&gt; keys ^ &#123;'sausage', 'juice'&#125;&#123;'juice', 'sausage', 'bacon', 'spam'&#125; 2.0 小结 字典是可变类型,键只能是由非hash的数据类型充当 字典子类的__missing__方法。 字典视图的元素为不重复且可哈希。 一张图总结如下 后记记得五年前听过的一句话,赠给自己,也赠给凑巧看到这篇博文的有缘人。 种一棵树最好的时间是在十年前，其次是现在。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>dictionary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python standard library -2 dictionary]]></title>
    <url>%2F2019%2F12%2F23%2Fpython-standard-library-2-dictionary%2F</url>
    <content type="text"><![CDATA[python 标准库学习笔记 – dictionary0.0 前言家里孩子发烧了,延迟更新标准库学习笔记 折腾了三个晚上,一家三口都累倒了。 人生就好比一个蹒跚学步的孩童,很容易被外界环境影响。 1.0 标准库- 内置函数参考文档: 内置类型-字典 python中主要内置类型包括numbers,sequences,mappings,classes,instance和exception。 1.1 逻辑值检测任何对象都可以进行逻辑值检测,以便在if 或while作为条件或是作为上下文所指返回值是布尔类型的表达式来使用。所以就有下面的用法。 12345L = []if(L): passwhile(L): pass 一个对象在默认情况下被认为是True,除非该对象定义了__boolean__() 方法且返回False 或者定义__len__()方法且返回零。下面三种情况的内置对象都会被认为是逻辑假值。 None 或 False 任何数值类型的零 空的序列和多项集 包括 空字符串、空列表、空集合、空字典、空元组以及空数列(reange(0)) 1.2 布尔运算 – and,or,not 运算 结果 注释 x or y if x is false, then y, else x 短路运算,只有第一个为假的时候才会对第二个求值 x and y if x is false, then x, else y 短路运算,只有第二个为真的时候才会对第二个求值 not x if x is false, then True, else False 逻辑取反 1.3 比较运算 运算 含义 &lt; 严格小于 &lt;= 小于或等于 &gt; 严格大于 &gt;= 大于或等于 == 等于 != 不等于 is 对象标识 is not 否定的对象标识 ==tips== 不同类型的对象之间不能使用比较运算,除非定义了对应的方法，例如__lt__(),__eq__()这样的函数 具有不同标识的类的实例,比较结果为False,除非你自己定义了__eq__()方法 一个类实例不能与相同类或的其他实例或其他类型的对象进行排序,除非定义了对应的方法，包括 __lt__(), __le__(), __gt__() 以及 __ge__() 1.4 数字类型 – int、float、complexpython中存在三种不同的数字类型: 整数, 浮点数 和 复数*。 运算 结果 注释 完整文档 x + y x 和 y 的和 x - y x 和 y 的差 x * y x 和 y 的乘积 x / y x 和 y 的商 x // y x 和 y 的商数 取整 x % y remainder of x / y 不可用于负数 -x x 取反 +x x 不变 abs(x) x 的绝对值或大小 abs() int(x) 将 x 转换为整数 小数会被截断 int() float(x) 将 x 转换为浮点数 (4)(6) float() complex(re, im) 一个带有实部 re 和虚部 im 的复数。im 默认为0。 (6) complex() c.conjugate() 复数 c 的共轭 divmod(x, y) (x // y, x % y) (2) divmod() pow(x, y) x 的 y 次幂 (5) pow() x ** y x 的 y 次幂 (5) 所有的numbers.Real类型（包括int 和 float)还包括以下运算: 运算 结果 math.trunc(x) x 截断为 Integral round(x[, n\]) x 舍入到 n 位小数，半数值会舍入到偶数。 如果省略 n，则默认为 0。 math.floor(x) &lt;= x 的最大 Integral math.ceil(x) &gt;= x 的最小 Integral 1.5 整数类型的附加方法int.bit_length() 返回以二进制表示一个整数锁需要的位数，不包括符号位和前面的零 1.6 浮点数类型的附加方法float.as_integer_ratio() 返回一对整数，其比率正好等于原浮点数并且分母为正数。 无穷大会引发 OverflowError 而 NaN 则会引发 ValueError。 float.is_integer() 如果 float 实例可用有限位整数表示则返回 True，否则返回 False: float.hex() 以十六进制字符串的形式返回一个浮点数表示。 对于有限浮点数，这种表示法将总是包含前导的 0x 和尾随的 p 加指数。 classmethod float.fromhex(s) 返回以十六进制字符串 s 表示的浮点数的类方法。 字符串 s 可以带有前导和尾随的空格。 ==tips==: float.hex() 是实例方法, float.fromhex(s)是类方法 1234&gt;&gt;&gt; float.fromhex('0x3.a7p10')3740.0&gt;&gt;&gt; float.hex(3740.0)'0x1.d380000000000p+11' 1.7 数字类型的哈希运算一个例子说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import sys, mathdef hash_fraction(m, n): """Compute the hash of a rational number m / n. Assumes m and n are integers, with n positive. Equivalent to hash(fractions.Fraction(m, n)). """ P = sys.hash_info.modulus # Remove common factors of P. (Unnecessary if m and n already coprime.) while m % P == n % P == 0: m, n = m // P, n // P if n % P == 0: hash_value = sys.hash_info.inf else: # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P. hash_value = (abs(m) % P) * pow(n, P - 2, P) % P if m &lt; 0: hash_value = -hash_value if hash_value == -1: hash_value = -2 return hash_valuedef hash_float(x): """Compute the hash of a float x.""" if math.isnan(x): return sys.hash_info.nan elif math.isinf(x): return sys.hash_info.inf if x &gt; 0 else -sys.hash_info.inf else: return hash_fraction(*x.as_integer_ratio())def hash_complex(z): """Compute the hash of a complex number z.""" hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag) # do a signed reduction modulo 2**sys.hash_info.width M = 2**(sys.hash_info.width - 1) hash_value = (hash_value &amp; (M - 1)) - (hash_value &amp; M) if hash_value == -1: hash_value = -2 return hash_value 1.8 映射类型 – dictpython中目前只有一种映射类型, 字典,映射属于可变对象。映射类型会将hashtable值映射到任意对象. 字典的键 几乎可以是任意值， 可hash的任意值,也就是包含列表、字典和其他可变类型的值,不可以用来充当字典中的键。 1.创建字典字典可以通过将以逗号分隔的 键: 值 对列表包含于花括号之内来创建，例如: {&#39;jack&#39;: 4098, &#39;sjoerd&#39;: 4127} 或 {4098: &#39;jack&#39;, 4127: &#39;sjoerd&#39;}，也可以通过 dict 构造器来创建。 2.构造函数class dict(**kwarg) class dict(mapping, **kwarg) class dict(iterable, **kwarg) 3. 其他函数 函数名 描述 list(d) 返回字典 d 中使用的所有键的列表。 len(d) 返回字典 d 中的项数。 d[key] 返回 d 中以 key 为键的项。 如果映射中不存在 key 则会引发 KeyError。 [1] d[key] = value 给d[key]的值设为value del d[key] 将 d[key] 从 d 中移除。 如果映射中不存在 key 则会引发 KeyError。 key in d 如果 d 中存在键 key 则返回 True，否则返回 False。 key not in d 等价于 not key in d。 iter(d) 返回以字典的键为元素的迭代器 clear() 移除字典中的所有元素。 copy() 返回原字典的浅拷贝。 classmethod fromkeys(iterable[, value]) 使用来自 iterable 的键创建一个新字典，并将键值设为 value。 get(key[, default]) 如果 key 存在于字典中则返回 key 的值，否则返回 default。 如果 default 未给出则默认为 None，因而此方法绝不会引发 KeyError。 items() 返回由字典项 ((键, 值) 对) 组成的一个新视图。 keys() 返回由字典键组成的一个新视图 pop(key[, default]) 如果 key 存在于字典中则将其移除并返回其值，否则返回 default。 如果 default 未给出且 key 不存在于字典中，则会引发 KeyError。 popitem() 从字典中移除并返回一个 (键, 值) 对。 键值对会按 LIFO 的顺序被返回。 reversed(d) 返回一个逆序获取字典键的迭代器 setdefault(key[, default]) 如果字典存在键 key ，返回它的值。如果不存在，插入值为 default 的键 key ，并返回 default 。 default 默认为 None。 update([other]) 使用来自 other 的键/值对更新字典，覆盖原有的键。 values() 返回由字典值组成的一个新视图 [2] 1234567891011121314#[1] 如果字典的子类定义了方法 __missing__() 并且 key 不存在，则 d[key] 操作将调用该方法并附带键 key 作为参数。 d[key] 随后将返回或引发 __missing__(key) 调用所返回或引发的任何对象或异常。 没有其他操作或方法会发起调用 __missing__()。 如果未定义 __missing__()，则会引发 KeyError。 __missing__() 必须是一个方法；它不能是一个实例变量:&gt;&gt;&gt; class Counter(dict):... def __missing__(self, key):... return 0&gt;&gt;&gt; c = Counter()&gt;&gt;&gt; c['red']0&gt;&gt;&gt; c['red'] += 1&gt;&gt;&gt; c['red']1#[2]两个 dict.values() 视图之间的相等性比较将总是返回 False。 这在 dict.values() 与其自身比较时也同样适用: &gt;&gt;&gt; d = &#123;'a': 1&#125;&gt;&gt;&gt; d.values() == d.values()False 字典比较: 两个字典的比较当且仅当它们具有相同的 (键, 值) 对时才会相等（不考虑顺序）。 排序比较 (‘&lt;’, ‘&lt;=’, ‘&gt;=’, ‘&gt;’) 会引发 TypeError。 字典会保留插入时的顺序。 请注意对键的更新不会影响顺序。 删除并再次添加的键将被插入到末尾。 1234567891011121314&gt;&gt;&gt; d = &#123;"one": 1, "two": 2, "three": 3, "four": 4&#125;&gt;&gt;&gt; d&#123;'one': 1, 'two': 2, 'three': 3, 'four': 4&#125;&gt;&gt;&gt; list(d)['one', 'two', 'three', 'four']&gt;&gt;&gt; list(d.values())[1, 2, 3, 4]&gt;&gt;&gt; d["one"] = 42&gt;&gt;&gt; d&#123;'one': 42, 'two': 2, 'three': 3, 'four': 4&#125;&gt;&gt;&gt; del d["two"]&gt;&gt;&gt; d["two"] = None&gt;&gt;&gt; d&#123;'one': 42, 'three': 3, 'four': 4, 'two': None&#125; 4.字典视图对象由 dict.keys(), dict.values() 和 dict.items() 所返回的对象是 视图对象。 该对象提供字典条目的一个动态视图，这意味着当字典改变时，视图也会相应改变。 字典视图函数 描述 len(dictview) 返回字典中的条目数 iter(dictview) 返回字典中的键、值或项（以 (键, 值) 为元素的元组表示）的迭代器 [1] x in dictview 如果 x 是对应字典中存在的键、值或项（在最后一种情况下 x 应为一个 (键, 值) 元组） 则返回 True reversed(dictview) 返回一个逆序获取字典键、值或项的迭代器。 视图将按与插入时相反的顺序进行迭代。 [2] 1234567891011121314151617181920212223242526272829#键视图类似于集合，因为其条目不重复且可哈希。 如果所有值都是可哈希的，即 (键, 值) 对也是不重复且可哈希的，那么条目视图也会类似于集合。 （值视图则不被视为类似于集合，因其条目通常都是有重复的。） 对于类似于集合的视图，为抽象基类 collections.abc.Set 所定义的全部操作都是有效的 (例如 ==, &lt; 或 ^)。&gt;&gt;&gt; dishes = &#123;'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500&#125;&gt;&gt;&gt; keys = dishes.keys()&gt;&gt;&gt; values = dishes.values()&gt;&gt;&gt; # iteration&gt;&gt;&gt; n = 0&gt;&gt;&gt; for val in values:... n += val&gt;&gt;&gt; print(n)504&gt;&gt;&gt; # keys and values are iterated over in the same order (insertion order)&gt;&gt;&gt; list(keys)['eggs', 'sausage', 'bacon', 'spam']&gt;&gt;&gt; list(values)[2, 1, 1, 500]&gt;&gt;&gt; # view objects are dynamic and reflect dict changes&gt;&gt;&gt; del dishes['eggs']&gt;&gt;&gt; del dishes['sausage']&gt;&gt;&gt; list(keys)['bacon', 'spam']&gt;&gt;&gt; # set operations&gt;&gt;&gt; keys &amp; &#123;'eggs', 'bacon', 'salad'&#125;&#123;'bacon'&#125;&gt;&gt;&gt; keys ^ &#123;'sausage', 'juice'&#125;&#123;'juice', 'sausage', 'bacon', 'spam'&#125; 2.0 小结 字典是可变类型,键只能是由非hash的数据类型充当 字典子类的__missing__方法。 字典视图的元素为不重复且可哈希。 一张图总结如下 后记记得五年前听过的一句话,赠给自己,也赠给凑巧看到这篇博文的有缘人。 种一棵树最好的时间是在十年前，其次是现在。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>dictionary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_standard_library_1_string]]></title>
    <url>%2F2019%2F12%2F20%2F2019-20-python-standard-library-1-string%2F</url>
    <content type="text"><![CDATA[python 标准库学习笔记 – string前言今天是2019年12月20日,刚刚晴朗的天 入冬以来的第二场雪就悄然而至 从今天开始,坚持更新博文100天,也算是对python学习的总结。那么从哪里开始呢？ 那就从python标准库开始撸吧。 操作系统 win7 sp1 64位 标准版 python版本 3.8 工具 vscode 标准库基础在不同操作系统,标准库的路径有所不同,以windows平台为例,我的python安装在C:\Python38 标准库文件就在C:\Python38\Lib 文件夹下 标准库分为几个部分,参考标准库介绍 内置函数:不需要import就可以使用的函数,例如 print 内置异常 内置模块 文本 二进制数据 数据类型 数学 函数式编程模块 文件和目录访问 数据持久化 文件格式 加密服务 并发执行 网络和进程间通信 互联网数据处理 互联网协议和支持 多媒体服务 国际化 程序框架 Tk图形用户界面 开发工具 调试和分析 软件打包和分发 python运行时服务 自定义python解释器 导入模块 Python语言服务 杂项服务 Windows系统相关模块 Unix专有服务 被取代的模块 day1 标准库 string参考：文本处理服务 string常见字符串操作 字符串常量123__all__ = ["ascii_letters", "ascii_lowercase", "ascii_uppercase", "capwords", "digits", "hexdigits", "octdigits", "printable", "punctuation", "whitespace", "Formatter", "Template"] 测试如下： 123456789101112import stringprint(string.__all__)print(string.ascii_letters) #abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.ascii_lowercase) #abcdefghijklmnopqrstuvwxyzprint(string.ascii_uppercase) #ABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.digits)# 十进制数字常数 0123456789print(string.hexdigits)#十六进制数字常数 0123456789abcdefABCDEFprint(string.octdigits)#八进制数字常数 01234567print(string.punctuation)print(string.printable)print(string.whitespace) 其中： string.whitespace ：由被视为空白符号的 ASCII 字符组成的字符串。 其中包括空格、制表、换行、回车、进纸和纵向制表符。 自定义字符串格式化 主要函数 功能 format(format_string, *args, **kwargs) 它采用格式字符串和一组任意位置和关键字参数。它只是一个调用vformat（）的包装器。 vformat(format_string, args, kwargs) 执行格式化的实际工作 parse(format_string) 循环遍历format_string并返回一个可迭代的元组（literal_text，field_name，format_spec，conversion）。 1234567891011121314151617181920212223242526data = ("Pi = ",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp)import stringdata = ("Pi=",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp) 12345678910111213141516171819202122import stringstrtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', '', '', None) 1 ('', '', '.4f', None) '''strtmp = "This is a test:&#123;Key2&#125;&#123;Key1&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', 'Key2', '', None) 1 ('', 'Key1', '', None) '''# string.Formatter.parse(format_string) End 格式化字符串范例按位置访问参数123456789tupdata = ("This","is","a","test") # 元组formatstr = '&#123;0&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format("This","is","a","test") print(formatstr) # This is a testformatstr = '&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # This is a testformatstr = '&#123;3&#125; &#123;2&#125; &#123;1&#125; &#123;0&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # test a is Thisformatstr = '&#123;2&#125; &#123;3&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format(*tupdata) # 参数可以重复print(formatstr) # a test is a test 按关键字访问参数12345dicdata = &#123;'Author':'leacoder','Time':'2019/04/17'&#125;formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(Author='leacoder',Time='2019/04/17')print(formatstr) # The author is leacoder，The time is 2019/04/17formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(**dicdata)print(formatstr) # The author is leacoder，The time is 2019/04/17 访问参数的属性12345678class Point: def __init__(self,x,y): self.x ,self.y = x, ypoint = Point(4,2)formatstr = 'Thie point is (&#123;key.x&#125;,&#123;key.y&#125;)'.format(key = point) # key 可为其他 print(formatstr) # Thie point is (4,2)formatstr = 'Thie point is (&#123;point.x&#125;,&#123;point.y&#125;)'.format(point = point) # point 可为其他 print(formatstr) # Thie point is (4,2) 访问参数的各项12345tupdata = ("leacoder","2019/04/17") # 元组formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(tupdata)print(formatstr) # The author is leacoder,The time is 2019/04/17formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(*tupdata) # 注意区别print(formatstr) # The author is l,The time is e 对齐文本并指定宽度12345678formatstr = '&#123;:&lt;30&#125;'.format('left aligned') # 左对齐 30位print(formatstr) # ‘left aligned ’ 为了体现位数加了‘’formatstr = '&#123;:&gt;30&#125;'.format('right aligned') # 右对齐 30位print(formatstr) # ‘ right aligned’formatstr = '&#123;:^30&#125;'.format('centered') # 中间对齐 30位print(formatstr) # ‘ centered ’formatstr = '&#123;:*^30&#125;'.format('centered') # 使用* 作为填充字符print(formatstr) # ‘***********centered***********’ Replacing %+f, %-f, and % f and specifying a sign: 替换％+ f，％ - f和％f并指定符号:123456formatstr = '&#123;:+f&#125;; &#123;:+f&#125;'.format(3.14, -3.14) # 总是显示它符号print(formatstr) # ‘+3.140000; -3.140000’formatstr = '&#123;: f&#125;; &#123;: f&#125;'.format(3.14, -3.14) # 正数前显示空格print(formatstr) # ‘ 3.140000; -3.140000’formatstr = '&#123;:-f&#125;; &#123;:-f&#125;'.format(3.14, -3.14) # 只显示负号 同 '&#123;:f&#125;; &#123;:f&#125;'print(formatstr) # ‘3.140000; -3.140000’ Replacing %x and %o and converting the value to different bases: 替换％x和％o并将值转换为不同的进制123456formatstr = "int: &#123;0:d&#125;; hex: &#123;0:x&#125;; oct: &#123;0:o&#125;; bin: &#123;0:b&#125;".format(64)print(formatstr) # int: 64; hex: 40; oct: 100; bin: 1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(64)print(formatstr) # int: 64; hex: 0x40; oct: 0o100; bin: 0b1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(0b1000001) # 也支持其他进制print(formatstr) # int: 65; hex: 0x41; oct: 0o101; bin: 0b100000 使用逗号作为千位分隔符1234points = 1total = 3formatstr = 'points / total = &#123;:.2%&#125;'.format(points/total)print(formatstr) # points / total = 33.33% 使用特定类型的格式1234import datetimed = datetime.datetime(2019, 4, 17, 22, 49, 2) # 2019/04/17 22:49:02formatstr = '&#123;:%Y-%m-%d %H:%M:%S&#125;'.format(d)print(formatstr) # 2019-04-17 22:49:02 模板字符串模板字符串规则12345678910'''模板字符串提供更简单的字符串替换，如PEP 292中所述 https://www.python.org/dev/peps/pep-0292/模板字符串支持基于$的替换，使用以下规则： 1、$$是转义; 它被替换为单个$。 2、$identifier 一个替换占位符，用于匹配映射关键字“identifier”默认情况下， “标识符”仅限于以下划线或ASCII字母开头的任何不区分大小写的ASCII字母数字字符串（包括下划线）。$字符后面的第一个非标识符字符结束此占位符。 3、$ &#123;identifier&#125;相当于$ identifier。当有效标识符字符跟随占位符但不是占位符的一部分时，例如“$ &#123;noun&#125; ification”，则需要它。 4、字符串中$的任何其他形式都将导致引发ValueError。字符串模块提供实现这些规则的Template类。class string.Template(template)''' class string.`Template`(template)substitute(mapping,**kwargs)123456789101112131415161718'''执行模板替换，返回一个新字符串。 mapping 为任意字典类对象，其中的键将匹配模板中的占位符。 或者你也可以提供一组关键字参数，其中的关键字即对应占位符。 当同时给出 mapping 和 kwds 并且存在重复时，则以 kwds 中的占位符为优先'''s = Template('The Author is $Author, The Time is $Time') # 使用Template类构造函数kewds = &#123;'Author':'leacoder', 'Time':'2019/04/18 00:01:38'&#125;templatestr = s.substitute(Author='leacoder', Time='2019/04/18 00:01:38') # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(**kewds) # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds) # mappingprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds,Author='250',Time = 'No Time') # mapping **kewdsprint(templatestr) # The Author is 250, The Time is No Timekewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.substitute(kewds1)print(templatestr) # KeyError: 'Time'# substitute(mapping, **kwds) End safe_substitute(mapping, **kwds)12345678'''类似于 substitute()，不同之处是如果有占位符未在 mapping 和 kwds 中找到，不是引发 KeyError 异常，而是将原始占位符不加修改地显示在结果字符串中。 另一个与 substitute() 的差异是任何在其他情况下出现的 $ 将简单地返回 $ 而不是引发 ValueError。'''# safe_substitute(mapping, **kwds)kewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.safe_substitute(kewds1)print(templatestr) # The Author is leacoder, The Time is $Time# safe_substitute(mapping, **kwds) End 辅助函数string.`capwords`(s, sep=None）123'''使用 str.split() 将参数拆分为单词，使用 str.capitalize() 将单词转为大写形式，使用 str.join() 将大写的单词进行拼接。 如果可选的第二个参数 sep 被省略或为 None，则连续的空白字符会被替换为单个空格符并且开头和末尾的空白字符会被移除，否则 sep 会被用来拆分和拼接单词''']]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_standard_libary_1_string]]></title>
    <url>%2F2019%2F12%2F20%2Fpython-standard-libary-1-string%2F</url>
    <content type="text"><![CDATA[python 标准库学习笔记 – string前言今天是2019年12月20日,刚刚晴朗的天 入冬以来的第二场雪就悄然而至 从今天开始,坚持更新博文100天,也算是对python学习的总结。那么从哪里开始呢？ 那就从python标准库开始撸吧。 操作系统 win7 sp1 64位 标准版 python版本 3.8 工具 vscode 标准库基础在不同操作系统,标准库的路径有所不同,以windows平台为例,我的python安装在C:\Python38 标准库文件就在C:\Python38\Lib 文件夹下 标准库分为几个部分,参考标准库介绍 内置函数:不需要import就可以使用的函数,例如 print 内置异常 内置模块 文本 二进制数据 数据类型 数学 函数式编程模块 文件和目录访问 数据持久化 文件格式 加密服务 并发执行 网络和进程间通信 互联网数据处理 互联网协议和支持 多媒体服务 国际化 程序框架 Tk图形用户界面 开发工具 调试和分析 软件打包和分发 python运行时服务 自定义python解释器 导入模块 Python语言服务 杂项服务 Windows系统相关模块 Unix专有服务 被取代的模块 day1 标准库 string参考：文本处理服务 string常见字符串操作 字符串常量123__all__ = ["ascii_letters", "ascii_lowercase", "ascii_uppercase", "capwords", "digits", "hexdigits", "octdigits", "printable", "punctuation", "whitespace", "Formatter", "Template"] 测试如下： 123456789101112import stringprint(string.__all__)print(string.ascii_letters) #abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.ascii_lowercase) #abcdefghijklmnopqrstuvwxyzprint(string.ascii_uppercase) #ABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.digits)# 十进制数字常数 0123456789print(string.hexdigits)#十六进制数字常数 0123456789abcdefABCDEFprint(string.octdigits)#八进制数字常数 01234567print(string.punctuation)print(string.printable)print(string.whitespace) 其中： string.whitespace ：由被视为空白符号的 ASCII 字符组成的字符串。 其中包括空格、制表、换行、回车、进纸和纵向制表符。 自定义字符串格式化 主要函数 功能 format(format_string, *args, **kwargs) 它采用格式字符串和一组任意位置和关键字参数。它只是一个调用vformat（）的包装器。 vformat(format_string, args, kwargs) 执行格式化的实际工作 parse(format_string) 循环遍历format_string并返回一个可迭代的元组（literal_text，field_name，format_spec，conversion）。 1234567891011121314151617181920212223242526data = ("Pi = ",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp)import stringdata = ("Pi=",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp) 12345678910111213141516171819202122import stringstrtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', '', '', None) 1 ('', '', '.4f', None) '''strtmp = "This is a test:&#123;Key2&#125;&#123;Key1&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', 'Key2', '', None) 1 ('', 'Key1', '', None) '''# string.Formatter.parse(format_string) End 格式化字符串范例按位置访问参数123456789tupdata = ("This","is","a","test") # 元组formatstr = '&#123;0&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format("This","is","a","test") print(formatstr) # This is a testformatstr = '&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # This is a testformatstr = '&#123;3&#125; &#123;2&#125; &#123;1&#125; &#123;0&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # test a is Thisformatstr = '&#123;2&#125; &#123;3&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format(*tupdata) # 参数可以重复print(formatstr) # a test is a test 按关键字访问参数12345dicdata = &#123;'Author':'leacoder','Time':'2019/04/17'&#125;formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(Author='leacoder',Time='2019/04/17')print(formatstr) # The author is leacoder，The time is 2019/04/17formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(**dicdata)print(formatstr) # The author is leacoder，The time is 2019/04/17 访问参数的属性12345678class Point: def __init__(self,x,y): self.x ,self.y = x, ypoint = Point(4,2)formatstr = 'Thie point is (&#123;key.x&#125;,&#123;key.y&#125;)'.format(key = point) # key 可为其他 print(formatstr) # Thie point is (4,2)formatstr = 'Thie point is (&#123;point.x&#125;,&#123;point.y&#125;)'.format(point = point) # point 可为其他 print(formatstr) # Thie point is (4,2) 访问参数的各项12345tupdata = ("leacoder","2019/04/17") # 元组formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(tupdata)print(formatstr) # The author is leacoder,The time is 2019/04/17formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(*tupdata) # 注意区别print(formatstr) # The author is l,The time is e 对齐文本并指定宽度12345678formatstr = '&#123;:&lt;30&#125;'.format('left aligned') # 左对齐 30位print(formatstr) # ‘left aligned ’ 为了体现位数加了‘’formatstr = '&#123;:&gt;30&#125;'.format('right aligned') # 右对齐 30位print(formatstr) # ‘ right aligned’formatstr = '&#123;:^30&#125;'.format('centered') # 中间对齐 30位print(formatstr) # ‘ centered ’formatstr = '&#123;:*^30&#125;'.format('centered') # 使用* 作为填充字符print(formatstr) # ‘***********centered***********’ Replacing %+f, %-f, and % f and specifying a sign: 替换％+ f，％ - f和％f并指定符号:123456formatstr = '&#123;:+f&#125;; &#123;:+f&#125;'.format(3.14, -3.14) # 总是显示它符号print(formatstr) # ‘+3.140000; -3.140000’formatstr = '&#123;: f&#125;; &#123;: f&#125;'.format(3.14, -3.14) # 正数前显示空格print(formatstr) # ‘ 3.140000; -3.140000’formatstr = '&#123;:-f&#125;; &#123;:-f&#125;'.format(3.14, -3.14) # 只显示负号 同 '&#123;:f&#125;; &#123;:f&#125;'print(formatstr) # ‘3.140000; -3.140000’ Replacing %x and %o and converting the value to different bases: 替换％x和％o并将值转换为不同的进制123456formatstr = "int: &#123;0:d&#125;; hex: &#123;0:x&#125;; oct: &#123;0:o&#125;; bin: &#123;0:b&#125;".format(64)print(formatstr) # int: 64; hex: 40; oct: 100; bin: 1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(64)print(formatstr) # int: 64; hex: 0x40; oct: 0o100; bin: 0b1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(0b1000001) # 也支持其他进制print(formatstr) # int: 65; hex: 0x41; oct: 0o101; bin: 0b100000 使用逗号作为千位分隔符1234points = 1total = 3formatstr = 'points / total = &#123;:.2%&#125;'.format(points/total)print(formatstr) # points / total = 33.33% 使用特定类型的格式1234import datetimed = datetime.datetime(2019, 4, 17, 22, 49, 2) # 2019/04/17 22:49:02formatstr = '&#123;:%Y-%m-%d %H:%M:%S&#125;'.format(d)print(formatstr) # 2019-04-17 22:49:02 模板字符串模板字符串规则12345678910'''模板字符串提供更简单的字符串替换，如PEP 292中所述 https://www.python.org/dev/peps/pep-0292/模板字符串支持基于$的替换，使用以下规则： 1、$$是转义; 它被替换为单个$。 2、$identifier 一个替换占位符，用于匹配映射关键字“identifier”默认情况下， “标识符”仅限于以下划线或ASCII字母开头的任何不区分大小写的ASCII字母数字字符串（包括下划线）。$字符后面的第一个非标识符字符结束此占位符。 3、$ &#123;identifier&#125;相当于$ identifier。当有效标识符字符跟随占位符但不是占位符的一部分时，例如“$ &#123;noun&#125; ification”，则需要它。 4、字符串中$的任何其他形式都将导致引发ValueError。字符串模块提供实现这些规则的Template类。class string.Template(template)''' class string.`Template`(template)substitute(mapping,**kwargs)123456789101112131415161718'''执行模板替换，返回一个新字符串。 mapping 为任意字典类对象，其中的键将匹配模板中的占位符。 或者你也可以提供一组关键字参数，其中的关键字即对应占位符。 当同时给出 mapping 和 kwds 并且存在重复时，则以 kwds 中的占位符为优先'''s = Template('The Author is $Author, The Time is $Time') # 使用Template类构造函数kewds = &#123;'Author':'leacoder', 'Time':'2019/04/18 00:01:38'&#125;templatestr = s.substitute(Author='leacoder', Time='2019/04/18 00:01:38') # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(**kewds) # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds) # mappingprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds,Author='250',Time = 'No Time') # mapping **kewdsprint(templatestr) # The Author is 250, The Time is No Timekewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.substitute(kewds1)print(templatestr) # KeyError: 'Time'# substitute(mapping, **kwds) End safe_substitute(mapping, **kwds)12345678'''类似于 substitute()，不同之处是如果有占位符未在 mapping 和 kwds 中找到，不是引发 KeyError 异常，而是将原始占位符不加修改地显示在结果字符串中。 另一个与 substitute() 的差异是任何在其他情况下出现的 $ 将简单地返回 $ 而不是引发 ValueError。'''# safe_substitute(mapping, **kwds)kewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.safe_substitute(kewds1)print(templatestr) # The Author is leacoder, The Time is $Time# safe_substitute(mapping, **kwds) End 辅助函数string.`capwords`(s, sep=None）123'''使用 str.split() 将参数拆分为单词，使用 str.capitalize() 将单词转为大写形式，使用 str.join() 将大写的单词进行拼接。 如果可选的第二个参数 sep 被省略或为 None，则连续的空白字符会被替换为单个空格符并且开头和末尾的空白字符会被移除，否则 sep 会被用来拆分和拼接单词''']]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>string</tag>
        <tag>standard_libary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_standard_library_1_string]]></title>
    <url>%2F2019%2F12%2F20%2Fpython-standard-library-1-string%2F</url>
    <content type="text"><![CDATA[python 标准库学习笔记 – string前言今天是2019年12月20日,刚刚晴朗的天 入冬以来的第二场雪就悄然而至 从今天开始,坚持更新博文100天,也算是对python学习的总结。那么从哪里开始呢？ 那就从python标准库开始撸吧。 操作系统 win7 sp1 64位 标准版 python版本 3.8 工具 vscode 标准库基础在不同操作系统,标准库的路径有所不同,以windows平台为例,我的python安装在C:\Python38 标准库文件就在C:\Python38\Lib 文件夹下 标准库分为几个部分,参考标准库介绍 内置函数:不需要import就可以使用的函数,例如 print 内置异常 内置模块 文本 二进制数据 数据类型 数学 函数式编程模块 文件和目录访问 数据持久化 文件格式 加密服务 并发执行 网络和进程间通信 互联网数据处理 互联网协议和支持 多媒体服务 国际化 程序框架 Tk图形用户界面 开发工具 调试和分析 软件打包和分发 python运行时服务 自定义python解释器 导入模块 Python语言服务 杂项服务 Windows系统相关模块 Unix专有服务 被取代的模块 day1 标准库 string参考：文本处理服务 string常见字符串操作 字符串常量123__all__ = ["ascii_letters", "ascii_lowercase", "ascii_uppercase", "capwords", "digits", "hexdigits", "octdigits", "printable", "punctuation", "whitespace", "Formatter", "Template"] 测试如下： 123456789101112import stringprint(string.__all__)print(string.ascii_letters) #abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.ascii_lowercase) #abcdefghijklmnopqrstuvwxyzprint(string.ascii_uppercase) #ABCDEFGHIJKLMNOPQRSTUVWXYZprint(string.digits)# 十进制数字常数 0123456789print(string.hexdigits)#十六进制数字常数 0123456789abcdefABCDEFprint(string.octdigits)#八进制数字常数 01234567print(string.punctuation)print(string.printable)print(string.whitespace) 其中： string.whitespace ：由被视为空白符号的 ASCII 字符组成的字符串。 其中包括空格、制表、换行、回车、进纸和纵向制表符。 自定义字符串格式化 主要函数 功能 format(format_string, *args, **kwargs) 它采用格式字符串和一组任意位置和关键字参数。它只是一个调用vformat（）的包装器。 vformat(format_string, args, kwargs) 执行格式化的实际工作 parse(format_string) 循环遍历format_string并返回一个可迭代的元组（literal_text，field_name，format_spec，conversion）。 1234567891011121314151617181920212223242526data = ("Pi = ",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp)import stringdata = ("Pi=",3.1415926)strtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()formatter.vformat(strtmp,data,&#123;&#125;)print(strtmp) #This is a test:&#123;&#125;&#123;:.4f&#125;data =&#123;"key1":3.1415926,"key2":"Pi: ="&#125;strtmp = "This is a test:&#123;key2&#125;&#123;key1&#125;"formatter = string.Formatter()strtmp = formatter.vformat(strtmp,(),data)print(strtmp) 12345678910111213141516171819202122import stringstrtmp = "This is a test:&#123;&#125;&#123;:.4f&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', '', '', None) 1 ('', '', '.4f', None) '''strtmp = "This is a test:&#123;Key2&#125;&#123;Key1&#125;"formatter = string.Formatter()strtuple = formatter.parse(strtmp)for i, v in enumerate(strtuple): print(i, v) ''' 0 ('This is a test:', 'Key2', '', None) 1 ('', 'Key1', '', None) '''# string.Formatter.parse(format_string) End 格式化字符串范例按位置访问参数123456789tupdata = ("This","is","a","test") # 元组formatstr = '&#123;0&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format("This","is","a","test") print(formatstr) # This is a testformatstr = '&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # This is a testformatstr = '&#123;3&#125; &#123;2&#125; &#123;1&#125; &#123;0&#125;'.format(*tupdata) # *data 解包参数序列print(formatstr) # test a is Thisformatstr = '&#123;2&#125; &#123;3&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;'.format(*tupdata) # 参数可以重复print(formatstr) # a test is a test 按关键字访问参数12345dicdata = &#123;'Author':'leacoder','Time':'2019/04/17'&#125;formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(Author='leacoder',Time='2019/04/17')print(formatstr) # The author is leacoder，The time is 2019/04/17formatstr = 'The author is &#123;Author&#125;，The time is &#123;Time&#125;'.format(**dicdata)print(formatstr) # The author is leacoder，The time is 2019/04/17 访问参数的属性12345678class Point: def __init__(self,x,y): self.x ,self.y = x, ypoint = Point(4,2)formatstr = 'Thie point is (&#123;key.x&#125;,&#123;key.y&#125;)'.format(key = point) # key 可为其他 print(formatstr) # Thie point is (4,2)formatstr = 'Thie point is (&#123;point.x&#125;,&#123;point.y&#125;)'.format(point = point) # point 可为其他 print(formatstr) # Thie point is (4,2) 访问参数的各项12345tupdata = ("leacoder","2019/04/17") # 元组formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(tupdata)print(formatstr) # The author is leacoder,The time is 2019/04/17formatstr = 'The author is &#123;0[0]&#125;,The time is &#123;0[1]&#125;'.format(*tupdata) # 注意区别print(formatstr) # The author is l,The time is e 对齐文本并指定宽度12345678formatstr = '&#123;:&lt;30&#125;'.format('left aligned') # 左对齐 30位print(formatstr) # ‘left aligned ’ 为了体现位数加了‘’formatstr = '&#123;:&gt;30&#125;'.format('right aligned') # 右对齐 30位print(formatstr) # ‘ right aligned’formatstr = '&#123;:^30&#125;'.format('centered') # 中间对齐 30位print(formatstr) # ‘ centered ’formatstr = '&#123;:*^30&#125;'.format('centered') # 使用* 作为填充字符print(formatstr) # ‘***********centered***********’ Replacing %+f, %-f, and % f and specifying a sign: 替换％+ f，％ - f和％f并指定符号:123456formatstr = '&#123;:+f&#125;; &#123;:+f&#125;'.format(3.14, -3.14) # 总是显示它符号print(formatstr) # ‘+3.140000; -3.140000’formatstr = '&#123;: f&#125;; &#123;: f&#125;'.format(3.14, -3.14) # 正数前显示空格print(formatstr) # ‘ 3.140000; -3.140000’formatstr = '&#123;:-f&#125;; &#123;:-f&#125;'.format(3.14, -3.14) # 只显示负号 同 '&#123;:f&#125;; &#123;:f&#125;'print(formatstr) # ‘3.140000; -3.140000’ Replacing %x and %o and converting the value to different bases: 替换％x和％o并将值转换为不同的进制123456formatstr = "int: &#123;0:d&#125;; hex: &#123;0:x&#125;; oct: &#123;0:o&#125;; bin: &#123;0:b&#125;".format(64)print(formatstr) # int: 64; hex: 40; oct: 100; bin: 1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(64)print(formatstr) # int: 64; hex: 0x40; oct: 0o100; bin: 0b1000000formatstr = "int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;".format(0b1000001) # 也支持其他进制print(formatstr) # int: 65; hex: 0x41; oct: 0o101; bin: 0b100000 使用逗号作为千位分隔符1234points = 1total = 3formatstr = 'points / total = &#123;:.2%&#125;'.format(points/total)print(formatstr) # points / total = 33.33% 使用特定类型的格式1234import datetimed = datetime.datetime(2019, 4, 17, 22, 49, 2) # 2019/04/17 22:49:02formatstr = '&#123;:%Y-%m-%d %H:%M:%S&#125;'.format(d)print(formatstr) # 2019-04-17 22:49:02 模板字符串模板字符串规则12345678910'''模板字符串提供更简单的字符串替换，如PEP 292中所述 https://www.python.org/dev/peps/pep-0292/模板字符串支持基于$的替换，使用以下规则： 1、$$是转义; 它被替换为单个$。 2、$identifier 一个替换占位符，用于匹配映射关键字“identifier”默认情况下， “标识符”仅限于以下划线或ASCII字母开头的任何不区分大小写的ASCII字母数字字符串（包括下划线）。$字符后面的第一个非标识符字符结束此占位符。 3、$ &#123;identifier&#125;相当于$ identifier。当有效标识符字符跟随占位符但不是占位符的一部分时，例如“$ &#123;noun&#125; ification”，则需要它。 4、字符串中$的任何其他形式都将导致引发ValueError。字符串模块提供实现这些规则的Template类。class string.Template(template)''' class string.`Template`(template)substitute(mapping,**kwargs)123456789101112131415161718'''执行模板替换，返回一个新字符串。 mapping 为任意字典类对象，其中的键将匹配模板中的占位符。 或者你也可以提供一组关键字参数，其中的关键字即对应占位符。 当同时给出 mapping 和 kwds 并且存在重复时，则以 kwds 中的占位符为优先'''s = Template('The Author is $Author, The Time is $Time') # 使用Template类构造函数kewds = &#123;'Author':'leacoder', 'Time':'2019/04/18 00:01:38'&#125;templatestr = s.substitute(Author='leacoder', Time='2019/04/18 00:01:38') # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(**kewds) # **kewdsprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds) # mappingprint(templatestr) # The Author is leacoder, The Time is 2019/04/18 00:01:38templatestr = s.substitute(kewds,Author='250',Time = 'No Time') # mapping **kewdsprint(templatestr) # The Author is 250, The Time is No Timekewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.substitute(kewds1)print(templatestr) # KeyError: 'Time'# substitute(mapping, **kwds) End safe_substitute(mapping, **kwds)12345678'''类似于 substitute()，不同之处是如果有占位符未在 mapping 和 kwds 中找到，不是引发 KeyError 异常，而是将原始占位符不加修改地显示在结果字符串中。 另一个与 substitute() 的差异是任何在其他情况下出现的 $ 将简单地返回 $ 而不是引发 ValueError。'''# safe_substitute(mapping, **kwds)kewds1 = &#123;'Author':'leacoder'&#125;templatestr = s.safe_substitute(kewds1)print(templatestr) # The Author is leacoder, The Time is $Time# safe_substitute(mapping, **kwds) End 辅助函数string.`capwords`(s, sep=None）123'''使用 str.split() 将参数拆分为单词，使用 str.capitalize() 将单词转为大写形式，使用 str.join() 将大写的单词进行拼接。 如果可选的第二个参数 sep 被省略或为 None，则连续的空白字符会被替换为单个空格符并且开头和末尾的空白字符会被移除，否则 sep 会被用来拆分和拼接单词''']]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>standard_library</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode Cannot edit in read-only editor]]></title>
    <url>%2F2019%2F12%2F12%2Fvscode-Cannot-edit-in-read-only-editor%2F</url>
    <content type="text"><![CDATA[vscode Cannot edit in read-only editor 错误解决原因 使用了Run Code插件,output是只读的 解决方法将 run code设置为在Terminal中运行 1File -&gt; Preferences -&gt; Settings 找到 run code in terminal 打上 √ 或 在settings.json文件中,添加一行配置信息 1"code-runner.runInTerminal": true]]></content>
      <categories>
        <category>python</category>
        <category>IDEs</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install python3.8 on Centos6.5]]></title>
    <url>%2F2019%2F12%2F03%2FInstall-python3-8-on-Centos6-5%2F</url>
    <content type="text"><![CDATA[1. 安装必要的工具1sudo yum install yum-utils 2. 使用 yum-builddep 命令 设置 python 编译环境，下载缺少的依赖1sudo yum-builddep python 3. 下载 python3 的源代码源代码可以在 https://www.python.org/ftp/python/ 下载 1curl -O https://www.python.org/ftp/python/3.8.0/Python-3.8.0a1.tgz 4. 对源代码进行解压并编译安装1234tar xf Python-3.8.0a1.tgzcd Python-3.8.0a1./configuresudo make &amp;&amp; make install 5. 现在 python3 已经完成安装，使用 python3 -version 查看版本号显示 Python 3.8.0a1 表示已经成功 1python3 --version 6. 如果你想把 python3 作为默认python 解析器，可以进行如下设置1alias python='/usr/local/bin/python3.8' 7. 配置阿里pip源1234567891011[root@localhost ~]# cd [root@localhost ~]# mkdir .pip[root@localhost ~]# cd .pip[root@localhost .pip]# vim pip.conf#文件内容如下[global]index-url = http://mirrors.aliyun.com/pypi/simple [install]trusted-host=mirrors.aliyun.com]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ios devices list]]></title>
    <url>%2F2019%2F12%2F02%2Fios-devices-list%2F</url>
    <content type="text"><![CDATA[ios 设备一览表iPhone 设备 时间 CPU 分辨率 大小 密度 @Nx iOS系统 iPhone 2007 armv6 320 x 480 3.5 165 @1x 1.0 - 3.1.3 iPhone 3G 2008 armv6 320 x 480 3.5 165 @1x 2.0 - 4.2.1 iPhone 3GS 2009 armv7 320 x 480 3.5 165 @1x 3.0 - 6.1.4 iPhone 4 (GSM) 2010 armv7 640 x 960 3.5 330 @2x 4.0 - 7.1.2 iPhone 4 (CDMA) 2011 armv7 640 x 960 3.5 330 @2x 4.2.4 - 7.1.2 iPhone 4S 2011 armv7 640 x 960 3.5 330 @2x 5.0 - 9.3.5 iPhone 5 2012 armv7s 640 x 1136 4 326 @2x 6.0 - 10.3.3 iPhone 5c 2013 armv7s 640 x 1136 4 326 @2x 7.0 - 10.3.3 iPhone 5s 2013 arm64 640 x 1136 4 326 @2x 7.0 - iPhone 6 2014 arm64 750 x 1334 4.7 326 @2x 8.0 - iPhone 6 Plus 2014 arm64 1242 x 2208 5.5 461 @3x 8.0 - iPhone 6s 2015 arm64 750 x 1334 4.7 326 @2x 9.0 - iPhone 6s Plus 2015 arm64 1242 x 2208 5.5 461 @3x 9.0 - iPhone SE 2016 arm64 640 x 1136 4 326 @2x 9.3 - iPhone 7 2016 arm64 750 x 1334 4.7 326 @2x 10.0 - iPhone 7 Plus 2016 arm64 1242 x 2208 5.5 461 @3x 10.0 - iPhone 8 2017 arm64 750 x 1334 4.7 326 @2x 11.0 - iPhone 8 Plus 2017 arm64 1242 x 2208 5.5 461 @3x 11.0 - iPhone X 2017 arm64 1125 x 2436 5.8 463 @3x 11.0 - iPhone XS 2018 arm64 1125 x 2436 5.8 463 @3x 12.0 - iPhone XS Max 2018 arm64 1242 x 2688 6.5 458 @3x 12.0 - iPhone XR 2018 arm64 828 x 1792 6.1 326 @2x 12.0 - iPhone 11 2019 arm64 828 x 1792 6.1 326 @2x 13.0 - iPhone 11 Pro 2019 arm64 1125 x 2436 5.8 458 @3x 13.0 - iPhone 11 Pro Max 2019 arm64 1242 x 2688 6.5 458 @3x 13.0 - 注：屏幕分辨率单位为英寸(inch)，分辨率密度单位为ppi iPad 设备 发布年份 CPU架构 分辨率 @Nx iOS系统 iPad 2010 armv7 768 x 1024 @1x 3.2 - 5.1.1 iPad 2 2011 armv7 768 x 1024 @1x 4.3 - 9.3.5 iPad (3rd) 2012 armv7 1536 x 2048 @2x 5.1 - 9.3.5 iPad mini 2012 armv7s 768 x 1024 @1x 6.0 - 9.3.5 iPad (4rd) 2012 armv7s 1536 x 2048 @2x 6.0 - iPad Air 2013 arm64 1536 x 2048 @2x 7.0 - iPad mini Retina 2013 arm64 1536 x 2048 @2x 7.0 - iPad Air 2 2014 arm64 1536 x 2048 @2x 8.1 - iPad mini 3 2014 arm64 1536 x 2048 @2x 8.1 - iPad mini 4 2015 arm64 1536 x 2048 @2x 9.0 - iPad Pro (12.9) 2015 arm64 2048 x 2732 @2x 9.1 - iPad Pro (9.7) 2016 arm64 1536 x 2048 @2x 9.3 - iPad (5rd) 2017 arm64 1536 x 2048 @2x 10.2.1 - iPad Pro (10.5) 2017 arm64 1668 x 2224 @2x 10.3.2 - iPad Pro (12.9-2) 2017 arm64 2048 x 2732 @2x 10.3.2 - iPad (10.2) 2019 arm64 1620 x 2160 @2x iPadOS iPod touch 设备 发布年份 CPU架构 分辨率 @Nx iOS系统 iPod touch 2007 armv6 320 x 480 @1x 1.1 - 3.1.3 iPod touch (2nd) 2008 armv6 320 x 480 @1x 2.1.1 - 4.2.1 iPod touch (3rd) 2009 armv7 320 x 480 @1x 3.1 - 5.1.1 iPod touch (4th) 2010 armv7 640 x 960 @2x 4.1 - 6.1.4 iPod touch (5th) 2012 armv7 640 x 1136 @2x 6.0 - 9.3.5 iPod touch (6th) 2015 arm64 640 x 1136 @2x 8.4 - 参考文档iOS设备一览表]]></content>
      <categories>
        <category>ios</category>
      </categories>
      <tags>
        <tag>app</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git diff usage]]></title>
    <url>%2F2019%2F11%2F21%2Fgit-diff-usage%2F</url>
    <content type="text"><![CDATA[Git 中 diff 命令使用整理总结工作中常用的git 命令, 今天是一个非常有用的命令 git diff 主要作用是用来比较差异，包括 commits之间,commit 和 工作区间 差异 命令格式如下： 12345git diff [&lt;options&gt;] [&lt;commit&gt;] [--] [&lt;path&gt;…​]git diff [&lt;options&gt;] --cached [&lt;commit&gt;] [--] [&lt;path&gt;…​]git diff [&lt;options&gt;] &lt;commit&gt; &lt;commit&gt; [--] [&lt;path&gt;…​]git diff [&lt;options&gt;] &lt;blob&gt; &lt;blob&gt;git diff [&lt;options&gt;] --no-index [--] &lt;path&gt; &lt;path&gt; 1. 比较工作区与暂存区1git diff 不加参数 2. 比较暂存区与 本地 最新版本 (最后一次commit)1git diff --cached 3. 比较工作区与最新本地版本库1git diff HEAD 4. 比较工作区与commit-id的差异1git diff commit-id 5. 比较暂存区与指定commit-id的差异1git diff --cached commit-id 6. 比较两个commit-id之间的差异1git diff commit-id commit-id 7. 比较不同本地分支的差异1git diff dev # 当前所处分支为master 8. 比较本地分支和远程分支之间的差异12git fetch origin mastergit diff master origin/master 9. 比较差异只显示文件名1git diff --name-only 10 . 比较差异 显示更改文件状态1git diff --name-status]]></content>
      <categories>
        <category>版本管理</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript get checkbox checked value]]></title>
    <url>%2F2019%2F09%2F28%2Fjavascript-get-checkbox-checked-value%2F</url>
    <content type="text"><![CDATA[javascript如何获取checkbox被选中的值预备知识javascript dom 常用方法 方法名 描述 例子 document.getElementById 返回给定id属性值的元素节点相对应的对象 document.getElementsByTagName 返回给定name属性的元素节点对应的元素集合 var hobbies = document.getElementsByName(“hobbies”); element.nextSibling 返回该元素紧跟的一个节点 nodeValue 获取节点中的文本值 ,例如：跑步 跑步 数组常用方法： 方法 或者 属性 说明 例子 arrayObject.length 属性：数组长度 arrayObject.push() 向数组末尾添加一个或多个元素 var arr = new Array(3) arr[0] = “George” arr[1] = “John” arr[2] = “Thomas” 页面如下：12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;javascript获取复选框值方法&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt; &lt;input type="checkbox" name="hobbies" id="hobbies" class="hobbies" value="1"&gt;游泳 &lt;input type="checkbox" name="hobbies" id="hobbies" class="hobbies" value="2"&gt;跑步 &lt;/p&gt; &lt;p&gt; &lt;button id="btn1"&gt;获取复选框值&lt;/button&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 方法一 通过复选框的name属性,遍历后将被选中的复选框的值输出 checkbox[index].nextSibling.nodeValue: 获取的是checkbox中标签包裹的文本值 123456789function get_checkbox_val() &#123; var hobbies = document.getElementsByName("hobbies"); for (let index = 0; index &lt; hobbies.length; index++) &#123; if (hobbies[index].checked) &#123; alert(hobbies[index].value + "," + hobbies[index].nextSibling.nodeValue); &#125; &#125; &#125; 方法二 建立一个数组,使用push方法将被选中的元素保存到数组 123456789function get_checkbox_val_with_array() &#123; var arr = []; for (let index = 0; index &lt; hobbies.length; index++) &#123; if (hobbies[index].checked) &#123; arr.push(hobbies[index].value); &#125; &#125; alert(arr); &#125; 方法三 通过class选择器 获取被选中的复选框的值 123456789function get_checkbox_val_with_selector() &#123; var hobbies = document.getElementsByClassName('hobbies'); for (let index = 0; index &lt; hobbies.length; index++) &#123; if (hobbies[index].checked) &#123; checkedValue = hobbies[index].value; alert(hobbies[index].value + "," + hobbies[index].nextSibling.nodeValue); &#125; &#125; &#125; 使用jquery 需要引入jquery,这里我使用国内的cdn jquery中通过each() 方法遍历所有被选中的复选框的值 12345678910&lt;script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"&gt;&lt;/script&gt;&lt;script&gt; $('#btn1').click(function () &#123; $("input[name='hobbies']:checked").each(function () &#123; alert($(this).val()); &#125;); &#125;); &lt;/script&gt; &lt;/script&gt; ==tips== : $(“input[name=’xxxx’]:checked”) 被选中的复选框对象集合]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>checkbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript中Boolean_Object与Boolean_Primitives]]></title>
    <url>%2F2019%2F09%2F20%2Fjavascript%E4%B8%ADBoolean-Object%E4%B8%8EBoolean-Primitives%2F</url>
    <content type="text"><![CDATA[先看下面的脚本，预测下结果 123456var flag = true;console.log(typeof(flag));//booleanvar fa = Boolean(true);console.log(typeof(fa));//booleanvar ff = new Boolean(true);console.log(typeof(ff)); //Object 在 jslint中明确提示 new Boolean(true)；do not use Boolean as a constructor. (W053)jshint(W053) 接下来的例子 123456789if(flag)&#123; console.log("true is true");&#125;if(fa)&#123; console.log("Boolean is true");&#125;if(ff)&#123; console.log("Object Boolean is true");&#125; 结果如下 123true is trueBoolean is trueObject Boolean is true 修改脚本： 123456var flag = true;console.log(typeof(false));//booleanvar fa = Boolean(false);console.log(typeof(fa));//booleanvar ff = new Boolean(false);console.log(typeof(ff)); //Object 结果竟然显示： 1Object Boolean is true 后来查阅资料发现, JavaScript的其他数据类型都可以转换成Boolean类型，注意！！！只有这几种类型会转换为false 123456undefinednull0-0NaN"" (空字符串) 其他都转化为true,包括空对象{}，空数组[] ， 负数 ，false的对象包装等。 123456789101112if(-1)&#123; console.log('-1转换为true');&#125;if(&#123;&#125;)&#123; console.log('&#123;&#125;转换为true');&#125;if([])&#123; console.log('[]转换为true');&#125;if(new Boolean(false))&#123; console.log('new Boolean(false)转换为true');&#125; new Boolean(false)是布尔值的包装对象 typeof (new Boolean(false)) // ‘object’ ,所以 转换为boolean是true，而不是false。 从另一个层面也证明了为啥jslint 禁止在构造方法里使用Boolean类型的数据。 后记Boolean.valueOf() 可以返回Boolean对象对应的值类型 1234/**/if(ff.valueOf())&#123; console.log("Object Boolean is true"); &#125; 补充对于数字0 连续使用两次!! 仍旧返回false. 123var fa = Boolean(0);console.log(fa); //falseconsole.log(!!0);//false 参考文章 JavaScript Boolean( new Boolean(false) ) 其实是true The Difference Between Boolean Objects and Boolean Primitives in JavaScript]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>Boolean</tag>
        <tag>坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to add 163 music to hexo]]></title>
    <url>%2F2019%2F09%2F06%2Fhow-to-add-163-music-to-hexo%2F</url>
    <content type="text"><![CDATA[如何给hexo添加网易音乐先看看效果 1.访问网易云首页，选择你喜欢的音乐，点击生成外链,我不希望音乐一直播放,如果来访的朋友想听,点击下播放就好。 这里我选择二十岁的某一天 2. 复制iframe插件下的src里的地址 3. 修改themes/next/layout/sidebar.swig文件12345&#123;% if theme.background_music %&#125; &lt;div&gt; &lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="210" height="110" src="&#123;&#123; theme.background_music &#125;&#125;"&gt;&lt;/iframe&gt; &lt;/div&gt;&#123;% endif %&#125; 4.添加音乐地址到主题1background_music : //music.163.com/outchain/player?type=2&amp;id=247172&amp;auto=1&amp;height=66]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>网易音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to Sort Python Dictionaries by Key or Value]]></title>
    <url>%2F2019%2F07%2F28%2Fhow-to-Sort-Python-Dictionaries-by-Key-or-Value%2F</url>
    <content type="text"><![CDATA[众所周知,python中字典是无序的,那么该如何对字典排序呢？ 例如下面的字典： 1numbers = &#123;'second': 2,'first': 1, 'third': 3, 'Fourth': 4&#125; 我们可以通过list()函数打印value,12&gt;&gt;&gt;list(numbers)['second', 'first', 'third', 'Fourth'] 备注: python3.6.4 以上的版本,字典根据插入的顺序自动排序 如何根据key 对字典排序可以使用python的内置函数sorted 来对字典排序,如下面的代码 12&gt;&gt;&gt; sorted(numbers)['Fourth', 'first', 'second', 'third'] 结果有点差强人意,因为默认sorted函数是根据字母的顺序升序排列的,这里的字典中 key 恰好是字母，所以才会显示这个结果。 根据value对字典排序用同样的方法,我们可以根据value来排序 12&gt;&gt;&gt; sorted(numbers.values())[1, 2, 3, 4] 如何根据自定义的规则对字典排序sorted函数还有一个可选参数叫key,注意这里的key和字典的key没有关系,根据指定的key 来进行排序,实现的机制类似迭代器。来看这个例子： 12&gt;&gt;&gt; sorted(numbers,key=numbers.__getitem__)['first', 'second', 'third', 'Fourth'] 这里我们使用了字典类中内置函数__getitem__ 在遍历字典值的过程中,获取对应的值来对字典排序 关于__getitem__ 函数的详细说明，请参考官方文档。 当然我们也可以使用列表推导的方式来进行排序(实质上是转化成了列表来进行排序) 1234&gt;&gt;&gt; sorted(numbers,key=numbers.__getitem__,reverse=True)['Fourth', 'third', 'second', 'first']&gt;&gt;&gt; [value for (key,value) in sorted(numbers.items(),reverse=True)][3, 2, 1, 4] 字典的key是数字或者字母的情况下对字典排序12&gt;&gt;&gt; sorted(numbers,key=str.lower)['first', 'Fourth', 'second', 'third'] 我们定义一个新的字典 12345&gt;&gt;&gt; month = dict(one='January', two='February', three='March', four='April', five='May') 通过__getitem__方法比较 我们定义的字典month中对应的值 123&gt;&gt;&gt; numbermap = &#123;'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5&#125;&gt;&gt;&gt; sorted(month, key=numbermap.__getitem__)['one', 'two', 'three', 'four', 'five'] 同样的原理,可以使用列表推导来实现排序 12&gt;&gt;&gt; [month[i] for i in sorted(month,key=numbermap.__getitem__)]['January', 'February', 'March', 'April', 'May'] 定义一个方法来定义我们自己的排序规则1234567891011def repeats(string): # Lower the case in the string string = string.lower() # Get a set of the unique letters uniques = set(string) # Count the max occurrences of each unique letter counts = [string.count(letter) for letter in uniques] return max(counts) 根据字母小写排序 12&gt;&gt;&gt; sorted(month.values(), key=repeats, reverse=True)['February', 'January', 'March', 'April', 'May'] 使用lambda表达式排序使用lambda表达式 12&gt;&gt;&gt; sorted(month.items(),key=lambda x:x[1])[('four', 'April'), ('two', 'February'), ('one', 'January'), ('three', 'March'), ('five', 'May')] 12&gt;&gt;&gt; sorted(month.items(),key=lambda x:x[0])[('five', 'May'), ('four', 'April'), ('one', 'January'), ('three', 'March'), ('two', 'February')] 其中： lambda x:x[1] 表明根据值排序 lambda x:x[0] 表明根据键排序 以上就是python中对字典排序的一个总结,希望能帮到大家。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>dict</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript-undefined-description]]></title>
    <url>%2F2019%2F06%2F11%2Fjavascript-undefined-description%2F</url>
    <content type="text"><![CDATA[Javascript 基础拾遗之undefined先看一个例子： 123var a;console.log(a);//undefinedconsole.log(typeof(a)); //undefined javascript中的数据类型包括undefined，null,boolean,number,string,boolean六种类型(ECMAScript 2015) undefined 小结undefined 类型的意思是当前对象未定义,适用于下面几种情况 变量声明,但未赋值 对象没有赋值的属性,该属性的值为undefined 调用函数参数,但是未提供参数，该参数的值为undefined 函数没有返回值时,默认返回undefined 再看下面的例子 123456789101112131415161718//1.var i;console.log(i);//2.var o = new Object();console.log(o.p);//3.function test(a)&#123; console.log(typeof a); // undefined return a;&#125;test();//4.myfunc()function myfunc()&#123; //console.log("my function.");&#125;console.log(myfunc()); 需要区别下面这个情况,不同浏览器提示信息可能会不同(Chrome和IE测试) 12console.log(b);// Uncaught ReferenceError: b is not defined 如何判断为空下面三种判断方法： 123456// 方式1if(typeof age === 'undefined')// 方式2if(age === undefined)// 方式3if(varName) //万能判断,包括boolean 参考文档火狐JavaScript教程 stackoverflow如何检查undefined]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>javaweb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Build path entry is missing /src/test/java missing问题解决]]></title>
    <url>%2F2019%2F06%2F03%2FMaven-webapp-buildpath-missing-test-folder%2F</url>
    <content type="text"><![CDATA[[问题描述]通过maven构建webapp,发现缺少java和test目录 [解决方案] project –right click –build path– config build path – libraries – double click “JRE System Library”–choose “workspace default JRE” OK 如下图所示]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>javaweb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how-to-fix-cannot-change-version-of-project-dynamic-web-module-to-3.1-in-Eclipse]]></title>
    <url>%2F2019%2F06%2F03%2Fhow-to-fix-cannot-change-version-of-project-dynamic-web-module-to-3.1-in-Eclipse%2F</url>
    <content type="text"><![CDATA[1.问题描述 试图转换Dynamic Web Module 发生如下错误: 12Cannot change version of project facet Dynamic Web Module to 3.0 One or more constraints have not been satisfied 操作步骤： 右键点击项目 选择Properties 点击Project facet 选项 更改Dynamic Web Module, 2.3 到 3.1 ,如下图 2. 解决步骤Step 1： 选择navigator 视图 Step 2: 打开org.eclipse.wst.common.project.facet.core.xml 修改jst.web 的值2.3 为 3.1 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;faceted-project&gt; &lt;fixed facet="wst.jsdt.web"/&gt; &lt;installed facet="jst.jaxrs" version="2.0"/&gt; &lt;installed facet="wst.jsdt.web" version="1.0"/&gt; &lt;installed facet="java" version="1.8"/&gt; &lt;installed facet="jst.web" version="3.1"/&gt;&lt;/faceted-project&gt; 注意 jst.web版本3.1,那么java版本必须是1.7以上才可以 Step 3: 刷新项目 鼠标右键点击项目 F5刷新项目 清理项目 点击顶部菜单栏 Project 选择Clean maven更新 鼠标右键点击项目名称 选择Maven 选择Update project 3. 问题总结没有清理项目就直接更新,缓存造成更新失败。 参考链接 how-to-fix-cannot-change-version-of-project-dynamic-web-module-to-3.1-in-Eclipse]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo建站搭建流程]]></title>
    <url>%2F2019%2F05%2F31%2Fhexo%E5%BB%BA%E7%AB%99%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[下载并安装 Visual Studio Code, 官方下载 下载并安装 Nodejs, 官方下载 12node -vnpm -v npm 镜像源修改为 淘宝NPM镜像 1npm install -g cnpm --registry=https://registry.npm.taobao.org 下载并安装 Git, 官方下载 123#配置名字和邮箱git config --global user.name &quot;test&quot;git config --global user.email &quot;test@.com&quot; 安装 Hexo, 官方文档 12cnpm install -g hexo-clihexo -v 初始化博客目录 1234cd Dhexo init blogcd blogcnpm install 启动服务器,本地预览 1hexo server Hexo 常用站点配置_config.yml 12345678910#网站标题title: test#作者昵称author: test#站点描述[签名]description: 站点描述#网站地址url: http://www.test.com#文章的链接格式permalink: :title.html 添加标签 1234#生成文件路径 source/tags/index.mdhexo new page tags#编辑index.md,添加typetype: &quot;tags&quot; 添加分类 1234#生成文件路径 source/categories/index.mdhexo new page categories#编辑index.md,添加typetype: &quot;categories&quot; 文章添加标签与分类 12345categories: - hexotags: - hexo - github 设置阅读全文 12#在文章中使用 &lt;!-- more --&gt; 手动截断 &lt;!-- more --&gt; Hexo 主题,这里选择 Next, Github地址 文档安装 Next 主题 1git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题并设置语言,站点配置 12theme: nextlanguage: zh-CN 主题常用配置,themes/next/_config.yml 12345678910111213141516171819#主题外观设定scheme: Gemini#设置菜单menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive#设置代码高亮主题highlight_theme: night eighties#添加友情链接links: test: http://www.test.com#文章自动添加版权声明post_copyright: enable: true#返回顶部按钮显示百分比sidebar: scrollpercent: true 设置RSS,安装hexo-generator-feed 1cnpm install hexo-generator-feed --save 安装hexo-generator-searchdb,添加百度/谷歌/本地 自定义站点内容搜索 1cnpm install hexo-generator-searchdb --save 启用搜索,主题配置 12local_search: enable: true 配置搜索,站点配置 12345search: path: search.xml field: post format: html limit: 7777 设置favicon.ico,将favicon.ico上传至站点根目录/source 目录下,主题配置 123favicon: small: favicon.ico medium: favicon.ico 部署Hexo至Github安装 hexo-deployer-git 1cnpm install hexo-deployer-git --save 站点配置 123deploy: type: git repo: https://github.com/github账号/github账号.github.io.git 生成并部署 1hexo d -g Github 自定义域名,由于Hexo每次部署到Github都会覆盖Github的域名配置,所以直接在Hexo配置,然后再部署,在根目录下的source目录下新建CNAME文件,无后缀名 12#自定义域名xxx.com 解析域名到 github.io,记录类型 = CNAME, 记录值 = github账号.github.io 码云新建一个项目, 路径 https://gitee.com/test/test.git Hexo 目录说明 12.deploy_git Hexo默认的.git配置文件夹public 根据source文件夹内容自动生成 进入 Hexo根目录,执行以下命令,先删除 themes/next 目录下的 .gitignore 文件 12345678910#初始化仓库git init#添加远程主机git remote add origin https://gitee.com/test/test.git#添加目录下所有文件,不包含 .gitignore 声明的文件git add .#添加更新说明git commit -m &quot;hexo first commit&quot;#推送更新到云端服务器git push -u origin master 创建 test 目录,将 Git 的内容同步到本地并安装Hexo 1234567mkdir testcd testgit initgit remote add origin https://gitee.com/test/test.gitgit fetch --allgit reset --hard origin/mastercnpm install blog 目录是A电脑, test 目录是B电脑, 更新文章后的同步操作： 12345678#A电脑修改了 test.md,添加更新说明并推送到远程仓库,使用git status查看状态会显示刚刚更改过的文件状态git commit -m &quot;update test.md&quot;git push origin mastergit status#B电脑同步更新git pull origin master#可以通过指定当前目录工作分支与远程仓库分支之间的链接关系git branch --set-upstream-to=origin/master master hexo 数据文件,通用配置文件,新建 source/_data 目录, 主题的配置可以在此目录下配置,以 Next 主题为例,在此目录下新建 next.yml, 则 next.yml 的配置会覆盖 themes/next/_config.yml 的相同配置]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python创建字典的几种方法]]></title>
    <url>%2F2019%2F05%2F28%2Fpython%E5%88%9B%E5%BB%BA%E5%AD%97%E5%85%B8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[python创建字典的几种方法1. 创建空字典123&gt;&gt;&gt; dic = &#123;&#125;&gt;&gt;&gt; type(dic)&lt;type &apos;dict&apos;&gt; 另一种形式：12temp = dict()temp[&apos;name&apos;] = &apos;xiaoming&apos; 2. 直接赋值创建123&gt;&gt;&gt; dic = &#123;&apos;spam&apos;:1, &apos;egg&apos;:2, &apos;bar&apos;:3&#125;&gt;&gt;&gt; dic&#123;&apos;bar&apos;: 3, &apos;egg&apos;: 2, &apos;spam&apos;: 1&#125; 3. 通过关键字dict和关键字参数创建123&gt;&gt;&gt; dic = dict(spam = 1, egg = 2, bar =3)&gt;&gt;&gt; dic&#123;&apos;bar&apos;: 3, &apos;egg&apos;: 2, &apos;spam&apos;: 1&#125; 4. 通过二元组列表创建1234&gt;&gt;&gt; list = [(&apos;spam&apos;, 1), (&apos;egg&apos;, 2), (&apos;bar&apos;, 3)]&gt;&gt;&gt; dic = dict(list)&gt;&gt;&gt; dic&#123;&apos;bar&apos;: 3, &apos;egg&apos;: 2, &apos;spam&apos;: 1&#125; 5. dict和zip结合创建123&gt;&gt;&gt; dic = dict(zip(&apos;abc&apos;, [1, 2, 3]))&gt;&gt;&gt; dic&#123;&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: 2&#125; 6. 通过字典推导式创建123&gt;&gt;&gt; dic = &#123;i:2*i for i in range(3)&#125;&gt;&gt;&gt; dic&#123;0: 0, 1: 2, 2: 4&#125; 7. 通过dict.fromkeys()创建123&gt;&gt;&gt; dic = dict.fromkeys(range(3), &apos;x&apos;)&gt;&gt;&gt; dic&#123;0: &apos;x&apos;, 1: &apos;x&apos;, 2: &apos;x&apos;&#125; 8. 其他1234&gt;&gt;&gt; list = [&apos;x&apos;, 1, &apos;y&apos;, 2, &apos;z&apos;, 3]&gt;&gt;&gt; dic = dict(zip(list[::2], list[1::2]))&gt;&gt;&gt; dic&#123;&apos;y&apos;: 2, &apos;x&apos;: 1, &apos;z&apos;: 3&#125;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>字典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python操作sqlite3]]></title>
    <url>%2F2019%2F05%2F28%2Fpython%E6%93%8D%E4%BD%9Csqlite3%2F</url>
    <content type="text"><![CDATA[sqlite3 简介1234567891011121314151617181920212223242526272829303132SQLite数据库是一款非常小巧的嵌入式开源数据库软件，也就是说没有独立的维护进程，所有的维护都来自于程序本身。在python中，使用sqlite3创建数据库的连接，当我们指定的数据库文件不存在的时候连接对象会自动创建数据库文件；如果数据库文件已经存在，则连接对象不会再创建数据库文件，而是直接打开该数据库文件。 连接对象可以是硬盘上面的数据库文件，也可以是建立在内存中的，在内存中的数据库 执行完任何操作后，都不需要提交事务的(commit) 创建在硬盘上面： conn = sqlite3.connect(&apos;c:\\test\\test.db&apos;) 创建在内存上面： conn = sqlite3.connect(&apos;&quot;memory:&apos;) 下面我们一硬盘上面创建数据库文件为例来具体说明： conn = sqlite3.connect(&apos;c:\\test\\hongten.db&apos;) 其中conn对象是数据库链接对象，而对于数据库链接对象来说，具有以下操作： commit() --事务提交 rollback() --事务回滚 close() --关闭一个数据库链接 cursor() --创建一个游标 cu = conn.cursor() 这样我们就创建了一个游标对象：cu 在sqlite3中，所有sql语句的执行都要在游标对象的参与下完成 对于游标对象cu，具有以下具体操作： execute() --执行一条sql语句 executemany() --执行多条sql语句 close() --游标关闭 fetchone() --从结果中取出一条记录 fetchmany() --从结果中取出多条记录 fetchall() --从结果中取出所有记录 scroll() --游标滚动 sqlite3常用操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197#!/usr/bin/env python# -*- coding: utf-8 -*-# @Date : 2019-03-14 16:10:24# @Author : Jeff.Sui (215687736@qq.com)# @Link : http://example.org# @Version : $Id$import sqlite3con = sqlite3.connect(&quot;:memory:&quot;)c = con.cursor()# Create tablec.execute(&apos;&apos;&apos;CREATE TABLE stocks (date text, trans text, symbol text, qty real, price real)&apos;&apos;&apos;)# Insert a row of datac.execute(&quot;INSERT INTO stocks VALUES (?,?,?,?,?)&quot;, (&apos;2006-03-27&apos;,&apos;BUY&apos;,&apos;RHAT&apos;,100,60.14))# Larger example that inserts many records at a timepurchases = [(&apos;2006-03-28&apos;, &apos;BUY&apos;, &apos;IBM&apos;, 1000, 45.00), (&apos;2006-04-05&apos;, &apos;BUY&apos;, &apos;MSFT&apos;, 1000, 72.00), (&apos;2006-04-06&apos;, &apos;SELL&apos;, &apos;IBM&apos;, 500, 53.00), (&apos;2006-04-07&apos;, &apos;SELL&apos;, &apos;MSFT&apos;, 500, 74.00), (&apos;2006-04-08&apos;, &apos;SELL&apos;, &apos;IBM&apos;, 500, 54.00), (&apos;2006-04-09&apos;, &apos;SELL&apos;, &apos;MSFT&apos;, 500, 73.00), (&apos;2006-04-10&apos;, &apos;SELL&apos;, &apos;MSFT&apos;, 500, 75.00), (&apos;2006-04-12&apos;, &apos;SELL&apos;, &apos;IBM&apos;, 500, 55.00), ]c.executemany(&apos;INSERT INTO stocks VALUES (?,?,?,?,?)&apos;, purchases)# Save (commit) the changescon.commit()# Do this insteadt = (&apos;RHAT&apos;,)c.execute(&apos;SELECT * FROM stocks WHERE symbol=?&apos;, t)#print(c.fetchone())#for row in c.execute(&apos;SELECT * FROM stocks ORDER BY price&apos;):# print(row) #for row in c.execute(&apos;SELECT * FROM stocks LIMIT 5 OFFSET 0&apos;):# print(row)for row in c.execute(&apos;SELECT * FROM stocks LIMIT 5 OFFSET 1&apos;): print(row)#Select Top N * From# ====================================================================================# SQLite 日期 &amp; 时间# ====================================================================================print(&apos;=&apos;*30)print(&apos;SQLite 日期 &amp; 时间&apos;)print(&apos;=&apos;*30)# 计算当前日期c.execute(&quot;SELECT date(&apos;now&apos;)&quot;)print(c.fetchone())# 计算当前月份的最后一天：c.execute(&quot;SELECT date(&apos;now&apos;,&apos;start of month&apos;,&apos;+1 month&apos;,&apos;-1 day&apos;);&quot;)print(c.fetchone())# 计算给定 UNIX 时间戳 1092941466 的日期和时间：c.execute(&quot;SELECT datetime(1092941466, &apos;unixepoch&apos;);&quot;)print(c.fetchone())# 计算给定 UNIX 时间戳 1092941466 相对本地时区的日期和时间：c.execute(&quot;SELECT datetime(1092941466, &apos;unixepoch&apos;, &apos;localtime&apos;);&quot;)print(c.fetchone())# 计算当前的 UNIX 时间戳：c.execute(&quot;SELECT datetime(1092941466, &apos;unixepoch&apos;, &apos;localtime&apos;);&quot;)print(c.fetchone())# 计算美国&quot;独立宣言&quot;签署以来的天数：c.execute(&quot;SELECT julianday(&apos;now&apos;) - julianday(&apos;1776-07-04&apos;);&quot;)print(c.fetchone())# 计算从 2004 年某一特定时刻以来的秒数：c.execute(&quot;SELECT strftime(&apos;%s&apos;,&apos;now&apos;) - strftime(&apos;%s&apos;,&apos;2004-01-01 02:34:56&apos;);&quot;)print(c.fetchone())# 计算当年 10 月的第一个星期二的日期：c.execute(&quot;SELECT date(&apos;now&apos;,&apos;start of year&apos;,&apos;+9 months&apos;,&apos;weekday 2&apos;);&quot;)print(c.fetchone())# 计算从 UNIX 纪元算起的以秒为单位的时间（类似 strftime(&apos;%s&apos;,&apos;now&apos;) ，不同的是这里有包括小数部分）：c.execute(&quot;SELECT (julianday(&apos;now&apos;) - 2440587.5)*86400.0;&quot;)print(c.fetchone())# 在 UTC 与本地时间值之间进行转换，当格式化日期时，使用 utc 或 localtime 修饰符，如下所示：c.execute(&quot;SELECT time(&apos;12:00&apos;, &apos;localtime&apos;);&quot;)print(c.fetchone())# c.execute(&quot;SELECT time(&apos;12:00&apos;, &apos;utc&apos;);&quot;)print(c.fetchone())con.close()# ====================================================================================# SQLite 常用函数# ====================================================================================print(&apos;=&apos;*30)print(&apos;SQLite 常用函数&apos;)print(&apos;=&apos;*30)con = sqlite3.connect(&quot;:memory:&quot;)c = con.cursor()# Create tablec.execute(&apos;&apos;&apos;CREATE TABLE COMPANY (ID integer, NAME text, AGE integer, ADDRESS text, SALARY real)&apos;&apos;&apos;)# Larger example that inserts many records at a timepurchases = [(1,&apos;Paul&apos;,32,&apos;California&apos;,20000.0), (2,&apos;Allen&apos;,25,&apos;Texas&apos;,15000.0), (3,&apos;Teddy&apos;,23,&apos;Norway&apos;,20000.0), (4,&apos;Mark&apos;,25,&apos;Rich-Mond&apos;,65000.0), (5,&apos;David&apos;,27,&apos;Texas&apos;,85000.0), (6,&apos;Kim&apos;,22,&apos;South-Hall&apos;,45000.0), (7,&apos;James&apos;,24,&apos;Houston&apos;,10000.0)]c.executemany(&apos;INSERT INTO COMPANY VALUES (?,?,?,?,?)&apos;, purchases)# Save (commit) the changescon.commit()# 返回数据库表最后 n 行记录# 先计算一个数据库表中的行数c.execute(&quot;SELECT count(*) FROM COMPANY;&quot;)last = c.fetchone()[0]n = 5c.execute(&quot;SELECT * FROM COMPANY LIMIT ? OFFSET ?;&quot;, (n, last-n))for row in c: print(row)# 计算一个数据库表中的行数c.execute(&quot;SELECT count(*) FROM COMPANY;&quot;)print(c.fetchone())# 选择某列的最大值c.execute(&quot;SELECT max(salary) FROM COMPANY;&quot;)print(c.fetchone())# 选择某列的最小值c.execute(&quot;SELECT min(salary) FROM COMPANY;&quot;)print(c.fetchone())# 计算某列的平均值c.execute(&quot;SELECT avg(salary) FROM COMPANY;&quot;)print(c.fetchone())# 为一个数值列计算总和c.execute(&quot;SELECT sum(salary) FROM COMPANY;&quot;)print(c.fetchone())# 返回一个介于 -9223372036854775808 和 +9223372036854775807 之间的伪随机整数c.execute(&quot;SELECT random() AS Random;&quot;)print(c.fetchone())# 返回数值参数的绝对值c.execute(&quot;SELECT abs(5), abs(-15), abs(NULL), abs(0), abs(&apos;ABC&apos;);&quot;)print(c.fetchone())# 把字符串转换为大写字母c.execute(&quot;SELECT upper(name) FROM COMPANY;&quot;)print(c.fetchone())# 把字符串转换为小写字母c.execute(&quot;SELECT lower(name) FROM COMPANY;&quot;)print(c.fetchone())# 返回字符串的长度c.execute(&quot;SELECT name, length(name) FROM COMPANY;&quot;)print(c.fetchone())# 返回 SQLite 库的版本c.execute(&quot;SELECT sqlite_version() AS &apos;SQLite Version&apos;;&quot;)print(c.fetchone())# c.execute(&quot;SELECT CURRENT_TIMESTAMP;&quot;)print(c.fetchone())]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>sqlite3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium元素操作封装]]></title>
    <url>%2F2019%2F05%2F28%2Fselenium%E5%85%83%E7%B4%A0%E6%93%8D%E4%BD%9C%E5%B0%81%E8%A3%85%2F</url>
    <content type="text"><![CDATA[selenium 常用的元素定位操作Selenium提供了8种定位方式。 id name class name tag name link text partial link text xpath css selector 这8种定位方式在Python selenium中所对应的方法为： find_element_by_id() find_element_by_name() find_element_by_class_name() find_element_by_tag_name() find_element_by_link_text() find_element_by_partial_link_text() find_element_by_xpath() find_element_by_css_selector() 常用元素定位封装12345678910111213141516171819202122232425262728293031323334def _locate_element(self, selector): """ to locate element by selector :arg selector should be passed by an example with "i,xxx" "x,//*[@id='langs']/button" :returns DOM element """ if self.by_char not in selector: return self.base_driver.find_element_by_id(selector) selector_by = selector.split(self.by_char)[0].strip() selector_value = selector.split(self.by_char)[1].strip() if selector_by == "i" or selector_by == 'id': element = self.base_driver.find_element_by_id(selector_value) elif selector_by == "n" or selector_by == 'name': element = self.base_driver.find_element_by_name(selector_value) elif selector_by == "c" or selector_by == 'class_name': element = self.base_driver.find_element_by_class_name(selector_value) elif selector_by == "l" or selector_by == 'link_text': element = self.base_driver.find_element_by_link_text(selector_value) elif selector_by == "p" or selector_by == 'partial_link_text': element = self.base_driver.find_element_by_partial_link_text(selector_value) elif selector_by == "t" or selector_by == 'tag_name': element = self.base_driver.find_element_by_tag_name(selector_value) elif selector_by == "x" or selector_by == 'xpath': element = self.base_driver.find_element_by_xpath(selector_value) elif selector_by == "s" or selector_by == 'css_selector': element = self.base_driver.find_element_by_css_selector(selector_value) else: raise NameError("Please enter a valid type of targeting elements.") return element]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>web test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用selenium访问爱奇艺网站]]></title>
    <url>%2F2019%2F05%2F28%2Fusing-selenium-visit-iqiyi-website%2F</url>
    <content type="text"><![CDATA[使用selenium访问爱奇艺网站 selenium 是一种常用的自动化测试工具。它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器，如果你在这些浏览器里面安装一个 Selenium 的插件，还可以通过录制，快速生成脚本。 selenium 支持多种主流的开发语言，比如Ruby，java，python，javascript。 环境搭建python3.7.3 运行 pip install selenium 就可以直接下载最新的selenium版本 准备浏览器:chrome 70.0.3538.77 操作系统：win7 selenium版本: 3.14.1 chromedriver: https://npm.taobao.org/mirrors/chromedriver/70.0.3538.97/ 使用selenium 打开和关闭浏览器1234from selenium import webdriverdriver = webdriver.Chrome()driver.get("http://www.iqiyi.com/")driver.quit() 定位搜索框12search_xpath=r"//*[@id='nav_searchboxIn']/input"driver.find_element_by_xpath(search_xpath).send_keys("复仇者联盟") 点击搜索图片12search_button=r"//*[@id='nav_searchboxOut']/span"driver.find_element_by_xpath(search_button).click() 切换tab页123456789101112131415#导入键盘操作--20190528更新from selenium.webdriver.common.keys import Keys#此处通过键盘操作切换tab页driver.find_element_by_tag_name("body").send_keys(Keys.CONTROL + "t")#all_handles 保存所有已经打开的tab窗体all_handles = driver.window_handlesprint(driver.window_handles)index_handle=driver.current_window_handleprint(index_handle)#用switch_to方法切换到tab窗体for handle in all_handles: if handle!=index_handle: print('now is search window') search_handle = handledriver.switch_to.window(search_handle) 打印页面的title，并截图12print(driver.title)driver.get_screenshot_as_file("aqiyi.png") 总结本文主要介绍了自动化工具selenium的基本使用，如何对页面元素进行基本操作，实现自动抓取关键字图片功能。]]></content>
      <categories>
        <category>自动化测试</category>
      </categories>
      <tags>
        <tag>selenium</tag>
        <tag>web test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[copy maven dependencies to a folder]]></title>
    <url>%2F2016%2F09%2F30%2Fcopy-maven-dependencies-to-a-folder%2F</url>
    <content type="text"><![CDATA[copy maven dependencies to a folderbackground一个简单的需求,当你的同事需要调试代码的时候,他并不想建立maven环境,这时候依赖的jar包 该如何导出呢? no code say nothing这时候你需要的是maven-dependency-plugin。 添加依赖配置123456789101112131415161718192021222324252627282930313233&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt; &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;lifecycleMappingMetadata&gt; &lt;pluginExecutions&gt; &lt;!-- copy-dependency plugin --&gt; &lt;pluginExecution&gt; &lt;pluginExecutionFilter&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;versionRange&gt;[1.0.0,)&lt;/versionRange&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/alternateLocation&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;false&lt;/overWriteSnapshots&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/pluginExecutionFilter&gt; &lt;action&gt; &lt;ignore /&gt; &lt;/action&gt; &lt;/pluginExecution&gt; &lt;/pluginExecutions&gt; &lt;/lifecycleMappingMetadata&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; 此处的&lt;outputDirectory&gt; 指定了你导出jar包的路径. 执行命令 mvn dependency:copy-dependencies查看项目多了一个/alternateLocation目录,并且依赖的jar包都下载到这个目录下了。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to use nginx on windows]]></title>
    <url>%2F2016%2F09%2F27%2Fhow-to-use-nginx-on-windows%2F</url>
    <content type="text"><![CDATA[how to use nginx on windows1. Download nginx lastest release from here.2. unzip to your local driver. eg: c:/apps/nginx3. start nginx12cd c:/apps/nginxstart nginx 4. monitoring nginx process12345tasklist /fi &quot;imagename eq nginx.exe&quot;Image Name PID Session Name Session# Mem Usage========================= ======== ================ =========== ============nginx.exe 11700 Console 1 10,696 Knginx.exe 1160 Console 1 11,180 K notice一个是主进程(main process),另一个是工作进程(work process).如果启动失败,请查看错误日志logs\error.log 5. visit http://localhost:80806. configuration file nginx.confreference config123456789101112131415161718error_log logs/error.log;http &#123; include mime.types; default_type application/octet-stream; server &#123; listen 8080; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; ...&#125; 7. the command list of nginx：1234nginx -s stop 快速退出nginx -s quit 优雅退出nginx -s reload 更换配置，启动新的工作进程，优雅的关闭以往的工作进程nginx -s reopen 重新打开日志文件]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how git changing author info]]></title>
    <url>%2F2016%2F09%2F22%2Fhow-git-changing-author-info%2F</url>
    <content type="text"><![CDATA[how git changing author info背景 gitlab中的统计视图是根据用户的信息统计工作量 迁移git repo中经常会遇到用户和邮箱不一致的情况 解决思路那么如何修改已经推送到远程的author信息呢? github 官方提供的建议如何变更用户信息 同时也有类似的项托管在github上，git-tips-blame-someone-else 思路基本一致,就是替换提交记录、分支、标签里的author信息。 方案1.打开终端或命令行(git bash)2.创建一个你项目的全新裸库12git clone --bare https://github.com/user/repo.gitcd repo.git 3.复制粘贴脚本,并根据你的信息修改下面的变量:123OLD_EMAILCORRECT_NAMECORRECT_EMAIL 脚本replace.sh12345678910111213141516171819#!/bin/shgit filter-branch --env-filter &apos;OLD_EMAIL=&quot;your-old-email@example.com&quot;CORRECT_NAME=&quot;Your Correct Name&quot;CORRECT_EMAIL=&quot;your-correct-email@example.com&quot;if [ &quot;$GIT_COMMITTER_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]then export GIT_COMMITTER_NAME=&quot;$CORRECT_NAME&quot; export GIT_COMMITTER_EMAIL=&quot;$CORRECT_EMAIL&quot;fiif [ &quot;$GIT_AUTHOR_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]then export GIT_AUTHOR_NAME=&quot;$CORRECT_NAME&quot; export GIT_AUTHOR_EMAIL=&quot;$CORRECT_EMAIL&quot;fi&apos; --tag-name-filter cat -- --branches --tags 4.执行这个脚本sh replace.sh 5.察看Git历史有没有错误git log 6.强制推送到远程git push --force --tags origin &#39;refs/heads/*&#39; 7.清除repo.git仓库12cd ..rm -rf repo.git]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to understand git detached HEAD]]></title>
    <url>%2F2016%2F08%2F08%2Fhow-to-understand-git-detached-HEAD%2F</url>
    <content type="text"><![CDATA[场景远程有一个develop分支，我想获取到本地,但是clone该项目的时候这个远程分支还没有创建,于是执行 git checkout commit_id(develop) 提示如下 1234567891011121314$ git checkout f7c774bChecking out files: 100% (357/357), done.Note: checking out &apos;f7c774b&apos;.You are in &apos;detached HEAD&apos; state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -b with the checkout command again. Example: git checkout -b new_branch_nameHEAD is now at f7c774b... update jeffsui.github.io 出现 detached from ...此时用git branch -av察看分支1234567$ git branch -av* (detached from f7c774b) f7c774b update jeffsui.github.io master 6ce1857 Site updated: 2016-08-07 22:09:10 remotes/origin/HEAD -&gt; origin/master remotes/origin/develop f7c774b update jeffsui.github.io remotes/origin/gh-pages 1eee93f Site updated: 2016-02-13 21:03:46 remotes/origin/master 6ce1857 Site updated: 2016-08-07 22:09:10 所谓的 detached HEAD 其实就是HEAD指向的是一个commit而不指向任何一个branch的临时分支,翻译过来就是游离. 众所周知,每一个分支都对应了一个commit,git checkout其实就是修改HEAD文件内容,让它指向不同的分支. 如何让detached HEAD所处分支指向远程分支此时的分支你可以执行commit操作,但是无法push到远程分支。那么我们如何把游离状态的分支指向我们指定的远程分支呢。123$ git fetch origin develop:developFrom https://github.com/jeffsui/jeffsui.github.io * [new branch] develop -&gt; develop 继续执行git branch -av 命令查看分支 12345678$ git branch -av* (detached from f7c774b) f7c774b update jeffsui.github.io develop f7c774b update jeffsui.github.io master 6ce1857 Site updated: 2016-08-07 22:09:10 remotes/origin/HEAD -&gt; origin/master remotes/origin/develop f7c774b update jeffsui.github.io remotes/origin/gh-pages 1eee93f Site updated: 2016-02-13 21:03:46 remotes/origin/master 6ce1857 Site updated: 2016-08-07 22:09:10 此时我们发现多了一个develop分支指向了远程develop 分支，这样我们就可以通过命令git push origin develop:develop到远程分支了。 更简洁的方法git fetch origin develop:develop or git checkount -b origin develop:develop 这样可以直接获取远程分支并创建一个本地分支。]]></content>
      <tags>
        <tag>git</tag>
        <tag>版本管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my-angle]]></title>
    <url>%2F2016%2F02%2F15%2Fmy-angle%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>photo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows-mongodb-install]]></title>
    <url>%2F2016%2F02%2F13%2Fwindows-mongodb-install%2F</url>
    <content type="text"><![CDATA[windows下mongodb安装下载mongodbhttp://www.mongodb.org/downloads 选择自定义安装本机路径为:d:\tools\mongodb 建立如下文件目录数据库路径:d:\tools\mongodb\db日志路径:d:\tools\mongodb\log配置文件目录d:\tools\mongodb\etc建立配置文件d:\tools\mongodb\etc\mongodb.conf 123456dbpath=d:\tools\mongodb\db #数据库路径logpath=d:\tools\mongodb\log\mongodb.log #日志输出文件路径logappend=true #错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件journal=true #启用日志文件，默认启用quiet=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为falseport=27017 #端口号 默认为27017 启动服务切换到d:\tools\mongodb\bin 目录下: 普通启动 mongod --config d:\tools\mongodb\etc\mongodb.conf 注册为windows服务 mongod --config d:\tools\mongodb\etc\mongodb.conf --install 补充 windows服务卸载 mongod --remove --serviceName &quot;MongoDB&quot; 启动服务net start mongodb 启动成功后,通过浏览器访问 http://localhost:27017 ,看到下面的文字,证明启动服务成功！ It looks like you are trying to access MongoDB over HTTP on the native driver port. 关闭服务net stop mongodb 图形化工具官方提供的很全:https://docs.mongodb.org/ecosystem/tools/administration-interfaces/ mongo express –Nodejs MongoBooster UMongo MongoHub MongoVUE –.NET]]></content>
      <categories>
        <category>db</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven3-jdk1.7-problem-fixed]]></title>
    <url>%2F2016%2F02%2F13%2Fmaven3-jdk1-7-problem-fixed%2F</url>
    <content type="text"><![CDATA[maven3下jdk1.7编译错误解决环境12345678Apache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T19:57:37+08:00)Maven home: d:\tools\apache-maven-3.3.3Java version: 1.7.0_45, vendor: Oracle CorporationJava home: c:\Program Files\Java\jdk1.7.0_45\jreDefault locale: zh_CN, platform encoding: GBKOS name: "windows 7", version: "6.1", arch: "amd64", family: "windows" 使用maven命令行创建java项目1mvn archetype:generate -DgroupId=org.linfeng -DartifactId=mavendemo -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 创建成功 12$ cd mavendemo &amp;&amp; lspom.xml src pom.xml 123456789101112131415161718&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.linfeng&lt;/groupId&gt; &lt;artifactId&gt;mavendemo&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;mavendemo&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 执行maven命令 mvn test 错误信息 12[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mavendemo: Compilation failure[ERROR] No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK? 解决方案 修改settings.xml,添加jdk1.7相关内容 123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.7&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.7&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.7&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 缺点:修改所有项目的jre环境 修改当前项目的pom.xml 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 重新执行mvn build 成功！ 问题分析Maven官方文档有如下描述： 编译器插件用来编译项目的源文件.从3.0版本开始, 用来编译Java源文件的默认编译器是javax.tools.JavaCompiler (如果你是用的是java 1.6) . 如果你想强制性的让插件使用javac,你必须配置插件选项 forceJavacCompilerUse.同时需要注意的是目前source选项和target 选项的默认设置都是1.5, 与运行Maven时的JDK版本无关.如果你想要改变这些默认设置, 可以参考 Setting the -source and -target of the Java Compiler中的描述来设置 source 和target 选项. #参考资料 http://stackoverflow.com/questions/15220392/maven-package-compilation-error http://www.cnblogs.com/leo100w/p/4017647.html]]></content>
      <categories>
        <category>ci</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>jdk</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how make cygwin multi-color]]></title>
    <url>%2F2015%2F08%2F12%2Fhow-make-cygwin-multi-color%2F</url>
    <content type="text"><![CDATA[打开.bashrc123456789101112131415161718# Default to human readable figures# alias df=&apos;df -h&apos;# alias du=&apos;du -h&apos;## Misc # alias less=&apos;less -r&apos; # raw control characters# alias whence=&apos;type -a&apos; # where, of a sort# alias grep=&apos;grep --color&apos; # show differences in colour# alias egrep=&apos;egrep --color=auto&apos; # show differences in colour# alias fgrep=&apos;fgrep --color=auto&apos; # show differences in colour## Some shortcuts for different directory listings# alias ls=&apos;ls -hF --color=tty&apos; # classify files in colour# alias dir=&apos;ls --color=auto --format=vertical&apos;# alias vdir=&apos;ls --color=auto --format=long&apos;# alias ll=&apos;ls -l&apos; # long list# alias la=&apos;ls -A&apos; # all but . and ..# alias l=&apos;ls -CF&apos; # 而我们要做的只是去掉#，启动即可：123456789101112131415161718# Default to human readable figuresalias df=&apos;df -h&apos;alias du=&apos;du -h&apos;## Misc alias less=&apos;less -r&apos; # raw control charactersalias whence=&apos;type -a&apos; # where, of a sortalias grep=&apos;grep --color&apos; # show differences in colouralias egrep=&apos;egrep --color=auto&apos; # show differences in colouralias fgrep=&apos;fgrep --color=auto&apos; # show differences in colour## Some shortcuts for different directory listingsalias ls=&apos;ls -hF --color=tty&apos; # classify files in colouralias dir=&apos;ls --color=auto --format=vertical&apos;alias vdir=&apos;ls --color=auto --format=long&apos;alias ll=&apos;ls -l&apos; # long listalias la=&apos;ls -A&apos; # all but . and ..alias l=&apos;ls -CF&apos; # 然后保存一下，再重启cygwin（或者直接用：source ~/.bashrc）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>cygwin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to build a private docker registry]]></title>
    <url>%2F2015%2F07%2F21%2Fhow-to-build-a-private-docker-registry%2F</url>
    <content type="text"><![CDATA[如何搭建docker私服##环境准备 软件包： centos6.5_x86_64 docker-engine-1.7.0-1.el6.x86_64.rpm docker环境搭建,请参照官方说明，本文采用的是官方的rpm包 ##何谓私服 官方的image镜像站位dockerhub,因为伟大的墙的缘故,所以下载镜像是很痛苦的一件事。当然你可以采用其他科学上网或者镜像加速的方法来获取image。docker官方也提供了一个私服镜像,大家可以通过docker search registry来查找该镜像。 12345NAME DESCRIPTION STARS OFFICIAL AUTOMATEDregistry Containerized docker registry 320 [OK] atcol/docker-registry-ui A web UI for easy private/local Docker Reg... 55 [OK]konradkleine/docker-registry-frontend Browse and modify your Docker registry in ... 40 [OK]samalba/docker-registry 35 ##下载官方registry镜像 下载镜像 使用命令docker pull registry执行下载镜像。 查看镜像 下载完毕后,通过docker images 查看该镜像。 给镜像打标签 执行这个命令docker tag registry:latest localhost:5000/registry:latest ##启动镜像 docker run -d -e SETTINGS_FLAVOR=dev -e STORAGE_PATH=/tmp/registry -v /opt/data/registry:/tmp/registry -p 5000:5000 registry 这里有几个参数说明下: 1.-e STORAGE_PATH=/tmp/registry :强制使用存储路径 2.-v /opt/data/registry:/tmp/registry :绑定本地镜像存储路径 3.-p 5000:5000:映射容器5000端口到本地5000端口 ##查看镜像状态 docker ps ##查看私服状态 curl http://localhost:5000 显示如下信息,证明registry启动成功: &quot;\&quot;docker-registry server\&quot;&quot; ##推送本地镜像库到registry私服 ###1. 第一步 给本地镜像 打tag例如给官方的nginx镜像打tag,执行下面的命令行docker pull nginxdocker tag nginx:latest localhost:5000/nginx:latest查看镜像库,发现localhost:5000/nginx的镜像已经有了。 ###2. 第二步 推送tag到registry私服 docker push localhost:5000/nginx:latest ###3. 第三步 查看私服镜像列表 curl http://localhost：5000/V1/search 看到类似这样的信息 12&#123;&quot;num_results&quot;: 5, &quot;query&quot;: &quot;&quot;, &quot;results&quot;: [&#123;&quot;description&quot;: null, &quot;name&quot;: &quot;correl/erlang&quot;&#125;, &#123;&quot;description&quot;: null, &quot;name&quot;: &quot;linfeng/cmd&quot;&#125;, &#123;&quot;description&quot;: null, &quot;name&quot;: &quot;library/my_nodejs_image&quot;&#125;, &#123;&quot;description&quot;: null, &quot;name&quot;: &quot;library/centos&quot;&#125;, &#123;&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/nginx&quot;&#125;]&#125; ##拉取私服镜像 docker pull 192.168.20.85:5000/library/centos:7 ##结论 这只是演示如何搭建一个简单的registry私服。因为只有通过命令行方式才能查看私服信息,所以不是很便于操作。下面的博文将演示如何给registry添加web界面。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
        <tag>registry-ui</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to build a private docker registry]]></title>
    <url>%2F2015%2F07%2F21%2Fhow-to-build-a-private-docker-registry%2F</url>
    <content type="text"><![CDATA[如何搭建docker私服环境准备软件包： centos6.5_x86_64 docker-engine-1.7.0-1.el6.x86_64.rpm docker环境搭建,请参照官方说明，本文采用的是官方的rpm包 何谓私服官方的image镜像站位dockerhub,因为伟大的墙的缘故,所以下载镜像是很痛苦的一件事。当然你可以采用其他科学上网或者镜像加速的方法来获取image。docker官方也提供了一个私服镜像,大家可以通过docker search registry来查找该镜像。 12345NAME DESCRIPTION STARS OFFICIAL AUTOMATEDregistry Containerized docker registry 320 [OK] atcol/docker-registry-ui A web UI for easy private/local Docker Reg... 55 [OK]konradkleine/docker-registry-frontend Browse and modify your Docker registry in ... 40 [OK]samalba/docker-registry 35 下载官方registry镜像 下载镜像 使用命令docker pull registry执行下载镜像。 查看镜像 下载完毕后,通过docker images 查看该镜像。 给镜像打标签 执行这个命令 1docker tag registry:latest localhost:5000/registry:latest 启动镜像1docker run -d -e SETTINGS_FLAVOR=dev -e STORAGE_PATH=/tmp/registry -v /opt/data/registry:/tmp/registry -p 5000:5000 registry 这里有几个参数说明下: 1.-e STORAGE_PATH=/tmp/registry :强制使用存储路径 2.-v /opt/data/registry:/tmp/registry :绑定本地镜像存储路径 3.-p 5000:5000:映射容器5000端口到本地5000端口 查看镜像状态docker ps 查看私服状态curl http://localhost:5000 显示如下信息,证明registry启动成功: &quot;\&quot;docker-registry server\&quot;&quot; 推送本地镜像库到registry私服1. 第一步 给本地镜像 打tag例如给官方的nginx镜像打tag,执行下面的命令行 docker pull nginx docker tag nginx:latest localhost:5000/nginx:latest 查看镜像库,发现localhost:5000/nginx的镜像已经有了。 2. 第二步 推送tag到registry私服docker push localhost:5000/nginx:latest 3. 第三步 查看私服镜像列表curl http://localhost：5000/V1/search 看到类似这样的信息 12&#123;"num_results": 5, "query": "", "results": [&#123;"description": null, "name": "correl/erlang"&#125;, &#123;"description": null, "name": "linfeng/cmd"&#125;, &#123;"description": null, "name": "library/my_nodejs_image"&#125;, &#123;"description": null, "name": "library/centos"&#125;, &#123;"description": "", "name": "library/nginx"&#125;]&#125; 拉取私服镜像1docker pull 192.168.20.85:5000/library/centos:7 结论这只是演示如何搭建一个简单的registry私服。因为只有通过命令行方式才能查看私服信息,所以不是很便于操作。下面的博文将演示如何给registry添加web界面。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
        <tag>registry-ui</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how git version rollback]]></title>
    <url>%2F2015%2F05%2F16%2Fhow-git-version-rollback%2F</url>
    <content type="text"><![CDATA[Git如何进行远程版本回退……引言 一切都要从一个蛋疼的需求开始,老板说,能给远程仓库的版本回退吗？我说为毛？他说我就是试试看git好使不,我…… 咋搞 背景 gitcafe 国内知名的源码托管平台 分析 12345678910111213141、git checkout the_branch2、git pull3、git branch the_branch_backup //备份一下这个分支当前的情况4、git reset --hard the_commit_id //把the_branch本地回滚到the_commit_id5、git push origin :the_branch //删除远程 the_branch6、git push origin the_branch //用回滚后的本地分支重新建立远程分支7、git push origin :the_branch_backup //如果前面都成功了，删除这个备份分支 删除远程分支 首先,任何一个git源码托管平台都会告诉你,别删除远程master分支,因为它是默认的分支……,请移步这里 操作步骤 如果远程只有一个master分支,请你创建一个非master分支,然后推送到远程。有人会问我为什么？打个比方,你见过上旱厕的时候,给自己脚下站着的板子抽走吗？ 脚本类似下面这样 1234git branch the_master_backupgit push origin the_master_backup 此时你查看远程分支应该有两个:master和the_master_backup 设置默认的分支为 the_master_backup 1234git branch -D branch_name //删除本地master分支git push :master //推送一个空分支,相当于删除远程master分支 然后你在the_master_backup分支上 回滚到你要回滚的commit_id,然后重建master分支并推送到远程,顺便删除the_master_backup分支(包括远程the_master_backup分支)。 123456789101112git checkout the_master_backupgit reset --hard commit_idgit branch master //重新创建master分支git push origin master //重新推送master分支git branch -D the_master_backup //删除本地the_master_backup分支git push origin :the_master_backup//删除远程the_master_backup分支 遇到的问题 忘记设置默认分支为非master分支 1234567891011121314remote: error: By default, deleting the current branch is denied, because the nextremote: error: &apos;git clone&apos; won&apos;t result in any file checked out, causing confusion.remote: error:remote: error: You can set &apos;receive.denyDeleteCurrent&apos; configuration variable toremote: error: &apos;warn&apos; or &apos;ignore&apos; in the remote repository to allow deleting theremote: error: current branch, with or without a warning message.remote: error:remote: error: To squelch this message, you can set it to &apos;refuse&apos;.... 总结如果你遇到的是所有提交只有master分支,那么希望我这个博文能帮到你。当然git强大的分支功能你基本也用不到了。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitcafe</tag>
        <tag>版本管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript oop 15 min programming]]></title>
    <url>%2F2015%2F04%2F23%2Fjavascript-oop-15-min-programming%2F</url>
    <content type="text"><![CDATA[javascript的面向对象15分钟教程第一种面向对象的写法创建空对象12var bill =&#123;&#125;;//创建一个空对象 给对象添加属性和方法12345bill.name = "Bill Goat";bill.work = function ()&#123; console.log("programming....");&#125;; 一步完成上面的两件事1234567var bill =&#123; name : "Bill Goat"; work : function()&#123; console.log("programming....");&#125;&#125;; 访问对象和属性123console.log(bill.name);bill.work(); 方法重写12345bill.name = "Bill Goat";bill.work =function(who)&#123; console.log("programming for "+who);&#125;; 通过this关键字访问内部属性1234bill.say = function ()&#123; console.log("bill's name is"+this.name);&#125;; 对象引用123456var silly = bill;console.log(silly.name);sally.name = "Silly";console.log(silly.name);console.log(bill.name); 另一个方式引用1234567bill.name = "Bill Goat";bill.say();var sayName = bill.say();sayName;sayName(); 有意思的地方 ：全局属性123var name = "Global";bill.say(); 发现此时输出的是bill&#39;s name is Global 另一种面向对象的写法定义对象及属性12function Game()&#123;&#125;; 创建对象1var DF = new Game(); 对象属性1DF.title = "星际争霸2"; 构造方法12345678function Game (title)&#123; this.title = typeof title !== 'undifined' ? title :"";&#125;;var d3 = new Game("d3");d3.title;d3.title ="starcraft2"; this.title = typeof title !== &#39;undifined&#39; ? title :&quot;&quot;;相当于 123456if(typeof title !== "undifined"）&#123; this.title = title;&#125;else&#123; this.title = "";&#125; 创建一个方法来访问这个属性1234d3.loveTitle = function ()&#123; console.log("I love "+this.title);&#125; 更好的写法12345Game.prototype.heartIt = function ()&#123; console.log("I love "+this.title);&#125;d3.heartIt(); 下次详解javascript的原生对象模型 to be continued~~~~]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>oop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[talk about software engineering]]></title>
    <url>%2F2015%2F04%2F22%2Ftalk-about-software-engineering%2F</url>
    <content type="text"><![CDATA[关于软件工程的讨论–质量篇 那为什么软件系统的质量不容易高呢？我觉得主要原因是流程不完善。那为什么不完善？需求容易变。为什么容易变？是因为不论程序员自己，还是需求方，其实潜意识都认为自己做的东西是变更成本较低的。 试想一下，为什么没人在盖高楼盖一半变更需求？为什么没人修大桥修一半变更需求？甚至做衣服做一半的时候变更需求，理发到一半变更需求，都会被人认为是不讲理。但是在软件领域，好像这倒成了普遍现象。 因为整个软件系统的实现，都是虚拟的，看不见摸不着，并不消耗什么物料，所以从这个角度想，变起来当然是容易的。但软件系统的架构，其实也跟实体的没本质区别，变更时候要考虑很多关联因素，并不是就那么孤立的看一小块地方，当然，也会有一些不影响全局的变更。打个比方说，如果你在盖房子盖到一半，那变更外墙颜色肯定是要比变更窗户大小容易的。要是想变得太多，估计只好拆了重来。 下面的讨论更加精彩: A:其实不是流程问题，老板和甲方问题 A:甲方尤其关键 A:尼玛，要8层楼房，付2层费用 ……]]></content>
      <categories>
        <category>软件工程</category>
      </categories>
      <tags>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript asynchronous programming learning :event]]></title>
    <url>%2F2015%2F04%2F20%2Fjavascript-asynchronous-programming-learning-event%2F</url>
    <content type="text"><![CDATA[javascript异步编程读书笔记之事件机制事件的调度 异步执行 setTimeout函数的解释:给定一个回调及n毫秒的延迟,setTimeout会在n毫秒后运行该回调。 代码清单1:12345for (var i = 1; i &lt;= 3; i++) &#123; setTimeout(function()&#123; console.log(i); &#125;, 0);&#125;; 输出结果: 123444 线程阻塞代码清单2: 123456var start = new Date;setTimeout(function()&#123;var end = new Date;console.log(&apos;Time elapsed:&apos;, end - start, &apos;ms&apos;);&#125;, 500);while (new Date - start &lt; 1000) &#123;&#125;; 队列 javascript使用队列的方式来循环处理请求,这种机制被称为事件循环。]]></content>
      <categories>
        <category>javascript</category>
        <category>异步</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[use-shorturl and two-dimensional-barcodes to beautify blog]]></title>
    <url>%2F2015%2F04%2F20%2Fuse-shorturl-and-two-dimensional-barcodes-to-beautify-blog%2F</url>
    <content type="text"><![CDATA[如何使用短网址和二维码简化网站访问 短网址(shorturl) web2.0时代的潮流,借助短网址您可以用简短的网址替代原来冗长的网址，让使用者可以更容易的分享链接。这里我使用的是百度的短网址服务:http://dwz.cn/ 访问http://dwz.cn/主页 输入你的博客地址我输入http://jeffsui.github.io/pinghailinfeng_blog/ 复制短网址 二维码(two-dimensional-barcodes)微信时代,不知道二维码的基本都属于外星球人了。这里我选择的是草料二维码:http://cli.im/ 输入二维码地址 进行一些基本设置包括前景色、背景色、渐变色等等。 嵌入图片 选用你喜欢的模板 保存二维码 在线存储这里我选择国内知名的七牛云存储（七牛不免费了,我迁移到了github） 在博客中引用图片地址就可以了]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>美化</tag>
        <tag>短网址</tag>
        <tag>二维码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的新文章]]></title>
    <url>%2F2015%2F04%2F17%2Fmy-new-post%2F</url>
    <content type="text"><![CDATA[#我的新文章 这是我的第一篇在github上的博客。记录下我的工作和生活,慢慢给其他的文章都更新到这里。嬉笑怒骂也好,喜怒哀乐也罢,我就是一个俗人罢了。]]></content>
      <tags>
        <tag>杂记</tag>
        <tag>博客</tag>
        <tag>文章</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[push-hexo-to-github]]></title>
    <url>%2F2015%2F04%2F17%2Fpush-hexo-to-github%2F</url>
    <content type="text"><![CDATA[如何使用hexo在github上建立静态博客环境搭建 hexo环境搭建 请参考 hexo.io 官方站点, 强烈建议给基本操作下的内容快速浏览一遍,下面的操作是我一个一个命令敲出来的,遇到的坑也会记录下来,希望大家能少走弯路。 github上建立静态博客 github账号申请（略） 建立一个github项目 git clone 项目地址 到本地 项目初始化cd 项目名echo # hexo 实例站点 &gt;&gt; README.mdgit initgit add README.mdgit commit -m “first blood”git remote add origin 项目地址git push -u origin master github免费站点建立规则,请仔细阅读这个规则https://help.github.com/articles/user-organization-and-project-pages/ 默认github域名 默认github 分配了 一个name.github.io的域名,还有一个name.github.io/project_name的二级域名,请参照github的提示设置URL。 华丽的分割线 站点配置流程 建立站点文件夹,并站点初始化 安装hexo依赖 修改node_module/hexo-server/index.js,用于本地调试 安装hexo-git-deployer插件 修改全局配置文件_config.yml,配置deploy# Site 站点配置title: 凭海临风的测试江湖subtitle:description: 凭海临风的博客author: Jeff Suilanguage: zh-CNtimezone &lt;/code&gt;&lt;/pre&gt; # URL 站点链接## If your site is put in a subdirectory, set url as ‘http://yoursite.com/child&#39; and root as ‘/child/‘url: http://jeffsui.github.ioroot: /pinghailinfeng_blog/permalink: :year/:month/:day/:title/permalink_defaults: # Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/jeffsui/pinghailinfeng_blog.git branch : master message : 以上配置仅供参考 创建文章 执行hexo new 命令 例如:hexo new post my-first-blog 将会自动在source/_posts下创建一个my-first-blog.md的文件,使用的是scaffolds下的post.md模板 修改并保存my-first-blog.md文件 站点生成hexo g 站点部署 hexo d 如果没有报错,恭喜你已经成功推送到 项目的master分支。 创建gh-pages分支并推送到远程 git fetch origin master git checkout gh-pages git merge master git push origin gh-pages 访问http://jeffsui.github.io/pinghailinfeng_blog/ 遇到的问题 github站点的规则不熟悉,url配置浪费我2个小时。项目建立的是二级域名,所以必须要按照我说的那样配置。 本地预览有可能不加载样式,重新删除node_module下所有,执行npm install,再hexo g,hexo server -i 127.0.0.1 -s -o即可。 hexo3.0版本的git插件必须要独立安装。 其他坑,自己填吧。 总结大坑各种有,github特别多,还有伟大的墙,兄弟们,github好上,填坑需谨慎！]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>搭建</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime run slow problem]]></title>
    <url>%2F2015%2F04%2F17%2Fsublime-run-slow-problem%2F</url>
    <content type="text"><![CDATA[解决sublime Text2运行缓慢的方法今天打开sublime想写博客发现整个页面打开很慢,切换tab要等好几秒。发现了一个帖子,说GitGutter这个插件在st2下会影响切换tab速度。 于是 ctrl+shift+p调出命令,remove package,选择GitGutter,回车。重启sublime,世界都变得清静了。]]></content>
      <categories>
        <category>工具篇</category>
      </categories>
      <tags>
        <tag>sublime</tag>
        <tag>GitGutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[first-blog]]></title>
    <url>%2F2015%2F04%2F17%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[#第一个博客 ##记录使用hexo的各种填坑。]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
</search>
